# Modelos lineares {#cap7}

## Pr√©-requisitos do cap√≠tulo {-}

Pacotes e dados que ser√£o utilizados neste cap√≠tulo.

```{r}
## Pacotes
library(ecodados)
library(car)
library(ggpubr)
library(ggforce)
library(lsmeans)
library(lmtest)
library(sjPlot)
library(nlme)
library(ape)
library(fields)
library(tidyverse)
library(vegan)
library(rdist)

## Dados
CRC_PN_macho <- ecodados::teste_t_var_igual
CRC_LP_femea <- ecodados::teste_t_var_diferente
Pareado <- ecodados::teste_t_pareado
correlacao_arbustos <- ecodados::correlacao
dados_regressao <- ecodados::regressoes
dados_regressao_mul <- ecodados::regressoes
dados_anova_simples <- ecodados::anova_simples
dados_dois_fatores <- ecodados::anova_dois_fatores
dados_dois_fatores_interacao <- ecodados::anova_dois_fatores
dados_dois_fatores_interacao2 <- ecodados::anova_dois_fatores_interacao2
dados_bloco <- ecodados::anova_bloco
dados_ancova <- ecodados::ancova
data("mite")
data("mite.xy")
coords <- mite.xy
colnames(coords) <- c("long", "lat")
data("mite.env")
```

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Estat√≠sticas frequentistas como as que ser√£o abordadas neste cap√≠tulo s√£o baseadas em testes estat√≠sticos (e.g., F, t, ùõò^2^, etc.), que s√£o resultados n√∫mericos do teste e possuem um valor de probabilidade (valor de P) associado com este teste [@gotelli_primer_2012]. **O valor de P** mede a probabilidade que os valores observados ou mais extremos seriam encontrados caso a hip√≥tese nula seja verdadeira (veja Cap√≠tulo \@ref(cap2)). Ao longo do livro usaremos o crit√©rio convencional de rejeitar a hip√≥tese nula quando P \< 0.05. Contudo, sugerimos a leitura destes artigos [@white2013; @barber2014; @burnham_pvalues_2014; @murtaugh2014; @Halsey2019; @MUFF2021] que discutem as limita√ß√µes e problemas associados ao valor de P.
:::

## Teste T (de Student) para duas amostras independentes

Uma das perguntas mais comuns em estat√≠stica √© saber se h√° diferen√ßa entre as m√©dias de dois grupos ou tratamentos. Para responder a esta pergunta, William Sealy Gosset, qu√≠mico da cervejaria Guinness, desenvolveu em 1908 o Teste T que √© uma est√°tistica que segue uma distribui√ß√£o t de Student para rejeitar ou n√£o uma hip√≥tese nula de m√©dias iguais entre dois grupos.

$$t = \frac{(\bar{X}_1 - \bar{X}_2)}{\sqrt{\frac{2S^2_p}{n}}}$$

Onde:

-   $\bar{X}$<sub>1</sub> - $\bar{X}$<sub>2</sub> = diferen√ßa entre as m√©dias de duas amostras
-   S<sup>2</sup><sub>p</sub> = desvio padr√£o das amostras
-   *n* = tamanho das amostras

**Premissas do Teste t**

-   As amostras devem ser independentes
-   As unidades amostrais s√£o selecionadas aleatoriamente
-   Distribui√ß√£o normal (gaussiana) dos res√≠duos. 
-   Homogeneidade da vari√¢ncia. 

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
1. Zar [-@zar_biostatistical_2010] indica que o Teste T √© robusto mesmo com moderada viola√ß√£o da normalidade, principalmente se o tamanho amostral for alto.
2. Caso as vari√¢ncias n√£o sejam homog√™neas, isso deve ser informado na linha de comando, pois o denominador da f√≥rmula acima ser√° corrigido.
:::

**Avalia√ß√£o das premissas**

Uma das maneiras de avaliarmos as premissas de normalidade e homogeneidade da vari√¢ncia relacionadas √†s an√°lises do teste T, ANOVA e regress√µes lineares simples e m√∫ltiplas √© o uso da inspe√ß√£o gr√°fica da distribui√ß√£o dos res√≠duos (Figura \@ref(fig:fig-homo-norm)) [@zuur_protocol_2009]. A homegeneidade da vari√¢ncia utiliza um gr√°fico dos res√≠duos (eixo X) pelos valores preditos da vari√°vel resposta (eixo Y) (Figura \@ref(fig:fig-homo-norm)A). A distribui√ß√£o dos res√≠duos ser√° homog√™nea sen√£o observarmos nenhum padr√£o na distribui√ß√£o dos pontos (i.e. forma em V, U ou funil). A normalidade dos res√≠duos utiliza um gr√°fico de quantis-quantis (QQ-plots). A distribui√ß√£o dos res√≠duos ser√° normal se os pontos estiverem pr√≥ximos √† reta (Figura \@ref(fig:fig-homo-norm)B).

```{r fig-homo-norm, echo=FALSE, fig.cap="Inspe√ß√£o gr√°fica da homogeneidade da vari√¢ncia (A) e normalidade dos res√≠duos (B). Os s√≠mbolos verdes indicam que os gr√°ficos em que os res√≠duos apresentam distribui√ß√£o homog√™nea e normal, enquanto os s√≠mbolos vermelhos indicam os gr√°ficos em que os res√≠duos violam as premissas do teste."}
knitr::include_graphics(path = "img/cap07_fig01.jpg")
```

**Exemplo pr√°tico 1 - Teste T para duas amostras com vari√¢ncias iguais**

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos o comprimento rostro-cloacal (CRC em mil√≠metros) de machos de *Physalaemus nattereri* (Anura:Leptodactylidae) amostrados em diferentes esta√ß√µes do ano com armadilhas de intercepta√ß√£o e queda na Regi√£o Noroeste do Estado de S√£o Paulo [@daSilva2010].

**Pergunta**

- O CRC dos machos de *P. nattereri* √© maior na esta√ß√£o chuvosa do que na esta√ß√£o seca?

**Predi√ß√µes**

- O CRC dos machos ser√° maior na esta√ß√£o chuvosa porque h√° uma vantangem seletiva para os indiv√≠duos maiores durante a atividade reprodutiva

**Vari√°veis**

- Vari√°veis resposta e preditoras

- Data frame com os indiv√≠duos (unidade amostral) nas linhas e CRC (mm - vari√°vel resposta cont√≠nua) e esta√ß√£o (vari√°vel preditora categ√≥rica) como colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Vamos olhar os dados usando a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(CRC_PN_macho) 
```

Vamos verificar a normalidade dos res√≠duos usando o QQ-plot (Figura \@ref(fig:fig-qqplot-var-igual)).

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Optamos por manter a vers√£o padr√£o em alguns gr√°ficos utilizados nos cap√≠tulos 7 e 15, principalmente aqueles gr√°ficos que s√£o "output" de an√°lises como, por exemplo, visualiza√ß√£o de normalidade de res√≠duos, homogeneidade de vari√¢ncias, entre outros. Em geral, essese gr√°ficos s√£o usados no processo de decis√£o de algum passo da an√°lise e n√£o possuem qualidade de publica√ß√£o. Como o usu√°rio vai obter o mesmo gr√°fico quando replicar as an√°lises propostas aqui ou suas pr√≥prias an√°lises, julgamos ser mais did√°tico manter a vers√£o original, em ingl√™s.
:::

```{r fig-qqplot-var-igual, fig.cap="Normalidade dos res√≠duos usando o QQ-plot."}
## Teste de normalidade
residuos <- lm(CRC ~ Estacao, data = CRC_PN_macho)
qqPlot(residuos)
```

Os pontos est√£o pr√≥ximos √† reta, indicando que a distribui√ß√£o dos res√≠duos √© normal (\@ref(fig:fig-homo-norm)).

Outra possibilidade √© usar os testes de Shapiro-Wilk e Levene para verificar a normalidade e a homogeneidade da vari√¢ncia, respectivamente.

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
A Hip√≥tese Nula (H<sub>0</sub>) destes testes √© que a distribui√ß√£o √© normal ou homog√™nea:

-   Valor de p \< 0.05 significa que os dados **n√£o apresentam** distribui√ß√£o normal ou homog√™nea
-   Valor de p \> 0.05 significa que os dados **apresentam** distribui√ß√£o normal ou homog√™nea
:::

Teste de Shapiro-Wilk para normalidade dos res√≠duos.

```{r}
## Teste de Shapiro-Wilk
residuos_modelo <- residuals(residuos)
shapiro.test(residuos_modelo)
```

Teste de Levene para homogeneidade de vari√¢ncia dos res√≠duos.

```{r}
## Teste de homogeneidade de vari√¢ncia
leveneTest(CRC ~ as.factor(Estacao), data = CRC_PN_macho)
```

Percebam que a distribui√ß√£o dos res√≠duos foi normal e homog√™nea na inspe√ß√£o gr√°fica, assim como nos testes de Shapiro e Levene, respectivamente. Agora podemos realizar a an√°lise sabendo que os dados seguem as premissas requeridas pelo Teste T.

Vamos para os c√≥digos da an√°lise do Teste T para amostragens indenpendentes e vari√¢ncias iguais.

```{r}
## An√°lise Teste T 
t.test(CRC ~ Estacao, data = CRC_PN_macho, var.equal = TRUE)
```

Quatro valores devem ser apresentados ao leitores: i) estat√≠stica do teste - representada por **t = 4,15**, ii) valor de signific√¢ncia - representado por **p-value = 0,0001**, iii) graus de liberdade - representado por **df = 49**, e iv) diferen√ßa entre as m√©dias. Veja abaixo como descrever os resultados no seu trabalho.

Visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-test-t-ind-var-igual)).

```{r fig-test-t-ind-var-igual, fig.cap="Boxplot da an√°lise do Teste T para duas amostras com vari√¢ncias iguais."}
## Gr√°fico
ggplot(data = CRC_PN_macho, aes(x = Estacao, y = CRC, color = Estacao)) + 
    labs(x = "Esta√ß√µes", 
         y = expression(paste("CRC (mm) - ", italic("P. nattereri")))) +
    geom_boxplot(fill = c("darkorange", "cyan4"), color = "black", 
                 outlier.shape = NA) +
    geom_jitter(shape = 16, position = position_jitter(0.1), 
                cex = 5, alpha = 0.7) +
    scale_color_manual(values = c("black", "black")) +
    tema_livro() +
    theme(legend.position = "none")
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, rejeitamos a hip√≥tese nula de que as m√©dias do CRC dos machos entre as esta√ß√µes seca e chuvosa s√£o iguais. Os resultados mostram que os machos de *P. nattereri* coletados na esta√ß√£o chuvosa foram em m√©dia 0,43 mm maiores do que os machos coletados na esta√ß√£o seca (t~49~ = 4,15, P \< 0,001).

**Exemplo pr√°tico 2 - Teste T para duas amostras independentes com vari√¢ncias diferentes**

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos o comprimento rostro-cloacal (CRC - mil√≠metros) de f√™meas de *Leptodactylus podicipinus* amostradas em diferentes esta√ß√µes do ano com armadilhas de intercepta√ß√£o e queda na Regi√£o Noroeste do Estado de S√£o Paulo [@daSilva2010]. 

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Os dados foram alterados em rela√ß√£o a publica√ß√£o original para se enquadrarem no exemplo de amostras com vari√¢ncias diferentes.
:::

**Pergunta**

- O CRC das f√™meas de *L. podicipinus* √© maior na esta√ß√£o chuvosa do que na esta√ß√£o seca?

**Predi√ß√µes**

- O CRC das f√™meas ser√° maior na esta√ß√£o chuvosa porque h√° uma vantangem seletiva para os indiv√≠duos maiores durante a atividade reprodutiva

**Vari√°veis**

-   Vari√°veis resposta e preditoras

-   Data frame com os indiv√≠duos (unidade amostral) nas linhas e CRC (mm - vari√°vel resposta cont√≠nua) e esta√ß√£o (vari√°vel preditora categ√≥rica) como colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Olhar os dados usando a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(CRC_LP_femea) 
```

Vamos avaliar as premissas do teste. Comen√ßando com o teste de normalidade (Figura \@ref(fig:fig-qqplot-var-dif)).

```{r fig-qqplot-var-dif, fig.cap="Normalidade dos res√≠duos usando o QQ-plot."}
## Teste de normalidade usando QQ-plot
residuos_LP <- lm(CRC ~ Estacao, data = CRC_LP_femea)
qqPlot(residuos_LP)
```

Os res√≠duos apresentam distribui√ß√£o normal. Vamos testar tamb√©m com o Shapiro-Wilk para normalidade dos res√≠duos.

```{r}
## Teste de Shapiro-Wilk
residuos_modelo_LP <- residuals(residuos_LP)
shapiro.test(residuos_modelo_LP)
```

Agora vamos avaliar a homogeneidade da vari√¢ncia.

```{r}
## Teste de homogeneidade da vari√¢ncia
leveneTest(CRC ~ as.factor(Estacao), data = CRC_LP_femea)
```

Os res√≠duos n√£o apresentam homogeneidade da vari√¢ncia. Portanto, vamos realizar o Teste T com vari√¢ncias diferentes. Para isso, use o argumento `var.equal = FALSE`.

```{r}
## Teste T
t.test(CRC ~ Estacao, data = CRC_LP_femea, var.equal = FALSE)
```

Neste exemplo, n√£o rejeitamos a hip√≥tese nula e consideramos que as m√©dias do CRC das f√™meas entre as esta√ß√µes seca e chuvosa s√£o iguais (t~6,49~ = 1,76, P = 0,12).

Vamos visualizar os resultados em um gr√°fico (Figura \@ref(fig:fig-test-t-ind-var-dif)).

```{r fig-test-t-ind-var-dif, fig.cap="Boxplot da an√°lise do Teste T para duas amostras independentes com vari√¢ncias diferentes."}
## Gr√°fico
ggplot(data = CRC_LP_femea, aes(x = Estacao, y = CRC, color = Estacao)) + 
    geom_boxplot(fill = c("darkorange", "cyan4"), width = 0.5, 
                 color = "black", outlier.shape = NA, alpha = 0.7) +
    geom_jitter(shape = 20, position = position_jitter(0.2), color = "black", cex = 5) +
    scale_color_manual(values = c("darkorange", "cyan4")) +
    labs(x = "Esta√ß√µes", 
         y = expression(paste("CRC (mm) - ", italic("L. podicipinus"))), size = 15) +
    tema_livro() +
    theme(legend.position = "none")
```

**Interpreta√ß√£o dos resultados**

Os resultados mostram que as f√™meas de *L. podicipinus* coletadas na esta√ß√£o chuvosa n√£o s√£o maiores do que as f√™meas coletadas na esta√ß√£o seca, apesar de possuirem maior vari√¢ncia, o que pode ser biologicamente interessante.

## Teste T para amostras pareadas

O Teste T Pareado √© uma estat√≠stica que usa dados medidos duas vezes na mesma unidade amostral, resultando em pares de observa√ß√µes para cada amostra (amostras pareadas). Ele determina se a diferen√ßa da m√©dia entre duas observa√ß√µes √© zero.

$$t = \frac{\bar{d}}{S_{\bar{d}}}$$

Onde:
-   $\bar{d}$ = m√©dia da diferen√ßa das medidas pareadas. Observe que o teste n√£o usa as medidas originais, e sim, a diferen√ßa para cada par
-   S<sub>$\bar{d}$</sub> = erro padr√£o da diferen√ßa das medidas pareadas

**Premissas do Teste t para amostras pareadas**

-   As unidades amostrais s√£o selecionadas aleatoriamente
-   As observa√ß√µes **n√£o** s√£o independentes
-   Distribui√ß√£o normal (gaussiana) dos valores da diferen√ßa para cada par

**Exemplo pr√°tico 1 - Teste T para amostras pareadas**

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos a diferen√ßa na riqueza de esp√©cies de artr√≥podes registradas em 27 localidades. Todas as localidades foram amostradas duas vezes. A primeira amostragem foi realizada na localidade antes da perturba√ß√£o e a segunda amostragem foi realizada ap√≥s a localidade ter sofrido uma queimada. Portanto, existe uma depend√™ncia temporal, uma vez que amostramos a mesma localidade antes e depois da queimada.

**Pergunta**

- A riqueza de esp√©cies de artr√≥podes √© prejudicada pelas queimadas?

**Predi√ß√µes**

- A riqueza de esp√©cies de artr√≥podes ser√° maior antes da queimada devido a extin√ß√£o local das esp√©cies

**Vari√°veis**

- Vari√°veis resposta e preditoras

-   data frame com as localidades nas linhas e riqueza de esp√©cies (vari√°vel resposta cont√≠nua) e estado (Pre-queimada ou P√≥s-queimada - vari√°vel preditora categ√≥rica) da localidade nas colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Olhando os dados com a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(Pareado) 
```

C√°lculo do Teste T com amostras pareadas.

```{r}
## An√°lise Teste T Pareado

t.test(Riqueza ~ Estado, paired = TRUE, data = Pareado)
```

Neste exemplo, rejeitamos a hip√≥tese nula de que a riqueza de esp√©cies de artr√≥podes √© igual antes e depois da queimada (t~26~ = 7,57, P \< 0,001).

Podemos visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-test-t-par)).

```{r fig-test-t-par, fig.cap="Boxplot da an√°lise do Teste T para duas amostras pareadas."}
## Gr√°fico
ggpaired(Pareado, x = "Estado", y = "Riqueza",
         color = "Estado", line.color = "gray", line.size = 0.8, 
         palette = c("darkorange", "cyan4"), width = 0.5, 
         point.size = 4, xlab = "Estado das localidades", 
         ylab = "Riqueza de Esp√©cies") +
    expand_limits(y = c(0, 150)) +
    tema_livro() 
```

**Interpreta√ß√£o dos resultados**

Os resultados mostram que as localidades ap√≥s as queimadas apresentam em m√©dia 44,5 esp√©cies de artr√≥podes a menos do que antes das queimadas.

## Correla√ß√£o de Pearson

√â um teste que mede a for√ßa relativa da rela√ß√£o linear entre duas vari√°veis cont√≠nuas (X e Y). Importante ressaltar que a an√°lise de correla√ß√£o n√£o assume que a vari√°vel X influencie a vari√°vel Y, ou que exista uma rela√ß√£o de causa e efeito entre elas [@zar_biostatistical_2010]. A an√°lise √© definida em termos da vari√¢ncia de X, a vari√¢ncia de Y, e a covari√¢ncia de X e Y (i.e. como elas variam juntas).

$$r = \frac{\sum{XY} - \frac{\sum{X} \sum{Y}}{n}}{\sqrt{\left(\sum{X^2} - \frac{\sum{X}^2}{n}\right)\left(\sum{Y^2} - \frac{\sum{Y}^2}{n}\right)}}$$

Onde:

-   r = coeficiente de correla√ß√£o que indica a for√ßa da rela√ß√£o linear entre as duas vari√°veis. Seu limite de valores est√° entre -1 $\leq$ r $\le$ 1. A correla√ß√£o positiva indica que o aumento no valor de uma das vari√°veis √© acompanhado pelo aumento no valor da outra vari√°vel. A correla√ß√£o negativa indica que o aumento no valor de uma das vari√°veis √© acompanhado pela diminui√ß√£o no valor da outra vari√°vel. Se *r* √© igual a zero, n√£o existe correla√ß√£o entre as vari√°veis (Figura \@ref(fig:fig-cor)).

```{r fig-cor, echo=FALSE, fig.cap="Exemplo de correla√ß√µes negativa (A), positiva (B) e nula (C) e vari√°veis que n√£o apresentam rela√ß√µes lineares entre si (D-E)."}
knitr::include_graphics(path = "img/cap07_fig02.jpg")
```

**Premissas da Correla√ß√£o de Person**

-   As amostras devem ser independentes e pareadas (i.e. as duas vari√°veis devem ser medidas na mesma unidade amostral)
-   As unidades amostrais s√£o selecionadas aleatoriamente
-   A rela√ß√£o entre as vari√°veis tem que ser linear

**Exemplo pr√°tico 1 - Correla√ß√£o de Pearson**

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos a correla√ß√£o entre a altura do tronco e o tamanho da raiz medidos em 35 indiv√≠duos de uma esp√©cie vegetal arbustiva.

**Pergunta**

- Existe correla√ß√£o entre a altura do tronco e o tamanho da raiz dos arbustos?

**Predi√ß√µes**

- A altura do tronco √© positivamente correlacionada com o tamanho da raiz

**Vari√°veis**

-   Vari√°veis
-   data frame com os indiv√≠duos (unidade amostral) nas linhas e altura do tronco e tamanho da raiz (duas vari√°veis tem que ser cont√≠nuas) como colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Vamos olhar os dados com a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(correlacao_arbustos) 
```

C√°lculo do Teste da Correla√ß√£o de Pearson. Para outros testes de correla√ß√£o como Kendall ou Spearman √© s√≥ alterar o argumento `method` e inserir o teste desejado.

```{r}
## Correla√ß√£o de Pearson
cor.test(correlacao_arbustos$Tamanho_raiz, correlacao_arbustos$Tamanho_tronco, method = "pearson")

## Alternativamente
cor.test(~ Tamanho_tronco + Tamanho_raiz, data = correlacao_arbustos, method = "pearson")
```

Neste exemplo, rejeitamos a hip√≥tese nula de que as vari√°veis n√£o s√£o correlacionadas (r = 0.89, P \< 0,001).

Podemos visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-cor-dados)).

```{r fig-cor-dados, fig.cap="Gr√°fico mostrando a rela√ß√£o entre as vari√°veis e uma linha de tend√™ncia dos dados."}
## Gr√°fico
ggplot(data = correlacao_arbustos, aes(x = Tamanho_raiz, y = Tamanho_tronco)) + 
    labs(x = "Tamanho da raiz (m)", y = "Altura do tronco (m)") +
    geom_point(size = 4, shape = 21, fill = "darkorange", alpha = 0.7) +
    geom_text(x = 14, y = 14, label = "r = 0.89, P < 0.001", 
              color = "black", size = 5) +
    geom_smooth(method = lm, se = FALSE, color = "black", linetype = "dashed") +
    tema_livro() +
    theme(legend.position = "none")
```

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
A linha de tend√™ncia tracejada no gr√°fico √© apenas para ilustrar a rela√ß√£o positiva entre as vari√°veis. Ela n√£o √© gerada pela an√°lise de correla√ß√£o.
:::

**Interpreta√ß√£o dos resultados**

Os resultados mostram que o aumento na altura dos arbutos √© acompanhado pelo aumento no tamanho da raiz.

## Regress√£o Linear Simples

A regress√£o linear simples √© usada para analisar a rela√ß√£o entre uma vari√°vel preditora (plotada no eixo-X) e uma vari√°vel resposta (plotada no eixo-Y). As duas vari√°veis devem ser cont√≠nuas. Diferente das correla√ß√µes, a regress√£o assume uma rela√ß√£o de causa e efeito entre as vari√°veis. O valor da vari√°vel preditora (X) causa, direta ou indiretamente, o valor da vari√°vel resposta (Y). Assim, Y √© uma fun√ß√£o linear de X:

$$Y = \beta_0 + \beta_{1}X_i + \epsilon_i$$

Onde:

-   $\beta_0$ = intercepto (*intercept*) que representa o valor da fun√ß√£o quando X = 0
-   $\beta_{1}$ = inclina√ß√£o (*slope*) que mede a mudan√ßa na vari√°vel Y para cada mudan√ßa de unidade da vari√°vel X
-   $\epsilon_{1}$ = erro aleat√≥rio referente √† vari√°vel Y que n√£o pode ser explicado pela vari√°vel X

**Premissas da Regress√£o Linear Simples**

-   As amostras devem ser independentes
-   As unidades amostrais s√£o selecionadas aleatoriamente
-   Distribui√ß√£o normal (gaussiana) dos res√≠duos
-   Homogeneidade da vari√¢ncia dos res√≠duos

**Exemplo pr√°tico 1 - Regress√£o Linear Simples**

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos a rela√ß√£o entre o gradiente de temperatura m√©dia anual (¬∞C) e o tamanho m√©dio do comprimento rostro-cloacal (CRC em mm) de popula√ß√µes de *Dendropsophus minutus* (Anura:Hylidae) amostradas em 109 localidades no Brasil [@boaratti2015].

**Pergunta**

- A temperatura afeta o tamanho do CRC de popula√ß√µes de Dendropsophus minutus?

**Predi√ß√µes**

- O CRC das popula√ß√µes ser√£o menores em localidades mais quentes do que em localidades mais frias de acordo com a Hip√≥tese do Balan√ßo de Calor [@olalla-t√°rraga2007]

**Vari√°veis**

-   Vari√°veis resposta e preditoras
        
    -   Data frame com as popula√ß√µes (unidade amostral) nas linhas e CRC (vari√°vel resposta) m√©dio (mm) e temperatura m√©dia anual (vari√°vel preditora) como colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Olhando os dados com a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(dados_regressao) 
```

Vamos calcular a regress√£o linear simples.

```{r}
## regress√£o simples
modelo_regressao <- lm(CRC ~ Temperatura, data = dados_regressao)
```

Antes de vermos os resultados, vamos verificar a normalidade e homogeneidade das vari√¢ncias (Figura \@ref(fig:fig-lm-pre)).

```{r fig-lm-pre, fig.cap="Gr√°ficos mostrando as premissas da regress√£o linear simples."}
## Verificar as premissas do teste
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(modelo_regressao)
dev.off() # volta a configura√ß√£o dos gr√°ficos para o formato padr√£o 
```

Os gr√°ficos *Residuals vs Fitted*, *Scale-Location*, e *Residual vs Leverage* est√£o relacionados com a homogeneidade da vari√¢ncia. Nestes gr√°ficos, esperamos ver os pontos dispersos no espa√ßo sem padr√µes com formatos em *U* ou funil. Neste caso, vemos que as linhas vermelhas (que indicam a tend√™ncia dos dados) est√£o praticamente retas, seguindo a linha pontilhada, sugerindo que n√£o exista heterogeneidade de vari√¢ncia dos res√≠duos. O gr√°fico *Residual vs Leverage*, identifica os valores extremos que estejam a mais de uma unidade da dist√¢ncia de Cook (linha pontilhada vermelha). Quando muito discrepantes, esses valores podem influenciar os resultados dos testes estat√≠sticos. Tamb√©m n√£o temos problemas com esse pressuposto do modelo aqui. O gr√°fico *Normal Q-Q (quantile-quantile plot)* mede desvios da normalidade. Neste caso, esperamos que os pontos sigam uma linha reta (i.e. fiquem muito pr√≥ximos da linha pontilhada) e n√£o apresentem padr√µes com formatos de *S* ou arco. Podemos observar que tanto a normalidade como a homogeneidade do res√≠duos est√£o dentro dos padr√µes esperados.

Vamos ver os resultados da regress√£o simples usando as fun√ß√µes `anova()` e `summary()`. A fun√ß√£o `anova()` retorna uma tabela contendo o grau de liberdade (df), soma dos quadrados, valor de F e o valor de P.

```{r}
## Resultados usando a fun√ß√£o anova
anova(modelo_regressao)
```

A fun√ß√£o `summary()` retorna uma tabela contendo o valor do intercepto, inclina√ß√£o da reta (*slope*) e o coeficiente de determina√ß√£o (R^2^) que indica a propor√ß√£o da varia√ß√£o na vari√°vel Y que pode ser atribu√≠da √† varia√ß√£o na vari√°vel X. Percebam que a parte final dos resultados apresentados no `summary()` s√£o os mesmo apresentados pela fun√ß√£o `anova()`.

```{r}
## Resultados usando a fun√ß√£o summary
summary(modelo_regressao)
```

Vamos visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-lm)).

```{r fig-lm, fig.cap="Gr√°fico mostrando a rela√ß√£o entre as vari√°veis e modelo linear simples, representado pela linha cont√≠nua."}
## Gr√°fico
ggplot(data = dados_regressao, aes(x = Temperatura, y = CRC)) + 
    labs(x = "Temperatura m√©dia anual (¬∞C)", 
         y = "Comprimento rostro-cloacal (mm)") +
    geom_point(size = 4, shape = 21, fill = "darkorange", alpha = 0.7) +
    geom_smooth(method = lm, se = FALSE, color = "black") +
    tema_livro() +
    theme(legend.position = "none")
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, rejeitamos a hip√≥tese nula de que n√£o existe rela√ß√£o entre o tamanho do CRC das popula√ß√µes de *D. minutus* e a temperatura da localidade onde elas ocorrem (F~1,107~ = 38,92, P \< 0,001). Os resultados mostram que o tamanho do CRC das popula√ß√µes tem uma rela√ß√£o positiva com a temperatura das localidades. Assim, popula√ß√µes de *D. minutus* em localidades mais quentes apresentam maior CRC do que as popula√ß√µes em localidades mais frias. Podemos tamb√©m usar os coeficientes da regress√£o para entender como a mudan√ßa na vari√°vel preditora (temperatura) afeta o tamanho corporal m√©dio dos anuros. Neste caso, ao usar o comando `coef(modelo_regressao)`, obtemos os valores 16,23 e 0,27, respectivamente os valores do intercepto (Œ≤<sub>0</sub>) e da temperatura (Œ≤<sub>1</sub>). O valor de 0,27 indica que a mudan√ßa de uma unidade na vari√°vel preditora (neste caso, graus), aumenta em 0,27 unidades (neste caso, cent√≠metros) da vari√°vel dependente. Por exemplo, o modelo indica que o tamanho m√©dio dos indiv√≠duos em locais com temperatura de 16¬∫ C √© de 20,55 cm, ao passo que em locais com 26¬∫ C o tamanho aumenta para 23,25 cm, o que representa um ganho de 13%.

## Regress√£o Linear M√∫ltipla

A regress√£o linear m√∫ltipla √© uma extens√£o da regress√£o linear simples. Ela √© usada quando queremos determinar o valor da vari√°vel resposta (Y) com base nos valores de duas ou mais vari√°veis preditoras (X~1~, X~2~, X~*n*~).

$$Y = \beta_0 + \beta_{1}X_1 + \beta_{n}X_n + \epsilon_i$$

Onde:

-   $\beta_0$ = intercepto (*intercept*) que representa o valor da fun√ß√£o quando X = 0
-   $\beta_{n}$ = inclina√ß√£o (*slope*) que mede a mudan√ßa na vari√°vel Y para cada mudan√ßa de unidade das vari√°veis X~n~
-   $\epsilon_{1}$ = erro aleat√≥rio referente a vari√°vel Y que n√£o pode ser explicado pelas vari√°veis preditoras

**Premissas da Regress√£o Linear M√∫ltipla**

-   As amostras devem ser independentes
-   As unidades amostrais s√£o selecionadas aleatoriamente
-   Distribui√ß√£o normal (gaussiana) dos res√≠duos
-   Homogeneidade da vari√¢ncia dos res√≠duos

**Exemplo pr√°tico 1 - Regress√£o Linear M√∫ltipla**

**Explica√ß√£o dos dados**

Utilizaremos o mesmo exemplo da regress√£o linear simples. Contudo, al√©m do gradiente de temperatura m√©dia anual (¬∞C), incluiremos o gradiente de precipita√ß√£o anual (mm) como outra vari√°vel preditora do tamanho m√©dio do comprimento rostro-cloacal (CRC em mm) de popula√ß√µes de *Dendropsophus minutus* (Anura:Hylidae) amostradas em 109 localidades no Brasil [@boaratti2015].

**Pergunta**

- O tamanho do CRC das popula√ß√µes de *D. minutus* √© influ√™nciado pela temperatura e precipita√ß√£o das localidades onde os indiv√≠duos ocorrem?

**Predi√ß√µes**

- O CRC das popula√ß√µes ser√£o menores em localidades com clima quente e chuvoso do que em localidades com clima frio e seco

**Vari√°veis**

- Vari√°veis resposta e preditoras

-   data frame com as popula√ß√µes (unidade amostral) nas linhas e CRC (vari√°vel resposta) m√©dio (mm) e temperatura e precipita√ß√£o (vari√°veis preditoras) como colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Olhando os dados usando a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(dados_regressao_mul) 
```

C√≥digos para ajustar o modelo de regress√£o m√∫ltipla.

```{r}
## Regress√£o m√∫ltipla
modelo_regressao_mul <- lm(CRC ~ Temperatura + Precipitacao,
                           data = dados_regressao_mul)
```

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Multicolinearidade ocorre quando as vari√°veis preditoras s√£o correlacionadas. Essa correla√ß√£o √© um problema porque as vari√°veis preditoras deveriam ser independentes. O Fator de Infla√ß√£o da Vari√¢ncia (VIF) √© um teste que quantifica quanto do erro padr√£o dos coeficientes estimados est√£o inflados devido √† multicolinearidade. Na regress√£o m√∫ltipla, cada vari√°vel preditora tem um valor de VIF. Alguns autores consideram valores de VIF acima de 10 como fortemente correlacionadas, outros mais conservadores consideram o valor de 5, 3 ou at√© mesmo 2. Mais detalhes em @zuur_protocol_2009 e @dormann_collinearity_2013.
:::

Vamos analisar se as vari√°veis apresentam multicolinearidade.

```{r}
# Multicolinearidade
vif(modelo_regressao_mul)
```

Os valores s√£o menores que 3, indicando que n√£o h√° multicolinearidade.

Agora vamos verificar as premissas de normalidade e homogeneidade das vari√¢ncias (Figura \@ref(fig:fig-lm-multi-pre)).

```{r fig-lm-multi-pre, fig.cap="Gr√°ficos mostrando as premissas da regress√£o linear m√∫ltipla."}
## Normalidade e homogeneidade das vari√¢ncias
plot_grid(plot_model(modelo_regressao_mul , type = "diag"))
```

Os res√≠duos apresentam distribui√ß√£o normal e vari√¢ncias homog√™neas.

Podemos ver os resultados da an√°lise.

```{r}
## regress√£o m√∫ltipla
summary(modelo_regressao_mul)
```

Percebam que a temperatura tem uma rela√ß√£o significativa e positiva com o tamanho do CRC das popula√ß√µes (P \< 0.001), enquanto a precipita√ß√£o n√£o apresenta rela√ß√£o com o CRC (P = 0.27). Neste caso, √© interessante saber se um modelo mais simples (e.g. contendo apenas temperatura) explicaria a distribui√ß√£o t√£o bem ou melhor do que este modelo mais complexo considerando duas vari√°veis (temperatura e precipita√ß√£o).

Para isso, podemos utilizar a *Likelihood-ratio test (LRT)* para comparar os modelos. A LRT compara dois modelos aninhados, testando se os par√¢metros do modelo mais complexo diferem significativamente do modelo mais simples. Em outras palavras, ele testa se h√° necessidade de se incluir uma vari√°vel extra no modelo para explicar os dados.

```{r}
## Criando os modelos aninhados
modelo_regressao_mul <- lm(CRC ~ Temperatura + Precipitacao, 
                           data = dados_regressao_mul)
modelo_regressao <- lm(CRC ~ Temperatura, data = dados_regressao_mul)

## Likelihood-ratio test (LRT)
lrtest(modelo_regressao_mul, modelo_regressao)
```

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
A Hip√≥tese Nula (H<sub>0</sub>) do teste *Likelihood-ratio test (LRT)* √© de que o modelo mais simples √© o melhor.

-   Valor de p \< 0.05 rejeita a hip√≥tese nula e o modelo mais complexo √© o melhor
-   Valor de p \> 0.05 n√£o rejeita a hip√≥tese nula e o modelo mais simples √© o melhor
:::

```{r}
## Comparando com o modelo somente com o intercepto
# Criando um modelo sem vari√°veis, s√≥ o intercepto.
modelo_intercepto <- lm(CRC ~ 1, data = dados_regressao_mul)
lrtest(modelo_regressao, modelo_intercepto)
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, a precipita√ß√£o n√£o est√° associada com a varia√ß√£o no tamanho do CRC das popula√ß√µes de *D. minutus*. Por outro lado, a temperatura explicou 26% da varia√ß√£o do tamanho do CRC das popula√ß√µes.

## An√°lises de Vari√¢ncia (ANOVA)

ANOVA refere-se a uma variedade de delineamentos experimentais nos quais a vari√°vel preditora √© categ√≥rica e a vari√°vel resposta √© cont√≠nua [@gotelli_primer_2012]. Exemplos desses delineamentos experimentais s√£o: ANOVA de um fator, ANOVA de dois fatores, ANOVA em blocos aleatorizados, ANOVA de medidas repetidas e ANOVA *split-splot*. De forma geral, a ANOVA √© um teste estat√≠stico usado para comparar a m√©dia entre grupos amostrados independentemente. Para isso, o teste leva em conta, al√©m das m√©dias dos grupos, a varia√ß√£o dos dados dentro e entre os grupos. Neste cap√≠tulo, iremos demonstrar os c√≥digos para alguns dos principais delineamentos experimentais.

**Premissas da ANOVA**

-   As amostras devem ser independentes
-   As unidades amostrais s√£o selecionadas aleatoriamente
-   Distribui√ß√£o normal (gaussiana) dos res√≠duos
-   Homogeneidade da vari√¢ncia

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
ANOVA de medidas repetidas e ANOVA *split-plot* s√£o an√°lises com desenhos experimentais que apresentam depend√™ncia entre as amostras, mas controlam esse deped√™ncia nas suas formula√ß√µes matem√°ticas.
:::

### ANOVA de um fator

Este teste considera delineamentos experimentais com apenas um fator (ou tratamento) que pode ser composto por tr√™s ou mais grupos (ou n√≠veis).

**Exemplo pr√°tico 1 - Anova de um fator**

**Explica√ß√£o dos dados**

Neste exemplo hipot√©tico, avaliaremos se o adubo X-2020 disponibilizado recentemente no mercado melhora o crescimento dos indiv√≠duos de *Coffea arabica* como divulgado pela empresa respons√°vel pela venda do produto. Para isso, foi realizado um experimento com indiv√≠duos de *C. arabica* cultivados em tr√™s grupos: i) grupo controle onde os indiv√≠duos n√£o receberam aduba√ß√£o, ii) grupo onde os indiv√≠duos receberam a adi√ß√£o do adubo tradicional mais utilizado pelos produtores de *C. arabica*, e iii) grupo onde os indiv√≠duos receberam a adi√ß√£o do adubo X-2020.

**Pergunta**

- O crescimento dos indiv√≠duos de *C. arabica* √© melhorado pela adi√ß√£o do adubo X-2020?

**Predi√ß√µes**

- O crescimento dos indiv√≠duos de *C. arabica* ser√° maior no grupo que recebeu o adubo X-2020

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Data frame com as plantas (unidade amostral) nas linhas e o crescimento dos indiv√≠duos de *C. arabica* (vari√°vel resposta) e os tratamentos (vari√°vel preditora) nas colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°vel preditora e resposta nas colunas

**An√°lise**

Olhando os dados e criando o modelo para Anova de um fator.

```{r}
## Cabe√ßalho dos dados
head(dados_anova_simples) 

## An√°lise ANOVA de um fator
Modelo_anova <- aov(Crescimento ~ Tratamento, data = dados_anova_simples) 
```

Vamos verificar a normalidade dos res√≠duos e homogeneidade da vari√¢ncia usando os testes de Shapiro-Wilk e Bartlett, respectivamente.

```{r}
## Normalidade 
shapiro.test(residuals(Modelo_anova))

## Homogeneidade da vari√¢ncia
bartlett.test(Crescimento ~ Tratamento, data = dados_anova_simples)
```

Os res√≠duos apresentam distribui√ß√£o normal e homogeneidade de vari√¢ncia.

Vamos ver os resultados da an√°lise.

```{r}
## Resultados da anova
anova(Modelo_anova)
```

Percebam que o resultado da ANOVA (Pr(\>F) \< 0.001) indica que devemos rejeitar a hip√≥tese nula que n√£o h√° diferen√ßa entre as m√©dias dos grupos. Contudo, os resultados n√£o mostram quais s√£o os grupos que apresentam diferen√ßas. Para isso, temos que realizar testes de compara√ß√µes m√∫ltiplas *post-hoc* para detectar os grupos que apresentam diferen√ßas significativas entre as m√©dias.

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Os testes *post-hoc* s√≥ devem ser utilizados quando rejeitamos a hip√≥tese nula (P \< 0.05) no teste da ANOVA.
:::

```{r}
## Diferen√ßas entre os tratamentos
# Teste de Tuckey's honest significant difference
TukeyHSD(Modelo_anova)
```

Visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-anova-um-fator)).

```{r fig-anova-um-fator, fig.cap="Gr√°fico de caixa mostrando o resultado da ANOVA de um fator."}
## Reorganizando a ordem que os grupos ir√£o aparecer no gr√°fico
dados_anova_simples$Tratamento <- factor(dados_anova_simples$Tratamento,
                                         levels = c("Controle", "Adubo_Tradicional", "Adubo_X-2020"))

## Gr√°fico
ggplot(data = dados_anova_simples, 
       aes(x = Tratamento, y = Crescimento, color = Tratamento)) + 
    geom_boxplot(fill = c("darkorange", "darkorchid", "cyan4"), 
                 color = "black", show.legend = FALSE, alpha = 0.4) +
    geom_jitter(shape = 16, position = position_jitter(0.1), 
                cex = 4, alpha = 0.7) +
    scale_color_manual(values = c("darkorange", "darkorchid", "cyan4")) +
    scale_y_continuous(limits = c(0, 20), breaks = c(0, 5, 10, 15, 20)) +
    geom_text(x = 1, y = 12, label = "ab", color = "black", size = 5) +
    geom_text(x = 2, y = 17, label = "a", color = "black", size = 5) +
    geom_text(x = 3, y = 17, label = "b", color = "black", size = 5) +
    scale_x_discrete(labels = c("Sem adubo", "Tradicional", "X-2020")) +
    labs(x = "Aduba√ß√£o", y = "Crescimento Coffea arabica (cm)", size = 20) +
    tema_livro() +
    theme(legend.position = "none") 
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, os indiv√≠duos de *C. arabica* que receberam aduba√ß√£o (tradicional e X-2020) apresentaram maior crescimento do que os indiv√≠duos que n√£o receberam aduba√ß√£o. Contudo, diferente do que foi divulgado pela empresa, o adubo X-2020 n√£o apresentou melhor desempenho que o adubo tradicional j√° utilizado pelos produtores.

### ANOVA com dois fatores ou ANOVA fatorial

Este teste considera delineamentos amostrais com dois fatores (ou tratamentos) que podem ser compostos por dois ou mais grupos (ou n√≠veis). Esta an√°lise tem uma vantagem, pois permite avaliar o efeito da intera√ß√£o entre os fatores na vari√°vel resposta. Quando a intera√ß√£o est√° presente, o impacto de um fator depende do n√≠vel (ou grupo) do outro fator.

**Exemplo pr√°tico 1 - ANOVA com dois fatores**

**Explica√ß√£o dos dados**

Neste exemplo hipot√©tico, avaliaremos se o tempo que o corpo leva para eliminar uma droga utilizada em exames de resson√¢ncia magn√©tica est√° relacionado com o sistema XY de determina√ß√£o do sexo e/ou com a idade dos pacientes. Para isso, foi realizado um experimento com 40 pacientes distribu√≠dos da seguinte maneira: i) 10 indiv√≠duos XX - jovens, ii) 10 indiv√≠duos XX - idosas, iii) 10 indiv√≠duos XY - jovens, e iv) 10 indiv√≠duos XY - idosos.

**Pergunta**

- O tempo de elimina√ß√£o da droga √© dependente do sistema XY de determina√ß√£o do sexo e idade dos pacientes?

**Predi√ß√µes**

- O tempo de elimina√ß√£o da droga vai ser mais r√°pido nas pacientes XX e jovens

**Vari√°veis**

-   Vari√°veis resposta e preditoras

-   data frame com os pacientes (unidade amostral) nas linhas e o tempo de elimina√ß√£o da droga (vari√°vel resposta) e os tratamentos sexo e idade dos pacientes (vari√°veis preditoras) nas colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e as vari√°veis preditoras e respostas nas colunas

**An√°lise**

Verificando os dados usando a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(dados_dois_fatores) 
```

C√≥digos para realizar a ANOVA com dois fatores.

```{r}
## An√°lise Anova de dois fatores 
# A intera√ß√£o entre os fatores √© representada por *
Modelo1 <- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores) 

# Olhando os resultados
anova(Modelo1)
```

Percebam que a intera√ß√£o n√£o apresenta um efeito significativo (P \> 0.05). Assim, iremos retirar a intera√ß√£o e verificar, usando Likelihood-ratio test, se o modelo mais simples √© melhor.

```{r}
# Criando modelo sem intera√ß√£o.
Modelo2 <- aov(Tempo ~ Pessoas + Idade, data = dados_dois_fatores) 

## LRT
lrtest(Modelo1, Modelo2)
```

Analisando o resultado do teste (P \> 0.05), a intera√ß√£o n√£o √© importante. Ent√£o podemos seguir com o modelo mais simples. Vamos verficiar a normalidade e homogeneidade da vari√¢ncia (Figura \@ref(fig:fig-lm-anova-fat-pre)).

```{r fig-lm-anova-fat-pre, fig.cap="Gr√°ficos mostrando as premissas da ANOVA fatorial."}
# Verificando as premissas do teste.
plot_grid(plot_model(Modelo2, type = "diag"))
```

Dois pontos est√£o fugindo da reta e chamam aten√ß√£o sobre a normalidade da distribui√ß√£o dos res√≠duos. A homogeneidade da vari√¢ncia est√° adequada. Por enquanto, vamos seguir a an√°lise, mas veja o Cap√≠tulo \@ref(cap8) para entender como lidar com modelos que os res√≠duos n√£o apresentam distribui√ß√£o normal.

```{r}
# Resultados do modelo
anova(Modelo2)
```

Percebam que o resultado da ANOVA (Pr(\>F) \< 0.001) indica que devemos rejeitar a hip√≥tese nula de que n√£o h√° diferen√ßa entre as m√©dias dos sistema XY e idade dos pacientes. Neste caso, n√£o precisamos realizar testes de compara√ß√µes m√∫ltiplas *post-hoc* porque os fatores apresentam apenas dois n√≠veis. Contudo, se no seu delineamento experimental um dos fatores apresentar tr√™s ou mais n√≠veis, voc√™ dever√° utilizar os testes de compara√ß√µes *post-hoc* para determinar as diferen√ßas entre os grupos.

Vamos visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-anova-fatorial)).

```{r fig-anova-fatorial, fig.cap="Gr√°fico de caixa mostrando o resultado da ANOVA fatorial."}
## Gr√°fico
ggplot(data = dados_dois_fatores_interacao, 
       aes(y = Tempo, x = Pessoas, color = Idade)) + 
    geom_boxplot() +
    stat_summary(fun = mean, geom ="point", aes(group = Idade, x = Pessoas),
                 color = "black",
                 position = position_dodge(0.7), size  = 4) +
    geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 40), color = "darkorange", 
              lwd  = 1.3, linetype = 2) + 
    geom_link(aes(x = 1.2, y = 19, xend = 2.2, yend = 26.5), 
              color = "cyan4", lwd  = 1.3, linetype = 2) + 
    labs(x = "Sistema XY de determina√ß√£o do sexo", 
         y = "Tempo (horas) para eliminar a droga") +
    scale_color_manual(values = c("darkorange", "cyan4", "darkorange", "cyan4")) +
    scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) +
    tema_livro()  
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, o sistema XY de determina√ß√£o do sexo e a idade dos pacientes t√™m um efeito no tempo de elimina√ß√£o da droga do organismo. Os pacientes XX e jovens apresentaram elimina√ß√£o mais r√°pida da droga do que pacientes XY e idosos.

**Exemplo pr√°tico 2 - ANOVA com dois fatores com efeito da intera√ß√£o**

**Explica√ß√£o dos dados**

Neste exemplo, novamente hipot√©tico, usaremos os mesmos dados do exemplo anterior. Entretanto, alteramos os dados para que agora a intera√ß√£o seja significativa.

```{r}
## Olhando os dados
head(dados_dois_fatores_interacao2)

## An√°lise anova de dois fatores 
Modelo_interacao2 <- aov(Tempo ~ Pessoas * Idade, 
                         data = dados_dois_fatores_interacao2)

## Olhando os resultados
anova(Modelo_interacao2)
```

Percebam que a intera√ß√£o √© significativa (P \< 0.05), mas a idade n√£o √© significativa. Nossa interpreta√ß√£o precisa ser baseada na intera√ß√£o entre os fatores. Vamos visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-anova-fatorial-int)).

```{r fig-anova-fatorial-int, fig.cap="Gr√°fico de caixa mostrando o resultado da ANOVA fatorial com intera√ß√£o."}
## Gr√°fico
ggplot(data = dados_dois_fatores_interacao2, 
       aes(y = Tempo, x = Pessoas, color = Idade)) + 
    geom_boxplot() +
    stat_summary(fun = mean, geom ="point", aes(group = Idade, x = Pessoas), 
                 color = "black", position = position_dodge(0.7), size  = 4) +
    geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 27), color = "darkorange", 
              lwd  = 1.3, linetype = 2) + 
    geom_link(aes(x = 1.2, y = 19, xend = 2.2, yend = 41), color = "cyan4", 
              lwd  = 1.3, linetype = 2) + 
    labs(x = "Sistema XY de determina√ß√£o do sexo", 
         y = "Tempo (horas) para eliminar a droga") +
    scale_color_manual(values = c("darkorange", "cyan4", "darkorange", "cyan4")) +
    scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) +
    tema_livro() 
```

**Interpreta√ß√£o dos resultados**

Percebam que as linhas se cruzam. Esse √© um exemplo cl√°ssico de intera√ß√£o. Novamente, para saber a resposta do fator idade (jovem ou idoso), voc√™ precisa saber com qual pessoa (XX ou XY) ele est√° associado. Jovens s√£o mais r√°pidos para eliminarem a droga em pessoas XX, enquanto os idosos s√£o mais r√°pidos para eliminarem a droga nas pessoas XY.

### ANOVA em blocos aleatorizados

No delineamento experimental com blocos aleatorizados, cada fator √© agrupado em blocos, com r√©plicas de cada n√≠vel do fator representado em cada bloco [@gotelli_primer_2012]. O bloco √© uma √°rea ou per√≠odo de tempo dentro do qual as condi√ß√µes ambientais s√£o relativamente homog√™neas. O objetivo do uso dos blocos √© controlar fontes de varia√ß√µes indesejadas na vari√°vel dependente que n√£o s√£o de interesse do pesquisador. Desta maneira, podemos retirar dos res√≠duos os efeitos das varia√ß√µes indesejadas que n√£o s√£o do nosso interesse, e testar com maior poder estat√≠stico os efeitos dos tratamentos de interesse. Importante, os blocos devem ser arranjados de forma que as condi√ß√µes ambientais sejam mais similares dentro dos blocos do que entre os blocos.

**Exemplo pr√°tico 1 - ANOVA em blocos aleatorizados**

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos a riqueza de esp√©cies de anuros amostradas em po√ßas artificiais instaladas a diferentes dist√¢ncias de seis fragmentos florestais no sudeste do Brasil [@daSilva2011]. Os fragmentos florestais apresentam diferen√ßas entre si que n√£o s√£o do interesse do pesquisador. Por isso, eles foram inclu√≠dos como blocos nas an√°lises. As po√ßas artificiais foram instaladas em todos os fragmentos florestais com base no seguinte delineamento experimental [@daSilva2011]: i) quatro po√ßas no interior do fragmento a 100 m de dist√¢ncia da borda do fragmento; ii) quatro po√ßas no interior no fragmento a 50 m de dist√¢ncia da borda do fragmento; iii) quatro po√ßas na borda do fragmento; iv) quatro po√ßas na matriz de pastagem a 50 m de dist√¢ncia da borda do fragmento; e v) quatro po√ßas na matriz de pastagem a 100 m de dist√¢ncia da borda do fragmento. Percebam que todos os tratamentos foram instalados em todos os blocos. 


::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Os valores da riqueza de esp√©cies foram alterados em rela√ß√£o a publica√ß√£o original [@daSilva2011] para deixar o exemplo mais did√°tico.
:::

**Pergunta**

- A dist√¢ncia da po√ßa artifical ao fragmento florestal influencia a riqueza de esp√©cies anuros?

**Predi√ß√µes**

- Po√ßas na borda do fragmento florestal apresentar√£o maior riqueza de esp√©cies do que po√ßas distantes da borda

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Data frame com as po√ßas (unidade amostral) nas linhas e a riqueza de esp√©cies (vari√°vel reposta), dist√¢ncia dos fragmentos florestais (vari√°vel preditora categ√≥rica) e fragmentos florestais (blocos) nas colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Olhando os dados usando a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(dados_bloco) 
```

An√°lise da ANOVA em blocos.

```{r}
## An√°lise Anova em blocos aleatorizados
model_bloco2 <- aov(Riqueza ~ Pocas + Error(Blocos), data = dados_bloco)
summary(model_bloco2)
```

Lembre-se que nos delineamentos experimentais em bloco, o pesquisador n√£o est√° interessado no efeito do bloco, mas sim em controlar a varia√ß√£o associada a ele.

O que n√£o pode acontecer √© ignorar o efeito do bloco que √© incorporado pelos res√≠duos quando n√£o informado no modelo. Veja abaixo a forma errada de analisar delineamento experimental com blocos.

```{r}
## Forma errada de an√°lisar Anova em blocos
modelo_errado <- aov(Riqueza ~ Pocas, data = dados_bloco)
anova(modelo_errado)
```

O resultado da ANOVA (Pr(\>F) \< 0.001) indica que devemos rejeitar a hip√≥tese nula que n√£o h√° diferen√ßa entre as m√©dias dos grupos. Contudo, os resultados n√£o mostram quais s√£o os grupos que apresentam diferen√ßas. Para isso, temos que realizar testes de compara√ß√µes m√∫ltiplas *post-hoc* para detectar os grupos que apresentam diferen√ßas significativas entre as m√©dias.

```{r}
## Teste de Tuckey's honest significant difference
pairs(lsmeans(model_bloco1, "Pocas"), adjust = "tukey")
```

Visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-anova-blocos)).

```{r fig-anova-blocos, fig.cap="Gr√°fico de caixa mostrando o resultado da ANOVA de blocos aleatorizados."}
# Reordenando a ordem que os grupos ir√£o aparecer no gr√°fico.
dados_bloco$Pocas <- factor(dados_bloco$Pocas, 
                            levels = c("Int-100m", "Int-50m", "Borda", "Mat-50m", "Mat-100m"))

## Gr√°fico
ggplot(data = dados_bloco, aes(x = Pocas, y = Riqueza)) + 
    labs(x = "Po√ßas artificiais", y = "Riqueza de esp√©cies de anuros") +
    geom_boxplot(color = "black", show.legend = FALSE, alpha = 0.4) +
    geom_jitter(shape = 16, position = position_jitter(0.1), cex = 4, alpha = 0.7) +
    scale_x_discrete(labels = c("-100m","-50m","Borda", "50m", "100m")) +
    tema_livro() +
    theme(legend.position = "none") 
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, rejeitamos a hip√≥tese nula de que a dist√¢ncia das po√ßas artificiais at√© as bordas dos fragmentos florestais n√£o influ√™ncia a riqueza de esp√©cies de anuros. As po√ßas artificiais instaladas nas bordas dos fragmentos florestais apresentaram maior riqueza de esp√©cies do que as po√ßas distantes.

### An√°lise de covari√¢ncia (ANCOVA)

A ANCOVA pode ser compreendida como uma extens√£o da ANOVA com a adi√ß√£o de uma vari√°vel cont√≠nua (covari√°vel) medida em todas as unidades amostrais [@gotelli_primer_2012]. A ideia √© que a covari√°vel tamb√©m afete os valores da vari√°vel resposta. N√£o incluir a covari√°vel ir√° fazer com que a varia√ß√£o n√£o explicada pelo modelo concentre-se nos res√≠duos. Incluindo a covari√°vel, o tamanho do res√≠duo √© menor e o teste para avaliar as diferen√ßas nos tratamentos, que √© o interesse do pesquisador, ter√° mais poder estat√≠stico.

**Exemplo pr√°tico 1 - ANCOVA**

**Explica√ß√£o dos dados**

Neste exemplo hipot√©tico, avaliaremos o efeito da herbivoria na biomassa dos frutos de uma esp√©cie de √°rvore na Mata Atl√¢ntica. O delineamento experimental permitiu que alguns indiv√≠duos sofressem herbivoria e outros n√£o. Os pesquisadores tamb√©m mediram o tamanho da raiz dos ind√≠viduos para inseri-la como uma covari√°vel no modelo.

**Pergunta**

- A herbivoria diminiu a biomassa dos frutos?

**Predi√ß√µes**

- Os indiv√≠duos que sofreram herbivoria ir√£o produzir frutos com menor biomassa do que os indiv√≠duos sem herbivoria

**Vari√°veis**

-   Vari√°veis resposta e preditoras

-   data frame com as indiv√≠duos da esp√©cie de planta (unidade amostral) nas linhas e a biomassa dos frutos (vari√°vel resposta), herbivoria (vari√°vel preditora categ√≥rica) e tamanho da raiz (covari√°vel cont√≠nua) nas colunas

**Checklist**

-   Verificar se o seu data frame est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas

**An√°lise**

Olhando os dados usando a fun√ß√£o `head()`.

```{r}
## Cabe√ßalho dos dados
head(dados_ancova) 
```

C√≥digos para o c√°lculo da ANCOVA (Figura \@ref(fig:fig-ancova-diag)).

```{r fig-ancova-diag, fig.cap="Gr√°ficos de diagn√≥stico dos res√≠duos da ANCOVA."}
## Gr√°fico
## Ancova
modelo_ancova <- lm(Biomassa ~ Herbivoria * Raiz, data = dados_ancova)

# Verificando as premissas da Ancova
plot_grid(plot_model(modelo_ancova, type = "diag"))
```

As premissas da ANCOVA est√£o adequadas. Vamos olhar os resultados do modelo.

```{r}
## Resultados do modelo
anova(modelo_ancova)
```

Percebam que o resultado da ANCOVA (Pr(\>F) \< 0.001) indica que tanto a herbivoria como o tamanho da raiz (covari√°vel) t√™m efeitos significativos na biomassa dos frutos. Contudo, a intera√ß√£o entre as vari√°veis n√£o foi signigicativa. Vamos usar o Likelihood-ratio test (LRT) para ver se podemos seguir com um modelo mais simples (sem intera√ß√£o).

```{r}
## Criando modelo sem intera√ß√£o
modelo_ancova2 <- lm(Biomassa ~ Herbivoria + Raiz, data = dados_ancova)

## Likelihood-ratio test
lrtest(modelo_ancova, modelo_ancova2)
```

A intera√ß√£o n√£o √© importante, pois P > 0.05. Seguiremos com o modelo mais simples.

Vamos fazer a visualizar os resultados em gr√°fico (Figura \@ref(fig:fig-ancova)).

```{r fig-ancova, fig.cap="Gr√°fico de caixa mostrando o resultado da ANCOVA."}
## Gr√°fico
ggplot(data = dados_ancova, aes(x = Raiz, y = Biomassa, fill = Herbivoria)) + 
    labs(x = "Tamanho da raiz (cm)", y = "Biomassa dos frutos (g)") +
    geom_point(size = 4, shape = 21, alpha = 0.7) +
    scale_colour_manual(values = c("darkorange", "cyan4")) +
    scale_fill_manual(values = c("darkorange", "cyan4"),
                      labels = c("Com herbivoria", "Sem herbivoria")) +
    geom_smooth(aes(color = Herbivoria), method = "lm", show.legend = FALSE) +
    tema_livro()
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, o tamanho da raiz (covari√°vel) tem uma rela√ß√£o positiva com a biomassa dos frutos. Quanto maior o tamanho da raiz, maior a biomassa dos frutos. Usando a ANCOVA e controlando o efeito da covari√°vel, percebemos que a herbivoria tamb√©m afeta a biomassa dos frutos. Os indiv√≠duos com o mesmo tamanho de raiz que n√£o sofreram herbivoria produziram frutos com maior biomassa do que os indiv√≠duos com herbivoria.

## Generalized Least Squares (GLS)

Em seu artigo cl√°ssico publicado em 1993, Pierre Legendre se pergunta se a autocorrela√ß√£o espacial √© um problema ou um novo paradigma [@legendre_spatial_1993]. Segundo o autor, estudar estruturas espaciais √© tanto uma necessidade, quanto um desafio para pesquisadores da ecologia e conserva√ß√£o que lidam com dados espacialmente distribu√≠dos. Uma vez que todas as vari√°veis tipicamente utilizadas em estudos de biodiversidade (popula√ß√µes, condi√ß√µes clim√°ticas, diversidade) possuem algum tipo de estrutura espacial, √© fundamental compreender os motivos de como incluir esta informa√ß√£o nos modelos anal√≠ticos. De fato, a Primeira Lei da Geografia postula que "todas as coisas est√£o relacionadas com todas as outras, por√©m coisas pr√≥ximas est√£o mais relacionadas do que coisas distantes". Como resultado, os valores observados em uma localidade (e.g., composi√ß√£o de esp√©cies) ser√£o mais afetados pelo conjunto de esp√©cies que ocorre nas localidades vizinhas e, desse modo, alguns pontos de coleta podem n√£o ser estatisticamente independentes. Como vimos anteriormente, um dos pressupostos dos modelos lineares √© a independ√™ncia das unidades amostrais. Assim, a presen√ßa de autocorrela√ß√£o espacial nos res√≠duos viola este pressuposto e, consequentemente, aumenta a taxa de Erro do Tipo I (rejeitar a hip√≥tese nula quando ela √© verdadeira) nos modelos. Uma das solu√ß√µes para incorporar a depend√™ncia espacial dos res√≠duos √© usar o m√©todo de M√≠nimos Quadrados Generalizados (*Generalized Least Squares* - GLS). Diferente dos modelos apresentados anteriormente, este m√©todo ajusta explicitamente modelos heterosced√°sticos e com res√≠duos correlacionados [@pinheiro_mixed-effects_2000]. Para representar a estrutura espacial (e, assim, a depend√™ncia entre as observa√ß√µes) √© necess√°rio incluir vari√°veis espaciais (geralmente coordenadas geogr√°ficas, i.e., vetores bimensionais: *sensu* @pinheiro_mixed-effects_2000) no argumento `corStruct` na fun√ß√£o `gls()` do pacote `nlme`. Este modelo basicamente assume que a estrutura de covari√¢ncia √© uma fun√ß√£o da dist√¢ncia entre as localidades [@littell2006sas]. √â importante ressaltar, todavia, que existem diferentes fun√ß√µes de covari√¢ncia que s√£o discutidas detalhadamente em @littell2006sas. Aqui, iremos nos
concentrar nas seguintes fun√ß√µes.

-   **Esf√©rica**: `corSpher(form=\~lat+long)`
-   **Exponencial**: `corExp(form=\~lat+long)`
-   **Gaussiana**: `corGaus(form=\~lat+long)`
-   **Linear**: `corLin(form=\~lat+long)`
-   **Raz√£o quadr√°tica**: `corRatio(form=\~lat+long)`

**Exemplo pr√°tico**

**Explica√ß√£o dos dados**

Neste exemplo, utilizamos os dados de riqueza de esp√©cies de √°caros (Oribatidae) em 70 amostras de musgo (g√™nero *Sphagnum*) [@borcard_partialling_1992]. Para cada amostra, al√©m da riqueza de √°caros, os autores registraram a quantidade de √°gua no substrato e as coordenadas geogr√°ficas. Os dados completos est√£o dispon√≠veis no pacote `vegan`.

```{r}
## Calcular a riqueza de esp√©cies em cada comunidade
riqueza <- specnumber(mite) 

## Selecionar a vari√°vel ambiental - quantidade de √°gua no substrato
agua <- mite.env[,2]

## Criar um data.frame com riqueza, quantidade de √°gua no substrato e coordenadas geogr√°ficas
mite_dat <- data.frame(riqueza, agua, coords)
```

**Modelo linear sem incorporar a estrutura espacial**

Vamos inicialmente ajustar um modelo sem incorporar a estrutura espacial (Figura \@ref(fig:fig-lm-esp-diag)).

```{r fig-lm-esp-diag, fig.cap="Gr√°ficos mostrando as premissas da regress√£o linear simples."}
## Modelo
linear_model <- lm(riqueza ~ agua, mite_dat) 

## Res√≠duos
par(mfrow = c(2, 2)) 
plot(linear_model, which = 1:4)

## Resultados do modelo
res_lm <- summary(linear_model)

## Coeficiente de determina√ß√£o e coeficientes
res_lm$adj.r.squared
res_lm$coefficients
```

**Acessando a informa√ß√£o espacial com o GLS**

Como dito, dependendo da estrutura espacial de suas vari√°veis (dependentes, independentes, covari√°veis), o pressuposto de independ√™ncia dos res√≠duos pode ser afetado e, desse modo, o modelo linear convencional ter√° maior chance de Erro do Tipo I. Abaixo, iremos comparar um modelo GLS sem incorporar estrutura espacial (o que √© exatamente igual ao modelo criado acima *Modelo Linear*) com diferentes modelos que utilizam explicitamente res√≠duos correlacionados.

```{r}
## Modelo gls sem estrutura espacial
no_spat_gls <- gls(riqueza ~ agua, mite_dat, method = "REML")
```

Uma maneira de identificar se os res√≠duos do modelo linear apresentam estrutura espacial √© fazendo uma figura chamada **variograma**. O variograma possui tr√™s par√¢metros: i) *nugget* , ii) *range* e iii) *sill* [@fortin_dale_2005]. O *nugget* √© utilizado para quantificar a variabilidade observada nos valores menores (ou seja, em pequenas dist√¢ncias). O *range*, por sua vez, √© usado para identificar a dist√¢ncia m√°xima em que a autocorrela√ß√£o espacial est√° presente (Figura \@ref(fig:fig-variograma), pontos laranjas). Deste modo, os valores posicionados a partir do *range* (Figura \@ref(fig:fig-variograma), pontos verdes) representam pontos n√£o correlacionados [@fortin_dale_2005]. A posi√ß√£o limiar que representa claramente a "pausa" no crescimento da curva (*range*) indica os pontos n√£o correlacionados e representa o *sill* (Figura \@ref(fig:fig-variograma)). No exemplo da Figura \@ref(fig:fig-variograma), o *sill* √© constante. Por√©m, √© poss√≠vel que os valores de *sill* n√£o sejam constantes [@chiles_1999]. Um exemplo √© o "efeito buraco" que √© caracterizado por um ou mais picos (ou vales) no variograma que correspondem ao n√∫mero de valores negativos na covari√¢ncia. Esses valores sugerem que valores altos podem estar rodeados de valores baixos [@chiles_1999]. Por√©m, os detalhamentos desses comportamentos vai al√©m do escopo deste livro.

```{r fig-variograma, fig.cap="Variograma representando a semi-vari√¢ncia *y(h)* em fun√ß√£o do intervalor espacial *h*. Cada ponto representa a dist√¢ncia entre localidades e a linha a varia√ß√£o te√≥rica a fun√ß√£o de covari√¢ncia esf√©rica (veja abaixo). Adaptado de @fortin_dale_2005.", echo=FALSE}
knitr::include_graphics(path = "img/cap07_fig03.png")
```

Abaixo, podemos analisar o variograma para os res√≠duos do modelo GLS ajustado (Figura \@ref(fig:fig-variog-dados)).

```{r fig-variog-dados, fig.cap="Variograma para os res√≠duos do modelo GLS ajustado."}
## Variograma
variog_mod1 <- nlme::Variogram(no_spat_gls, form = ~lat+long, 
                               resType = "normalized") 

## Gr√°fico
plot(variog_mod1)

## √çndice I de Moran

## Primeiro precisamos calcular uma matriz de dist√¢ncias geogr√°ficas entre as comunidades
dat_dist <- pdist(coords) # matriz de dist√¢ncia

Moran.I(x = mite_dat$riqueza, w = dat_dist)
```

O primeiro passo √© utilizar diferentes variogramas te√≥ricos para identificar o melhor modelo que representa a estrutura espacial dos seus dados.

```{r}
## Covari√¢ncia esf√©rica
espher_model <- gls(riqueza ~ agua, mite_dat, 
                    corSpher(form = ~lat+long, nugget = TRUE))

## Covari√¢ncia exponencial
expon_model <- gls(riqueza ~ agua, mite_dat, 
                   corExp(form = ~lat+long, nugget = TRUE))

## Covari√¢ncia Gaussiana
gauss_model <- gls(riqueza ~ agua, mite_dat, 
                   corGaus(form = ~lat+long, nugget = TRUE))

## Covari√¢ncia linear
cor_linear_model <- gls(riqueza ~ agua, mite_dat, 
                        corLin(form = ~lat+long, nugget = TRUE))

## Covari√¢ncia raz√£o quadr√°tica
ratio_model <- gls(riqueza ~ agua, mite_dat, 
                   corRatio(form = ~lat+long, nugget = TRUE))
```

Agora, depois de ajustar o modelo GLS com os  diferentes variogramas √© necess√°rio comparar os modelos para escolher o mais "prov√°vel", utilizando a sele√ß√£o de modelos pelo Crit√©rio de Sele√ß√£o de Akaike (AIC) [@chiles_1999; @fortin_dale_2005] (Figura \@ref(fig:fig-diag-ratio)).

```{r fig-diag-ratio, fig.cap="Gr√°fico dos res√≠duos em rela√ß√£o aos dodos ajustados do modelo GLS Ratio."}
## Sele√ß√£o de modelos
aic_fit <- AIC(no_spat_gls, espher_model, expon_model, gauss_model, cor_linear_model, ratio_model)
aic_fit %>% arrange(AIC)

## Gr√°fico
plot(residuals(ratio_model, type = "normalized") ~ fitted(ratio_model))
```

O variograma ajustado pelo modelo raz√£o quadr√°tica (*ratio_model*) demonstra que o *range* n√£o √© crescente (indicando correla√ß√£o espacial entre localidades pr√≥ximas) e, desse modo, sugere que √© mais apropriado usar o modelo GLS do que um modelo linear desconsiderando a estrutura espacial (Figura \@ref(fig:fig-variog-ratio)).

```{r fig-variog-ratio, fig.cap="Variogramas para os res√≠duos do modelo GLS Normal e Ratio."}
## Varigrama
ratio_variog <- Variogram(ratio_model, form = ~lat+long, resType = "normalized")

## Resumo dos modelos
summary(ratio_model)$tTable 
summary(no_spat_gls)$tTable

## Gr√°ficos
plot(ratio_variog, main = "Variograma como Modelo Ratio")
plot(variog_mod1, main = "Variograma Modelo Normal")
```

**Interpreta√ß√£o dos resultados**

Dessa forma, O valor mais apropriado da estat√≠stica t √© de -4.33 (*ratio_model*) ao inv√©s de -7.78 (*no_spat_gls*). Neste caso, a decis√£o (quantidade de √°gua afetando a riqueza de √°caros) n√£o foi afetada (*P* \< 0.05 nos dois modelos), somente a estat√≠stica do teste.

## Para se aprofundar

-   Recomendamos aos interessados os livros: i) Zar [-@zar_biostatistical_2010] Biostatiscal analysis, ii) Gotelli & Ellison [-@gotelli_primer_2012] A primer of ecological statistics, iii) Quinn & Keough [-@quinn_experimental_2002] Experimental design and data analysis for biologists, iv) Zuur e colabodores [-@zuur_analysing_2007] Analysing Ecological Data e v) Touchon [-@touchon_applied_2021] Applied statistics with R: a practical guide for the life sciences.
