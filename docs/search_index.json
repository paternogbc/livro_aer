[["index.html", "An√°lises Ecol√≥gicas no R Capa", " An√°lises Ecol√≥gicas no R 2021-11-04 Capa "],["pref√°cio.html", "Pref√°cio", " Pref√°cio "],["cap1.html", "Cap√≠tulo 1 Pr√©-requisitos 1.1 Introdu√ß√£o 1.2 Instala√ß√£o do R 1.3 Instala√ß√£o do RStudio 1.4 Vers√£o do R 1.5 Pacotes 1.6 Dados", " Cap√≠tulo 1 Pr√©-requisitos 1.1 Introdu√ß√£o O objetivo desta se√ß√£o √© informar como fazer a instala√ß√£o dos Programas R e RStudio, al√©m de descrever os pacotes e dados necess√°rios para reproduzir os exemplos do livro. 1.2 Instala√ß√£o do R Para come√ßarmos a trabalhar com o R √© necess√°rio baix√°-lo na p√°gina do R Project. Ent√£o, acesse esse site e em seguida, clique no link download R. Figura 1.1: P√°gina do R project indicando o link para download do programa Esse link o levar√° √† p√°gina do CRAN Mirrors (Comprehensive R Archive Network). Escolha a p√°gina espelho do Brasil mais pr√≥xima de voc√™ para baixar o programa. Figura 1.2: P√°gina do R project mostrando os espelhos distribu√≠dos em diferentes pa√≠ses Escolha agora o sistema operacional do seu computador (passos adicionais existem para diferentes distribui√ß√µes Linux). Figura 1.3: P√°gina do R project indiciando os sistemas operacionais dispon√≠veis. Selecionamos a op√ß√£o do Windows. Agora clique em base para finalmente chegar √† p√°gina de download com a vers√£o mais recente do R. Figura 1.4: P√°gina do R project indicando os passos para instala√ß√£o do programa. 1.3 Instala√ß√£o do RStudio O RStudio possui algumas caracter√≠sticas que o tornam popular: v√°rias janelas de visualiza√ß√£o, marca√ß√£o e preenchimento autom√°tico do script, integra√ß√£o com controle de vers√£o, dentre outras funcionalidades. Para fazer o download do RStudio, acessamos o site, e clique em download. Figura 1.5: P√°gina inicial do R Studio indicando o local de download. Escolhemos a vers√£o gratuita. Figura 1.6: P√°gina do R Studio para download do programa. Escolhemos o instalador com base em nosso sistema operacional. Figura 1.7: P√°gina do R Studio para instala√ß√£o do programa. 1.4 Vers√£o do R Todas os comandos, pacotes e an√°lises disponibilizados no livro foram realizos no Programa R vers√£o 4.1.1 (10-08-2021). 1.5 Pacotes Descrevemos no Cap√≠tulo 4 o que s√£o e como instalar os pacotes para realizar as an√°lises estat√≠sticas no R. üìù Importante: Criamos o pacote ecodados que contem todas as informa√ß√µes e dados utilizados neste livro. Assim, recomendamos que voc√™ instale e carregue este pacote no in√≠cio de cada cap√≠tulo, para ter acesso aos dados necess√°rios para executar as fun√ß√µes no R. Abaixo, listamos todos os pacotes que foram utilizados em alguma das an√°lises descritas no livro. Voc√™ pode instalar os pacotes agora ou esperar para instal√°-los quando ler o @ref[cap4] e entender o que s√£o as fun√ß√µes install.packages(), library() e install_github(). install.packages(c(&quot;ade4&quot;, &quot;adespatial&quot;, &quot;ape&quot;, &quot;bbmle&quot;, &quot;betapart&quot;, &quot;BiodiversityR&quot;, &quot;car&quot;, &quot;cati&quot;, &quot;datasauRus&quot;, &quot;devtools&quot;, &quot;DHARMa&quot;, &quot;dplyr&quot;, &quot;emmeans&quot;, &quot;factoextra&quot;, &quot;FactoMineR&quot;, &quot;fasterize&quot;, &quot;FD&quot;, &quot;forcats&quot;, &quot;geobr&quot;, &quot;GGally&quot;, &quot;ggExtra&quot;, &quot;ggforce&quot;, &quot;ggord&quot;, &quot;ggplot2&quot;, &quot;ggpubr&quot;, &quot;ggrepel&quot;, &quot;ggspatial&quot;, &quot;glmmTMB&quot;, &quot;grid&quot;, &quot;gridExtra&quot;, &quot;here&quot;, &quot;hillR&quot;, &quot;iNEXT&quot;, &quot;janitor&quot;, &quot;kableExtra&quot;, &quot;knitr&quot;, &quot;labdsv&quot;, &quot;lattice&quot;, &quot;leaflet&quot;, &quot;lmtest&quot;, &quot;lsmeans&quot;, &quot;lubridate&quot;, &quot;mapview&quot;, &quot;MASS&quot;, &quot;MuMIn&quot;, &quot;nlme&quot;, &quot;ordinal&quot;, &quot;palmerpenguins&quot;, &quot;performance&quot;, &quot;pez&quot;, &quot;phyloregion&quot;, &quot;phytools&quot;, &quot;picante&quot;, &quot;piecewiseSEM&quot;, &quot;purrr&quot;, &quot;pvclust&quot;, &quot;raster&quot;, &quot;readr&quot;, &quot;reshape2&quot;, &quot;rgdal&quot; , &quot;rnaturalearth&quot;, &quot;RVAideMemoire&quot;, &quot;sciplot&quot;, &quot;sf&quot;, &quot;sidrar&quot;, &quot;sjPlot&quot;, &quot;spData&quot;, &quot;spdep&quot;, &quot;stringr&quot;, &quot;SYNCSA&quot;, &quot;tibble&quot;, &quot;tidyr&quot;, &quot;tidyverse&quot;, &quot;tmap&quot;, &quot;tmaptools&quot;, &quot;TPD&quot;, &quot;vegan&quot;, &quot;viridis&quot;, &quot;visdat&quot;), dependencies = TRUE) Diferente dos pacotes anteriores que s√£o baixados do CRAN, alguns pacotes s√£o baixados do github dos pesquisadores respons√°veis pelos pacotes. Nestes casos, precisamos carregar o pacote devtools para acessar a fun√ß√£o install_github. Durante as instala√ß√µes deste pacotes, o R ir√° pedir para voc√™ digitar um n√∫mero indicando os pacotes que voc√™ deseja fazer update. Neste caso, digite 1 que ir√° indicar para ao programa que ele deve instalar todos os pacotes atualizados. library(devtools) install_github(&quot;paternogbc/ecodados&quot;) install_github(&quot;mwpennell/geiger-v2&quot;) install_github(&quot;fawda123/ggord&quot;) install_github(&quot;jinyizju/V.PhyloMaker&quot;) 1.6 Dados A maioria dos exemplos utilizados s√£o baseados em dados reais que j√° foram publicados em artigos cient√≠ficos ou s√£o dados coletados por um dos autores deste livro. Em alguns casos, os dados foram simulados para facilitar a interpreta√ß√£o dos resultados de algumas an√°lises estat√≠sticas. Todos os dados, publicados ou simulados, est√£o dispon√≠veis no pacote ecodados. Al√©m disso, em cada cap√≠tulo fazemos uma breve descri√ß√£o dos dados para facilitar a compreens√£o sobre o que √© vari√°vel resposta ou preditora, como essas vari√°veis est√£o relacionadas com as perguntas e predi√ß√µes do exemplo. "],["cap2.html", "Cap√≠tulo 2 Introdu√ß√£o 2.1 Hist√≥rico deste livro 2.2 Objetivo deste livro 2.3 O que voc√™ n√£o encontrar√° neste livro 2.4 Por que usar o R? 2.5 Indo al√©m da linguagem de progra√ß√£o para a Ecologia 2.6 Como usar este livro", " Cap√≠tulo 2 Introdu√ß√£o 2.1 Hist√≥rico deste livro Este livro foi estruturado a partir da apostila elaborada pelos pesquisadores Diogo B. Provete, Fernando R. da Silva e Thiago Gon√ßalves-Souza para ministrar o curso Estat√≠stica aplicada √† ecologia usando o R no PPG em Biologia Animal da UNESP de S√£o Jos√© Rio Preto/SP, em abril de 2011. Os tr√™s pesquisadores eram ent√£o alunos do PPG em Biologia Animal quando elaboraram o material disponibilizado na apostila. A proposta de transformar a apostila em livro sempre foi um t√≥pico recorrente desde 2011, e concretizado agora, 10 anos depois. Neste per√≠odo, Diogo, Fernando e Thiago foram contratados pela Universidade Federal de Mato Grosso do Sul, Universidade Federal de S√£o Carlos campus Sorocaba, e Universidade Federal Rural de Pernambuco, respectivamente. Nestes anos eles ofertaram diferentes vers√µes do curso Estat√≠stica aplicada √† ecologia usando o R para alunos de gradua√ß√£o e p√≥s-gradua√ß√£o em diferentes institui√ß√µes do Brasil. A possibilidade da oferta destes novos cursos fortaleceu a ideia de trasformar a apostila em um livro com base nas experi√™ncias dos pesquisadores em sala de aula. Considerando que novas abordagens ecol√≥gicas v√™m sendo descritas e criadas a uma taxa elevada nos √∫ltimos anos, era de se esperar que as informa√ß√µes dispon√≠veis na apostila estivessem defasadas ap√≥s 10 anos. Por este motivo, Diogo, Fernando e Thiago convidaram outros dois pesquisadores, Gustavo B. Paterno da Georg-August-University of G√∂ttingen e Maur√≠cio H. Vancine do PPG em Ecologia, Evolu√ß√£o e Biodiversidade da UNESP C√¢mpus de Rio Claro, que s√£o refer√™ncias no uso de estat√≠stica em ecologia usando o R. Com o time completo, passaram mais de um ano realizando reuni√µes, compartilhando scripts e pagando cerveja para os coautores por cap√≠tulos atrasados at√© chegarem neste primeira vers√£o do livro. 2.2 Objetivo deste livro Nossa proposta com este livro √© de tra√ßar o melhor caminho (pelo menos do nosso ponto de vista) entre quest√µes ecol√≥gicas e os m√©todos estat√≠sticos mais robustos para test√°-las. Guiar seus passos nesse caminho (nem sempre linear) necessita que voc√™ utilize um requisito b√°sico: o de utilizar seu esfor√ßo para caminhar. O nosso esfor√ßo, em contrapartida, ser√° o de indicar as melhores dire√ß√µes para que voc√™ adquira certa independ√™ncia em an√°lises ecol√≥gicas. Um dos nossos objetivos √© mostrar que o conhecimento de teorias ecol√≥gicas e a utiliza√ß√£o de quest√µes apropriadas s√£o o primeiro passo na caminhada rumo √† compreens√£o da l√≥gica estat√≠stica. N√£o deixe que a estat√≠stica se torne a ‚Äúpedra no seu caminho.‚Äù Em nossa opini√£o, programas com ambiente de programa√ß√£o favorecem o entendimento da l√≥gica estat√≠stica, uma vez que cada passo (lembre-se de que voc√™ est√° caminhado em uma estrada desconhecida e cheia de pedras) precisa ser coordenado, ou seja, as linhas de comando (detalhes abaixo) precisam ser compreendidas para que voc√™ teste suas hip√≥teses. A primeira parte deste livro pretende utilizar uma estrat√©gia que facilita a escolha do teste estat√≠stico apropriado, por meio da sele√ß√£o de quest√µes/hip√≥teses claras e da liga√ß√£o dessas hip√≥teses com a teoria e o m√©todo (veja Figura 3.1 no Cap√≠tulo 3). Enfatizamos que √© fundamental ter em mente aonde se quer chegar, para poder escolher o que deve ser feito. Posteriormente √† escolha de suas quest√µes, √© necess√°rio transferir o contexto ecol√≥gico para um contexto meramente estat√≠stico (hip√≥tese nula/alternativa). A partir da defini√ß√£o de uma hip√≥tese nula, partiremos para a aplica√ß√£o de cada teste estat√≠stico (de modelos lineares generalizados √† an√°lises multivariadas) utilizando a linguagem R. Antes de detalhar cada an√°lise estat√≠stica, apresentaremos os comandos b√°sicos para a utiliza√ß√£o da linguagem R e os tipos de distribui√ß√£o estat√≠stica que s√£o essenciais para a compreens√£o dos testes estat√≠sticos. Para isso, organizamos um esquema que chamamos de ‚Äúestrutura l√≥gica‚Äù que facilita a compreens√£o dos passos necess√°rios para testar suas hip√≥teses (veja Figura 3.2 no Cap√≠tulo 3). 2.3 O que voc√™ n√£o encontrar√° neste livro Aprofundamento te√≥rico, detalhes matem√°ticos, e explica√ß√£o dos algoritmos s√£o informa√ß√µes que infelizmente n√£o ser√£o abordadas neste livro. O foco aqui √© a explica√ß√£o de como cada teste funciona (teoria e procedimentos matem√°ticos b√°sicos) e sua aplica√ß√£o em testes ecol√≥gicos usando scripts na linguagem R. Para tanto, o livro de Pierre e Louis Legendre (P. Legendre and Legendre 2012b) √© uma leitura que permite o aprofundamento de cada uma das an√°lises multivariadas propostas aqui. Al√©m disso, s√£o de fundamental import√¢ncia para o amadurecimento em an√°lises ecol√≥gicas as seguintes leituras: Manly (1991), Pinheiro and Bates (2000b), Scheiner and Gurevitch (2001), Burnham and Anderson (2014a), Quinn and Keough (2002), Venables and Ripley (2002), Magurran and McGill (2011), N. J. Gotelli and Ellison (2013), Zar (2010), Zuur, Ieno, and Elphick (2009a), Crawley (2012) e James et al. (2013). 2.4 Por que usar o R? Os criadores do R o chamam de uma linguagem e ambiente de programa√ß√£o estat√≠stica e gr√°fica (Venables and Ripley 2002). A linguagem R tamb√©m √© chamada de programa√ß√£o ‚Äúorientada ao objeto‚Äù (object oriented programming), o que significa que utilizar o R envolve basicamente a cria√ß√£o e manipula√ß√£o de objetos em uma tela branca, em que o usu√°rio tem de dizer exatamente o que deseja que o programa execute, ao inv√©s de simplesmente clicar em bot√µes. E vem da√≠ uma das grandes vantagens em se usar o R: o usu√°rio tem total controle sobre o que est√° acontecendo e tamb√©m tem de compreender o que deseja antes de executar uma an√°lise. Al√©m disso, o R permite integra√ß√£o com outros programas escritos em C++, Python e Java, permitindo que os usu√°rios possam aplicar novas metodologias sem ter que aprender novas linguagens. Na p√°gina pessoal do Prof.¬†Nicolas J. Gotelli (link), existem v√°rios conselhos para um estudante iniciante de ecologia. Dentre esses conselhos, o Prof.¬†Gotelli menciona que o dom√≠nio de uma linguagem de programa√ß√£o √© uma das habilidades mais importantes, porque d√° liberdade ao ec√≥logo para executar tarefas que v√£o al√©m daquelas dispon√≠veis em pacotes estat√≠sticos comerciais. Al√©m disso, a maioria das novas an√°lises propostas nos mais reconhecidos peri√≥dicos em ecologia normalmente s√£o implementadas em linguagem R, e os autores incluem normalmente o c√≥digo fonte no material suplementar dos artigos, tornando a an√°lise acess√≠vel. A partir do momento que essas an√°lises ficam dispon√≠veis (seja por c√≥digo fornecido pelo autor ou por implementa√ß√£o em pacotes pr√©-existentes), √© mais simples entendermos a l√≥gica de an√°lises complexas, especialmente as multivariadas, utilizando nossos pr√≥prios dados, realizando-as passo a passo. Sem a utiliza√ß√£o do R, normalmente temos que contatar os autores que nem sempre s√£o t√£o acess√≠veis. Uma √∫ltima vantagem √© que por ser um software livre, a cita√ß√£o do R em artigos √© permitida e at√© aconselh√°vel. Para saber como citar o R, digite citation() na linha de comando. Para citar um pacote espec√≠fico, digite citation() com o nome do pacote entre aspas dentro dos par√™nteses. Neste ponto, esperamos ter convencido voc√™ leitor, de que aprender a utilizar o R tem in√∫meras vantagens. Entretanto, provavelmente vai ser dif√≠cil no come√ßo, mas continue e perceber√° que o investimento vai valer √† pena no futuro. 2.5 Indo al√©m da linguagem de progra√ß√£o para a Ecologia Um ponto em comum em que todos os autores deste livro concordaram em conversas durante sua estrutura√ß√£o, foi a dificuldade que todos tivemos quando est√°vamos aprendendo a linguagem: Como transcrever os objetivos (manipula√ß√£o de dados, an√°lises e gr√°ficos) em linguagem R Como interpretar os resultados das an√°lises estat√≠sticas do R para os objetivos ecol√≥gicos Num primeiro momento, quando estamos aprendendo a linguagem R √© muito desafiador pensar em como estruturar nossos c√≥digos para que eles fa√ßam o que precisamos: importar dados, selecionar linhas ou colunas, qual pacote ou fun√ß√£o usar para uma certa an√°lise ou como fazer um gr√°fico que nas nossas anota√ß√µes s√£o simples, mas no c√≥digo parece imposs√≠vel. Bem, n√£o h√° um caminho f√°cil nesse sentido e ele depende muito da experi√™ncia e familiaridade adquirida com o tempo de uso da linguagem, assim como outra l√≠ngua qualquer, como ingl√™s ou espanhol. Entretanto, uma dica pode ajudar: estruture seus c√≥digos antes de partir para o R. Num papel escreva os pontos que quer que seus c√≥digos fa√ßam, como se estivesse explicando para algu√©m os passos que precisa para realizar as tarefas. Depois disso, transcreva para o script (iremos explicar esse conceito no @[cap4]) esse texto. Por fim, traduza isso em linguam R. Pode parecer massante e cansativo no come√ßo, mas isso o ajudar√° a ter maior dom√≠nio da linguagem, sendo que esse passo se torna desnecess√°rio quando se adquire bastante experi√™ncia. Uma vez transposta esse barreira inicial e temos os resultados de nossas an√°lises (valores de estat√≠sticas, par√¢metros estimados, valores de p e R¬≤, etc.), com gr√°ficos e outras figuras que precisamos, como interpretamos √† luz da teoria ecol√≥gica? Esse ponto √© talvez um dos mais complicados. Com o tempo, ter um valor final de uma estat√≠stica ou gr√°fico √† partir da linaguagem R √© relativamente simples, mas o que esse valor ou gr√°fico significam para nossa hip√≥tese ecol√≥gica √© o ponto mais complicado. Essa dificuldade por ser por inexperi√™ncia te√≥rica (ainda n√£o lemos muito sobre um aspecto ecol√≥gico) ou inexperi√™ncia cient√≠fica (ainda temos dificuldade para expandir nossos argumentos de forma indutiva). Destacamos esse ponto porque ele √© fundamental no processo cient√≠fico e talvez seja o principal aspecto que diferencia os cientistas de outros profissionais: sua capacidade de entendimento dos padr√µes √† partir dos processos e mecanismos atrelados. Nesse ponto, quase sempre recorremos √† nossos orientadores ou colegas mais experientes para nos ajudar, mas √© natural e faz parte do processo de aprendizado de uso da linguagem R junto √† Ecologia como ci√™ncia. Entretanto, contrapomos a import√¢ncia dessa extrapola√ß√£o para n√£o nos tornarmos apenas especialistas em linguagem R sem a fundamental capacidade de entendimento do sistema ecol√≥gico que estamos estudando. 2.6 Como usar este livro Os conte√∫dos apresentados em cada cap√≠tulo s√£o independentes entre si. Portanto, voc√™ pode utilizar este livro de duas formas. A primeira √© seguir uma ordem sequencial (cap√≠tulos 1, 2, 3, ‚Ä¶) que recomendamos, principalmente, para as pessoas que n√£o possuem familiaridade com a linguagem R. A segunda forma, √© selecionar o cap√≠tulo que cont√©m a an√°lise de seu interesse e mudar de um cap√≠tulo para outro sem seguir a sequ√™ncia apresentada no livro. Com exce√ß√£o dos cap√≠tulos 3, 4, 5 e 15, os outros cap√≠tulos foram elaborados seguindo a mesma estrutura contendo uma descri√ß√£o da an√°lise estat√≠stica (aspecto te√≥ricos) e exemplos relacionados com quest√µes ec√≥logicas que podem ser respondidas por esta an√°lise. Todos os exemplos s√£o compostos por: i) uma descri√ß√£o dos dados utilizados, ii) pergunta e predi√ß√£o do trabalho, iii) descri√ß√£o das vari√°veis resposta(s) e preditora(s), e iv) descri√ß√£o e explica√ß√£o das linhas de comando do R necess√°rias para realiza√ß√£o das an√°lises. Os exemplos utilizados s√£o baseados em dados reais que j√° foram publicados em artigos cient√≠ficos ou s√£o dados coletados por um dos autores deste livro. N√≥s recomendamos que primeiro voc√™ utilize estes exemplos para se familiarizar com as an√°lises e a formata√ß√£o das linhas e colunas das planilhas. Em seguida, utilize seus pr√≥prios dados para realizar as an√°lises. Esta √© a melhor maneira de se familiarizar com as linhas de comando do R. Muitas das m√©tricas ou √≠ndices apresentados neste livro n√£o foram traduzidas para o portugu√™s, porque seus acr√¥nimos s√£o cl√°ssicos e bem estabelecidos na literatura ecol√≥gica. Nestes casos, consideramos que a tradu√ß√£o poderia confundir as pessoas que est√£o come√ßando a se familiarizar com a literatura espec√≠fica. Real√ßamos que n√£o estamos abordando todas as possibilidades dispon√≠veis, e existem muito outros pacotes e fun√ß√µes no R que realizam as mesmas an√°lises. Contudo, esperamos que o conte√∫do apresentado permita que os leitores adquiram independ√™ncia e seguran√ßa, para que possam caminhar sozinhos na explora√ß√£o de novos pacotes e fun√ß√µes para responderem suas perguntas biol√≥gicas e ecol√≥gicas. Refer√™ncias "],["cap3.html", "Cap√≠tulo 3 Voltando ao b√°sico: como dominar a arte de fazer perguntas cientificamente relevantes 3.1 Introdu√ß√£o 3.2 Perguntas devem preceder as an√°lises estat√≠sticas 3.3 Fluxograma: Conectando Vari√°veis para Melhorar o desenho experimental e as an√°lises estat√≠sticas 3.4 Quest√µes fundamentais em etnobiologia, ecologia e conserva√ß√£o 3.5 Considera√ß√µes Finais 3.6 Refer√™ncias", " Cap√≠tulo 3 Voltando ao b√°sico: como dominar a arte de fazer perguntas cientificamente relevantes Cap√≠tulo originalmente publicado por Gon√ßalves-Souza, Provete, Garey, Silva &amp; Albuquerque (2019), in Methods and Techniques in Ethnobiology and Ethnoecology (tradu√ß√£o autorizada por Springer). 3.1 Introdu√ß√£o Aquele que ama a pr√°tica sem teoria √© como um marinheiro que embarca em um barco sem um leme e uma b√∫ssola e nunca sabe onde pode atracar - Leonardo da Vinci. Qual √© a sua pergunta? Talvez esta seja a frase que pesquisadores mais jovens ouvem quando come√ßam suas atividades cient√≠ficas. Apesar de aparentemente simples, responder a esta pergunta se torna um dos maiores desafios da forma√ß√£o cient√≠fica. Seja na pesquisa quantitativa ou qualitativa, todo processo de busca de conhecimento parte de uma quest√£o/problema formulada pelo pesquisador no in√≠cio desse processo. Esta quest√£o guiar√° o pesquisador em todas as etapas da pesquisa. No caso espec√≠fico de pesquisa quantitativa, a quest√£o √© a porta de entrada de uma das formas mais poderosas de pensar cientificamente: o m√©todo hipot√©tico-dedutivo (MHD) definido por Karl Popper (1959). Este cap√≠tulo prop√µe uma maneira de pensar sobre hip√≥teses (geradas dentro do MHD) para melhorar o pensamento estat√≠stico usando um fluxograma que relaciona vari√°veis por liga√ß√µes causais. Al√©m disso, argumentamos que voc√™ pode facilmente usar fluxogramas para (1) identificar vari√°veis relevantes e como elas afetam umas √†s outras; (2) melhorar (quando necess√°rio) o desenho experimental/observacional; (3) facilitar a escolha de an√°lises estat√≠sticas; e (4) melhorar a interpreta√ß√£o e comunica√ß√£o dos dados e an√°lises. 3.2 Perguntas devem preceder as an√°lises estat√≠sticas 3.2.1 Um besti√°rio1 para o teste de hip√≥teses (Voc√™ est√° fazendo a pergunta certa?) A maioria dos alunos e professores de ci√™ncias biol√≥gicas possuem avers√£o √† palavra ‚Äúestat√≠stica.‚Äù N√£o surpreendentemente, enquanto a maioria das disciplinas acad√™micas que comp√µem o ‚ÄúSTEM‚Äù (termo em ingl√™s para aglomerar Ci√™ncia, Tecnologia, Engenharia e Matem√°tica) t√™m uma s√≥lida forma√ß√£o estat√≠stica durante a gradua√ß√£o, cursos de ci√™ncias biol√≥gicas t√™m um curr√≠culo fraco ao integrar o pensamento estat√≠stico dentro de um contexto biol√≥gico (Metz 2008). Esses cursos t√™m sido frequentemente ministrados sem qualquer abordagem pr√°tica para integrar os alunos em uma plataforma de solu√ß√£o de problemas (Horgan et al. 1999). Infelizmente, a Etnobiologia, Ecologia e Conserva√ß√£o (daqui em diante EEC) n√£o s√£o exce√ß√µes. Talvez mais importante, uma grande preocupa√ß√£o durante o treinamento estat√≠stico de estudantes de EEC √© a necessidade de trabalhar com problemas complexos e multidemensionais que exigem solu√ß√µes anal√≠ticas ainda mais complicadas para um p√∫blico sem experi√™ncia em estat√≠stica e matem√°tica. Por este motivo, muitos pesquisadores consideram a estat√≠stica como a parte mais problem√°tica de sua pesquisa cient√≠fica. Argumentamos neste cap√≠tulo que a dificuldade de usar estat√≠stica em EEC est√° associada √† aus√™ncia de uma plataforma de solu√ß√£o de problemas gerando hip√≥teses claras que s√£o derivadas de uma teoria. No entanto, concordamos que h√° um grande desafio em algumas disciplinas como a Etnobiologia para integrar esta abordagem direcionada por hip√≥teses, uma vez que foi introduzida apenas recentemente [veja Phillips and Gentry (1993); phillips_useful_1993-1; U. P. Albuquerque and Hanazaki (2009)]. Devido √† falta de uma plataforma de solu√ß√£o de problemas, frequentemente percebemos que alunos/pesquisadores na EEC geralmente t√™m dificuldades de responder perguntas b√°sicas para uma pesquisa cient√≠fica, tais como: Qual √© a principal teoria ou racioc√≠nio l√≥gico do seu estudo? Qual √© a quest√£o principal do seu estudo? Qual √© a sua hip√≥tese? Quais s√£o suas predi√ß√µes? Qual √© a unidade amostral, vari√°vel independente e dependente de seu trabalho? Existe alguma covari√°vel? Qual √© o grupo controle? Como selecionar qualquer teste estat√≠stico sem responder a essas cinco perguntas? A estrutura estat√≠stica frequentista fornece uma maneira de ir progressivamente suportando ou falseando uma hip√≥tese (Neyman and Pearson 1933; Popper 1959). A decis√£o de rejeitar uma hip√≥tese nula √© feita usando um valor de probabilidade (geralmente P &lt; 0,05) calculado pela compara√ß√£o de eventos observados com observa√ß√µes repetidas obtidas a partir de uma distribui√ß√£o nula. Agora, vamos ensinar atrav√©s de um exemplo e apresentar um ‚Äúguia para o pensamento estat√≠stico‚Äù que conecta alguns elementos essenciais para executar qualquer an√°lise multivariada (ou univariada) Underwood (1997). Primeiro, imagine que voc√™ observou os seguintes fen√¥menos na natureza: (1) ‚Äúindiv√≠duos de uma popula√ß√£o tradicional selecionar algumas plantas para fins m√©dicos‚Äù e (2)‚Äúmanchas monodominantes da √°rvore Prosopis juliflora, uma esp√©cie invasora em v√°rias regi√µes.‚Äù Do lado da etnobiologia, para entender como e porque o conhecimento tradicional √© constru√≠do, existe uma teoria ou hip√≥tese (por exemplo, hip√≥tese de apar√™ncia: Gon√ßalves, Albuquerque, and Medeiros 2016) explicando os principais processos que ditam a sele√ß√£o da planta (Fig. 3.1a).Ent√£o, voc√™ pode fazer uma ou mais perguntas relacionadas √†quele fen√¥meno observado (Fig. 3.1b). Por exemplo, como a urbaniza√ß√£o afeta o conhecimento das pessoas sobre o uso de plantas medicinais em diferentes biomas? Do lado ecol√≥gico/conserva√ß√£o, para entender por que esp√©cies introduzidas afetam as esp√©cies nativas locais, voc√™ precisa entender as teorias do nicho ecol√≥gico e evolutiva (MacDougall, Gilbert, and Levine 2009; Saul and Jeschke 2015). Voc√™ pode perguntar, por exemplo, como as plantas ex√≥ticas afetam a estrutura de comunidades de plantas nativas? Quest√µes complexas ou vagas dificultam a constru√ß√£o do fluxograma de pesquisa (ver descri√ß√£o abaixo) e a sele√ß√£o de testes estat√≠sticos. Em vez disso, uma pergunta √∫til deve indicar as vari√°veis relevantes do seu estudo, como as independentes e dependentes, covari√°veis, unidade de amostral e a escala espacial de interesse (Fig. 3.1b). No exemplo etnobiol√≥gico fornecido, a urbaniza√ß√£o e o conhecimento das pessoas s√£o as vari√°veis independentes e dependentes, respectivamente. Al√©m disso, este estudo tem uma escala ampla, pois compara biomas diferentes. A pr√≥xima etapa √© construir a hip√≥tese biol√≥gica (Fig. 3.1c), que indicar√° a associa√ß√£o entre vari√°veis independentes e dependentes. No exemplo etnobiol√≥gico, a hip√≥tese √© que (1) ‚Äúa urbaniza√ß√£o afeta o conhecimento das pessoas sobre o uso de plantas medicinais,‚Äù enquanto a hip√≥tese ecol√≥gica √© que (2) ‚Äúesp√©cies ex√≥ticas afetam a estrutura de comunidades de plantas nativas.‚Äù Observe que isso √© muito semelhante √† quest√£o principal. Mas voc√™ pode ter m√∫ltiplas hip√≥teses (Platt 1964) derivado de uma teoria. Depois de selecionar a hip√≥tese biol√≥gica (ou cient√≠fica), √© hora de pensar sobre a deriva√ß√£o l√≥gica da hip√≥tese, que √© chamada de predi√ß√£o ou previs√£o (Fig. 3.1d). Os padr√µes preditos s√£o uma etapa muito importante, pois ap√≥s defini-los voc√™ pode operacionalizar suas vari√°veis e visualizar seus dados. Por exemplo, a vari√°vel te√≥rica ‚ÄúUrbaniza√ß√£o‚Äù pode ser medida como ‚Äúgrau de urbaniza√ß√£o ao longo das √°reas urbanas, periurbanas e rurais‚Äù e ‚Äúconhecimento das pessoas‚Äù como ‚Äúo n√∫mero e tipo de esp√©cies de plantas √∫teis usadas para diferentes doen√ßas.‚Äù Assim, a predi√ß√£o √© que o grau de urbaniza√ß√£o diminua o n√∫mero e tipo de esp√©cies de plantas conhecidas utilizadas para fins medicinais. No exemplo ecol√≥gico, a vari√°vel ‚Äúesp√©cies ex√≥ticas‚Äù pode ser medida como ‚Äúa densidade da planta ex√≥tica Prosopis juliflora‚Äù e ‚ÄúEstrutura da comunidade‚Äù como ‚Äúriqueza e composi√ß√£o de esp√©cies nativas.‚Äù Depois de operacionalizar o seu trabalho √† luz do m√©todo hipot√©tico-dedutivo (HDM), o pr√≥ximo passo √© ‚Äúpensar estatisticamente‚Äù sobre a hip√≥tese biol√≥gica formulada (ver Figura 3.1 e, f). Figura 3.1: Um guia para o pensamento estat√≠stico combinando o m√©todo hipot√©tico-dedutivo (a ‚Äì d, i) e estat√≠stica frequentista (e ‚Äì i). Veja tamb√©m a Fig. 1 em Underwood 1997, Fig. 1 em Ford 2004 e Fig. 1.3 em Legendre &amp; Legendre 2012. Ent√£o, voc√™ precisa definir as hip√≥tese estat√≠stica nula (H0) e a alternativa (H1). Duas ‚Äúhip√≥teses estat√≠sticas‚Äù diferentes podem ser derivadas de uma hip√≥tese biol√≥gica (Fig. 3.1e). Portanto, n√≥s usamos o termo ‚Äúhip√≥tese estat√≠stica‚Äù entre aspas, porque as chamadas hip√≥teses estat√≠sticas s√£o predi√ß√µes sensu stricto, e muitas vezes confundem jovens estudantes. A hip√≥tese estat√≠stica nula representa uma aus√™ncia de relac√£o entre as vari√°veis independentese e dependentes. Depois de definir a hip√≥tese estat√≠stica nula, voc√™ pode derivar uma ou v√°rias hip√≥teses estat√≠sticas alternativas, que demonstram a(s) associa√ß√£o(√µes) esperada(s) entre suas vari√°veis (Fig. 3.1e). Em nosso exemplo, a hip√≥tese nula √© que ‚Äúo grau de urbaniza√ß√£o n√£o afeta o n√∫mero de esp√©cies de plantas √∫teis conhecidas pela popula√ß√£o local.‚Äù Por sua vez, a hip√≥tese alternativa √© que ‚Äúo grau de urbaniza√ß√£o afeta o n√∫mero de esp√©cies de plantas √∫teis conhecidas pela popula√ß√£o local.‚Äù Depois de operacionalizar suas vari√°veis e definir o valor nulo e hip√≥teses alternativas, √© hora de visualizar o resultado esperado (Fig. 3.2, Caixa 1) e escolher um m√©todo estat√≠stico adequado. Por exemplo, se voc√™ deseja comparar a diferen√ßa na composi√ß√£o de plantas √∫teis entre √°reas urbanas, periurbanas e rurais, voc√™ pode executar uma PERMANOVA (Gon√ßalves-Souza, Garey, et al. 2019) que usa uma estat√≠stica de teste chamada pseudo-F. Ent√£o, voc√™ deve escolher o limite de probabilidade (o valor P) do teste estat√≠stico para decidir se a hip√≥tese nula deve ou n√£o deve ser rejeitada (Nicholas J. Gotelli and Ellison 2012). Se voc√™ encontrar um P &lt; 0,05, voc√™ deve rejeitar a hip√≥tese estat√≠stica nula (urbaniza√ß√£o n√£o afeta o n√∫mero e a composi√ß√£o das plantas). Por outro lado, um P &gt; 0,05 indica que voc√™ n√£o pode rejeitar a hip√≥tese nula estat√≠stica. Assim, a estat√≠stica do teste e o valor P representam a √∫ltima parte do teste de hip√≥tese estat√≠stica, que √© a decis√£o e conclus√µes apropriadas que ser√£o usadas para retroalimentar a teoria principal (Figura 3.1g ‚Äì i). Generalizando seus resultados e falseando (ou n√£o) suas hip√≥teses, o estudo busca refinar a constru√ß√£o conceitual da teoria, que muda constantemente (Fig. 1i, Ford 2004). No entanto, h√° um ponto cr√≠tico nesta √∫ltima frase, porque a signific√¢ncia estat√≠stica n√£o significa necessariamente relev√¢ncia biol√≥gica Mart√≠nez-Abra√≠n (2008). Nas palavras de Ford (2004): ‚Äúas estat√≠sticas s√£o usadas para iluminar o problema, e n√£o para apoiar uma posi√ß√£o.‚Äù Al√©m disso, o procedimento de teste de hip√≥tese tem alguma incerteza, que pode influenciar resultados ‚Äúfalso-positivos‚Äù (erro tipo 1) e ‚Äúfalso-negativos‚Äù (erro tipo 2) (Whitlock and Schluter 2015). Para simplificar, n√£o discutiremos em detalhes os pr√≥s e contras da estat√≠stica frequentista, bem como m√©todos alternativos (por exemplo, Bayesiano e M√°xima Verossimilhan√ßa), e quest√µes filos√≥ficas relativas ao ‚Äúvalor P‚Äù (para uma discuss√£o sobre esses t√≥picos, consulte o f√≥rum em Ellison et al. 2014). Caixa 1. Tipo de vari√°veis e visualiza√ß√£o de dados Conforme descrito na Se√ß√£o 3, o fluxograma √© essencial para conectar vari√°veis relevantes para a pesquisa. Para aproveitar ao m√°ximo esta abordagem, voc√™ pode desenhar suas pr√≥prias predi√ß√µes gr√°ficas para te ajudar a pensar sobre diferentes possibilidades anal√≠ticas. Aqui, n√≥s fornecemos uma descri√ß√£o completa dos tipos de vari√°veis que voc√™ deve saber antes de executar qualquer an√°lise estat√≠stica e representar seus resultados. Al√©m disso, mostramos uma breve galeria (Fig. 3.2) com exemplos de boas pr√°ticas em visualiza√ß√£o de dados (Fig. 3.3b, veja tamb√©m figuras em Gon√ßalves-Souza, Garey, et al. 2019). Al√©m de conectar diferentes vari√°veis no fluxograma, voc√™ deve distinguir o tipo de vari√°vel. Primeiro voc√™ deve identificar as vari√°veis independentes (tamb√©m conhecidos como explicativas ou preditoras) e dependentes (tamb√©m conhecidas como resposta). A vari√°vel independente √© aquela (ou aquelas) que prev√™ ou afeta a vari√°vel resposta (por exemplo, a fertilidade do solo √© a vari√°vel independente capaz de afetar a abund√¢ncia de uma esp√©cie de planta focal, a vari√°vel dependente). Al√©m disso, uma covari√°vel √© uma vari√°vel cont√≠nua que pode afetar tanto a vari√°vel resposta quanto a independente (ou ambos), mas geralmente n√£o √© do interesse do pesquisador. Depois de definir as vari√°veis relevantes, conectando-as no fluxograma, √© hora de diferenciar seu tipo: (1) quantitativa ou cont√≠nua, e (2) categ√≥rica ou qualitativa (Fig. 3.2a, Caixa 1). O tipo de vari√°vel ir√° definir que tipo de figura voc√™ pode selecionar. Por exemplo, se voc√™ est√° comparando duas vari√°veis cont√≠nuas ou uma vari√°vel cont√≠nua e uma bin√°ria, a melhor maneira de visualiz√°-los (Fig. 3.2b) √© um gr√°fico de dispers√£o (Fig. 3.2c, d). A linha representa os valores preditos pelo modelo estat√≠stico usado (por exemplo, linear, log√≠stico). Se voc√™ est√° interessado em comparar a gama de diferentes atributos (ou a descri√ß√£o de qualquer vari√°vel num√©rica) entre as vari√°veis categ√≥ricas (por exemplo, esp√©cies ou popula√ß√µes locais), um gr√°fico de halteres (do ingl√™s Dumbbell plot) √© uma boa op√ß√£o (Fig. 3.2e). Histogramas tamb√©m podem ser usados para mostrar a distribui√ß√£o de duas vari√°veis cont√≠nuas de dois grupos ou fatores (Fig. 3.2f). No entanto, se voc√™ quiser testar o efeito de uma vari√°vel categ√≥rica independente (como em um desenho de ANOVA) sobre uma vari√°vel dependente, boxplots (Fig. 3.2g) ou gr√°ficos de violino podem resumir essas rela√ß√µes de maneira elegante. Conjuntos de dados multivariados, por sua vez, podem ser visualizados com ordena√ß√£o (Fig. 3.2h) ou gr√°ficos de agrupamento (n√£o mostrados). Existe um site abrangente apresentando v√°rias maneiras de visualizar dados chamado https://www.datavizproject.com/. Figura 3.2: (A) Tipos de vari√°veis e (B) visualiza√ß√£o de dados para representar a rela√ß√£o entre vari√°veis independentes e dependentes ou covari√°veis. 3.3 Fluxograma: Conectando Vari√°veis para Melhorar o desenho experimental e as an√°lises estat√≠sticas McIntosh e Pontius (2017) afirmaram que o pensamento estat√≠stico (representado na Fig. 3.1 inclui quatro etapas importantes: (1) quais perguntas voc√™ investigaria (Se√ß√£o 4), (2) como e onde coletar os dados (Ruxton and Colegrave 2016), (3) quais fatores devem ser considerados e como eles afetam suas vari√°veis de interesse (e como elas afetam umas √†s outras), e (4) qual an√°lise estat√≠stica voc√™ deve usar e como interpretar e comunicar os resultados (Se√ß√£o 4). No entanto, a etapa (3) deve ser feita antes de coletar os dados. Por exemplo, se voc√™ est√° interessado na investiga√ß√£o dos benef√≠cios das matas ciliares para as esp√©cies nativas de peixes, quais vari√°veis devem ser inclu√≠das no estudo? Se voc√™ escolher rios com e sem mata ciliar como √∫nica vari√°vel preditora, seu projeto de amostragem ir√° omitir outras vari√°veis de confus√£o, como ordem do rio e carbono org√¢nico do solo a montante. Vellend (2016) nomeou este problema como o ‚Äúproblema de tr√™s caixas‚Äù (ver tamb√©m Ruxton and Colegrave 2016) , que se refere √† limita√ß√£o em inferir que X (vari√°vel independente) causa varia√ß√£o em Y (vari√°vel depende) quando outras vari√°veis criam ou ampliam a correla√ß√£o entre X e Y (ver Fig. 2 em Ruxton and Colegrave 2016). Uma ferramenta √∫til para compreender a rela√ß√£o entre todas as vari√°veis relevantes do seu estudo √© um fluxograma. No ‚Äúfluxograma de pesquisa‚Äù [ver tamb√©m magnusson_statistics_2015] proposto aqui, vari√°veis dependentes (tamb√©m conhecidas como resposta) e independentes (ou preditora), bem como covari√°veis s√£o representadas como caixas (com formas distintas: Fig. 3.3). Al√©m disso, voc√™ pode usar uma seta para representar uma (poss√≠vel) via causal indicando for√ßa e sinal (positivo ou negativo) da vari√°vel preditora na vari√°vel dependente (Fig. 3.3) Ao fazer isso, voc√™ pode melhorar o desenho experimental ou observacional incluindo ou controlando vari√°veis de confus√£o o que, por sua vez, pode ajudar a separar a contribui√ß√£o relativa de diferentes vari√°veis preditoras em seu sistema. Mais importante, fazer conex√µes entre vari√°veis melhora sua capacidade de visualizar o ‚ÄúQuadro geral‚Äù de sua pesquisa, o que pode afetar seu experimento, an√°lise estat√≠stica e revis√£o da literatura. Na verdade, Arlidge et al. (2017)argumentam que fluxogramas facilitam a constru√ß√£o de narrativas, melhorando: (1) a defini√ß√£o de m√∫ltiplas hip√≥teses, (2) coleta, interpreta√ß√£o e dissemina√ß√£o de dados e (3) a comunica√ß√£o do conte√∫do do estudo. Voc√™ tamb√©m pode ler o livro de Magnusson et al. (2015) para entender mais como usar fluxogramas para auxiliar an√°lises estat√≠sticas. Al√©m disso, Ford (2004) recomenda o uso de uma abordagem anal√≠tica para fomentar o desenvolvimento da pesquisa. Al√©m disso, o fluxograma de pesquisa pode ser usado como uma ferramenta forte para contemplar os conselhos de Ford (2004), que foram: (1) definir a pergunta da pesquisa, (2) definir a teoria a ser usada, (3) definir a t√©cnica de investiga√ß√£o (por exemplo, experimento, observa√ß√£o de campo), (4) definir as medi√ß√µes, (5) definir como fazer infer√™ncia, e (6) interpretar, generalizar,e sintetizar a partir de dados que, por sua vez, s√£o usados para refinar a teoria e modificar (quando necess√°rio) quest√µes futuras (Fig. 3.1). Figura 3.3: Exemplo de como usar um fluxograma para melhorar o entendimento do sistema estudado. A pergunta te√≥rica ‚ÄúQual √© o impacto da invas√£o na comunidade nativa e nas propriedades do ecossistema?‚Äù pode gerar duas predi√ß√µes: (1) a planta ex√≥tica Prosopis juliflora reduz a diversidade beta de comunidades de plantas nativas, e (2) Prosopis juliflora modifica a composi√ß√£o das comunidades de plantas e reduz o estoque de carbono e as taxas de decomposi√ß√£o. Ap√≥s selecionar suas predi√ß√µes, voc√™ pode construir um fluxograma conectando as vari√°veis relevantes e as associa√ß√µes entre elas. Al√©m disso, voc√™ pode usar as informa√ß√µes na Caixa 1 para identificar que tipo de vari√°vel voc√™ ir√° coletar e quais figuras podem ser usadas (b). 3.4 Quest√µes fundamentais em etnobiologia, ecologia e conserva√ß√£o As teorias s√£o generaliza√ß√µes. As teorias cont√™m perguntas. Para algumas teorias, as perguntas s√£o expl√≠citas e representam o que a teoria pretende explicar. Para outras, as quest√µes s√£o impl√≠citas e se relacionam com a quantidade e tipo de generaliza√ß√£o, dada a escolha de m√©todos e exemplos usados por pesquisadores na constru√ß√£o da teoria. As teorias mudam continuamente, √† medida que exce√ß√µes s√£o encontradas √†s suas generaliza√ß√µes e como quest√µes impl√≠citas sobre m√©todo e op√ß√µes de estudos s√£o expostas. - E. David Ford (2004) Como argumentamos antes, uma quest√£o relevante e test√°vel precede as an√°lises estat√≠sticas. Assim, apresentamos a seguir 12 quest√µes que podem estimular pesquisas futuras na ECC. Observe, no entanto, que n√£o queremos dizer que eles s√£o as √∫nicas quest√µes relevantes a serem testadas na EEC (ver, por exemplo, Sutherland et al. (2013) para uma avalia√ß√£o completa da pesquisa de ponta em Ecologia; e Caixa 6.1 em Pickett et al. (2007)2). Especificamente, essas quest√µes s√£o muito amplas e podem ser desenvolvidas em perguntas, hip√≥teses e predi√ß√µes mais restritas. Depois de cada quest√£o te√≥rica, apresentamos um estudo que testou essas hip√≥teses bem como as vari√°veis relevantes que podem estimular estudos futuros. Como o uso da terra afeta a manuten√ß√£o da biodiversidade e a distribui√ß√£o de esp√©cies em diferentes escalas espaciais? Exemplo: V√°rios estudos em diferentes ecossistemas e escalas investigaram como o uso da terra afeta a biodiversidade. No entanto, destacamos um estudo comparando os efeitos globais do uso da terra (por exemplo, densidade populacional humana, paisagem para usos humanos, tempo desde a convers√£o da floresta) em esp√©cies terrestres (por exemplo, mudan√ßa l√≠quida na riqueza local, dissimilaridade composicional m√©dia) (Newbold et al. 2015). Qual √© o impacto da invas√£o bi√≥tica nas comunidades nativas e propriedades do ecossistema? Exemplo: Investigar como o estabelecimento de esp√©cies ex√≥ticas afetam a riqueza de esp√©cies do receptor, comunidades nativas, bem como como isso afeta a entrega do servi√ßos ecossit√™micos. Estudos anteriores controlaram a presen√ßa de esp√©cies invasoras ou registros hist√≥ricos comparados (estudos observacionais) dessas esp√©cies e como elas impactam a biodiversidade. Al√©m disso, h√° algum esfor√ßo em compreender os preditores de invasibilidade (por exemplo, produto interno bruto de regi√µes, densidade populacional humana, litoral continental e ilhas) Dawson et al. (2017). Como o decl√≠nio do predador de topo afeta a entrega de servi√ßos ecossist√™micos? Exemplo: Investigar como a remo√ß√£o de grandes carn√≠voros afeta o fornecimento de servi√ßos ecossist√™micos, como o sequestro de carbono, doen√ßas e controle de danos √†s colheitas. Estudos anteriores investigaram esta quest√£o controlando a presen√ßa de predadores de topo ou comparando registros hist√≥ricos (estudo observacionais) de esp√©cies e v√°rios preditores (por exemplo, perda e fragmenta√ß√£o de habitat, conflito entre humanos e esp√©cies ca√ßadas, utiliza√ß√£o para a medicina tradicional e superexplora√ß√£o de presas) (Ripple et al. 2014). Como a acidifica√ß√£o dos oceanos afeta a produtividade prim√°ria e teias alimentares em ecossistemas marinhos? Exemplo: Estudos recentes testaram os efeitos individuais e interativos da acidifica√ß√£o e do aquecimento do oceano nas intera√ß√µes tr√≥ficas em uma teia alimentar. A acidifica√ß√£o e o aquecimento foram manipulados pela mudan√ßa dos n√≠veis de CO2 e temperatura, respectivamente. Estudos anteriores demonstraram que eleva√ß√£o de CO2 e temperatura aumentou a produtividade prim√°ria e afetou a for√ßa do controle de cima para baixo exercido por predadores (Goldenberg et al. 2017). Como podemos reconciliar as necessidades da sociedade por recursos naturais com conserva√ß√£o da Natureza? Exemplo: Existe uma literatura crescente usando abordagens de paisagem para melhorar a gest√£o da terra para reconciliar conserva√ß√£o e desenvolvimento econ√¥mico. Os estudos possuem diversos objetivos, mas em geral eles usaram o engajamento das partes interessadas, apoio institucional, estruturas eficazes de governan√ßa como vari√°veis preditoras e melhorias ambientais (por exemplo, conserva√ß√£o do solo e da √°gua, cobertura vegetal) e socioecon√¥micas (renda, capital social, sa√∫de p√∫blica, emprego) como vari√°veis dependentes (Reed et al. 2017). Qual √© o papel das √°reas protegidas (UCs) para a manuten√ß√£o da biodiversidade e dos servi√ßos ecossist√™micos? Exemplo: Houve um trabalho consider√°vel na √∫ltima d√©cada comparando a efic√°cia das UCs para a conserva√ß√£o da biodiversidade. Embora esta quest√£o n√£o esteja completamente separada da quest√£o anterior, o desenho dos estudos √© relativamente distinto. Em geral, os pesquisadores contrastam o n√∫mero de esp√©cies e o fornecimento de servi√ßos ecossist√™micos (por exemplo, reten√ß√£o de √°gua e solo, sequestro de carbono) entre √°reas legalmente protegidas (UCs) e n√£o protegidas (Xu et al. 2017). Como integrar o conhecimento cient√≠fico e das pessoas locais para mitigar os impactos negativos das mudan√ßas clim√°ticas e do uso da terra na biodiversidade? Exemplo: Eventos clim√°ticos extremos podem ter forte impacto sobre rendimento agr√≠cola e produ√ß√£o de alimentos. Autores recentes t√™m argumentado que esse efeito pode ser mais forte para os pequenos agricultores. Estudos futuros podem investigar como a precipita√ß√£o e a temperatura afetam o rendimento agr√≠cola e como os agricultores tradicionais ou ind√≠genas lidam com esse impacto negativo. Sistemas de agricultura tradicional t√™m menor eros√£o do solo e emiss√µes de N2O / CO2 do que as monoculturas e, portanto, podem ser vistos como uma atividade de mitiga√ß√£o vi√°vel em um mundo em constante mudan√ßa (Niggli et al. 2009; Altieri and Nicholls 2017). Como as mudan√ßas clim√°ticas afetam a resili√™ncia e estrat√©gias adaptativas em sistemas socioecol√≥gicos? Exemplo: A mudan√ßa do clima altera tanto a pesca quanto a agricultura em todo o mundo, o que por sua vez obriga os humanos a mudar suas estrat√©gias de cultivo. Estudos recentes t√™m argumentado que a agricultura em alguns pa√≠ses enfrentar√° riscos com as mudan√ßas clim√°ticas. Esses estudos comparam diferentes sistemas de produ√ß√£o, de agricultura convencional a outros tipos empregados por popula√ß√µes locais. Por exemplo, h√° uma forte conex√£o entre (1) esp√©cies amea√ßadas e sobrepesca, (2) √≠ndice de desenvolvimento humano (IDH) e depend√™ncia m√©dia da pesca e aquicultura. Al√©m disso, h√° evid√™ncias de que a biodiversidade pode amortecer os impactos das mudan√ßas clim√°ticas aumentando a resili√™ncia da terra [Niggli et al. (2009); Altieri and Nicholls (2017); blanchard_linked_2017]. Uma abordagem interessante √© investigar como as popula√ß√µes locais lidam com esses desafios em termos de percep√ß√µes e comportamento. Como a invas√£o biol√≥gica afeta espacial e temporalmente a estrutura e funcionalidade dos sistemas s√≥cio-ecol√≥gicos? Exemplo: Muitos estudos demonstraram que esp√©cies invasoras t√™m consequ√™ncias biol√≥gicas, econ√¥micas e sociais negativas. Aqui, da mesma forma que a pergunta B, os pesquisadores controlaram a presen√ßa de esp√©cies invasoras ou utilizaram registros hist√≥ricos. No entanto, trabalhos recentes quantificam n√£o apenas a riqueza e composi√ß√£o de esp√©cies nativas, mas tamb√©m atributos funcionais de animais/vegetais que afetam diretamente o fornecimento de servi√ßos ecossist√™micos como abastecimento (comida, √°gua), regula√ß√£o (clima, controle de inunda√ß√µes), suporte (ciclagem de nutrientes, forma√ß√£o do solo) e cultural (ecoturismo, patrim√¥nio cultural) (Chaffin et al. 2016). Mas, esp√©cies invasoras podem provocar efeitos positivos no sistema s√≥cio-ecol√≥gico aumentando a disponibilidade de recursos naturais, impactando como as pessoas gerenciam e usam a biodiversidade local. Qual √© a rela√ß√£o entre as diversidades filogen√©tica e taxon√¥mica com a diversidade biocultural? Exemplo: Estudos recentes mostraram que existe um padr√£o filogen√©tico e taxon√¥mico nos recursos que as pessoas incorporam em seus sistemas s√≥cio-ecol√≥gicos, especialmente em plantas medicinais. Existe uma tend√™ncia para as pessoas, em diferentes partes do mundo, para usar plantas pr√≥ximas filogeneticamente para os mesmos prop√≥sitos. Aqui, os pesquisadores podem testar o quanto isso afeta a diversidade de pr√°ticas em um sistema s√≥cio-ecol√≥gico considerando o ambiente, bem como sua estrutura e fun√ß√µes [C. H. Saslis-Lagoudakis et al. (2012); saslis-lagoudakis_evolution_2014]. Quais vari√°veis ambientais e s√≥cio-pol√≠ticas mudam a estrutura e funcionalidade dos sistemas s√≥cio-ecol√≥gicos tropicais? Exemplo: Testar a influ√™ncia das mudan√ßas ambientais afetadas pela esp√©cie humana (por exemplo, fogo, explora√ß√£o madeireira, aquecimento) em esp√©cies-chave e, consequentemente, como esse efeito em cascata pode afetar outras esp√©cies e servi√ßos ecossist√™micos (por exemplo, armazenamento de carbono, ciclo da √°gua e din√¢mica do fogo) (Lindenmayer and Sato 2018). Os atributos das esp√©cies influenciam como as popula√ß√µes locais distinguem plantas ou animais √∫teis e n√£o-√∫teis? Exemplo: Investigar se a popula√ß√£o local possui prefer√™ncia ao selecionar esp√©cies de animais ou plantas. Voc√™ pode avaliar se grupos diferentes (por exemplo, turistas) ou popula√ß√µes locais (por exemplo, pescadores) selecionam esp√©cies com base em atributos das esp√©cies. Estudos recentes t√™m mostrado uma liga√ß√£o potencial entre planta (por exemplo, cor, folha, flora√ß√£o) e p√°ssaro (por exemplo, cor, vocalza√ß√£o) e alguns servi√ßos culturais do ecossistema, como est√©tica, recreativa e espiritual/religiosa (Goodness et al. 2016). Como voc√™ notou, as quest√µes eram mais te√≥ricas e, consequentemente, voc√™ pode derivar predi√µes test√°veis (usando vari√°veis) a partir delas (Figuras 1 e 3). Por exemplo, da quest√£o ‚ÄúComo o uso da terra afeta a manuten√ß√£o da biodiversidade e distribui√ß√£o de esp√©cies em diferentes escalas?‚Äù podemos derivar duas predi√ß√µes diferentes: (1) densidade populacional (vari√°vel operacional de uso da terra) muda a composi√ß√£o de esp√©cies e reduz a riqueza de esp√©cies na escala da paisagem (predi√ß√£o derivada da hip√≥tese da homogeneiza√ß√£o bi√≥tica: Solar et al. 2015); (2) a composi√ß√£o dos atributos funcionais das plantas √© diferente em remanescentes florestais com diferentes matrizes (cana-de-a√ß√∫car, gado, cidade, etc.). 3.5 Considera√ß√µes Finais Conte-me seus segredos E fa√ßa-me suas perguntas Oh, vamos voltar para o in√≠cio Correndo em c√≠rculos, perseguindo caudas Cabe√ßas em uma ci√™ncia √† parte Ningu√©m disse que seria f√°cil (‚Ä¶) Desfazendo en√≠gmas Quest√µes da ci√™ncia, ci√™ncia e progresso - O Cientista, Coldplay Este √© um trecho de uma m√∫sica da banda brit√¢nica de rock Coldplay, do √°lbum de 2002 A Rush of Blood to the Head. A letra √© uma compara√ß√£o incr√≠vel entre a ci√™ncia e os altos e baixos de um relacionamento fadado ao fraca√ßo. A banda traz uma mensagem surpreendentemente clara de que como cientistas, n√≥s (dever√≠amos) frequentemente fazer perguntas, voltar ao in√≠cio ap√≥s descobrir que est√°vamos errados (ou n√£o) e que corremos em c√≠rculos tentando melhorar nosso conhecimento. A banda descreveu de uma forma t√£o precisa o qu√£o c√≠clico (mas n√£o repetitivo) √© o m√©todo cient√≠fico. Como disse a can√ß√£o: n√£o √© f√°cil, mas aprender como fazer boas perguntas √© um passo essencial para a consolida√ß√£o do conhecimento. Ao incluir o teste de hip√≥tese no EEC, podemos ser mais precisos. Definitivamente, isso n√£o significa que a ci√™ncia descritiva seja in√∫til. Ao contr√°rio, o desenvolvimento da ECC e principalmente da Etnobiologia, foi constru√≠do sobre uma linha de frente descritiva, o que significa que foi valioso para a funda√ß√£o da Etnobiologia como disciplina consolidada [Group (2003); stepp_advances_2005]. No entanto, estudos recentes defendem que a etnobiologia deve dialogar com disciplinas com maior respaldo te√≥rico, como ecologia e biologia evolutiva para melhorar a pesquisa sobre biodiversidade (U. P. Albuquerque and Ferreira J√∫nior 2017). Por sua vez, incorporando o conhecimento local em ecologia e evolu√ß√£o ir√° certamente refinar seu pr√≥prio desenvolvimento, que em √∫ltima an√°lise beneficia a conserva√ß√£o biol√≥gica (C. Haris Saslis-Lagoudakis and Clarke 2013). Al√©m disso, h√° uma necessidade urgente de formar jovens pesquisadores em filosofia e metodologia da ci√™ncia, bem como comunica√ß√£o e produ√ß√£o cient√≠fica (U. Albuquerque P. 2013). Como coment√°rio final, acreditamos que a forma√ß√£o dos alunos em EEC precisa de uma reavalia√ß√£o que necessariamente volta aos conceitos e m√©todos b√°sicos. Assim, os pesquisadores podem combinar o m√©todo hipot√©tico-dedutivo com pensamento estat√≠stico usando um fluxograma de pesquisa para ir al√©m da descri√ß√£o b√°sica. Termo3 Defini√ß√£o Pressuposto Condi√ß√µes necess√°rias para sustentar uma hip√≥tese ou constru√ß√£oa teoria Hip√≥tese Afirma√ß√£o test√°vel derivada ou representando v√°rios componentes de uma teoria Mecanismo Intera√ß√£o direta de uma rela√ß√£o causal que resultaem um fen√¥meno Padr√£o Eventos repetidos, entidades recorrentes ou rela√ß√µes replicadasrela√ß√µes observadas no tempo ou no espa√ßo Fen√¥meno Um evento, entidade ou relacionamento observ√°vel Predi√ß√£o Uma declara√ß√£o de expectativa deduzida da l√≥gicaestrutura ou derivada da estrutura causal de um teoria Processo Um subconjunto de fen√¥menos em que os eventos seguem umoutro no tempo ou espa√ßo, que pode ou n√£o sercausalmente conectado. √â causa, mecanismo ou contens√£o explicando um padr√£o 3.6 Refer√™ncias Refer√™ncias "],["cap4.html", "Cap√≠tulo 4 Introdu√ß√£o ao R Pr√©-requisitos do cap√≠tulo 4.1 Contextualiza√ß√£o 4.2 R e RStudio 4.3 Funcionamento da linguagem R 4.4 Estrutura e manipula√ß√£o de objetos 4.5 Exerc√≠cios 4.6 Para se aprofundar", " Cap√≠tulo 4 Introdu√ß√£o ao R Pr√©-requisitos do cap√≠tulo Pacotes e dados que ser√£o utilizados nesse cap√≠tulo. ## Pacotes library(ecodados) library(devtools) library(knitr) 4.1 Contextualiza√ß√£o O objetivo desta se√ß√£o √© apresentar os aspectos b√°sicos da linguagem R para que qualquer pessoa possa realizar os principais passos para a an√°lise de dados utilizando essa linguagem. Abordaremos aqui as quest√µes b√°sicas sobre a linguagem R, como: 1) R e RStudio, 2) funcionamento da linguagem, 3) estrutura e manipula√ß√£o de objetos, 4) exerc√≠cios e 5) principais livros e material para se aprofundar nos seus estudos. Todo processo de aprendizagem torna-se mais efetivo quando a teoria √© combinada com a pr√°tica, ent√£o recomendamos fortemente que voc√™ leitor(a) acompanhe os c√≥digos e exerc√≠cios deste livro, ao mesmo tempo que os executa em seu computador e n√£o s√≥ os leia passivamente. Al√©m disso, se voc√™ tiver seus pr√≥prios dados √© muito importante tentar executar replicar an√°lises ou gr√°ficos. Por motivos de espa√ßo, n√£o abordaremos todas as quest√µes relacionadas ao uso da linguagem R nesta se√ß√£o. Logo, aconselhamos que voc√™ consulte o material sugerido no final desta se√ß√£o para se aprofundar. Este cap√≠tulo, na maioria das vezes, pode desestimular as pessoas que est√£o iniciando, uma vez que ele n√£o apresenta os c√≥digos para realizar as an√°lises estat√≠sticas. Contudo, ele √© essencial para o entendimento e interpreta√ß√£o do que est√° sendo informado nas linhas de c√≥digo, al√©m de facilitar a manipula√ß√£o dos dados antes de realizar as an√°lises estat√≠sticas. A leitora ou leitor vai perceber que n√£o usar√° este cap√≠tulo para fazer as an√°lises, mas voltar√° neste cap√≠tulo diversas vezes para relembrar qual √© o c√≥digo ou que significa determinada express√£o ou objeto usados nos pr√≥ximos cap√≠tulos. 4.2 R e RStudio Com o R, √© poss√≠vel manipular, analisar e visualizar dados, al√©m de escrever desde pequenas linhas de c√≥digos at√© programas inteiros. O R √© a vers√£o em c√≥digo aberto de uma linguagem de programa√ß√£o criada por John M. Chambers (Stanford University, CA, EUA) nos anos 1980 no Bell Labs, chamada de S, que contou com tr√™s vers√µes: Old S (1976-1987), New S (1988-1997) e S4 (1998), utilizada na IDE S-PLUS (1988-2008). Essa linguagem tornou-se bastante popular e v√°rios produtos comerciais que a usam est√£o dispon√≠veis, como o S-PLUS, SPSS, STATA e SAS. No final dos anos 1990, Robert Gentleman e Ross Ihaka (ambos da Universidade de Auckland, Nova Zel√¢ndia), iniciaram o desenvolvimento da vers√£o free da linguagem S, com o seguinte hist√≥rico: Desenvolvimento (1997-2000), Vers√£o 1 (2000-2004), Vers√£o 2 (2004-2013), Vers√£o 3 (2013-2020) e Vers√£o 4 (2020). Para mais detalhes do hist√≥rico de desenvolvimento das linguagens S e R, consultar Wickham (2013). Atualmente a linguagem R √© mantida por uma rede de colaboradores denominada R Core Team. A origem do nome R √© desconhecida, mas reza a lenda que ao lan√ßarem o nome da linguagem os autores se valeram da letra que vinha antes do S, uma vez que a linguagem R foi baseada nela e utilizaram a letra ‚ÄúR.‚Äù Outra hist√≥ria conta que pelo fato do nome dos dois autores iniciarem por ‚ÄúR,‚Äù batizaram a linguagem com essa letra. Um aspecto digno de nota √© que a linguagem R √© uma linguagem interpretada, ao contr√°rio de outras linguagens como Fortran e C que s√£o compiladas. Isso a faz ser mais f√°cil de programar, pois processa linhas de comando e as transforma em linguagem de m√°quina (c√≥digo bin√°rio que o computador efetivamente l√™), apesar desse fato diminuir a velocidade de processamento. Para come√ßarmos a trabalhar com o R √© necess√°rio baix√°-lo na p√°gina do R Project. Ent√£o, acesse esse site, e em seguida, clique no link download R, que o levar√° √† p√°gina do CRAN Mirrors (Comprehensive R Archive Network). Os detalhes de instala√ß√£o s√£o apresentados no @ref[cap1]. Reserve algum tempo para explorar esta p√°gina do R-Project. Existem v√°rios livros dedicados a diversos assuntos baseados no R. Al√©m disso, est√£o dispon√≠veis manuais em diversas l√≠nguas para serem baixados gratuitamente. Como o R √© um software livre, n√£o existe a possibilidade de o usu√°rio entrar em contato com um servi√ßo de suporte de usu√°rios, muito comuns em softwares pagos. Ao inv√©s disso, existem v√°rias listas de emails que fornecem suporte √† comunidade de usu√°rios. N√≥s, particularmente, recomendamos o ingresso nas seguintes listas: R-help, R-sig-ecology, e R-br. Este √∫ltimo re√∫ne um grupo de pessoas usu√°rias brasileiras do programa R. Apesar de podemos utilizar o R com o IDE (Ambiente de Desenvolvimento Integrado - Integrated Development Environment) RGui que vem com a instala√ß√£o da linguagem para usu√°rios Windows (Figura 4.1) ou no pr√≥prio terminal para usu√°rios Linux e MacOS, existem alguns IDEs espec√≠ficos para facilitar nosso uso dessa linguagem. Figura 4.1: Interface do RGui. Os n√∫meros indicam: (1) R Script, (2) R Console, e (3) R Graphics. Dessa forma, n√≥s que escrevemos utilizamos o RStudio e assumimos que voc√™ que est√° lendo far√° o mesmo. O RStudio permite diversas personaliza√ß√µes, grande parte delas contidas em Tools &gt; Global options. Incentivamos as leitoras e leitores a ‚Äúfu√ßar,‚Äù com certa dose de cuidado, nas op√ß√µes para customiza√ß√£o. Dentre essas mudan√ßas, destacamos duas: Tools &gt; Global options &gt; Appearance &gt; Editor theme para escolher um tema para seu RStudio Tools &gt; Global options &gt; Code &gt; [X] Soft-wrap R source files com essa op√ß√£o habilitada, quando escrevemos coment√°rios longos ou mudamos a largura da janela que estamos trabalhando, todo o texto e o c√≥digo se ajustam a janela automaticamente Um √∫ltimo ponto importante: para evitar poss√≠veis erros √© importante instalar primeiro o software que possui a linguagem R e depois o IDE RStudio. 4.3 Funcionamento da linguagem R Nesta se√ß√£o, veremos os principais conceitos para entender como a linguagem R funciona ou como geralmente utilizamos o IDE RStudio no dia a dia, para executar nossas rotinas utilizando a linguagem R. Veremos ent√£o: 1) console, 2) script, 3) operadores, 4) objetos, 5) fun√ß√µes, 6) pacotes, 7) ajuda (help), 8) ambiente (environment/workspace), 9) cita√ß√µes e 10) principais erros. Antes de iniciarmos o uso do R pelo RStudio √© fundamental entendermos alguns pontos sobre as janelas e o funcionamento delas no RStudio (Figura 4.2). Figura 4.2: Interface do RStudio. Os n√∫meros indicam: (1) janela com abas de Script, R Markdown, dentre outras; (2) janela com abas de Console, Terminal e Jobs; (3) janela com abas de Environment, History, Conections e Tutorial; e (4) janela com abas de Files, Plots, Packages, Help e Viewer. Detalhando algumas dessas janelas e abas, temos: Console: painel onde os c√≥digos s√£o rodados e vemos as sa√≠das Editor/Script: painel onde escrevemos nossos c√≥digos em R, R Markdown ou outro formato Environment: painel com todos os objetos criados na sess√£o History: painel com o hist√≥rico dos c√≥digos rodados Files: painel que mostra os arquivos no diret√≥rio de trabalho Plots: painel onde os gr√°ficos s√£o apresentados Packages: painel que lista os pacotes Help: painel onde a documenta√ß√£o das fun√ß√µes √© exibida No RStudio, alguns atalhos s√£o fundamentais para aumentar nossa produtividade: F1: abre o painel de Help quando digitado em cima de uma fun√ß√£o Ctrl + Enter: roda a linha de c√≥digo selecionada no script Ctrl + Shift + N: abre um novo script Ctrl + S: salva um script Ctrl + Z: desfaz uma opera√ß√£o Ctrl + Shift + Z: refaz uma opera√ß√£o Alt + -: insere um sinal de atribui√ß√£o (&lt;-) Ctrl + Shift + M: insere um operador pipe (%&gt;%) Ctrl + Shift + C: comenta uma linha no script - insere um (#) Ctrl + Shift + R: insere uma sess√£o (# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-) Ctrl + Shift + H: abre uma janela para selecionar o diret√≥rio de trabalho Ctrl + Shift + F10: reinicia o console Ctrl + L: limpa os c√≥digos do console Alt + Shift + K: abre uma janela com todos os atalhos dispon√≠veis 4.3.1 Console O console √© onde a vers√£o da linguagem R instalada √© carregada para executar os c√≥digos da linguagem R (Figura 4.2 (2)). Na janela do console aparecer√° o s√≠mbolo &gt; seguida de uma barra vertical | que fica piscando, onde digitaremos ou enviaremos nossos c√≥digos do script. Podemos fazer um pequeno exerc√≠cio: vamos digitar 10 + 2, seguido da tecla Enter para que essa opera√ß√£o seja executada. 10 + 2 #&gt; [1] 12 O resultado retorna o valor 12, precedido de um valor entre colchetes. Esses colchetes demonstram a posi√ß√£o do elemento numa sequ√™ncia de valores. Se fizermos essa outra opera√ß√£o 1:42, o R vai criar uma sequ√™ncia unit√°ria de valores de 1 a 42. A depender da largura da janela do console, vai aparecer um n√∫mero diferente entre colchetes indicando sua posi√ß√£o na sequ√™ncia: antes do 1 vai aparecer o [1], depois quando a sequ√™ncia for quebrada, vai aparecer o n√∫mero correspondente da posi√ß√£o do elemento, por exemplo, [26]. 1:42 #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #&gt; [31] 31 32 33 34 35 36 37 38 39 40 41 42 Podemos ver o hist√≥rico dos c√≥digos executados no Console na aba History (Figura 4.2 (3)). 4.3.2 Scripts Scripts s√£o rascunhos dos c√≥digos e onde de fato os c√≥digos s√£o escritos e depois enviados ao console (Figura 4.2 (1)). Scripts s√£o arquivos de texto simples, criados com a extens√£o (termina√ß√£o) .R (ative a visualiza√ß√£o da extens√£o de arquivos para ver). Para criar um script, basta ir em File &gt; New File &gt; R Script, ou clicando no √≠cone logo abaixo de File, ou ainda usando o atalho Ctrl + Shift + N. Tamb√©m √© poss√≠vel usar outro editor de c√≥digos, como o bloco de notas .txt, Sublime Text, Notepad++ e similares. Os c√≥digos podem ser escritos nesses editores e depois salvos com a extens√£o .R que ao ser aberto no RStudio ir√£o ser executados normalmente. Uma vez escrito os c√≥digos no script podemos rodar esses c√≥digos de duas formas: 1) todo o script de uma vez, clicando em Source ou usando o atalho Ctrl + Shift + Enter; ou 2) apenas a linha onde o cursor estiver posicionado, independente de sua posi√ß√£o naquela linha, clicando em Run ou usando o atalho Ctrl + Enter. Devemos sempre salvar nossos scripts, tomando por via de regra: primeiro criar o arquivo e depois ir salvando nesse mesmo arquivo a cada passo de desenvolvimento das an√°lises (n√£o √© raro o R fechar sozinho e voc√™ perder algum tempo de trabalho‚Ä¶). H√° diversos motivos para criar um script: continuar o desenvolvimento do mesmo em outro momento ou em outro computador, preservar trabalhos passados, ou ainda compartilhar seus c√≥digos com outra pessoa. Para criar ou salvar um script basta ir em File &gt; Save, escolher um diret√≥rio e nome para o script e salvar. Podemos ainda utilizar o atalho Ctrl + S. Em rela√ß√£o aos scripts, ainda h√° os coment√°rios, representados pelos s√≠mbolos # (hash) ou #' (hash-linha). A diferen√ßa entre eles √© que para o segundo, quando precionamos a tecla Enter o coment√°rio #' √© inserido automaticamente na linha seguinte. Linhas de c√≥digos do script contendo coment√°rios em seu in√≠cio n√£o s√£o lidos pelo console do R. Se o coment√°rio estiver no final da linha, essa linha de c√≥digo ainda ser√° lida. Os coment√°rios s√£o utilizados geralmente para: 1) descrever informa√ß√µes sobre dados ou fun√ß√µes e/ou 2) suprimir linhas de c√≥digo. √â interessante ter no in√≠cio de cada script um cabe√ßalho identificando o objetivo ou an√°lise, autor e data para facilitar o compartilhamento e reprodutibilidade. Os coment√°rios podem ser inseridos ou retirados das linhas com o atalho: Ctrl + Shift + C. #&#39; --- #&#39; T√≠tulo: Cap√≠tulo 04 - Introdu√ß√£o ao R #&#39; Autor: Maur√≠cio Vancine #&#39; Data: 20-05-2021 #&#39; --- Al√©m disso, podemos usar coment√°rios para adicionar informa√ß√µes sobre os c√≥digos. ## Coment√°rios # O R nao l√™ a linha do c√≥digo depois do # (hash). 42 # Essas palavras n√£o s√£o executadas, apenas o 42, a resposta para quest√£o fundamental da vida, o universo e tudo mais. #&gt; [1] 42 Por fim, outro ponto fundamental √© ter boas pr√°ticas de estilo de c√≥digo. Quanto mais organizado e padronizado estiver os scripts, mais f√°cil de entend√™-los e de procurar poss√≠veis erros. Existem dois guias de boas pr√°ticas para adequar seus scripts: Hadley Wickham e Google. Ainda temos os Code Snippets (Fragmentos de c√≥digo), que s√£o macros de texto usadas para inserir rapidamente fragmentos comuns de c√≥digo. Por exemplo, o snippet fun insere uma defini√ß√£o de fun√ß√£o R. Para mais detalhes, ler o artigo do RStudio: link. # fun {snippet} fun name &lt;- function(variables) { } Uma aplica√ß√£o bem interessante dos Code Snippets no script √© o ts. Basta digitar esse c√≥digo e em seguida completar um a tecla Tab para inserir rapidamente a data e hor√°rio atuais no script em forma de coment√°rio. # ts {snippet} # Mon Jul 26 11:25:03 2021 ------------------------------ 4.3.3 Operadores No R, temos cinco tipos de operadores: aritm√©ticos, relacionais, l√≥gicos, atribui√ß√£o e diversos. Grande parte deles s√£o descritos na Tabela 4.1. Tabela 4.1: Operadores no R. Operador Tipo Descri√ß√£o Aritm√©tico Adi√ß√£o Aritm√©tico Subtra√ß√£o Aritm√©tico Multiplica√ß√£o / Aritm√©tico Divis√£o %% Aritm√©tico Resto da divis√£o %/% Aritm√©tico Divis√£o inteira ^ ou ** Aritm√©tico Expoente &gt; Relacional Maior &lt; Relacional Menor &gt;= Relacional Maior ou igual &lt;= Relacional Menor ou igual == Relacional Igualdade != Relacional Diferen√ßa ! L√≥gico L√≥gico N√ÉO &amp; L√≥gico L√≥gico elementar E | L√≥gico L√≥gico elementar OU &amp;&amp; L√≥gico L√≥gico E || L√≥gico L√≥gico OU &lt;- ou = Atribui√ß√£o Atribui√ß√£o √† esquerda &lt;&lt;- Atribui√ß√£o Super atribui√ß√£o √† esquerda -&gt; Atribui√ß√£o Atribui√ß√£o √† direita -&gt;&gt; Atribui√ß√£o Super atribui√ß√£o √† direita : Diversos Sequ√™ncia unit√°ria %in% Diversos Elementos que pertencem a um vetor %*% Diversos Multiplicar matriz com sua transposta %&gt;% Diversos Pipe (pacote magrittr) |&gt; Diversos Pipe (R base nativo) %‚Äì% Diversos Intervalo de datas (pacote lubridate) Como exemplo, podemos fazer opera√ß√µes simples usando os operadores aritm√©ticos. ## Opera√ß√µes aritm√©ticas 10 + 2 # adi√ß√£o #&gt; [1] 12 10 * 2 # multiplica√ß√£o #&gt; [1] 20 Precisamos ficar atentos √† prioridade dos operadores aritm√©ticos: PRIORIT√ÅRIO () &gt; ^ &gt; * ou / &gt; + ou - N√ÉO PRIORIT√ÅRIO Veja no exemplo abaixo como o uso dos par√™nteses muda o resultado. ## Sem especificar a ordem # Segue a ordem dos operadores. 1 * 2 + 2 / 2 ^ 2 #&gt; [1] 2.5 ## Especificando a ordem # Segue a ordem dos parenteses. ((1 * 2) + (2 / 2)) ^ 2 #&gt; [1] 9 4.3.4 Objetos Objetos s√£o palavras √†s quais s√£o atribu√≠dos dados. A atribui√ß√£o possibilita a manipula√ß√£o de dados ou resultados de an√°lises. Utilizaremos os s√≠mbolos &lt; (menor), seguido de - (menos), sem espa√ßo, dessa forma &lt;-. Tamb√©m podemos utilizar o s√≠mbolo de igual (=), mas n√£o recomendamos, por n√£o fazer parte das boas pr√°ticas de escrita de c√≥digos em R. Podemos inserir essa combina√ß√£o de s√≠mbolos com o atalho Alt + -. Para demonstrar, vamos atribuir o valor 10 √† palavra obj_10, e chamar esse objeto novamente para verificar seu conte√∫do. ## Atribui√ß√£o - s√≠mbolo (&lt;-) obj_10 &lt;- 10 obj_10 #&gt; [1] 10 Todos os objetos criados numa sess√£o do R ficam listados na aba Environment (Figura 4.2 (3)). Al√©m disso, o RStudio possui a fun√ß√£o autocomplete, ou seja, podemos digitar as primeiras letras de um objeto (ou fun√ß√£o) e em seguida apertar Tab para que o RStudio liste tudo que come√ßar com essas letras. Dois pontos importantes sobre atribui√ß√µes: primeiro, o R sobrescreve os valores dos objetos com o mesmo nome, deixando o objeto com o valor da segunda atribui√ß√£o. ## Sobrescreve o valor dos objetos obj &lt;- 100 obj #&gt; [1] 100 ## O objeto &#39;obj&#39; agora vale 2 obj &lt;- 2 obj #&gt; [1] 2 Segundo, o R tem limita√ß√µes ao nomear objetos: nome de objetos s√≥ podem come√ßar por letras (a-z ou A-Z) ou pontos (.) nome de objetos s√≥ podem conter letras (a-z ou A-Z), n√∫meros (0-9), underscores (_) ou pontos (.) R √© case-sensitive, i.e., ele reconhece letras mai√∫sculas como diferentes de letras min√∫scula. Assim, um objeto chamado ‚Äúresposta‚Äù √© diferente do objeto ‚ÄúRESPOSTA‚Äù devemos evitar acentos ou cedilha (√ß) para facilitar a memoriza√ß√£o dos objetos e tamb√©m para evitar erros de encoding/codifica√ß√£o de caracteres nome de objetos n√£o podem ser iguais a nomes especiais, reservados para programa√ß√£o (break, else, FALSE, for, function, if, Inf, NA, NaN, next, repeat, return, TRUE, while) Podemos ainda utilizar objetos para fazer opera√ß√µes e criar objetos. Isso pode parecer um pouco confuso para os iniciantes na linguagem, mas √© fundamental aprender essa l√≥gica para passar para os pr√≥ximos passos. ## Definir dois objetos va1 &lt;- 10 va2 &lt;- 2 ## Opera√ß√µes com objetos e atribuic√£o adi &lt;- va1 + va2 adi #&gt; [1] 12 4.3.5 Fun√ß√µes Fun√ß√µes s√£o c√≥digos preparados para realizar uma tarefa espec√≠fica de modo simples. Outra forma de entender uma fun√ß√£o √©: c√≥digos que realizam opera√ß√µes em argumentos. A estrutura de uma fun√ß√£o √© muito similar √† sintaxe usada em planilhas eletr√¥nicas, sendo composta por: nome_da_fun√ß√£o(argumento1, argumento2, ‚Ä¶) Nome da fun√ß√£o: remete ao que ela faz Par√™nteses: limitam a fun√ß√£o Argumentos: valores, par√¢metros ou express√µes onde a fun√ß√£o atuar√° V√≠rgulas: separam os argumentos Os argumentos de uma fun√ß√£o podem ser de dois tipos: Valores ou objetos: a fun√ß√£o alterar√° os valores em si ou os valores atribu√≠dos aos objetos Par√¢metros: valores fixos que informam um m√©todo ou a realiza√ß√£o de uma opera√ß√£o. Informa-se o nome desse argumento, seguido de ‚Äú=‚Äù e um n√∫mero, texto ou TRUE ou FALSE Alguns exemplos de argumentos como valores ou objetos. ## Fun√ß√µes - argumentos como valores sum(10, 2) #&gt; [1] 12 ## Fun√ß√µes - argumentos como objetos sum(va1, va2) #&gt; [1] 12 Alguns exemplos de argumentos como par√¢metros. Note que apesar do valor do argumento ser o mesmo (10), seu efeito no resultado muda drasticamente. Aqui tamb√©m √© importante destacar um ponto: 1) podemos informar os argumentos sequencialmente, sem explicitar seus nomes, ou 2) independente da ordem, mas explicitando seus nomes. Entretanto, como no exemplo abaixo, devemos informar o nome do argumento (i.e., par√¢metro), para que seu efeito seja o que desejamos. ## Fun√ß√µes - argumentos como par√¢metros ## Repeti√ß√£o - repete todos os elementos rep(x = 1:5, times = 10) #&gt; [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 #&gt; [46] 1 2 3 4 5 ## Repeti√ß√£o - repete cada um dos elementos rep(x = 1:5, each = 10) #&gt; [1] 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 #&gt; [46] 5 5 5 5 5 Um ponto fundamental, e que deve ser entendido nesse ponto, √© o fluxo de atribui√ß√µes do resultado da opera√ß√£o de fun√ß√µes a novos objetos. No desenvolvimento de qualquer script na linguagem R, grande parte da estrutura do mesmo ser√° dessa forma: atribui√ß√£o de dados &gt; opera√ß√µes com fun√ß√µes &gt; atribui√ß√£o dos resultados a novos objetos &gt; opera√ß√µes com fun√ß√µes desses novos objetos &gt; atribui√ß√£o dos resultados a novos objetos‚Ä¶ Ao entender esse funcionamento, come√ßamos a entender como devemos pensar na organiza√ß√£o do nosso script para montar as an√°lises que precisamos. ## Atribuic√£o dos resultados ## Repeti√ß√£o rep_times &lt;- rep(1:5, times = 10) rep_times #&gt; [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 #&gt; [46] 1 2 3 4 5 ## Somar e atribuir rep_times_soma &lt;- sum(rep_times) rep_times_soma #&gt; [1] 150 ## Raiz e atribuir rep_times_soma_raiz &lt;- sqrt(rep_times_soma) rep_times_soma_raiz #&gt; [1] 12.24745 Por fim, √© fundamental tamb√©m entender a origem das fun√ß√µes que usamos no R. Todas as fun√ß√µes s√£o advindas de pacotes. Esses pacotes possuem duas origens. pacotes j√° instalados por padr√£o e que s√£o carregados quando abrimos o R (R Base) pacotes que instalamos e carregamos com fun√ß√µes 4.3.6 Pacotes Pacotes s√£o conjuntos extras de fun√ß√µes para executar tarefas espec√≠ficas, al√©m do R Base. Existe literalmente milhares de pacotes para as mais diversas tarefas: estat√≠stica, ecologia, geografia, sensoriamento remoto, econometria, ci√™ncias sociais, gr√°ficos, machine learning, etc. Podemos verificar este vasto conjunto de pacotes pelo link que lista por nome os pacotes oficiais, ou seja, que passaram pelo crivo do CRAN. Existem ainda muito mais pacotes em desenvolvimento, geralmente disponibilizados em reposit√≥rios do GitHub ou GitLab. Primeiramente, com uma sess√£o do R sem carregar nenhum pacote extra, podemos verificar pacotes carregados pelo R Base utilizando a fun√ß√£o search(). ## Verificar pacotes carregados search() Podemos ainda verificar todos pacotes instalados em seu computador com a fun√ß√£o library(). ## Verificar pacotes instalados library() No R, quando tratamos de pacotes, devemos destacar a diferen√ßa de dois conceitos: instalar um pacote e carregar um pacote. A instala√ß√£o de pacotes possui algumas caracter√≠sticas: Instala-se um pacote apenas uma vez Precisamos estar conectados √† internet O nome do pacote precisa estar entre aspas na fun√ß√£o Fun√ß√£o (CRAN): install.packages() Vamos instalar o pacote vegan diretamente do CRAN, que possui fun√ß√µes para realizar uma s√©rie de an√°lise em ecologia. Para isso, podemos ir em Tools &gt; Install Packages..., ou ir na aba Packages (Figura 4.2 (4)), procurar o pacote e simplesmente clicar em ‚ÄúInstall.‚Äù Podemos ainda utilizar a fun√ß√£o install.packages(). ## Instalar pacotes install.packages(&quot;vegan&quot;) Podemos conferir em que diret√≥rios um pacote ser√° instalado com a fun√ß√£o .libPaths(). ## Diret√≥rios de intala√ß√£o dos pacotes .libPaths() #&gt; [1] &quot;/home/paterno/R/x86_64-pc-linux-gnu-library/4.1&quot; #&gt; [2] &quot;/usr/local/lib/R/site-library&quot; #&gt; [3] &quot;/usr/lib/R/site-library&quot; #&gt; [4] &quot;/usr/lib/R/library&quot; Uma vez instalado um pacote, n√£o h√° necessidade de instal√°-lo novamente. Entretanto, todas as vezes que iniciarmos uma sess√£o no R, precisamos carregar os pacotes com as fun√ß√µes que precisamos utilizar. O carregamento de pacotes possui algumas caracter√≠sticas: Carrega-se o pacote toda vez que se abre uma nova sess√£o do R N√£o precisamos estar conectados √† internet O nome do pacote n√£o precisa estar entre aspas na fun√ß√£o Fun√ß√µes: library() ou require() Vamos carregar o pacote vegan que instalamos anteriormente. Podemos ir na aba Packages (Figura 4.2 (4)) e ‚Äúticar‚Äù o pacote que queremos carregar ou utilizar a fun√ß√£o library(). ## Carregar pacotes library(vegan) Como dissemos, alguns pacotes em desenvolvimento encontram-se dispon√≠veis em reposit√≥rios do GitHub ou GitLab. Para instalar pacotes do GitHub, por exemplo, precisamos instalar e carregar o pacote devtools. ## Instalar pacote devtools install.packages(&quot;devtools&quot;) ## Carregar pacote devtools library(devtools) Uma vez instalado e carregado esse pacote, podemos instalar o pacote do GitHub, utilizando a fun√ß√£o devtools::install_github(). Precisamos atentar para usar essa forma ‚Äúnome_usuario/nome_repositorio,‚Äù retirados do link do reposit√≥rio de interesse. Como exemplo, podemos instalar o mesmo pacote vegan do reposit√≥rio do GitHub vegandevs/vegan, e depois utilizar a fun√ß√£o library() para carreg√°-lo normalmente. ## Instalar pacote do github devtools::install_github(&quot;vegandevs/vegan&quot;) ## Carregar pacote do github library(&quot;vegan&quot;) Pode ser que em algumas circunst√¢ncias iremos precisar instalar pacotes com vers√µes espec√≠ficas para algumas an√°lises. A forma mais simples de fazer isso √© instalar um pacote a partir de um arquivo compactado .tar.gz. Para isso podemos ir √† base do CRAN e realizar o download: https://cran.r-project.org/src/contrib/Archive/. Para exemplificar, vamos instalar o pacote vegan 2.4.0. ## Download do arquivo .tar.gz download.file(url = &quot;https://cran.r-project.org/src/contrib/Archive/vegan/vegan_2.4-0.tar.gz&quot;, destfile = &quot;vegan_2.4-0.tar.gz&quot;, mode = &quot;wb&quot;) ## Instalar o pacote vegan 2.4.0 install.packages(&quot;vegan_2.4-0.tar.gz&quot;, repos = NULL, type = &quot;source&quot;) A maioria dos pacotes vem com bancos de dados que podem ser acessados pela fun√ß√£o data(). Esses bancos de dados podem ser usados para testar as fun√ß√µes do pacote. Se estiver com d√∫vida na maneira como voc√™ deve preparar a planilha para realizar uma an√°lise espec√≠fica, entre no help da fun√ß√£o e veja os conjuntos de dados que est√£o no exemplo desta fun√ß√£o. Como exemplo, vamos carregar os dados dune do pacote vegan. ## Carregar dados de um pacote library(vegan) data(dune) dune[1:6, 1:6] #&gt; Achimill Agrostol Airaprae Alopgeni Anthodor Bellpere #&gt; 1 1 0 0 0 0 0 #&gt; 2 3 0 0 2 0 3 #&gt; 3 0 4 0 7 0 2 #&gt; 4 0 8 0 2 0 2 #&gt; 5 2 0 0 0 4 2 #&gt; 6 2 0 0 0 3 0 Se por algum motivo precisarmos desinstalar um pacote, podemos utilizar a fun√ß√£o remove.packages(). J√° para descarregar um pacote de uma sess√£o do R, podemos usar a fun√ß√£o detach(). ## Descarregar um pacote detach(&quot;package:vegan&quot;, unload = TRUE) E um √∫ltimo ponto fundamental sobre pacotes, diz respeito √† atualiza√ß√£o dos mesmos. Os pacotes s√£o atualizados com frequ√™ncia, e infelizmente ou felizmente (pois as atualiza√ß√µes podem oferecer algumas quebras entre pacotes), n√£o se atualizam sozinhos. Muitas vezes, a instala√ß√£o de um pacote pode depender da vers√£o dos pacotes dependentes, e geralmente uma janela se abre perguntando se voc√™ quer que todos os pacotes dependentes sejam atualizados. Podemos ir na aba Packages (Figura 4.2 (4)) e clicar em ‚ÄúUpdate‚Äù ou usar a fun√ß√£o update.packages(checkBuilt = TRUE, ask = FALSE) para atualiz√°-los, entretanto, essa √© uma fun√ß√£o que costuma demorar muito para terminar de ser executada. ## Atualiza√ß√£o dos pacotes update.packages(checkBuilt = TRUE, ask = FALSE) Para fazer a atualiza√ß√£o dos pacotes instalados pelo GitHub, recomendamos o uso do pacote dtupdate. ## Atualiza√ß√£o dos pacotes instalados pelo GitHub dtupdate::github_update(auto.install = TRUE, ask = FALSE) Destacamos e incentivamos ainda uma pr√°tica que achamos interessante para aumentar a reprodutibilidade de nossos c√≥digos e scripts: a de chamar as fun√ß√µes de pacotes carregados dessa forma pacote::fun√ß√£o(). Dessa forma, deixamos claro o pacote em que a fun√ß√£o est√° implementada. Destacamos aqui o exemplo de como instalar pacotes do GitHub do pacote devtools. ## Pacote seguido da fun√ß√£o implementada daquele pacote devtools::install_github() 4.3.7 Ajuda (Help) Um importante passo para melhorar a usabilidade e ter mais familiaridade com a linguagem R √© aprender a usar a ajuda de cada fun√ß√£o. Para tanto, podemos utilizar a fun√ß√£o help() ou o operador ?, depois de ter carregado o pacote, para abrir uma nova aba (Figura 4.2 (4)) que possui diversas informa√ß√µes sobre a fun√ß√£o de interesse. O arquivo de ajuda do R possui geralmente nove ou dez t√≥picos, que nos auxiliam muito no entendimento dos dados de entrada, argumentos e que opera√ß√µes est√£o sendo realizadas. Description: resumo da fun√ß√£o Usage: como utilizar a fun√ß√£o e quais os seus argumentos Arguments: detalha os argumentos e como os mesmos devem ser especificados Details: detalhes importantes para se usar a fun√ß√£o Value: mostra como interpretar a sa√≠da (output) da fun√ß√£o (os resultados) Note: notas gerais sobre a fun√ß√£o Authors: autores da fun√ß√£o References: refer√™ncias bibliogr√°ficas para os m√©todos usados para constru√ß√£o da fun√ß√£o See also: fun√ß√µes relacionadas Examples: exemplos do uso da fun√ß√£o. √Äs vezes pode ser √∫til copiar esse trecho e colar no R para ver como funciona e como usar a fun√ß√£o. Vamos realizar um exemplo, buscando o help da fun√ß√£o aov(), que realiza uma an√°lise de vari√¢ncia. ## Ajuda help(aov) ?aov Al√©m das fun√ß√µes, podemos buscar detalhes de um pacote em espec√≠fico, para uma p√°gina simples do help utilizando a fun√ß√£o help() ou o operador ?. Entretanto, para uma op√ß√£o que ofere√ßa uma descri√ß√£o detalhada e um √≠ndice de todas as fun√ß√µes do pacote, podemos utilizar a fun√ß√£o library(), mas agora utilizando o argumento help, indicando o pacote de interesse entre aspas. ## Ajuda do pacote help(vegan) ?vegan ## Help detalhado library(help = &quot;vegan&quot;) Outra ferramenta de busca √© a p√°gina rseek, na qual √© poss√≠vel buscar por um termo n√£o s√≥ nos pacotes do R, mas tamb√©m em listas de emails, manuais, p√°ginas na internet e livros sobre o programa. 4.3.8 Ambiente (Environment) O ambiente Environment como vimos √© onde os objetos criados s√£o armazenados. √â fundamental entender que um objeto √© uma aloca√ß√£o de um pequeno espa√ßo na mem√≥ria RAM do seu computador, onde o R armazenar√° um valor ou o resultado de uma fun√ß√£o, utilizando o nome que definimos na atribui√ß√£o. Sendo assim, se fizermos uma atribui√ß√£o de um objeto maior que o tamanho da mem√≥ria RAM, esse objeto n√£o ser√° alocado, e a atribui√ß√£o n√£o funcionar√°. Existem op√ß√µes para contornar esse tipo de limita√ß√£o, mas n√£o a abordaremos aqui. Entretanto, podemos utilizar a fun√ß√£o object.size() para saber quanto espa√ßo nosso objeto criado est√° alocando de mem√≥ria RAM. ## Tamanho de um objeto object.size(adi) #&gt; 56 bytes Podemos listar todos os objetos criados com a fun√ß√£o ls() ou objects(). ## Listar todos os objetos ls() #&gt; [1] &quot;a1&quot; &quot;abu&quot; #&gt; [3] &quot;abundancia&quot; &quot;adi&quot; #&gt; [5] &quot;agua&quot; &quot;aic_fit&quot; #&gt; [7] &quot;aic_fit_ext&quot; &quot;ambie_dat&quot; #&gt; [9] &quot;ambie_fren_dat&quot; &quot;amostragem&quot; #&gt; [11] &quot;analise&quot; &quot;analise2&quot; #&gt; [13] &quot;aninha_plot&quot; &quot;anuros_ab&quot; #&gt; [15] &quot;anuros_comm&quot; &quot;anuros_comm_rel&quot; #&gt; [17] &quot;anuros_IC&quot; &quot;ar&quot; #&gt; [19] &quot;aranha.cent&quot; &quot;aranhas&quot; #&gt; [21] &quot;assumption3&quot; &quot;autovalores&quot; #&gt; [23] &quot;autovetores&quot; &quot;betad_fren&quot; #&gt; [25] &quot;betad.aves&quot; &quot;bird.rda&quot; #&gt; [27] &quot;bocaina_transf&quot; &quot;bocaina_transf2&quot; #&gt; [29] &quot;ca.env&quot; &quot;candidates&quot; #&gt; [31] &quot;Carpornis&quot; &quot;chat&quot; #&gt; [33] &quot;cofresult&quot; &quot;colar&quot; #&gt; [35] &quot;COMDIST_AB_plot&quot; &quot;COMDIST_PA_plot&quot; #&gt; [37] &quot;COMDISTNT_AB_plot&quot; &quot;COMDISTNT_PA_plot&quot; #&gt; [39] &quot;comm_baselga&quot; &quot;commAux&quot; #&gt; [41] &quot;composicao_acaros&quot; &quot;composicao_especies&quot; #&gt; [43] &quot;composicao_PA&quot; &quot;comun_dat&quot; #&gt; [45] &quot;comun_fren_dat&quot; &quot;comunidade&quot; #&gt; [47] &quot;concatenar&quot; &quot;coord&quot; #&gt; [49] &quot;cor_linear_model&quot; &quot;cores&quot; #&gt; [51] &quot;correlacao_arbustos&quot; &quot;CRC_LP_femea&quot; #&gt; [53] &quot;CRC_PN_macho&quot; &quot;curvas_dominancia_com2&quot; #&gt; [55] &quot;curvas_dominancia_todas&quot; &quot;cwm_dis&quot; #&gt; [57] &quot;cwm_ex&quot; &quot;cwm_fren&quot; #&gt; [59] &quot;dados&quot; &quot;dados_amostras&quot; #&gt; [61] &quot;dados_ancova&quot; &quot;dados_anova_simples&quot; #&gt; [63] &quot;dados_bloco&quot; &quot;dados_coleta&quot; #&gt; [65] &quot;dados_combinado&quot; &quot;dados_combinado_ext&quot; #&gt; [67] &quot;dados_dis&quot; &quot;dados_dis_AB&quot; #&gt; [69] &quot;dados_div&quot; &quot;dados_dois_fatores&quot; #&gt; [71] &quot;dados_dois_fatores_interacao&quot; &quot;dados_dois_fatores_interacao2&quot; #&gt; [73] &quot;dados_inext&quot; &quot;dados_inext_abu&quot; #&gt; [75] &quot;dados_matriz&quot; &quot;dados_PA&quot; #&gt; [77] &quot;dados_prec&quot; &quot;dados_rarefacao&quot; #&gt; [79] &quot;dados_regressao&quot; &quot;dados_regressao_mul&quot; #&gt; [81] &quot;dados_semNA&quot; &quot;darknessmale&quot; #&gt; [83] &quot;dat&quot; &quot;dat_betapart&quot; #&gt; [85] &quot;dat.graf&quot; &quot;data&quot; #&gt; [87] &quot;data.frame_AB&quot; &quot;data.frame_PA&quot; #&gt; [89] &quot;dend&quot; &quot;dendro&quot; #&gt; [91] &quot;df&quot; &quot;df_sem_na&quot; #&gt; [93] &quot;dis_prec&quot; &quot;dist_categ&quot; #&gt; [95] &quot;dist_mist&quot; &quot;dist_normal&quot; #&gt; [97] &quot;distBocaina&quot; &quot;doubs&quot; #&gt; [99] &quot;dune&quot; &quot;E&quot; #&gt; [101] &quot;ED&quot; &quot;eigen_aranhas&quot; #&gt; [103] &quot;eixos&quot; &quot;eixos_cat&quot; #&gt; [105] &quot;eixos_cont&quot; &quot;eixos_mist&quot; #&gt; [107] &quot;env&quot; &quot;env_cont&quot; #&gt; [109] &quot;env.contin&quot; &quot;env.dist&quot; #&gt; [111] &quot;env.mite.pco&quot; &quot;env.pad&quot; #&gt; [113] &quot;env.pad.cat&quot; &quot;env.pca&quot; #&gt; [115] &quot;env.sel&quot; &quot;env2&quot; #&gt; [117] &quot;EP&quot; &quot;EP2&quot; #&gt; [119] &quot;especies_plantas&quot; &quot;espher_model&quot; #&gt; [121] &quot;est_ace&quot; &quot;est_boot&quot; #&gt; [123] &quot;est_chao1&quot; &quot;est_chao2&quot; #&gt; [125] &quot;est_jack1&quot; &quot;est_jack2&quot; #&gt; [127] &quot;euclid_dis&quot; &quot;expon_model&quot; #&gt; [129] &quot;fator&quot; &quot;fator_nominal&quot; #&gt; [131] &quot;fator_ordinal&quot; &quot;FD&quot; #&gt; [133] &quot;fdis&quot; &quot;fdiv&quot; #&gt; [135] &quot;feve&quot; &quot;filho_intervalo&quot; #&gt; [137] &quot;filho_nascimento&quot; &quot;filogenia_aves&quot; #&gt; [139] &quot;filogenia_cortada&quot; &quot;filogenia_nova&quot; #&gt; [141] &quot;fish&quot; &quot;fitofis&quot; #&gt; [143] &quot;flo&quot; &quot;fric&quot; #&gt; [145] &quot;fun_beta&quot; &quot;fun_beta_multi&quot; #&gt; [147] &quot;fun_jaccard&quot; &quot;fun_nestedness&quot; #&gt; [149] &quot;fun_turnover&quot; &quot;g_acari_axi1&quot; #&gt; [151] &quot;g_acari_axi2&quot; &quot;g_bar_h&quot; #&gt; [153] &quot;g_bar_v&quot; &quot;g_donut&quot; #&gt; [155] &quot;g_pie&quot; &quot;g1&quot; #&gt; [157] &quot;gauss_model&quot; &quot;grp.int&quot; #&gt; [159] &quot;grp.mon&quot; &quot;grp.pla&quot; #&gt; [161] &quot;hill_res_q_0&quot; &quot;hill_res_q_1&quot; #&gt; [163] &quot;hill_res_q_2&quot; &quot;hull.data&quot; #&gt; [165] &quot;hur_NB&quot; &quot;i&quot; #&gt; [167] &quot;ind_env&quot; &quot;intror_anfibios_locais&quot; #&gt; [169] &quot;itv_biomass&quot; &quot;itv_BS&quot; #&gt; [171] &quot;itv_eye_size&quot; &quot;itv_flatness&quot; #&gt; [173] &quot;itv_results&quot; &quot;k&quot; #&gt; [175] &quot;ktab_list&quot; &quot;li&quot; #&gt; [177] &quot;lista&quot; &quot;lista_nome&quot; #&gt; [179] &quot;lista_rarefacao&quot; &quot;lm_dat&quot; #&gt; [181] &quot;ma&quot; &quot;ma_cbind&quot; #&gt; [183] &quot;ma_col&quot; &quot;ma_rbind&quot; #&gt; [185] &quot;ma_row&quot; &quot;Margalef&quot; #&gt; [187] &quot;mat_knn&quot; &quot;mat_listw&quot; #&gt; [189] &quot;mat_nb&quot; &quot;matriz_cov&quot; #&gt; [191] &quot;matriz_F&quot; &quot;Megascops&quot; #&gt; [193] &quot;MEM_mat&quot; &quot;Menhinick&quot; #&gt; [195] &quot;metricas&quot; &quot;metricas_divergencia&quot; #&gt; [197] &quot;metricas_divergencia_beta&quot; &quot;metricas_riqueza&quot; #&gt; [199] &quot;metricas_riqueza_beta&quot; &quot;MidPoint&quot; #&gt; [201] &quot;minha_arvore&quot; &quot;mite&quot; #&gt; [203] &quot;mite.env&quot; &quot;mite.hel&quot; #&gt; [205] &quot;mite.riqueza&quot; &quot;mite.xy&quot; #&gt; [207] &quot;MNTD_AB_plot&quot; &quot;MNTD_AP_plot&quot; #&gt; [209] &quot;mod_biomass&quot; &quot;mod_body_size&quot; #&gt; [211] &quot;mod_eye_size&quot; &quot;mod_flatness&quot; #&gt; [213] &quot;mod_itv&quot; &quot;mod_log&quot; #&gt; [215] &quot;mod_nb&quot; &quot;mod_pois&quot; #&gt; [217] &quot;mod_pro&quot; &quot;mod_quasipois&quot; #&gt; [219] &quot;mod.mite&quot; &quot;mod1&quot; #&gt; [221] &quot;mod2&quot; &quot;mod3&quot; #&gt; [223] &quot;model_bloco1&quot; &quot;model_bloco2&quot; #&gt; [225] &quot;modelo_ancova&quot; &quot;modelo_ancova2&quot; #&gt; [227] &quot;Modelo_anova&quot; &quot;modelo_errado&quot; #&gt; [229] &quot;Modelo_interacao1&quot; &quot;Modelo_interacao2&quot; #&gt; [231] &quot;modelo_intercepto&quot; &quot;modelo_regressao&quot; #&gt; [233] &quot;modelo_regressao_mul&quot; &quot;Modelo1&quot; #&gt; [235] &quot;Modelo2&quot; &quot;modelos_nulo&quot; #&gt; [237] &quot;moran.comp&quot; &quot;moran.env&quot; #&gt; [239] &quot;MPD_AB_plot&quot; &quot;MPD_PA_plot&quot; #&gt; [241] &quot;mu&quot; &quot;multi&quot; #&gt; [243] &quot;n&quot; &quot;nmds.beta&quot; #&gt; [245] &quot;no_spat_gls&quot; &quot;novas_filogenias&quot; #&gt; [247] &quot;nulo&quot; &quot;obj&quot; #&gt; [249] &quot;obj_10&quot; &quot;obj_caracter&quot; #&gt; [251] &quot;obj_complexo&quot; &quot;obj_logico&quot; #&gt; [253] &quot;obj_numerico_double&quot; &quot;obj_numerico_inteiro&quot; #&gt; [255] &quot;op&quot; &quot;parasitas&quot; #&gt; [257] &quot;Pareado&quot; &quot;particao_phylosor&quot; #&gt; [259] &quot;pca.comp&quot; &quot;pca.p&quot; #&gt; [261] &quot;pcoa_traits_cat&quot; &quot;pcoa_traits_cont&quot; #&gt; [263] &quot;pcoa_traits_mist&quot; &quot;pcoa.dat&quot; #&gt; [265] &quot;pcoa.sps&quot; &quot;PD_plot&quot; #&gt; [267] &quot;PE_plot&quot; &quot;penguin_islands&quot; #&gt; [269] &quot;penguins&quot; &quot;penguins_01&quot; #&gt; [271] &quot;penguins_02&quot; &quot;penguins_arrange&quot; #&gt; [273] &quot;penguins_arrange_across&quot; &quot;penguins_arrange_desc&quot; #&gt; [275] &quot;penguins_arrange_desc_m&quot; &quot;penguins_bind_cols&quot; #&gt; [277] &quot;penguins_bind_rows&quot; &quot;penguins_count&quot; #&gt; [279] &quot;penguins_count_two&quot; &quot;penguins_distinct&quot; #&gt; [281] &quot;penguins_distinct_keep_all&quot; &quot;penguins_distinct_keep_all_across&quot; #&gt; [283] &quot;penguins_filter&quot; &quot;penguins_filter_between&quot; #&gt; [285] &quot;penguins_filter_if&quot; &quot;penguins_filter_in&quot; #&gt; [287] &quot;penguins_filter_na&quot; &quot;penguins_filter_two&quot; #&gt; [289] &quot;penguins_group_by&quot; &quot;penguins_group_by_across&quot; #&gt; [291] &quot;penguins_left_join&quot; &quot;penguins_mean&quot; #&gt; [293] &quot;penguins_mutate&quot; &quot;penguins_mutate_across&quot; #&gt; [295] &quot;penguins_pad&quot; &quot;penguins_prop&quot; #&gt; [297] &quot;penguins_raw_colunas_na&quot; &quot;penguins_raw_multi_factor&quot; #&gt; [299] &quot;penguins_raw_pivot_longer&quot; &quot;penguins_raw_pivot_wider&quot; #&gt; [301] &quot;penguins_raw_sel_col&quot; &quot;penguins_raw_separar&quot; #&gt; [303] &quot;penguins_raw_separar_linhas&quot; &quot;penguins_raw_subs_na&quot; #&gt; [305] &quot;penguins_raw_todas_na&quot; &quot;penguins_raw_unir&quot; #&gt; [307] &quot;penguins_relocate_col&quot; &quot;penguins_relocate_ncol&quot; #&gt; [309] &quot;penguins_rename&quot; &quot;penguins_rename_with&quot; #&gt; [311] &quot;penguins_select_contains&quot; &quot;penguins_select_names&quot; #&gt; [313] &quot;penguins_select_position&quot; &quot;penguins_select_pull&quot; #&gt; [315] &quot;penguins_slice&quot; &quot;penguins_slice_head&quot; #&gt; [317] &quot;penguins_slice_max&quot; &quot;penguins_slice_sample&quot; #&gt; [319] &quot;penguins_stringr_nomes&quot; &quot;penguins_stringr_valores&quot; #&gt; [321] &quot;penguins_summarise&quot; &quot;penguins_summarise_across&quot; #&gt; [323] &quot;penguins_trait&quot; &quot;penguins2&quot; #&gt; [325] &quot;perm.aves&quot; &quot;perman_fren&quot; #&gt; [327] &quot;Pielou&quot; &quot;plot_betapart&quot; #&gt; [329] &quot;plot_phylosor&quot; &quot;plot_pred1&quot; #&gt; [331] &quot;plot_pred2&quot; &quot;plot_trait_cat&quot; #&gt; [333] &quot;plot_trait_cont&quot; &quot;plot_trait_mist&quot; #&gt; [335] &quot;plot_unifrac&quot; &quot;pois_plain&quot; #&gt; [337] &quot;prec_dis&quot; &quot;precipitacao&quot; #&gt; [339] &quot;pred.env&quot; &quot;pred.scores.mite&quot; #&gt; [341] &quot;pred.vars&quot; &quot;predito&quot; #&gt; [343] &quot;predito_ext&quot; &quot;PSR_plot&quot; #&gt; [345] &quot;pv.birds&quot; &quot;r_hoje&quot; #&gt; [347] &quot;r_inicio&quot; &quot;r_intervalo&quot; #&gt; [349] &quot;r_quadr&quot; &quot;rank_com2&quot; #&gt; [351] &quot;rank_com3&quot; &quot;rarefacao_anuros&quot; #&gt; [353] &quot;rarefacao_repteis&quot; &quot;ratio_model&quot; #&gt; [355] &quot;rda.bird&quot; &quot;rda.p&quot; #&gt; [357] &quot;redmale&quot; &quot;relAbund&quot; #&gt; [359] &quot;rep_times&quot; &quot;rep_times_soma&quot; #&gt; [361] &quot;rep_times_soma_raiz&quot; &quot;repeticao&quot; #&gt; [363] &quot;res_ace&quot; &quot;res_boot&quot; #&gt; [365] &quot;res_chao&quot; &quot;res_chao2&quot; #&gt; [367] &quot;res_hill&quot; &quot;res_indval&quot; #&gt; [369] &quot;res_jack1&quot; &quot;res_jack2&quot; #&gt; [371] &quot;res_rarefacao_amostras&quot; &quot;res.axis&quot; #&gt; [373] &quot;res.p.axis&quot; &quot;res.p.var&quot; #&gt; [375] &quot;res.var&quot; &quot;residuos&quot; #&gt; [377] &quot;residuos_LP&quot; &quot;resultado_AB&quot; #&gt; [379] &quot;resultado_PA&quot; &quot;resultados&quot; #&gt; [381] &quot;resultados_abundancia&quot; &quot;resultados_ace&quot; #&gt; [383] &quot;resultados_anuros&quot; &quot;resultados_boot&quot; #&gt; [385] &quot;resultados_chao2&quot; &quot;resultados_Comdist_AB&quot; #&gt; [387] &quot;resultados_Comdist_PA&quot; &quot;resultados_Comdistnt_AB&quot; #&gt; [389] &quot;resultados_Comdistnt_PA&quot; &quot;resultados_comunidades&quot; #&gt; [391] &quot;resultados_comunidades_ext&quot; &quot;resultados_ED&quot; #&gt; [393] &quot;resultados_extrapolacao&quot; &quot;resultados_incidencia&quot; #&gt; [395] &quot;resultados_jack1&quot; &quot;resultados_jack2&quot; #&gt; [397] &quot;resultados_MNTD_AB&quot; &quot;resultados_MNTD_PA&quot; #&gt; [399] &quot;resultados_morcegos&quot; &quot;resultados_MPD_AB&quot; #&gt; [401] &quot;resultados_MPD_PA&quot; &quot;resultados_PD&quot; #&gt; [403] &quot;resultados_PE&quot; &quot;resultados_Phylosor&quot; #&gt; [405] &quot;resultados_Phylosor_particao&quot; &quot;resultados_PSR&quot; #&gt; [407] &quot;resultados_PSV&quot; &quot;resultados_rarefacao&quot; #&gt; [409] &quot;resultados_repteis&quot; &quot;resultados_SES_MNTD&quot; #&gt; [411] &quot;resultados_SES_MPD&quot; &quot;resultados_SES_PD&quot; #&gt; [413] &quot;resultados_UniFrac&quot; &quot;resultados_UniFrac_particao&quot; #&gt; [415] &quot;resultados_VPD&quot; &quot;richness&quot; #&gt; [417] &quot;riqueza&quot; &quot;riqueza_extrapolada&quot; #&gt; [419] &quot;Riqueza_plot&quot; &quot;riqueza_rarefeita&quot; #&gt; [421] &quot;riqueza_sp&quot; &quot;sel.vars&quot; #&gt; [423] &quot;sequencia&quot; &quot;sequencia_esp&quot; #&gt; [425] &quot;ses.physo&quot; &quot;shannon_res&quot; #&gt; [427] &quot;simpson_res&quot; &quot;simulationBion&quot; #&gt; [429] &quot;simulationOutput&quot; &quot;sol1&quot; #&gt; [431] &quot;sorensen_plot&quot; &quot;sp&quot; #&gt; [433] &quot;sp_compos&quot; &quot;spatial.pred&quot; #&gt; [435] &quot;spe&quot; &quot;spe.KM.cascade&quot; #&gt; [437] &quot;spe.kmeans&quot; &quot;spe.norm&quot; #&gt; [439] &quot;species&quot; &quot;species.hel&quot; #&gt; [441] &quot;spNames&quot; &quot;sps.dis&quot; #&gt; [443] &quot;spVector&quot; &quot;Strix&quot; #&gt; [445] &quot;subst_plot&quot; &quot;tab_indval&quot; #&gt; [447] &quot;tempo_estudando_r&quot; &quot;tempo_estudando_r_dur&quot; #&gt; [449] &quot;theme_book&quot; &quot;tidy_anfibios_locais&quot; #&gt; [451] &quot;trait_baselga&quot; &quot;trait_cat&quot; #&gt; [453] &quot;trait_categ&quot; &quot;trait_dat&quot; #&gt; [455] &quot;trait_decomp&quot; &quot;trait_fren_dat&quot; #&gt; [457] &quot;trait_m&quot; &quot;trait_ord&quot; #&gt; [459] &quot;trait_pad&quot; &quot;traits&quot; #&gt; [461] &quot;traitsVector&quot; &quot;tree_dend&quot; #&gt; [463] &quot;va1&quot; &quot;va2&quot; #&gt; [465] &quot;valores&quot; &quot;var_env&quot; #&gt; [467] &quot;ve&quot; &quot;vec_1&quot; #&gt; [469] &quot;vec_2&quot; &quot;vec_ch&quot; #&gt; [471] &quot;vec_fa&quot; &quot;vec_nu&quot; #&gt; [473] &quot;W_sel_mat&quot; &quot;wITVResults&quot; #&gt; [475] &quot;x&quot; &quot;xy&quot; #&gt; [477] &quot;y&quot; &quot;z&quot; #&gt; [479] &quot;ziNB_mod2&quot; &quot;ziP_mod2&quot; Podemos ainda remover objetos criados com a fun√ß√£o rm() ou remove(). Ou ainda fazer uma fun√ß√£o composta para remover todos os objetos do Environment. ## Remover um objeto rm(adi) ## Remover todos os objetos criados rm(list = ls()) Quando usamos a fun√ß√£o ls() agora, nenhum objeto √© listado. ## Listar todos os objetos ls() #&gt; character(0) Toda a vez que fechamos o R os objetos criados s√£o apagados do Environment. Dessa forma, em algumas ocasi√µes, por exemplo, an√°lises estat√≠sticas que demoram um grande tempo para serem realizadas, pode ser interessante exportar alguns ou todos os objetos criados. Para salvar todos os objetos, ou seja, todo o workspace, podemos ir em Session -&gt; Save Workspace As... e escolher o nome do arquivo do workspace, por exemplo, ‚Äúmeu_workspace.RData.‚Äù Podemos ainda utilizar fun√ß√µes para essas tarefas. A fun√ß√£o save.image() salva todo workspace com a extens√£o .RData. ## Salvar todo o workspace save.image(file = &quot;meu_workspace.RData&quot;) Depois disso, podemos fechar o RStudio tranquilamente, e quando formos trabalhar novamente, podemos carregar os objetos criados indo em Session -&gt; Load Workspace... ou utilizando a fun√ß√£o load(). ## Carregar todo o workspace load(&quot;meu_workspace.RData&quot;) Entretanto, em algumas ocasi√µes, n√£o precisamos salvar todos os objetos. Dessa forma, podemos salvar apenas alguns objetos espec√≠ficos usando a fun√ß√£o save(), tamb√©m com a extens√£o .RData. ## Salvar apenas um objeto save(obj1, file = &quot;meu_obj.RData&quot;) ## Salvar apenas um objeto save(obj1, obj2, file = &quot;meus_objs.RData&quot;) ## Carregar os objetos load(&quot;meus_objs.RData&quot;) Ou ainda podemos salvar apenas um objeto com a extens√£o .rds. Para isso, usamos as fun√ß√µes saveRDS() e readRDS(), para exportar e importar esses dados, respectivamente. ## Salvar um objeto para um arquivo saveRDS(obj, file = &quot;meu_obj.rds&quot;) ## Carregar esse objeto readRDS(file = &quot;meu_obj.rds&quot;) 4.3.9 Cita√ß√µes Ao utilizar o R para realizar alguma an√°lise em nossos estudos, √© fundamental a cita√ß√£o do mesmo. Para saber como citar exatamente o R em artigos, existe uma fun√ß√£o denominada citation(), que prov√™ um formato gen√©rico de cita√ß√£o e um BibTeX para arquivos LaTeX e R Markdown. ## Cita√ß√£o do R citation() #&gt; #&gt; To cite R in publications use: #&gt; #&gt; R Core Team (2021). R: A language and environment for statistical computing. R #&gt; Foundation for Statistical Computing, Vienna, Austria. URL #&gt; https://www.R-project.org/. #&gt; #&gt; A BibTeX entry for LaTeX users is #&gt; #&gt; @Manual{, #&gt; title = {R: A Language and Environment for Statistical Computing}, #&gt; author = {{R Core Team}}, #&gt; organization = {R Foundation for Statistical Computing}, #&gt; address = {Vienna, Austria}, #&gt; year = {2021}, #&gt; url = {https://www.R-project.org/}, #&gt; } #&gt; #&gt; We have invested a lot of time and effort in creating R, please cite it when using #&gt; it for data analysis. See also &#39;citation(&quot;pkgname&quot;)&#39; for citing R packages. No resultado dessa fun√ß√£o, h√° uma mensagem muito interessante: ‚ÄúSee also ‚Äòcitation(‚Äúpkgname‚Äù)‚Äô for citing R packages.‚Äù Dessa forma, aconselhamos os usu√°rios de R a citar tamb√©m os pacotes que utilizaram em suas an√°lises para dar os devidos cr√©ditos aos desenvolvedores das fun√ß√µes implementadas nos pacotes. Como exemplo, vamos ver como fica a cita√ß√£o do pacote vegan. ## Cita√ß√£o do pacote vegan citation(&quot;vegan&quot;) #&gt; #&gt; To cite package &#39;vegan&#39; in publications use: #&gt; #&gt; Jari Oksanen, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre #&gt; Legendre, Dan McGlinn, Peter R. Minchin, R. B. O&#39;Hara, Gavin L. Simpson, Peter #&gt; Solymos, M. Henry H. Stevens, Eduard Szoecs and Helene Wagner (2020). vegan: #&gt; Community Ecology Package. R package version 2.5-7. #&gt; https://CRAN.R-project.org/package=vegan #&gt; #&gt; A BibTeX entry for LaTeX users is #&gt; #&gt; @Manual{, #&gt; title = {vegan: Community Ecology Package}, #&gt; author = {Jari Oksanen and F. Guillaume Blanchet and Michael Friendly and Roeland Kindt and Pierre Legendre and Dan McGlinn and Peter R. Minchin and R. B. O&#39;Hara and Gavin L. Simpson and Peter Solymos and M. Henry H. Stevens and Eduard Szoecs and Helene Wagner}, #&gt; year = {2020}, #&gt; note = {R package version 2.5-7}, #&gt; url = {https://CRAN.R-project.org/package=vegan}, #&gt; } #&gt; #&gt; ATTENTION: This citation information has been auto-generated from the package #&gt; DESCRIPTION file and may need manual editing, see &#39;help(&quot;citation&quot;)&#39;. Podemos ainda utilizar a fun√ß√£o write_bib() do pacote knitr para exportar a cita√ß√£o do pacote no formato .bib. ## Exportar uma cita√ß√£o em formato .bib knitr::write_bib(&quot;vegan&quot;, file = &quot;vegan_ex.bib&quot;) 4.3.10 Principais erros de iniciantes Errar quando est√° come√ßando a usar o R √© muito comum e faz parte do aprendizado. Entretanto, os erros nunca devem ser encarados como uma forma de desest√≠mulo para continuar tentando. Todos n√≥s, autores desse livro, e provavelmente usu√°rios mais ou menos experientes, j√° passaram por um momento em que se quer desistir de tudo. Jovem aprendiz de R, a √∫nica diferen√ßa entre voc√™ que est√° iniciando agora e n√≥s que usamos h√° mais tempo s√£o as horas a mais de uso (e raiva). O que temos a mais √© experi√™ncia para olhar o erro, l√™-lo e conseguir interpretar o que est√° errado e saber buscar ajuda. Dessa forma, o ponto mais importante de quem est√° iniciando √© ter paci√™ncia, calma, bom humor, ler e entender as mensagens de erros. Listaremos aqui o que consideramos os principais erros dos iniciantes no R. 1. Esquecer de completar uma fun√ß√£o ou bloco de c√≥digos Esquecer de completar uma fun√ß√£o ou bloco de c√≥digos √© algo bem comum. Geralmente esquecemos de fechar aspas \"\" ou par√™nteses (), mas felizmente geralmente o R nos informa isso, indicando um s√≠mbolo de +. sum(1, 2 + #&gt; Error: &lt;text&gt;:3:0: unexpected end of input #&gt; 1: sum(1, 2 #&gt; 2: + #&gt; ^ 2. Esquecer da v√≠rgula Outro erro bastante comum √© esquecer de acrescentar a v√≠rgula , para separar argumentos dentro de uma fun√ß√£o, principalmente se estamos compondo v√°rias fun√ß√µes acopladas, i.e., uma fun√ß√£o dentro da outra. sum(1 2) #&gt; Error: &lt;text&gt;:1:7: unexpected numeric constant #&gt; 1: sum(1 2 #&gt; ^ 3. Chamar um objeto errado Pode parecer simples, mas esse √© de longe o erro mais comum que pessoas iniciantes comentem. Quando temos um longo script, √© de se esperar que tenhamos atribu√≠do diversos objetos e em algum momento atribu√≠mos um nome do qual n√£o lembramos. Dessa forma, quando chamamos o objeto ele n√£o existe e devolve um erro. Entretanto, esse tipo de erro pode ser facilmente identificado, como o exemplo abaixo. obj &lt;- 10 OBJ #&gt; Error in eval(expr, envir, enclos): object &#39;OBJ&#39; not found 4. Esquecer de carregar um pacote Esse tamb√©m √© um erro recorrente, mesmo para usu√°rios mais experientes. Em scripts de an√°lises complexas, que requerem v√°rios pacotes, geralmente esquecemos de um ou outro‚Ä¶ A melhor forma de evitar esse tipo de erro √© listar os pacotes que vamos precisar usar logo no in√≠cio do script. ## Carregar dados data(dune) ## Fun√ß√£o do pacote vegan decostand(dune, &quot;hell&quot;) #&gt; Achimill Agrostol Airaprae Alopgeni Anthodor Bellpere Bromhord Chenalbu Cirsarve #&gt; 1 0.2357023 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 2 0.2672612 0.0000000 0.0000000 0.2182179 0.0000000 0.2672612 0.3086067 0.0000000 0.0000000 #&gt; 3 0.0000000 0.3162278 0.0000000 0.4183300 0.0000000 0.2236068 0.0000000 0.0000000 0.0000000 #&gt; 4 0.0000000 0.4216370 0.0000000 0.2108185 0.0000000 0.2108185 0.2581989 0.0000000 0.2108185 #&gt; 5 0.2156655 0.0000000 0.0000000 0.0000000 0.3049971 0.2156655 0.2156655 0.0000000 0.0000000 #&gt; 6 0.2041241 0.0000000 0.0000000 0.0000000 0.2500000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 7 0.2236068 0.0000000 0.0000000 0.0000000 0.2236068 0.0000000 0.2236068 0.0000000 0.0000000 #&gt; 8 0.0000000 0.3162278 0.0000000 0.3535534 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 9 0.0000000 0.2672612 0.0000000 0.2672612 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 10 0.3049971 0.0000000 0.0000000 0.0000000 0.3049971 0.2156655 0.3049971 0.0000000 0.0000000 #&gt; 11 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 12 0.0000000 0.3380617 0.0000000 0.4780914 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 13 0.0000000 0.3892495 0.0000000 0.3892495 0.0000000 0.0000000 0.0000000 0.1740777 0.0000000 #&gt; 14 0.0000000 0.4082483 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 15 0.0000000 0.4170288 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 16 0.0000000 0.4605662 0.0000000 0.3481553 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 17 0.3651484 0.0000000 0.3651484 0.0000000 0.5163978 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 18 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.2721655 0.0000000 0.0000000 0.0000000 #&gt; 19 0.0000000 0.0000000 0.3110855 0.0000000 0.3592106 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 20 0.0000000 0.4016097 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; Comapalu Eleopalu Elymrepe Empenigr Hyporadi Juncarti Juncbufo Lolipere Planlanc #&gt; 1 0.0000000 0.0000000 0.4714045 0.0000000 0.0000000 0.0000000 0.0000000 0.6236096 0.0000000 #&gt; 2 0.0000000 0.0000000 0.3086067 0.0000000 0.0000000 0.0000000 0.0000000 0.3450328 0.0000000 #&gt; 3 0.0000000 0.0000000 0.3162278 0.0000000 0.0000000 0.0000000 0.0000000 0.3872983 0.0000000 #&gt; 4 0.0000000 0.0000000 0.2981424 0.0000000 0.0000000 0.0000000 0.0000000 0.3333333 0.0000000 #&gt; 5 0.0000000 0.0000000 0.3049971 0.0000000 0.0000000 0.0000000 0.0000000 0.2156655 0.3409972 #&gt; 6 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.3535534 0.3227486 #&gt; 7 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.2236068 0.3872983 0.3535534 #&gt; 8 0.0000000 0.3162278 0.0000000 0.0000000 0.0000000 0.3162278 0.0000000 0.3162278 0.0000000 #&gt; 9 0.0000000 0.0000000 0.3779645 0.0000000 0.0000000 0.3086067 0.3086067 0.2182179 0.0000000 #&gt; 10 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.3735437 0.2641353 #&gt; 11 0.0000000 0.0000000 0.0000000 0.0000000 0.2500000 0.0000000 0.0000000 0.4677072 0.3061862 #&gt; 12 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.3380617 0.0000000 0.0000000 #&gt; 13 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.3015113 0.0000000 0.0000000 #&gt; 14 0.2886751 0.4082483 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 15 0.2948839 0.4662524 0.0000000 0.0000000 0.0000000 0.3611576 0.0000000 0.0000000 0.0000000 #&gt; 16 0.0000000 0.4923660 0.0000000 0.0000000 0.0000000 0.3015113 0.0000000 0.0000000 0.0000000 #&gt; 17 0.0000000 0.0000000 0.0000000 0.0000000 0.3651484 0.0000000 0.0000000 0.0000000 0.3651484 #&gt; 18 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.2721655 0.3333333 #&gt; 19 0.0000000 0.0000000 0.0000000 0.2540003 0.4016097 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 20 0.0000000 0.3592106 0.0000000 0.0000000 0.0000000 0.3592106 0.0000000 0.0000000 0.0000000 #&gt; Poaprat Poatriv Ranuflam Rumeacet Sagiproc Salirepe Scorautu Trifprat Trifrepe #&gt; 1 0.4714045 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 2 0.3086067 0.4082483 0.0000000 0.0000000 0.0000000 0.0000000 0.3450328 0.0000000 0.3450328 #&gt; 3 0.3535534 0.3872983 0.0000000 0.0000000 0.0000000 0.0000000 0.2236068 0.0000000 0.2236068 #&gt; 4 0.2981424 0.3333333 0.0000000 0.0000000 0.3333333 0.0000000 0.2108185 0.0000000 0.1490712 #&gt; 5 0.2156655 0.3735437 0.0000000 0.3409972 0.0000000 0.0000000 0.2641353 0.2156655 0.2156655 #&gt; 6 0.2500000 0.2886751 0.0000000 0.3535534 0.0000000 0.0000000 0.2500000 0.3227486 0.3227486 #&gt; 7 0.3162278 0.3535534 0.0000000 0.2738613 0.0000000 0.0000000 0.2738613 0.2236068 0.2236068 #&gt; 8 0.3162278 0.3162278 0.2236068 0.0000000 0.2236068 0.0000000 0.2738613 0.0000000 0.2236068 #&gt; 9 0.3086067 0.3450328 0.0000000 0.2182179 0.2182179 0.0000000 0.2182179 0.0000000 0.2672612 #&gt; 10 0.3049971 0.3049971 0.0000000 0.0000000 0.0000000 0.0000000 0.2641353 0.0000000 0.3735437 #&gt; 11 0.3535534 0.0000000 0.0000000 0.0000000 0.2500000 0.0000000 0.3952847 0.0000000 0.3061862 #&gt; 12 0.0000000 0.3380617 0.0000000 0.2390457 0.3380617 0.0000000 0.2390457 0.0000000 0.2927700 #&gt; 13 0.2461830 0.5222330 0.2461830 0.0000000 0.2461830 0.0000000 0.2461830 0.0000000 0.2461830 #&gt; 14 0.0000000 0.0000000 0.2886751 0.0000000 0.0000000 0.0000000 0.2886751 0.0000000 0.5000000 #&gt; 15 0.0000000 0.0000000 0.2948839 0.0000000 0.0000000 0.0000000 0.2948839 0.0000000 0.2085144 #&gt; 16 0.0000000 0.2461830 0.2461830 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 #&gt; 17 0.2581989 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.3651484 0.0000000 0.0000000 #&gt; 18 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.3333333 0.4303315 0.0000000 0.2721655 #&gt; 19 0.0000000 0.0000000 0.0000000 0.0000000 0.3110855 0.3110855 0.4399413 0.0000000 0.2540003 #&gt; 20 0.0000000 0.0000000 0.3592106 0.0000000 0.0000000 0.4016097 0.2540003 0.0000000 0.0000000 #&gt; Vicilath Bracruta Callcusp #&gt; 1 0.0000000 0.0000000 0.0000000 #&gt; 2 0.0000000 0.0000000 0.0000000 #&gt; 3 0.0000000 0.2236068 0.0000000 #&gt; 4 0.0000000 0.2108185 0.0000000 #&gt; 5 0.0000000 0.2156655 0.0000000 #&gt; 6 0.0000000 0.3535534 0.0000000 #&gt; 7 0.0000000 0.2236068 0.0000000 #&gt; 8 0.0000000 0.2236068 0.0000000 #&gt; 9 0.0000000 0.2182179 0.0000000 #&gt; 10 0.1524986 0.2156655 0.0000000 #&gt; 11 0.2500000 0.3535534 0.0000000 #&gt; 12 0.0000000 0.3380617 0.0000000 #&gt; 13 0.0000000 0.0000000 0.0000000 #&gt; 14 0.0000000 0.0000000 0.4082483 #&gt; 15 0.0000000 0.4170288 0.0000000 #&gt; 16 0.0000000 0.3481553 0.3015113 #&gt; 17 0.0000000 0.0000000 0.0000000 #&gt; 18 0.1924501 0.4714045 0.0000000 #&gt; 19 0.0000000 0.3110855 0.0000000 #&gt; 20 0.0000000 0.3592106 0.3110855 Geralmente a mensagem de erro ser√° de que a fun√ß√£o n√£o foi encontrada ou algo nesse sentido. Carregando o pacote, esse erro √© contornado. ## Carregar o pacote library(vegan) ## Carregar dados data(dune) ## Fun√ß√£o do pacote vegan decostand(dune[1:6, 1:6], &quot;hell&quot;) #&gt; Achimill Agrostol Airaprae Alopgeni Anthodor Bellpere #&gt; 1 1.0000000 0.0000000 0 0.0000000 0.0000000 0.0000000 #&gt; 2 0.6123724 0.0000000 0 0.5000000 0.0000000 0.6123724 #&gt; 3 0.0000000 0.5547002 0 0.7337994 0.0000000 0.3922323 #&gt; 4 0.0000000 0.8164966 0 0.4082483 0.0000000 0.4082483 #&gt; 5 0.5000000 0.0000000 0 0.0000000 0.7071068 0.5000000 #&gt; 6 0.6324555 0.0000000 0 0.0000000 0.7745967 0.0000000 5. Usar o nome da fun√ß√£o de forma err√¥nea Esse erro n√£o √© t√£o comum, mas pode ser inc√¥modo √†s vezes. Algumas fun√ß√µes possuem nomes no padr√£o ‚ÄúCamel Case,‚Äù i.e., com letras mai√∫sculas para no meio do nome da fun√ß√£o. Isso √†s vezes pode confundir, ou ainda, as fun√ß√µes podem ou n√£o ser separadas com ., como row.names() e rownames(). No Cap√≠tulo de tidyverse 5, veremos que houve uma tentativa de padroniza√ß√£o nos nomes das fun√ß√µes para ‚ÄúSnake Case,‚Äù i.e, todas as fun√ß√µes possuem letras min√∫sculas, com palavras separadas por underscore _. ## Soma das colunas colsums(dune) #&gt; Error in colsums(dune): could not find function &quot;colsums&quot; ## Soma das colunas colSums(dune) #&gt; Achimill Agrostol Airaprae Alopgeni Anthodor Bellpere Bromhord Chenalbu Cirsarve Comapalu #&gt; 16 48 5 36 21 13 15 1 2 4 #&gt; Eleopalu Elymrepe Empenigr Hyporadi Juncarti Juncbufo Lolipere Planlanc Poaprat Poatriv #&gt; 25 26 2 9 18 13 58 26 48 63 #&gt; Ranuflam Rumeacet Sagiproc Salirepe Scorautu Trifprat Trifrepe Vicilath Bracruta Callcusp #&gt; 14 18 20 11 54 9 47 4 49 10 6. Atentar para o diret√≥rio correto Muitas vezes o erro √© simplesmente porque o usu√°rio(a) n√£o definiu o diret√≥rio correto onde est√° o arquivo a ser importado. Por isso √© fundamental sempre verificar se o diret√≥rio foi definido corretamente, geralmente com as fun√ß√µes dir() ou list.files() para listar no console a lista de arquivos no diret√≥rio. Podemos ainda usar o argumento pattern para listar arquivos por um padr√£o textual. ## Listar os arquivos do diret√≥rio definido dir() list.files() ## Listar os arquivos do diret√≥rio definido por um padr√£o dir(pattern = &quot;.csv&quot;) Al√©m disso, √© fundamental ressaltar a import√¢ncia de verificar se o nome do arquivo que importaremos foi digitado corretamente, atentando-se tamb√©m para a extens√£o: .csv, .txt, .xlsx, etc. 4.4 Estrutura e manipula√ß√£o de objetos O conhecimento sobre a estrutura e manipula√ß√£o de objetos √© fundamental para ter dom√≠nio e entendimento do funcionamento da linguagem R. Nesta se√ß√£o, trataremos da estrutura e manipula√ß√£o de dados no R, no que ficou conhecido como modo R Base, em contrapartida ao tidyverse, t√≥pico do Cap√≠tulo 5. Abordaremos aqui temas chaves: 1) atributos de objetos, 2) manipula√ß√£o de objetos unidimensionais e multidimensionais, 3) valores faltantes e especiais, 4) diret√≥rio de trabalho, e 5) importar, conferir e exportar dados. 4.4.1 Atributo dos objetos Quando fazemos atribui√ß√µes de dados no R (&lt;-), os objetos gerados possuem tr√™s caracter√≠sticas. Nome: palavra que o R reconhece os dados atribu√≠dos Conte√∫do: dados em si Atributos: modos (natureza) e estruturas (organiza√ß√£o) dos elementos Vamos explorar mais a fundo os modos e estruturas dos objetos. Vale ressaltar que isso √© uma simplifica√ß√£o, pois h√° muitas classes de objetos, como fun√ß√µes e sa√≠das de fun√ß√µes que possuem outros atributos. Podemos verificar os atributos dos objetos com a fun√ß√£o attributes(). ## Atributos attributes(dune) #&gt; $names #&gt; [1] &quot;Achimill&quot; &quot;Agrostol&quot; &quot;Airaprae&quot; &quot;Alopgeni&quot; &quot;Anthodor&quot; &quot;Bellpere&quot; &quot;Bromhord&quot; &quot;Chenalbu&quot; #&gt; [9] &quot;Cirsarve&quot; &quot;Comapalu&quot; &quot;Eleopalu&quot; &quot;Elymrepe&quot; &quot;Empenigr&quot; &quot;Hyporadi&quot; &quot;Juncarti&quot; &quot;Juncbufo&quot; #&gt; [17] &quot;Lolipere&quot; &quot;Planlanc&quot; &quot;Poaprat&quot; &quot;Poatriv&quot; &quot;Ranuflam&quot; &quot;Rumeacet&quot; &quot;Sagiproc&quot; &quot;Salirepe&quot; #&gt; [25] &quot;Scorautu&quot; &quot;Trifprat&quot; &quot;Trifrepe&quot; &quot;Vicilath&quot; &quot;Bracruta&quot; &quot;Callcusp&quot; #&gt; #&gt; $row.names #&gt; [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; &quot;11&quot; &quot;12&quot; &quot;13&quot; &quot;14&quot; &quot;15&quot; &quot;16&quot; &quot;17&quot; &quot;18&quot; #&gt; [19] &quot;19&quot; &quot;20&quot; #&gt; #&gt; $class #&gt; [1] &quot;data.frame&quot; 4.4.1.1 Modo dos objetos A depender da natureza dos elementos que comp√µem os dados e que foram atribu√≠dos aos objetos, esses objetos podem ser, de forma simples um dos cinco modos: num√©rico do tipo inteiro (integer), num√©rico do tipo flutuante (double), texto (character), l√≥gico (logical) ou complexo (complex). A atribui√ß√£o de n√∫meros no R podem gerar dois tipos de modos: integer para n√∫meros inteiros e double para n√∫meros flutuantes ou com decimais. ## Num√©rico double obj_numerico_double &lt;- 1 ## Modo mode(obj_numerico_double) #&gt; [1] &quot;numeric&quot; ## Tipo typeof(obj_numerico_double) #&gt; [1] &quot;double&quot; A t√≠tulo de praticidade, ambos s√£o incorporados como o modo numeric, com o tipo double, a menos que especifiquemos que seja inteiro com a letra L depois do n√∫mero. ## Num√©rico integer obj_numerico_inteiro &lt;- 1L ## Modo mode(obj_numerico_inteiro) #&gt; [1] &quot;numeric&quot; ## Tipo typeof(obj_numerico_inteiro) #&gt; [1] &quot;integer&quot; Al√©m de n√∫meros, podemos atribuir textos, utilizando para isso aspas \"\". ## Caracter ou string obj_caracter &lt;- &quot;a&quot; # atencao para as aspas ## Modo mode(obj_caracter) #&gt; [1] &quot;character&quot; Em algumas situa√ß√µes, precisamos indicar a ocorr√™ncia ou n√£o de um evento ou opera√ß√£o. Para isso, utilizamos as palavras reservadas (TRUE e FALSE), chamadas de vari√°veis booleanas, pois assumem apenas duas possibilidades: 0 ou 1. Devemos nos ater para o fato dessas palavras serem escritas com letras mai√∫sculas e sem aspas. ## L√≥gico obj_logico &lt;- TRUE # maiusculas e sem aspas ## Modo mode(obj_logico) #&gt; [1] &quot;logical&quot; Por fim, existe um modo pouco utilizado que cria n√∫meros complexos (raiz de n√∫meros negativos). ## Complexo obj_complexo &lt;- 1+1i ## Modo mode(obj_complexo) #&gt; [1] &quot;complex&quot; Podemos verificar o modo dos objetos ou fazer a convers√£o entre esses modos com diversas fun√ß√µes. ## Verificar o modo dos objetos is.numeric() is.integer() is.character() is.logical() is.complex() ## Convers√µes entre modos as.numeric() as.integer() as.character() as.logical() as.complex() 4.4.1.2 Estrutura dos objetos Uma vez entendido a natureza dos modos dos elementos dos objetos no R, podemos passar para o passo seguinte e entender como esses elementos s√£o estruturados dentro dos objetos. Essa estrutura√ß√£o ir√° nos contar sobre a organiza√ß√£o dos elementos, com rela√ß√£o aos modos e dimensionalidade da disposi√ß√£o dos elementos (Figura 4.3). De modo bem simples, os elementos podem ser estruturados em cinco tipos: Vetores e fatores: homog√™neo (um modo) e unidimensional (uma dimens√£o). Um tipo especial de vetor s√£o os fatores, usados para designar vari√°veis categ√≥ricas Matrizes: homog√™neo (um modo) e bidimensional (duas dimens√µes) Arrays: homog√™neo (um modo) e multidimensional (mais de duas dimens√µes) Data frames: heterog√™neo (mais de um modo) e bidimensional (duas dimens√µes) Listas: heterog√™neo (mais de um modo) e unidimensional (uma dimens√£o) Figura 4.3: Estruturas de dados mais comuns de R: vetores, matrizes, arrays, listas e data frames. Adaptado de: Grolemund (2014). 4.4.1.2.1 Vetor Vetores representam o encadeamento de elementos numa sequ√™ncia unidimensional. No Cap√≠tulo 3, vimos o conceito de vari√°vel aleat√≥ria e seus tipos. No R, essas vari√°veis podem ser operacionalizadas como vetores. Dessa forma, essa estrutura de dados pode ser traduzida como medidas de uma vari√°vel num√©rica (discretas ou cont√≠nuas), vari√°vel bin√°ria (booleana - TRUE e FALSE) ou descri√ß√£o (informa√ß√µes em texto). H√° diversas formas de se criar um vetor no R: Concatenando elementos com a fun√ß√£o c() Criando sequ√™ncias unit√°rias : ou com a fun√ß√£o seq() Criando repeti√ß√µes com a fun√ß√£o rep() ‚ÄúColar‚Äù palavras com uma sequ√™ncia num√©rica com a fun√ß√£o paste() ou paste0() Amostrando aleatoriamente elementos com a fun√ß√£o sample() ## Concatenar elementos num√©ricos concatenar &lt;- c(15, 18, 20, 22, 18) concatenar #&gt; [1] 15 18 20 22 18 ## Sequ√™ncia unit√°ria (x1:x2) sequencia &lt;- 1:10 sequencia #&gt; [1] 1 2 3 4 5 6 7 8 9 10 ## Sequ√™ncia com diferentes espa√ßamentos sequencia_esp &lt;- seq(from = 0, to = 100, by = 10) sequencia_esp #&gt; [1] 0 10 20 30 40 50 60 70 80 90 100 ## Repeti√ß√£o repeticao &lt;- rep(x = c(TRUE, FALSE), times = 5) repeticao #&gt; [1] TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE ## Cola palavra e sequ√™ncia num√©rica colar &lt;- paste(&quot;amostra&quot;, 1:5) colar #&gt; [1] &quot;amostra 1&quot; &quot;amostra 2&quot; &quot;amostra 3&quot; &quot;amostra 4&quot; &quot;amostra 5&quot; ## Amostragem aleat√≥ria amostragem &lt;- sample(x = 1:100, size = 10) amostragem #&gt; [1] 45 23 76 63 47 31 68 73 69 5 Como os vetores s√£o homog√™neos, i.e., s√≥ comportam um modo, quando combinamos mais de um modo no mesmo objeto ocorre uma domin√¢ncia de modos. Existe, dessa forma, uma coer√ß√£o dos elementos combinados para que todos fiquem iguais. Essa domin√¢ncia segue essa ordem: DOMINANTE character &gt; double &gt; integer &gt; logical RECESSIVO Al√©m disso, podemos utilizar as convers√µes listadas anteriormente para alterar os modos. Vamos exemplificar combinando os vetores criados anteriormente e convertendo-os. ## Coer√ß√£o c(colar, amostragem) #&gt; [1] &quot;amostra 1&quot; &quot;amostra 2&quot; &quot;amostra 3&quot; &quot;amostra 4&quot; &quot;amostra 5&quot; &quot;45&quot; &quot;23&quot; #&gt; [8] &quot;76&quot; &quot;63&quot; &quot;47&quot; &quot;31&quot; &quot;68&quot; &quot;73&quot; &quot;69&quot; #&gt; [15] &quot;5&quot; ## Convers√£o as.numeric(repeticao) #&gt; [1] 1 0 1 0 1 0 1 0 1 0 4.4.1.2.2 Fator O fator representa medidas de uma vari√°vel categ√≥rica, podendo ser nominal ou ordinal. √â fundamental destacar que fatores no R devem ser entendidos como um vetor de integer, i.e., ele √© composto por n√∫meros inteiros representando os n√≠veis da vari√°vel categ√≥rica. Para criar um fator no R usamos uma fun√ß√£o espec√≠fica factor(), na qual podemos especificar os n√≠veis com o argumento level, ou fazemos uma convers√£o usando a fun√ß√£o as.factor(). Trabalhar com fatores no R Base n√£o √© das tarefas mais agrad√°veis, sendo assim, no Cap√≠tulo ?? usamos a vers√£o tidyverse usando o pacote forcats. ## Fator nominal fator_nominal &lt;- factor(x = sample(x = c(&quot;floresta&quot;, &quot;pastagem&quot;, &quot;cerrado&quot;), size = 20, replace = TRUE), levels = c(&quot;floresta&quot;, &quot;pastagem&quot;, &quot;cerrado&quot;)) fator_nominal #&gt; [1] cerrado cerrado floresta pastagem pastagem cerrado cerrado pastagem cerrado floresta #&gt; [11] floresta floresta pastagem pastagem cerrado cerrado pastagem cerrado floresta pastagem #&gt; Levels: floresta pastagem cerrado ## Fator ordinal fator_ordinal &lt;- factor(x = sample(x = c(&quot;baixa&quot;, &quot;media&quot;, &quot;alta&quot;), size = 20, replace = TRUE), levels = c(&quot;baixa&quot;, &quot;media&quot;, &quot;alta&quot;), ordered = TRUE) fator_ordinal #&gt; [1] alta alta baixa media baixa media alta media baixa media baixa media alta baixa media #&gt; [16] media alta media baixa baixa #&gt; Levels: baixa &lt; media &lt; alta ## Convers√£o fator &lt;- as.factor(x = sample(x = c(&quot;floresta&quot;, &quot;pastagem&quot;, &quot;cerrado&quot;), size = 20, replace = TRUE)) fator #&gt; [1] cerrado pastagem floresta floresta cerrado cerrado pastagem cerrado pastagem cerrado #&gt; [11] pastagem cerrado pastagem pastagem floresta cerrado pastagem pastagem cerrado floresta #&gt; Levels: cerrado floresta pastagem 4.4.1.2.3 Matriz A matriz representa dados no formato de tabela, com linhas e colunas. As linhas representam unidades amostrais (locais, transectos, parcelas) e as colunas representam vari√°veis num√©ricas (discretas ou cont√≠nuas), vari√°veis bin√°rias (TRUE ou FALSE) ou descri√ß√µes (informa√ß√µes em texto). Podemos criar matrizes no R de duas formas. A primeira delas dispondo elementos de um vetor em um certo n√∫mero de linhas e colunas com a fun√ß√£o matrix(), podendo preencher essa matriz com os elementos do vetor por linhas ou por colunas alterando o argumento byrow. ## Vetor ve &lt;- 1:12 ## Matrix - preenchimento por linhas - horizontal ma_row &lt;- matrix(data = ve, nrow = 4, ncol = 3, byrow = TRUE) ma_row #&gt; [,1] [,2] [,3] #&gt; [1,] 1 2 3 #&gt; [2,] 4 5 6 #&gt; [3,] 7 8 9 #&gt; [4,] 10 11 12 ## Matrix - preenchimento por colunas - vertical ma_col &lt;- matrix(data = ve, nrow = 4, ncol = 3, byrow = FALSE) ma_col #&gt; [,1] [,2] [,3] #&gt; [1,] 1 5 9 #&gt; [2,] 2 6 10 #&gt; [3,] 3 7 11 #&gt; [4,] 4 8 12 A segundo forma, combinando vetores, utilizando a fun√ß√£o rbind() para combinar vetores por linha, i.e., vetor embaixo do outro, e cbind() para combinar vetores por coluna, i.e., vetor ao lado do outro. ## Criar dois vetores vec_1 &lt;- c(1, 2, 3) vec_2 &lt;- c(4, 5, 6) ## Combinar por linhas - vertical - um embaixo do outro ma_rbind &lt;- rbind(vec_1, vec_2) ma_rbind #&gt; [,1] [,2] [,3] #&gt; vec_1 1 2 3 #&gt; vec_2 4 5 6 ## Combinar por colunas - horizontal - um ao lado do outro ma_cbind &lt;- cbind(vec_1, vec_2) ma_cbind #&gt; vec_1 vec_2 #&gt; [1,] 1 4 #&gt; [2,] 2 5 #&gt; [3,] 3 6 4.4.1.2.4 Array O array representa combina√ß√£o de tabelas, com linhas, colunas e dimens√µes. Essa combina√ß√£o pode ser feita em m√∫ltiplas dimens√µes, mas apesar disso, geralmente √© mais comum o uso em Ecologia para tr√™s dimens√µes, por exemplo: linhas (unidades amostrais), colunas (esp√©cies) e dimens√£o (tempo). Isso gera um ‚Äúcubo m√°gico‚Äù ou ‚Äúcartas de um baralho,‚Äù onde podemos comparar, nesse caso, comunidades ao longo do tempo. Al√©m disso, arrays tamb√©m s√£o muito comuns em morfometria geom√©trica ou sensoriamento remoto. Podemos criar arrays no R dispondo elementos de um vetor em um certo n√∫mero de linhas, colunas e dimens√µes com a fun√ß√£o array(). Em nosso exemplo, vamos compor cinco comunidades de cinco esp√©cies ao longo de tr√™s per√≠odos. ## Array ar &lt;- array(data = sample(x = c(0, 1), size = 75, rep = TRUE), dim = c(5, 5, 3)) ar #&gt; , , 1 #&gt; #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 0 1 1 0 #&gt; [2,] 1 0 1 1 0 #&gt; [3,] 1 1 1 1 1 #&gt; [4,] 0 1 0 1 0 #&gt; [5,] 1 0 1 0 0 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0 0 0 1 0 #&gt; [2,] 0 1 0 1 0 #&gt; [3,] 1 1 1 1 0 #&gt; [4,] 0 0 0 0 1 #&gt; [5,] 0 0 0 0 0 #&gt; #&gt; , , 3 #&gt; #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0 1 1 1 1 #&gt; [2,] 0 0 0 0 0 #&gt; [3,] 0 1 1 1 1 #&gt; [4,] 0 0 1 0 0 #&gt; [5,] 0 1 0 1 0 4.4.1.2.5 Data frame O data frame tamb√©m representa dados no formato de tabela, com linhas e colunas, muito semelhante √† matriz. Mas diferentemente das matrizes, os data frames comportam mais de um modo em suas colunas. Dessa forma, as linhas do data frame ainda representam unidades amostrais (locais, transectos, parcelas), mas as colunas agora podem representar descri√ß√µes (informa√ß√µes em texto), vari√°veis num√©ricas (discretas ou cont√≠nuas), vari√°veis bin√°rias (TRUE ou FALSE) e vari√°veis categ√≥ricas (nominais ou ordinais). A forma mais simples de criar data frames no R √© atrav√©s da combina√ß√£o de vetores. Essa combina√ß√£o √© feita com a fun√ß√£o data.frame() e ocorre de forma horizontal, semelhante √† fun√ß√£o cbind(). Sendo assim, todos os vetores precisam ter o mesmo n√∫mero de elementos, ou seja, o mesmo comprimento. Podemos ainda nomear as colunas de cada vetor. ## Criar tr√™s vetores vec_ch &lt;- c(&quot;sp1&quot;, &quot;sp2&quot;, &quot;sp3&quot;) vec_nu &lt;- c(4, 5, 6) vec_fa &lt;- factor(c(&quot;campo&quot;, &quot;floresta&quot;, &quot;floresta&quot;)) ## Data frame - combinar por colunas - horizontal - um ao lado do outro df &lt;- data.frame(vec_ch, vec_nu, vec_fa) df #&gt; vec_ch vec_nu vec_fa #&gt; 1 sp1 4 campo #&gt; 2 sp2 5 floresta #&gt; 3 sp3 6 floresta ## Data frame - nomear as colunas df &lt;- data.frame(especies = vec_ch, abundancia = vec_nu, vegetacao = vec_fa) df #&gt; especies abundancia vegetacao #&gt; 1 sp1 4 campo #&gt; 2 sp2 5 floresta #&gt; 3 sp3 6 floresta 4.4.1.2.6 Lista A lista √© um tipo especial de vetor que aceita objetos como elementos. Ela √© a estrutura de dados utilizada para agrupar objetos, e √© geralmente a sa√≠da de muitas fun√ß√µes. Podemos criar listas atrav√©s da fun√ß√£o list(). Essa fun√ß√£o funciona de forma semelhante √† fun√ß√£o c() para a cria√ß√£o de vetores, mas agora estamos concatenando objetos. Podemos ainda nomear os elementos (objetos) que estamos combinando. Um ponto interessante para entender data frames, √© que eles s√£o listas, em que todos os elementos (colunas) possuem o mesmo n√∫mero de elementos, ou seja, mesmo comprimento. ## Lista lista &lt;- list(rep(1, 20), # vector factor(1, 1), # factor cbind(c(1, 2), c(1, 2))) # matrix lista #&gt; [[1]] #&gt; [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #&gt; #&gt; [[2]] #&gt; [1] 1 #&gt; Levels: 1 #&gt; #&gt; [[3]] #&gt; [,1] [,2] #&gt; [1,] 1 1 #&gt; [2,] 2 2 ## Lista - nomear os elementos lista_nome &lt;- list(vector = rep(1, 20), # vector factor = factor(1, 1), # factor matrix = cbind(c(1, 2), c(1, 2))) # matrix lista_nome #&gt; $vector #&gt; [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #&gt; #&gt; $factor #&gt; [1] 1 #&gt; Levels: 1 #&gt; #&gt; $matrix #&gt; [,1] [,2] #&gt; [1,] 1 1 #&gt; [2,] 2 2 4.4.1.2.7 Fun√ß√µes Uma √∫ltima estrutura de objetos criados no R s√£o as fun√ß√µes. Elas s√£o objetos criados pelo usu√°rio e reutilizados para fazer opera√ß√µes espec√≠ficas. A cria√ß√£o de fun√ß√µes geralmente √© um t√≥pico tratado num segundo momento, quando o usu√°rio de R adquire certo conhecimento da linguagem. Aqui abordaremos apenas seu funcionamento b√°sico, diferenciando sua estrutura para entendimento e sua diferencia√ß√£o das demais estruturas. Vamos criar uma fun√ß√£o simples que retorna a multiplica√ß√£o de dois termos. Criaremos a fun√ß√£o com o nome multi, √† qual ser√° atribu√≠da uma fun√ß√£o com o nome function(), com dois argumentos x e y. Depois disso abrimos chaves {}, que √© onde iremos incluir nosso bloco de c√≥digo. Nosso bloco de c√≥digo √© composto por duas linhas, a primeira contendo a opera√ß√£o de multiplica√ß√£o dos argumento com a atribui√ß√£o ao objeto mu e a sugunda contendo a fun√ß√£o return() para retornar o valor da multiplica√ß√£o. ## Criar uma fun√ß√£o multi &lt;- function(x, y){ mu &lt;- (x * y) return(mu) } multi #&gt; function(x, y){ #&gt; #&gt; mu &lt;- (x * y) #&gt; return(mu) #&gt; #&gt; } ## Uso da fun√ß√£o multi(42, 42) #&gt; [1] 1764 4.4.2 Manipula√ß√£o de objetos unidimensionais Vamos agora explorar formas de manipular elementos de objetos unidimensionais, ou seja, vetores, fatores e listas. A primeira forma de manipula√ß√£o √© atrav√©s da indexa√ß√£o, utilizando os operadores []. Com a indexa√ß√£o podemos acessar elementos de vetores e fatores por sua posi√ß√£o. Utilizaremos n√∫meros, sequ√™ncia de n√∫meros ou opera√ß√µes booleanas para retornar partes dos vetores ou fatores. Podemos ainda retirar elementos dessas estruturas com o operador aritm√©tico -. No exemplo a seguir, iremos fixar o ponto de partida da amostragem da fun√ß√£o sample(), utilizando a fun√ß√£o set.seed(42) (usamos 42 porque √© a resposta para a vida, o universo e tudo mais - O Guia do Mochileiro das Gal√°xias, mas poderia ser outro n√∫mero qualquer). Isso permite que o resultado da amostragem aleat√≥rio seja igual em diferentes computadores. ## Fixar a amostragem set.seed(42) ## Amostrar 10 elementos de uma sequ√™ncia ve &lt;- sample(x = seq(0, 2, .05), size = 10) ve #&gt; [1] 1.80 0.00 1.20 0.45 1.75 0.85 1.15 0.30 1.90 0.20 ## Seleciona o quinto elemento ve[5] #&gt; [1] 1.75 ## Seleciona os elementos de 1 a 5 ve[1:5] #&gt; [1] 1.80 0.00 1.20 0.45 1.75 ## Retira o decimo elemento ve[-10] #&gt; [1] 1.80 0.00 1.20 0.45 1.75 0.85 1.15 0.30 1.90 ## Retira os elementos 2 a 9 ve[-(2:9)] #&gt; [1] 1.8 0.2 Podemos ainda fazer uma sele√ß√£o condicional do vetor. Ao utilizarmos operadores relacionais, teremos como resposta um vetor l√≥gico. Esse vetor l√≥gico pode ser utilizado dentro da indexa√ß√£o para sele√ß√£o de elementos. ## Quais valores sao maiores que 1? ve &gt; 1 #&gt; [1] TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE ## Valores acima de 1 ve[ve &gt; 1] #&gt; [1] 1.80 1.20 1.75 1.15 1.90 Al√©m da indexa√ß√£o, temos algumas fun√ß√µes que nos auxiliam em algumas opera√ß√µes com objetos unidimensionais, listadas na Tabela 4.2. Tabela 4.2: Fun√ß√µes para verifica√ß√£o e resumo de dados unidimensionais. Fun√ß√£o Descri√ß√£o max() Valor m√°ximo min() Valor m√≠nimo range() Amplitude length() Comprimento sum() Soma cumsum() Soma cumulativa prod() Produto sqrt() Raiz quadrada abs() Valor absoluto exp() Expoente log() Logaritmo natural log1p() Logaritmo natural mais 1 log(x + 1) log2() Logaritmo base 2 log10() Logaritmo base 10 mean() M√©dia mean.weighted() M√©dia ponderada var() Vari√¢ncia sd() Desvio Padr√£o mediam() Mediana quantile() Quantil quarters() Quartil IQR() Amplitude interquartil round() Arredondamento sort() Ordena√ß√£o order() Posi√ß√£o ordenada rev() Reverso unique() √önicos summary() Resumo estat√≠stico cut() Divide vari√°vel cont√≠nua em fator pretty() Divide vari√°vel cont√≠nua em intervalos scale() Padroniza√ß√£o e centraliza√ß√£o sub() Substitui caracteres grep() Posi√ß√£o de caracteres any() Algum valor? all() Todos os valores? which() Quais valores? subset() Subconjunto ifelse() Opera√ß√£o condicional Para listas, tamb√©m podemos usar a indexa√ß√£o [] para acessar ou retirar elementos. ## Lista li &lt;- list(elem1 = 1, elem2 = 2, elem3 = 3) ## Acessar o primeiro elemento li[1] #&gt; $elem1 #&gt; [1] 1 ## Retirar o primeiro elemento li[-1] #&gt; $elem2 #&gt; [1] 2 #&gt; #&gt; $elem3 #&gt; [1] 3 Podemos ainda usar a indexa√ß√£o dupla [[]] para acessar os valores desses elementos. ## Acessar o valor do primeiro elemento li[[1]] #&gt; [1] 1 ## Acessar o valor do segundo elemento li[[2]] #&gt; [1] 2 Para listas nomeadas, podemos ainda utilizar o operador $ para acessar elementos pelo nome. ## Acessar o primeiro elemento li$elem1 #&gt; [1] 1 E ainda podemos utilizar fun√ß√µes para medir o comprimento dessa lista, listar os nomes dos elementos ou ainda renomear os elementos: length() e names(). ## Comprimento length(li) #&gt; [1] 3 ## Nomes names(li) #&gt; [1] &quot;elem1&quot; &quot;elem2&quot; &quot;elem3&quot; ## Renomear names(li) &lt;- paste0(&quot;elemento0&quot;, 1:3) li #&gt; $elemento01 #&gt; [1] 1 #&gt; #&gt; $elemento02 #&gt; [1] 2 #&gt; #&gt; $elemento03 #&gt; [1] 3 4.4.3 Manipula√ß√£o de objetos multidimensionais Da mesma forma que para objetos unidimensionais, podemos manipular elementos de objetos multidimensionais, ou seja, matrizes, data frames e arrays. Novamente, a primeira forma de manipula√ß√£o √© atrav√©s da indexa√ß√£o, utilizando os operadores []. Com a indexa√ß√£o podemos acessar elementos de matrizes, data frames e arrays por sua posi√ß√£o. Podemos ainda retirar elementos dessas estruturas com o operador aritm√©tico -. Entretanto, agora temos mais de uma dimens√£o na estrutura√ß√£o dos elementos dentro dos objetos. Assim, utilizamos n√∫meros, sequ√™ncia de n√∫meros ou opera√ß√£o booleanas para retornar partes desses objetos, mas as dimens√µes t√™m de ser explicitadas e separadas por v√≠rgulas para acessar linhas e colunas. Essa indexa√ß√£o funciona para matrizes e data frames. Para arrays, especificamos tamb√©m as dimens√µes, tamb√©m separadas por v√≠rgulas para acessar essas dimens√µes. ## Matriz ma &lt;- matrix(1:12, 4, 3) ma #&gt; [,1] [,2] [,3] #&gt; [1,] 1 5 9 #&gt; [2,] 2 6 10 #&gt; [3,] 3 7 11 #&gt; [4,] 4 8 12 ## Indexa√ß√£o ma[3, ] # linha 3 #&gt; [1] 3 7 11 ma[, 2] # coluna 2 #&gt; [1] 5 6 7 8 ma[1, 2] # elemento da linha 1 e coluna 2 #&gt; [1] 5 ma[1, 1:2] # elementos da linha 1 e coluna 1 e 2 #&gt; [1] 1 5 ma[1, c(1, 3)] # elementos da linha 1 e coluna 1 e 3 #&gt; [1] 1 9 ma[-1, ] # retirar a linha 1 #&gt; [,1] [,2] [,3] #&gt; [1,] 2 6 10 #&gt; [2,] 3 7 11 #&gt; [3,] 4 8 12 ma[, -3] # retirar a coluna 3 #&gt; [,1] [,2] #&gt; [1,] 1 5 #&gt; [2,] 2 6 #&gt; [3,] 3 7 #&gt; [4,] 4 8 Para data frames, al√©m de utilizar n√∫meros e/ou sequ√™ncias de n√∫meros dentro do operador [] simples, assim como podemos utilizar o operador [[]] duplo para retornar apenas os valores de uma linha ou uma coluna. Se as colunas estiverem nomeadas, podemos utilizar o nome da coluna de interesse entre aspas dentro dos operadores [] (retornar coluna) e [[]] (retornar apenas os valores), assim como ainda podemos utilizar o operador $ para data frames. Essas √∫ltimas opera√ß√µes retornam um vetor, para o qual podemos fazer opera√ß√µes de vetores ou ainda atualizar o valor dessa coluna selecionada ou adicionar outra coluna. ## Criar tr√™s vetores sp &lt;- paste(&quot;sp&quot;, 1:10, sep = &quot;&quot;) abu &lt;- 1:10 flo &lt;- factor(rep(c(&quot;campo&quot;, &quot;floresta&quot;), each = 5)) ## data frame df &lt;- data.frame(sp, abu, flo) df #&gt; sp abu flo #&gt; 1 sp1 1 campo #&gt; 2 sp2 2 campo #&gt; 3 sp3 3 campo #&gt; 4 sp4 4 campo #&gt; 5 sp5 5 campo #&gt; 6 sp6 6 floresta #&gt; 7 sp7 7 floresta #&gt; 8 sp8 8 floresta #&gt; 9 sp9 9 floresta #&gt; 10 sp10 10 floresta ## [] - n√∫meros df[, 1] #&gt; [1] &quot;sp1&quot; &quot;sp2&quot; &quot;sp3&quot; &quot;sp4&quot; &quot;sp5&quot; &quot;sp6&quot; &quot;sp7&quot; &quot;sp8&quot; &quot;sp9&quot; &quot;sp10&quot; ## [] - nome das colunas - retorna coluna df[&quot;flo&quot;] #&gt; flo #&gt; 1 campo #&gt; 2 campo #&gt; 3 campo #&gt; 4 campo #&gt; 5 campo #&gt; 6 floresta #&gt; 7 floresta #&gt; 8 floresta #&gt; 9 floresta #&gt; 10 floresta ## [[]] - nome das colunas - retorna apenas os valores df[[&quot;flo&quot;]] #&gt; [1] campo campo campo campo campo floresta floresta floresta floresta floresta #&gt; Levels: campo floresta ## $ funciona apenas para data frame df$sp #&gt; [1] &quot;sp1&quot; &quot;sp2&quot; &quot;sp3&quot; &quot;sp4&quot; &quot;sp5&quot; &quot;sp6&quot; &quot;sp7&quot; &quot;sp8&quot; &quot;sp9&quot; &quot;sp10&quot; ## Opera√ß√£o de vetors length(df$abu) #&gt; [1] 10 ## Converter colunas df$abu &lt;- as.character(df$abu) mode(df$abu) #&gt; [1] &quot;character&quot; ## Adicionar colunas set.seed(42) df$abu2 &lt;- sample(x = 0:1, size = nrow(df), rep = TRUE) df #&gt; sp abu flo abu2 #&gt; 1 sp1 1 campo 0 #&gt; 2 sp2 2 campo 0 #&gt; 3 sp3 3 campo 0 #&gt; 4 sp4 4 campo 0 #&gt; 5 sp5 5 campo 1 #&gt; 6 sp6 6 floresta 1 #&gt; 7 sp7 7 floresta 1 #&gt; 8 sp8 8 floresta 1 #&gt; 9 sp9 9 floresta 0 #&gt; 10 sp10 10 floresta 1 Podemos ainda fazer sele√ß√µes condicionais para retornar linhas com valores que temos interesse, semelhante ao uso de filtro de uma planilha eletr√¥nica. ## Selecionar linhas de uma matriz ou data frame df[df$abu &gt; 4, ] #&gt; sp abu flo abu2 #&gt; 5 sp5 5 campo 1 #&gt; 6 sp6 6 floresta 1 #&gt; 7 sp7 7 floresta 1 #&gt; 8 sp8 8 floresta 1 #&gt; 9 sp9 9 floresta 0 df[df$flo == &quot;floresta&quot;, ] #&gt; sp abu flo abu2 #&gt; 6 sp6 6 floresta 1 #&gt; 7 sp7 7 floresta 1 #&gt; 8 sp8 8 floresta 1 #&gt; 9 sp9 9 floresta 0 #&gt; 10 sp10 10 floresta 1 Al√©m disso, h√° uma s√©rie de fun√ß√µes para confer√™ncia e manipula√ß√£o de dados que listamos na Tabela 4.3. Tabela 4.3: Fun√ß√µes para verifica√ß√£o e resumo de dados multidimensionais. Fun√ß√£o Descri√ß√£o head() Mostra as primeiras 6 linhas tail() Mostra as √∫ltimas 6 linhas nrow() Mostra o n√∫mero de linhas ncol() Mostra o n√∫mero de colunas dim() Mostra o n√∫mero de linhas e de colunas rownames() Mostra os nomes das linhas (locais) colnames() Mostra os nomes das colunas (vari√°veis) str() Mostra as classes de cada coluna (estrutura) summary() Mostra um resumo dos valores de cada coluna rowSums() Calcula a soma das linhas (horizontal) colSums() Calcula a soma das colunas (vertical) rowMeans() Calcula a m√©dia das linhas (horizontal) colMeans() Calcula a m√©dia das colunas (vertical) str() Mostra a estrutura dos dados table() Tabula√ß√£o cruzada t() Matriz ou data frame transposto 4.4.4 Valores faltantes e especiais Valores faltantes e especiais s√£o valores reservados que representam dados faltantes, indefini√ß√µes matem√°ticas, infinitos e objetos nulos. NA (Not Available): significa dado faltante ou indispon√≠vel NaN (Not a Number): representa indefini√ß√µes matem√°ticas Inf (Infinito): √© um n√∫mero muito grande ou um limite matem√°tico NULL (Nulo): representa um objeto nulo, sendo √∫til para preenchimento em aplica√ß√µes de programa√ß√£o ## Data frame com elemento NA df &lt;- data.frame(var1 = c(1, 4, 2, NA), var2 = c(1, 4, 5, 2)) df #&gt; var1 var2 #&gt; 1 1 1 #&gt; 2 4 4 #&gt; 3 2 5 #&gt; 4 NA 2 ## Resposta booleana para elementos NA is.na(df) #&gt; var1 var2 #&gt; [1,] FALSE FALSE #&gt; [2,] FALSE FALSE #&gt; [3,] FALSE FALSE #&gt; [4,] TRUE FALSE ## Algum elemento √© NA? any(is.na(df)) #&gt; [1] TRUE ## Remover as linhas com NAs df_sem_na &lt;- na.omit(df) df_sem_na #&gt; var1 var2 #&gt; 1 1 1 #&gt; 2 4 4 #&gt; 3 2 5 ## Substituir NAs por 0 df[is.na(df)] &lt;- 0 df #&gt; var1 var2 #&gt; 1 1 1 #&gt; 2 4 4 #&gt; 3 2 5 #&gt; 4 0 2 ## Desconsiderar os NAs em fun√ß√µes com o argumento rm.na = TRUE sum(1, 2, 3, 4, NA, na.rm = TRUE) #&gt; [1] 10 ## NaN - not a number 0/0 #&gt; [1] NaN log(-1) #&gt; [1] NaN ## Limite matem√°tico 1/0 #&gt; [1] Inf ## N√∫mero grande 10^310 #&gt; [1] Inf ## Objeto nulo nulo &lt;- NULL nulo #&gt; NULL 4.4.5 Diret√≥rio de trabalho O diret√≥rio de trabalho √© o endere√ßo da pasta (ou diret√≥rio) de onde o R importar√° ou exportar nossos dados. Podemos utilizar o pr√≥prio RStudio para tal tarefa, indo em Session &gt; Set Work Directory &gt; Choose Directory... ou simplesmente utilizar o atalho Ctrl + Shift + H. Podemos ainda utilizar as fun√ß√µes do R para definir o diret√≥rio. Para tanto, podemos navegar com o aplicativo de gerenciador de arquivos (e.g., Windows Explorer) at√© nosso diret√≥rio de interesse e copiar o endere√ßo na barra superior. Voltamos para o R e colamos esse endere√ßo entre aspas como um argumento da fun√ß√£o setwd(). √â fundamental destacar que em Sistemas Operacionais Windows √© necess√°rio inverter as barras (\\ por /). Aconselhamos ainda utilizar as fun√ß√µes getwd() para retornar o diret√≥rio definido na sess√£o do R, assim como as fun√ß√µes dir() ou list.files() para listagem dos arquivos no diret√≥rio, ambas medidas de confer√™ncia do diret√≥rio correto. ## Definir o diret√≥rio de trabalho setwd(&quot;/home/mude/data/github/livro_r_ecologia/dados&quot;) ## Verificar o diret√≥rio getwd() ## Listar os arquivos no diret√≥rio dir() list.files() Outra forma de definir o diret√≥rio √© digitar a tecla tab dentro da fun√ß√£o setwd(\"tab\"). Quando apertamos a tab dentro das aspas conseguimos selecionar o diret√≥rio manualmente, pois abre-se uma lista de diret√≥rio que podemos ir selecionando at√© chegar no diret√≥rio de interesse. ## Mudar o diret√≥rio com a tecla tab setwd(&quot;`tab`&quot;) 4.4.6 Importar dados Uma das opera√ß√µes mais corriqueiras do R, antes de realizar alguma an√°lise ou plotar um gr√°fico, √© a de importar dados que foram tabulados numa planilha eletr√¥nica e salvos no formato .csv, .txt ou .xlsx. Ao importar esse tipo de dado para o R, o formato que o mesmo assume, se nenhum par√¢metro for especificado, √© o da classe data frame, prevendo que a planilha de dados possua colunas com diferentes modos. Existem diversas formas de importar dados para o R. Podemos importar utilizando o RStudio, indo na janela Environment (Figura 4.2 (3)) e clicar em ‚ÄúImportar Dataset.‚Äù Entretanto, aconselhamos o uso de fun√ß√µes que fiquem salvas em um script para aumentar a reprodutibilidade do mesmo. Dessa forma, as tr√™s principais fun√ß√µes para importar os arquivos nos tr√™s principais extens√µes (.csv, .txt ou .xlsx) s√£o, respectivamente: read.csv(), read.table() e openxlsx::read.xlsx(), sendo o √∫ltimo do pacote openxlsx. ## Instalar o pacote openxlsx install.packages(&quot;openxlsx&quot;) library(openxlsx) Para exemplificar como importar dados vamos usar os dados de comunidades de anf√≠bios da Mata Atl√¢ntica (Atlantic Amphibians, Vancine et al. (2018)). Faremos o download diretamente do site da fonte dos dados. Vamos antes escolher um diret√≥rio de trabalho com a fun√ß√£o setwd(), e em seguida criar um diret√≥rio com a fun√ß√£o dir.create() chamado ‚Äúdados.‚Äù Em seguida, vamos mudar nosso diret√≥rio para essa pasta e criar mais um diret√≥rio chamado ‚Äútabelas,‚Äù e por fim, definir esse diret√≥rio para que o conte√∫do do download seja armazenado ali. ## Escolher um diret√≥rio setwd(&quot;/home/mude/data/github/livro_r_ecologia&quot;) ## Criar um diret√≥rio &#39;dados&#39; dir.create(&quot;dados&quot;) ## Escolher diret√≥rio &#39;dados&#39; setwd(&quot;dados&quot;) ## Criar um diret√≥rio &#39;tabelas&#39; dir.create(&quot;tabelas&quot;) ## Escolher diret√≥rio &#39;tabelas&#39; setwd(&quot;tabelas&quot;) Agora podemos fazer o download do arquivo .zip e extrair as tabelas usando a fun√ß√£o unzip() nesse mesmo diret√≥rio. ## Download download.file(url = &quot;https://esajournals.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1002%2Fecy.2392&amp;file=ecy2392-sup-0001-DataS1.zip&quot;, destfile = &quot;atlantic_amphibians.zip&quot;, mode = &quot;wb&quot;) ## Unzip unzip(zipfile = &quot;atlantic_amphibians.zip&quot;) Agora podemos importar a tabela de dados com a fun√ß√£o read.csv(), atribuindo ao objeto intror_anfibios_locais. Devemos atentar para o argumento encoding, que selecionamos aqui como latin1 para corrigir um erro do autor dos dados que publicou esse data paper com erros‚Ä¶ ## Importar a tabela de locais intror_anfibios_locais &lt;- read.csv(&quot;dados/tabelas/ATLANTIC_AMPHIBIANS_sites.csv&quot;, encoding = &quot;latin1&quot;) Esse arquivo foi criado com separador de decimais sendo . e separador de colunas sendo ,. Caso tivesse sido criado com separador de decimais sendo , e separador de colunas sendo ;, usar√≠amos a fun√ß√£o read.csv2(). Para outros formatos, basta usar as outras fun√ß√µes apresentadas, atentando-se para os argumentos espec√≠ficos de cada fun√ß√£o. Outra forma de importar dados, principalmente quando n√£o sabemos exatamente o nome do arquivo e tamb√©m para evitar erros de digita√ß√£o, √© utilizar a tecla tab dentro das aspas da fun√ß√£o de importa√ß√£o. Dessa forma, conseguimos ter acesso aos arquivos do nosso diret√≥rio e temos a possibilidade de selecion√°-los sem erros de digita√ß√£o. ## Importar usando a tecla tab intror_anfibios_locais &lt;- read.csv(&quot;`tab`&quot;) intror_anfibios_locais Caso o download n√£o funcione ou haja problemas com a importa√ß√£o, disponibilizamos os dados tamb√©m no pacote ecodados. ## Importar os dados pelo pacote ecodados data(intror_anfibios_locais) head(intror_anfibios_locais) #&gt; id reference_number species_number record sampled_habitat active_methods #&gt; 1 amp1001 1001 19 ab fo,ll as #&gt; 2 amp1002 1002 16 co fo,la,ll as #&gt; 3 amp1003 1002 14 co fo,la,ll as #&gt; 4 amp1004 1002 13 co fo,la,ll as #&gt; 5 amp1005 1003 30 co fo,ll,br as #&gt; 6 amp1006 1004 42 co tp,pp,la,ll,is &lt;NA&gt; #&gt; passive_methods complementary_methods period month_start year_start month_finish #&gt; 1 pt &lt;NA&gt; mo,da,tw,ni 9 2000 1 #&gt; 2 pt &lt;NA&gt; mo,da,tw,ni 12 2007 5 #&gt; 3 pt &lt;NA&gt; mo,da,tw,ni 12 2007 5 #&gt; 4 pt &lt;NA&gt; mo,da,tw,ni 12 2007 5 #&gt; 5 &lt;NA&gt; &lt;NA&gt; mo,da,ni 7 1988 8 #&gt; 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; year_finish effort_months country state state_abbreviation municipality #&gt; 1 2002 16 Brazil Piau√≠ BR-PI Canto do Buriti #&gt; 2 2009 17 Brazil Cear√° BR-CE S√£o Gon√ßalo do Amarante #&gt; 3 2009 17 Brazil Cear√° BR-CE S√£o Gon√ßalo do Amarante #&gt; 4 2009 17 Brazil Cear√° BR-CE S√£o Gon√ßalo do Amarante #&gt; 5 2001 157 Brazil Cear√° BR-CE Baturit√© #&gt; 6 NA NA Brazil Cear√° BR-CE Quebrangulo #&gt; site latitude longitude coordinate_precision altitude #&gt; 1 Parque Nacional Serra das Confus√µes -8.680000 -43.42194 gm 543 #&gt; 2 Dunas -3.545527 -38.85783 dd 15 #&gt; 3 Jardim Bot√¢nico¬†Municipal de¬†Bauru -3.574194 -38.88869 dd 29 #&gt; 4 Ta√≠ba -3.515250 -38.91880 dd 25 #&gt; 5 Serra de Baturit√© -4.280556 -38.91083 gm 750 #&gt; 6 Reserva Biol√≥gica de Pedra Talhada -9.229167 -36.42806 &lt;NA&gt; 745 #&gt; temperature precipitation #&gt; 1 24.98 853 #&gt; 2 26.53 1318 #&gt; 3 26.45 1248 #&gt; 4 26.55 1376 #&gt; 5 21.35 1689 #&gt; 6 20.45 1249 4.4.7 Confer√™ncia dos dados importados Uma vez importados os dados para o R, geralmente antes de iniciarmos qualquer manipula√ß√£o, visualiza√ß√£o ou an√°lise de dados, fazemos a confer√™ncia desses dados. Para isso, podemos utilizar as fun√ß√µes listadas na Tabela 4.3. Dentre todas essas fun√ß√µes de verifica√ß√£o, destacamos a import√¢ncia destas fun√ß√µes apresentadas abaixo para saber se as vari√°veis foram importadas e interpretadas corretamente e reconhecer erros de digita√ß√£o, por exemplo. ## Primeiras linhas head(intror_anfibios_locais) #&gt; id reference_number species_number record sampled_habitat active_methods #&gt; 1 amp1001 1001 19 ab fo,ll as #&gt; 2 amp1002 1002 16 co fo,la,ll as #&gt; 3 amp1003 1002 14 co fo,la,ll as #&gt; 4 amp1004 1002 13 co fo,la,ll as #&gt; 5 amp1005 1003 30 co fo,ll,br as #&gt; 6 amp1006 1004 42 co tp,pp,la,ll,is &lt;NA&gt; #&gt; passive_methods complementary_methods period month_start year_start month_finish #&gt; 1 pt &lt;NA&gt; mo,da,tw,ni 9 2000 1 #&gt; 2 pt &lt;NA&gt; mo,da,tw,ni 12 2007 5 #&gt; 3 pt &lt;NA&gt; mo,da,tw,ni 12 2007 5 #&gt; 4 pt &lt;NA&gt; mo,da,tw,ni 12 2007 5 #&gt; 5 &lt;NA&gt; &lt;NA&gt; mo,da,ni 7 1988 8 #&gt; 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; year_finish effort_months country state state_abbreviation municipality #&gt; 1 2002 16 Brazil Piau√≠ BR-PI Canto do Buriti #&gt; 2 2009 17 Brazil Cear√° BR-CE S√£o Gon√ßalo do Amarante #&gt; 3 2009 17 Brazil Cear√° BR-CE S√£o Gon√ßalo do Amarante #&gt; 4 2009 17 Brazil Cear√° BR-CE S√£o Gon√ßalo do Amarante #&gt; 5 2001 157 Brazil Cear√° BR-CE Baturit√© #&gt; 6 NA NA Brazil Cear√° BR-CE Quebrangulo #&gt; site latitude longitude coordinate_precision altitude #&gt; 1 Parque Nacional Serra das Confus√µes -8.680000 -43.42194 gm 543 #&gt; 2 Dunas -3.545527 -38.85783 dd 15 #&gt; 3 Jardim Bot√¢nico¬†Municipal de¬†Bauru -3.574194 -38.88869 dd 29 #&gt; 4 Ta√≠ba -3.515250 -38.91880 dd 25 #&gt; 5 Serra de Baturit√© -4.280556 -38.91083 gm 750 #&gt; 6 Reserva Biol√≥gica de Pedra Talhada -9.229167 -36.42806 &lt;NA&gt; 745 #&gt; temperature precipitation #&gt; 1 24.98 853 #&gt; 2 26.53 1318 #&gt; 3 26.45 1248 #&gt; 4 26.55 1376 #&gt; 5 21.35 1689 #&gt; 6 20.45 1249 ## √öltimas linhas tail(intror_anfibios_locais) #&gt; id reference_number species_number record sampled_habitat active_methods #&gt; 1158 amp2158 1389 3 co &lt;NA&gt; &lt;NA&gt; #&gt; 1159 amp2159 1389 9 co &lt;NA&gt; &lt;NA&gt; #&gt; 1160 amp2160 1389 6 co &lt;NA&gt; &lt;NA&gt; #&gt; 1161 amp2161 1389 1 co &lt;NA&gt; &lt;NA&gt; #&gt; 1162 amp2162 1389 2 co &lt;NA&gt; &lt;NA&gt; #&gt; 1163 amp2163 1389 2 co &lt;NA&gt; &lt;NA&gt; #&gt; passive_methods complementary_methods period month_start year_start month_finish #&gt; 1158 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; 1159 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; 1160 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; 1161 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; 1162 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; 1163 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA NA NA #&gt; year_finish effort_months country state state_abbreviation municipality #&gt; 1158 NA NA Argentina Misiones AR-N Manuel Belgrano #&gt; 1159 NA NA Argentina Misiones AR-N Posadas #&gt; 1160 NA NA Argentina Misiones AR-N Montecarlo #&gt; 1161 NA NA Argentina Misiones AR-N San Pedro #&gt; 1162 NA NA Argentina Misiones AR-N Caingu√°s #&gt; 1163 NA NA Argentina Misiones AR-N Ober√° #&gt; site latitude longitude coordinate_precision altitude #&gt; 1158 Comandante Andresito -25.66944 -54.04556 gms 251 #&gt; 1159 Posadas -27.45333 -55.89250 gms 105 #&gt; 1160 Montecarlo -26.56889 -53.60889 gms 597 #&gt; 1161 Refugio Mocon√° -27.14083 -53.92611 gms 202 #&gt; 1162 Balneario Municipal Cu√±√° Pir√∫ -27.08722 -54.95278 gms 213 #&gt; 1163 Chacra San Juan de Dios -27.47333 -55.17194 gms 254 #&gt; temperature precipitation #&gt; 1158 19.94 1780 #&gt; 1159 21.30 1768 #&gt; 1160 18.35 1954 #&gt; 1161 19.92 1850 #&gt; 1162 21.04 1553 #&gt; 1163 20.67 1683 ## N√∫mero de linhas e colunas nrow(intror_anfibios_locais) #&gt; [1] 1163 ncol(intror_anfibios_locais) #&gt; [1] 25 dim(intror_anfibios_locais) #&gt; [1] 1163 25 ## Nome das linhas e colunas rownames(intror_anfibios_locais) colnames(intror_anfibios_locais) ## Estrutura dos dados str(intror_anfibios_locais) ## Resumo dos dados summary(intror_anfibios_locais) ## Verificar NAs any(is.na(intror_anfibios_locais)) which(is.na(intror_anfibios_locais)) ## Remover as linhas com NAs intror_anfibios_locais_na &lt;- na.omit(intror_anfibios_locais) 4.4.8 Exportar dados Uma vez realizado as opera√ß√µes de manipula√ß√£o ou tendo dados que foram analisados e armazenados num objeto no formato de data frame ou matriz, podemos exportar esses dados do R para o diret√≥rio que definimos anteriormente. Para tanto, podemos utilizar fun√ß√µes de escrita de dados, como write.csv(), write.table() e openxlsx::write.xlsx(). Dois pontos s√£o fundamentais: 1. o nome do arquivo tem de estar entre aspas e no final dele deve constar a extens√£o que pretendemos que o arquivo tenha; 2. √© interessante utilizar os argumentos row.names = FALSE e quote=FALSE, para que o arquivo escrito n√£o tenha o nome das linhas ou aspas em todas as c√©lulas, respectivamente. ## Exportar dados na extens√£o .csv write.csv(intror_anfibios_locais_na, &quot;ATLANTIC_AMPHIBIAN_sites_na.csv&quot;, row.names = FALSE, quote = FALSE) ## Exportar dados na extens√£o .txt write.table(intror_anfibios_locais_na, &quot;ATLANTIC_AMPHIBIAN_sites_na.txt&quot;, row.names = FALSE, quote = FALSE) ## Exportar dados na extens√£o .xlsx openxlsx::write.xlsx(intror_anfibios_locais_na, &quot;ATLANTIC_AMPHIBIAN_sites_na.xlsx&quot;, row.names = FALSE, quote = FALSE) 4.5 Exerc√≠cios Use o R para verificar o resultado da opera√ß√£o 7 + 7 √∑ 7 + 7 x 7 - 7. Verifique atrav√©s do R se 3x2¬≥ √© maior que 2x3¬≤. Crie dois objetos (qualquer nome) com os valores 100 e 300. Multiplique esses objetos (fun√ß√£o prod()) e atribuam ao objeto mult. Fa√ßa o logaritmo natural (fun√ß√£o log()) do objeto mult e atribuam ao objeto ln. Quantos pacotes existem no CRAN nesse momento? Execute essa combina√ß√£o no Console: nrow(available.packages(repos = \"http://cran.r-project.org\")). Instale o pacote tidyverse do CRAN. Escolha n√∫meros para jogar na mega-sena usando o R, nomeando o objeto como mega. Lembrando: s√£o 6 valores de 1 a 60 e atribuam a um objeto. Crie um fator chamado tr, com dois n√≠veis (‚Äúcont‚Äù e ‚Äútrat‚Äù) para descrever 100 locais de amostragem, 50 de cada tratamento. O fator deve ser dessa forma cont, cont, cont, ...., cont, trat, trat, ...., trat. Crie uma matriz chamada ma, resultante da disposi√ß√£o de um vetor composto por 10000 valores aleat√≥rios entre 0 e 10. A matriz deve conter 100 linhas e ser disposta por colunas. Crie um data frame chamado df, resultante da composi√ß√£o desses vetores: id: 1:50 sp: sp01, sp02, ..., sp49, sp50 ab: 50 valores aleat√≥rios entre 0 a 5 Crie uma lista com os objetos criados anteriormente: mega, tr, ma e df. Selecione os elementos √≠mpares do objeto tr, e atribua ao objeto tr_impar. Selecione as linhas com ids pares do objeto df, e atribua ao objeto df_ids_par. Fa√ßa uma amostragem de 10 linhas do objeto df, e atribua ao objeto df_amos10. 4.6 Para se aprofundar Listamos a seguir livros e links com material que recomendamos para seguir com sua aprendizagem em R Base. 4.6.1 Livros Mayer F. P., Bonat W. H., Zeviani W. M., Krainski E. T., Ribeiro Jr.¬†P. J. 2018. Estat√≠stica Computacional com R. [http://cursos.leg.ufpr.br/ecr/index.html] Zeviani W. M. 2019. Manual de Planejamento e An√°lise de Experimentos com R. [http://leg.ufpr.br/~walmes/mpaer/] Curso-R. 2021. Ci√™ncia de Dados em R. [https://livro.curso-r.com/] Adler J. 2012. R in a Nutshell: A Desktop Quick Reference. 2 ed.¬†O‚ÄôReilly Media. Burns P. 2011. The R Inferno. [https://www.burns-stat.com/pages/Tutor/R_inferno.pdf] Cotton R. 2013. Learning R: A Step-by-Step Function Guide to Data Analysis. O‚ÄôReilly Media. Crawley MJ. 2012. The R Book. 2 ed.¬†Wiley. Davies TM. 2016. The Book of R: A First Course in Programming and Statistics. No Starch Press. Douglas A, Roos D, Mancini F, Couto A, Lusseau D. An Introduction to R. 2021 [https://intro2r.com/] Engel C. 2019. Introduction to R. [https://cengel.github.io/R-intro/] Gillespie C., Lovelace R, 2016. Efficient R programming. O‚ÄôReilly Media. [https://bookdown.org/csgillespie/efficientR/] Grolemund G. 2014. Hands-On Programming with R. O‚ÄôReilly Media. Holmes S, Huber W. 2019. Modern Statistics for Modern Biology. Cambridge University Press. [https://www.huber.embl.de/msmb/] Irizarry RA, Love MI. 2016. Data Analysis for the Life Sciences with R. Chapman and Hall/CRC. James G, Witten D, Hastie T, Tibshirani R. 2013. An Introduction to Statistical Learning: with Applications in R. 2 ed.¬†Springer. [http://faculty.marshall.usc.edu/gareth-james/ISL/] Kabacoff RI. 2015. R in Action: Data analysis and graphics with R. 2 ed.¬†Manning. Lander JP. 2017. R for Everyone: Advanced Analytics and Graphics. Addison-Wesley Professional. Matloff N. 2011. The Art of R Programming: A Tour of Statistical Software Design. No Starch Press. Long JD, Teetor P. 2019. R Cookbook.2 ed.¬†O‚ÄôReilly Media. [https://rc2e.com/] Wickham H. 2019. Advanced R. 2 ed.¬†Chapman and Hall/CRC. [https://adv-r.hadley.nz/] Wickham H. 2015. R Packages: Organize, Test, Document, and Share Your Code. O‚ÄôReilly Media. [https://r-pkgs.org/] 4.6.2 Links Materiais sobre R R resources (free courses, books, tutorials, &amp; cheat sheets) Data Science for Ecologists and Environmental Scientists Data Analysis and Visualization in R for Ecologists A (very) shortintroduction to R - Paul Torfs &amp; Claudia Brauer R forBeginners - Emmanuel Paradis Refer√™ncias "],["cap5.html", "Cap√≠tulo 5 Tidyverse Pr√©-requisitos do cap√≠tulo 5.1 Contextualiza√ß√£o 5.2 tidyverse 5.3 here 5.4 readr, readxl e writexl 5.5 tibble 5.6 magrittr (pipe - %&gt;%) 5.7 tidyr 5.8 dplyr 5.9 stringr 5.10 forcats 5.11 lubridate 5.12 purrr 5.13 Exerc√≠cios 5.14 Para se aprofundar", " Cap√≠tulo 5 Tidyverse Pr√©-requisitos do cap√≠tulo Pacotes que ser√£o utilizados nesse cap√≠tulo. ## Pacotes library(tidyverse) library(here) library(ggplot2) library(purrr) library(tibble) library(dplyr) library(tidyr) library(stringr) library(readr) library(forcats) library(palmerpenguins) library(lubridate) 5.1 Contextualiza√ß√£o Como todo idioma, a linguagem R vem passando por transforma√ß√µes nos √∫ltimos anos. Grande parte dessas mudan√ßas est√£o dentro do paradigma da Ci√™ncia de Dados (Data Science), uma nova √°rea de conhecimento que vem se moldando a partir do desenvolvimento da sociedade em torno da era digital e da grande quantidade de dados gerados e dispon√≠veis pela internet, de onde adv√©m os pilares das inova√ß√µes tecnol√≥gicas: Big Data, Machine Learning e Internet of Things. A grande necessidade de computa√ß√£o para desenvolver esse novo paradigma colocaram o R e o python como as principais linguagens de programa√ß√£o frente a esses novos desafios. Apesar de n√£o serem as √∫nicas ferramentas utilizadas para esse prop√≥sito, elas rapidamente se tornaram uma das melhores escolhas, dado v√°rios fatores como: s√£o de c√≥digo-aberto e gratuitas, possu√≠rem grandes comunidades contribuidoras, serem linguagens de interpreta√ß√£o (orientadas a objeto) e relativamente f√°ceis de serem aprendidas e aplicadas. Essas mudan√ßas e expan√ß√µes na utiliza√ß√£o da linguagem R para a Ci√™ncia de Dados come√ßaram a ser implementadas principalmente devido a um pesquisador: Hadley Wickham, que iniciou sua contribui√ß√£o √† comunidade R com o desenvolvimento do j√° consagrado pacote ggplot2 (Wickham 2016) para a composi√ß√£o de gr√°ficos no R (ver mais no Cap√≠tulo 6), baseado na gram√°tica de gr√°ficos (Wilkinson and Wills 2005). Depois disso, Wickham dedicou-se ao desenvolvimento do pensamento de uma nova abordagem dentro da manipula√ß√£o de dados, denominada Tidy Data (Dados organizados) (Wickham 2014), na qual focou na limpeza e organiza√ß√£o de dados. A ideia postula que dados est√£o tidy quando: 1) vari√°veis est√£o nas colunas, 2) observa√ß√µes est√£o nas linhas e 3) valores est√£o nas c√©lulas, sendo que para esse √∫ltimo, n√£o deve haver mais de um valor por c√©lula (Figura 5.2). A partir dessas ideias, o tidyverse foi operacionalizado no R como uma cole√ß√£o de pacotes que atuam no workflow comum da ci√™ncia de dados: importa√ß√£o, manipula√ß√£o, explora√ß√£o, visualiza√ß√£o, an√°lise e comunica√ß√£o de dados e an√°lises (Wickham et al. 2019) (Figura 5.1). O principal objetivo do tidyverse √© aproximar a linguagem para melhorar a intera√ß√£o entre ser humano e computador sobre dados, de modo que os pacotes compartilham uma filosofia de design de alto n√≠vel e gram√°tica, al√©m da estrutura de dados de baixo n√≠vel (Wickham et al. 2019). As principais leituras sobre o tema no R s√£o os artigos (Wickham 2014) e (Wickham et al. 2019), e o livro (Wickham and Grolemund 2017), dispon√≠vel on-line neste link, al√©m do site que possui muito mais informa√ß√µes. Figura 5.1: Modelo das ferramentas necess√°rias em um projeto t√≠pico de ci√™ncia de dados: importar, organizar, entender (transformar, visualizar, modelar) e comunicar, envolto √† essas ferramentas est√° a programa√ß√£o. Adaptado de: Wickham and Grolemund (2017). 5.2 tidyverse Uma vez instalado e carregado, o pacote tidyverse disponibiliza um conjunto de ferramentas atrav√©s de v√°rios pacotes. Esses pacotes compartilham uma filosofia de design, gram√°tica e estruturas. Podemos entender o tidyverse como um ‚Äúdialeto novo‚Äù para a linguagem R, onde tidy quer dizer organizado, arrumado, ordenado, e verse √© universo. A seguir, listamos os principais pacotes e suas especifica√ß√µes. readr: importa dados tabulares (e.g.¬†.csv e .txt) tibble: implementa a classe tibble tidyr: transforma√ß√£o de dados para tidy dplyr: manipula√ß√£o de dados stringr: manipula√ß√£o de caracteres forcats: manipula√ß√£o de fatores ggplot2: possibilita a visualiza√ß√£o de dados purrr: disponibiliza ferramentas para programa√ß√£o funcional Al√©m dos pacotes principais, fazemos tamb√©m men√ß√£o a outros pacotes que est√£o dentro dessa abordagem e que trataremos ainda neste cap√≠tulo, em outro momento do livro, ou que voc√™ leitor(a) deve se familiarizar. Alguns pacotes comp√µem o tidyverse outros s√£o mais gerais, entretanto, todos est√£o envolvidos de alguma forma com Data Science. readxl e writexl: importa e exporta dados tabulares (.xlsx) janitor: examinar e limpar dados sujos DBI: interface de banco de dados R haven: importa e exporta dados do SPSS, Stata e SAS httr: ferramentas para trabalhar com URLs e HTTP rvest: coletar facilmente (raspe) p√°ginas da web xml2: trabalhar com arquivos XML jsonlite: um analisador e gerador JSON simples e robusto para R hms: hora do dia lubridate: facilita o tratamento de datas magrittr: prov√™ os operadores pipe (%&gt;%, %$%, %&lt;&gt;%) glue: facilita combinar dados e caracteres rmarkdown: cria documentos de an√°lise din√¢mica que combinam c√≥digo, sa√≠da renderizada (como figuras) e texto knitr: projetado para ser um mecanismo transparente para gera√ß√£o de relat√≥rios din√¢micos com R shiny: framework de aplicativo Web para R flexdashboard: pain√©is interativos para R here: facilita a defini√ß√£o de diret√≥rios usethis: automatiza tarefas durante a configura√ß√£o e desenvolvimento de projetos (Git, ‚ÄòGitHub‚Äô e Projetos RStudio) data.table: pacote que fornece uma vers√£o de alto desempenho do data.frame (importar, manipular e expotar) reticulate: pacote que fornece ferramentas para integrar Python e R sparklyr: interface R para Apache Spark broom: converte objetos estat√≠sticos em tibbles organizados modelr: fun√ß√µes de modelagem que funcionam com o pipe tidymodels: cole√ß√£o de pacotes para modelagem e aprendizado de m√°quina usando os princ√≠pios do tidyverse Destacamos a grande expans√£o e aplicabilidade dos pacotes rmarkdown, knitr e bookdown, que permitiram a escrita desse livro usando essas ferramentas. Para instalar os principais pacotes que integram o tidyverse podemos instalar o pacote tidyverse. ## Instalar o pacote tidyverse install.packages(&quot;tidyverse&quot;) Quando carregamos o pacote tidyverse podemos notar uma mensagem indicando quais pacotes foram carregados, suas respectivas vers√µes e os conflitos com outros pacotes. ## Carregar o pacote tidyverse library(tidyverse) Podemos ainda listar todos os pacotes do tidyverse com a fun√ß√£o tidyverse::tidyverse_packages(). ## Listar todos os pacotes do tidyverse tidyverse::tidyverse_packages() #&gt; [1] &quot;broom&quot; &quot;cli&quot; &quot;crayon&quot; &quot;dbplyr&quot; &quot;dplyr&quot; #&gt; [6] &quot;dtplyr&quot; &quot;forcats&quot; &quot;googledrive&quot; &quot;googlesheets4&quot; &quot;ggplot2&quot; #&gt; [11] &quot;haven&quot; &quot;hms&quot; &quot;httr&quot; &quot;jsonlite&quot; &quot;lubridate&quot; #&gt; [16] &quot;magrittr&quot; &quot;modelr&quot; &quot;pillar&quot; &quot;purrr&quot; &quot;readr&quot; #&gt; [21] &quot;readxl&quot; &quot;reprex&quot; &quot;rlang&quot; &quot;rstudioapi&quot; &quot;rvest&quot; #&gt; [26] &quot;stringr&quot; &quot;tibble&quot; &quot;tidyr&quot; &quot;xml2&quot; &quot;tidyverse&quot; Tamb√©m podemos verificar se os pacotes est√£o atualizados, sen√£o, podemos atualiz√°-los com a fun√ß√£o tidyverse::tidyverse_update(). ## Verificar e atualizar os pacotes do tidyverse tidyverse::tidyverse_update(repos = &quot;http://cran.us.r-project.org&quot;) #&gt; The following packages are out of date: #&gt; #&gt; ‚Ä¢ broom (0.7.9 -&gt; 0.7.10) #&gt; ‚Ä¢ hms (1.1.0 -&gt; 1.1.1) #&gt; ‚Ä¢ lubridate (1.7.10 -&gt; 1.8.0) #&gt; ‚Ä¢ pillar (1.6.2 -&gt; 1.6.4) #&gt; ‚Ä¢ readr (2.0.1 -&gt; 2.0.2) #&gt; ‚Ä¢ rlang (0.4.11 -&gt; 0.4.12) #&gt; ‚Ä¢ rvest (1.0.1 -&gt; 1.0.2) #&gt; ‚Ä¢ tibble (3.1.4 -&gt; 3.1.5) #&gt; ‚Ä¢ tidyr (1.1.3 -&gt; 1.1.4) #&gt; #&gt; Start a clean R session then run: #&gt; install.packages(c(&quot;broom&quot;, &quot;hms&quot;, &quot;lubridate&quot;, &quot;pillar&quot;, &quot;readr&quot;, &quot;rlang&quot;, &quot;rvest&quot;, #&gt; &quot;tibble&quot;, &quot;tidyr&quot;)) Apesar de podermos fazer a instala√ß√£o e carregamento de todos os pacotes juntos, usando o pacote tidyverse, podemos instalar e carregar os pacotes individualmente. ## Instalar os pacotes do tidyverse individualmente install.packages(c(&quot;ggplot2&quot;, &quot;purrr&quot;, &quot;tibble&quot;, &quot;dplyr&quot;, &quot;tidyr&quot;, &quot;stringr&quot;, &quot;readr&quot;, &quot;forcats&quot;), dependencies = TRUE) ## Carregar os pacotes do tidyverse individualmente library(ggplot2) library(purrr) library(tibble) library(dplyr) library(tidyr) library(stringr) library(readr) library(forcats) Todas as fun√ß√µes dos pacotes tidyverse usam fonte min√∫scula e _ (underscore) para separar os nomes internos das fun√ß√µes, seguindo a mesma sintaxe do python (‚ÄúSnake Case‚Äù). Neste sentido de padroniza√ß√£o, √© importante destacar ainda que existe um guia pr√≥prio para que os scripts sigam a recomenda√ß√£o de padroniza√ß√£o, o The tidyverse style guide, criado pelo Hadley Wickham. Para pessoas que desenvolvem existe o Tidyverse design guide criado pelo Tidyverse team. ## Fun√ß√µes no formato snake case read_csv() read_xlsx() as_tibble() left_join() group_by() Por fim, para evitar poss√≠veis conflitos de fun√ß√µes com o mesmo nome entre pacotes, recomendamos fortemente o h√°bito de usar as fun√ß√µes precedidas do operador :: e o respectivo pacote. Assim, garante-se que a fun√ß√£o utilizada √© referente ao pacote daquela fun√ß√£o. Segue um exemplo com as fun√ß√µes apresentadas anteriormente. ## Fun√ß√µes seguidas de seus respectivos pacotes readr::read_csv() readxl::read_xlsx() tibble::as_tibble() dplyr::left_join() dplyr::group_by() Seguindo essas ideias do novo paradigma da Ci√™ncia de Dados, outro conjunto de pacotes foi desenvolvido, chamado de tidymodels que atuam no workflow da an√°lise de dados em ci√™ncia de dados: separa√ß√£o e reamostragem, pr√©-processamento, ajuste de modelos e m√©tricas de performasse de ajustes. Por raz√µes de espa√ßo e especificidade, n√£o entraremos em detalhes desse pacote. Seguindo o workflow da Figura 5.1, iremos ver nos itens das pr√≥ximas se√ß√µes como esses passos s√£o realizados com fun√ß√µes de cada pacote. 5.3 here Dentro do workflow do tidyverse, devemos sempre trabalhar com Projetos do RStudio. Junto com o projeto, tamb√©m podemos fazer uso do pacote here. Ele permite construir caminhos para os arquivos do projeto de forma mais simples e com maior reprodutibilidade. Esse pacote cobre o ponto que discutimos no cap√≠tulo 4, dado que muitas vezes mudar o diret√≥rio com a fun√ß√£o setwd() tende a ser demorado, principalmente quando se trata de um script em que v√°rias pessoas est√£o trabalhando em diferentes computadores e sistemas operacionais. Al√©m disso, ele elimina a quest√£o da fragilidade dos scripts, pois geralmente um script est√° com os diret√≥rios conectados exatamente a um lugar e a um momento. Por fim, ele tamb√©m simplifica o trabalho com subdiret√≥rios, facilitando importar ou exportar arquivos para subpastas. Seu uso √© relativamente simples: uma vez criado e aberto o RStudio pelo Projeto do RStudio, o diret√≥rio automaticamente √© definido para o diret√≥rio do projeto. Depois disso, podemos usar a fun√ß√£o here::here() para definir os subdiret√≥rios onde est√£o os dados. O exemplo da aplica√ß√£o fica para a se√ß√£o seguinte, quando iremos de fato importar um arquivo para o R. Logo abaixo, mostramos como instalar e carregar o pacote here. ## Instalar install.packages(&quot;here&quot;) ## Carregar library(here) 5.4 readr, readxl e writexl Dado que possu√≠mos um conjunto de dados e que geralmente esse conjunto de dados estar√° no formato tabular com umas das extens√µes: .csv, .txt ou .xlsx, usaremos o pacote readr ou readxl para importar esses dados para o R. Esses pacotes leem e escrevem grandes arquivos de forma mais r√°pida, al√©m de fornecerem medidores de progresso de importa√ß√£o e exporta√ß√£o, e imprimir a informa√ß√£o dos modos das colunas quando faz a importa√ß√£o. Outro ponto bastante positivo √© que tamb√©m classificam automaticamente o modo dos dados de cada coluna, i.e., se uma coluna possui dados num√©ricos ou apenas texto, essa informa√ß√£o ser√° considerada para classificar o modo da coluna toda. A classe do objeto atribu√≠do quando lido por esses pacotes √© automaticamente um tibble, que veremos melhor na se√ß√£o seguinte. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. Usamos as fun√ß√µes readr::read_csv() e readr::write_csv() para importar e exportar arquivos .csv do R, respectivamente. Para dados com a extens√£o .txt, podemos utilizar as fun√ß√µes readr::read_tsv() ou ainda readr::read_delim(). Para arquivos tabulares com a extens√£o .xlsx, temos de instalar e carregar dois pacotes adicionais: readxl e writexl, dos quais usaremos as fun√ß√µes readxl::read_excel(), readxl::read_xlsx() ou readxl::read_xls() para importar dados, atentado para o fato de podermos indicar a aba com os dados com o argumento sheet, e writexl::write_xlsx() para exportar. ## Instalar install.packages(&quot;writexl&quot;) ## Carregar library(readxl) library(writexl) Se o arquivo .csv foi criado com separador de decimais sendo . e separador de colunas sendo ,, usamos as fun√ß√µes normalmente. Caso seja criado com separador de decimais sendo , e separador de colunas sendo ;, usar√≠amos a fun√ß√£o readr::read_csv2() para importar e readr::write_csv2() para exportar nesse formato, que √© mais comum no Brasil. Para exemplificar como essas fun√ß√µes funcionam, vamos importar novamente os dados de comunidades de anf√≠bios da Mata Atl√¢ntica (Atlantic Amphibians, Vancine et al. (2018)), que fizemos o download no Cap√≠tulo 4. Estamos usando a fun√ß√£o readr::read_csv(), indicando os diret√≥rios com a fun√ß√£o here::here(), e a classe do arquivo √© tibble. Devemos atentar para o argumento locale = readr::locale(encoding = \"latin1\", que selecionamos aqui como latin1 para corrigir um erro do autor dos dados que publicou esse data paper com erros‚Ä¶ ## Importar locais tidy_anfibios_locais &lt;- readr::read_csv( here::here(&quot;dados&quot;, &quot;tabelas&quot;, &quot;ATLANTIC_AMPHIBIANS_sites.csv&quot;), locale = readr::locale(encoding = &quot;latin1&quot;) ) #&gt; Rows: 1163 Columns: 25 #&gt; ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #&gt; Delimiter: &quot;,&quot; #&gt; chr (13): id, record, sampled_habitat, active_methods, passive_methods, complementary_meth... #&gt; dbl (12): reference_number, species_number, month_start, year_start, month_finish, year_fi... #&gt; #&gt; ‚Ñπ Use `spec()` to retrieve the full column specification for this data. #&gt; ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message. Caso o download n√£o funcione ou haja problemas com a importa√ß√£o, disponibilizamos os dados tamb√©m no pacote ecodados. ## Importar os dados pelo pacote ecodados data(tidy_anfibios_locais) head(tidy_anfibios_locais) Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 11 Data import de Wickham and Grolemund (2017). 5.5 tibble O tibble (tbl_sf) √© uma vers√£o aprimorada do data frame (data.frame). Ele √© a classe aconselhada para que as fun√ß√µes do tidyverse funcionem melhor sobre conjuntos de dados tabulares importados para o R. Geralmente, quando utilizamos fun√ß√µes tidyverse para importar dados para o R, √© essa classe que os dados adquirem depois de importados. Al√©m da importa√ß√£o de dados, podemos criar um tibble no R usando a fun√ß√£o tibble::tibble(), semelhante ao uso da fun√ß√£o data.frame(). Podemos ainda converter um data.frame para um tibble usando a fun√ß√£o tibble::as_tibble(). Entretanto, em alguns momentos precisaremos da classe data.frame para algumas fun√ß√µes espec√≠ficas, e podemos converter um tibble para data.frame usando a fun√ß√£o tibble::as_data_frame(). Existem duas diferen√ßas principais no uso do tibble e do data.frame: impress√£o e subconjunto. Objetos da classe tibbles possuem um m√©todo de impress√£o que mostra a contagem do n√∫mero de linhas e colunas, e apenas as primeiras 10 linhas e todas as colunas que cabem na tela no console, al√©m dos modos ou tipos das colunas. Dessa forma, cada coluna ou vari√°vel, pode ser do modo numbers (int ou dbl), character (chr), logical (lgl), factor (fctr), date + time (dttm) e date (date), al√©m de outras in√∫meras possibilidades. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. ## Tibble - impress√£o tidy_anfibios_locais #&gt; # A tibble: 1,163 √ó 25 #&gt; id reference_number species_number record sampled_habitat active_methods passive_methods #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 amp1001 1001 19 ab fo,ll as pt #&gt; 2 amp1002 1002 16 co fo,la,ll as pt #&gt; 3 amp1003 1002 14 co fo,la,ll as pt #&gt; 4 amp1004 1002 13 co fo,la,ll as pt #&gt; 5 amp1005 1003 30 co fo,ll,br as &lt;NA&gt; #&gt; 6 amp1006 1004 42 co tp,pp,la,ll,is &lt;NA&gt; &lt;NA&gt; #&gt; 7 amp1007 1005 23 co sp as &lt;NA&gt; #&gt; 8 amp1008 1005 19 co sp,la,sw as,sb,tr &lt;NA&gt; #&gt; 9 amp1009 1005 13 ab fo &lt;NA&gt; pt #&gt; 10 amp1010 1006 1 ab fo &lt;NA&gt; pt #&gt; # ‚Ä¶ with 1,153 more rows, and 18 more variables: complementary_methods &lt;chr&gt;, period &lt;chr&gt;, #&gt; # month_start &lt;dbl&gt;, year_start &lt;dbl&gt;, month_finish &lt;dbl&gt;, year_finish &lt;dbl&gt;, #&gt; # effort_months &lt;dbl&gt;, country &lt;chr&gt;, state &lt;chr&gt;, state_abbreviation &lt;chr&gt;, #&gt; # municipality &lt;chr&gt;, site &lt;chr&gt;, latitude &lt;dbl&gt;, longitude &lt;dbl&gt;, #&gt; # coordinate_precision &lt;chr&gt;, altitude &lt;dbl&gt;, temperature &lt;dbl&gt;, precipitation &lt;dbl&gt; Para o subconjunto, como vimos anteriormente, para selecionar colunas e linhas de objetos bidimensionais podemos utilizar os operadores [] ou [[]], associado com n√∫meros separados por v√≠rgulas ou o nome da coluna entre aspas, e o operador $ para extrair uma coluna pelo seu nome. Comparando um data.frame a um tibble, o √∫ltimo √© mais r√≠gido na sele√ß√£o das colunas: eles nunca fazem correspond√™ncia parcial e gerar√£o um aviso se a coluna que voc√™ est√° tentando acessar n√£o existir. ## Tibble - subconjunto tidy_anfibios_locais$ref #&gt; Warning: Unknown or uninitialised column: `ref`. #&gt; NULL Por fim, podemos ‚Äúespiar‚Äù os dados utilizando a fun√ß√£o tibble::glimpse() para ter uma no√ß√£o geral de n√∫mero de linhas, colunas, e conte√∫do de todas as colunas. Essa √© fun√ß√£o tidyverse da fun√ß√£o R Base str(). ## Espiar os dados tibble::glimpse(tidy_anfibios_locais[, 1:10]) #&gt; Rows: 1,163 #&gt; Columns: 10 #&gt; $ id &lt;chr&gt; &quot;amp1001&quot;, &quot;amp1002&quot;, &quot;amp1003&quot;, &quot;amp1004&quot;, &quot;amp1005&quot;, &quot;amp100‚Ä¶ #&gt; $ reference_number &lt;dbl&gt; 1001, 1002, 1002, 1002, 1003, 1004, 1005, 1005, 1005, 1006, 10‚Ä¶ #&gt; $ species_number &lt;dbl&gt; 19, 16, 14, 13, 30, 42, 23, 19, 13, 1, 1, 2, 4, 4, 6, 5, 8, 2,‚Ä¶ #&gt; $ record &lt;chr&gt; &quot;ab&quot;, &quot;co&quot;, &quot;co&quot;, &quot;co&quot;, &quot;co&quot;, &quot;co&quot;, &quot;co&quot;, &quot;co&quot;, &quot;ab&quot;, &quot;ab&quot;, &quot;a‚Ä¶ #&gt; $ sampled_habitat &lt;chr&gt; &quot;fo,ll&quot;, &quot;fo,la,ll&quot;, &quot;fo,la,ll&quot;, &quot;fo,la,ll&quot;, &quot;fo,ll,br&quot;, &quot;tp,p‚Ä¶ #&gt; $ active_methods &lt;chr&gt; &quot;as&quot;, &quot;as&quot;, &quot;as&quot;, &quot;as&quot;, &quot;as&quot;, NA, &quot;as&quot;, &quot;as,sb,tr&quot;, NA, NA, NA‚Ä¶ #&gt; $ passive_methods &lt;chr&gt; &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;, NA, NA, NA, NA, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;, &quot;pt&quot;‚Ä¶ #&gt; $ complementary_methods &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA‚Ä¶ #&gt; $ period &lt;chr&gt; &quot;mo,da,tw,ni&quot;, &quot;mo,da,tw,ni&quot;, &quot;mo,da,tw,ni&quot;, &quot;mo,da,tw,ni&quot;, &quot;m‚Ä¶ #&gt; $ month_start &lt;dbl&gt; 9, 12, 12, 12, 7, NA, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5‚Ä¶ Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 10 Tibbles de Wickham and Grolemund (2017). 5.6 magrittr (pipe - %&gt;%) O operador pipe %&gt;% permite o encadeamento de v√°rias fun√ß√µes, eliminando a necessidade de criar objetos para armazenar resultados intermedi√°rios. Dessa forma, pipes s√£o uma ferramenta poderosa para expressar uma sequ√™ncia de m√∫ltiplas opera√ß√µes. O operador pipe %&gt;% vem do pacote magrittr, entretanto, todos os pacotes no tidyverse automaticamente tornam o pipe dispon√≠vel. Essa fun√ß√£o torna os c√≥digos em R mais simples, pois realizamos m√∫ltiplas opera√ß√µes em uma √∫nica linha. Ele captura o resultado de uma declara√ß√£o e o torna a entrada da pr√≥xima declara√ß√£o, ent√£o podemos pensar como ‚ÄúEM SEGUIDA FA√áA‚Äù ao final de cada linha de c√≥digo. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. A principal vantagem do uso dos pipes √© facilitar o debuging (achar erros) nos c√≥digos, porque seu uso torna a linguagem R mais pr√≥xima do que falamos e pensamos, uma vez que evita o uso de fun√ß√µes dentro de fun√ß√µes (fun√ß√µes compostas, lembra-se do fog e gof? Evitamos eles aqui tamb√©m‚Ä¶). Digitar %&gt;% √© um pouco chato, dessa forma, existe um atalho para sua inser√ß√£o nos scripts: Ctrl + Shift + M. Para deixar esse t√≥pico menos estranho a quem possa ver essa opera√ß√£o pela primeira vez, vamos fazer alguns exemplos. ## Base R - sem pipe sqrt(sum(1:100)) #&gt; [1] 71.06335 ## Tidyverse - com pipe 1:100 %&gt;% sum() %&gt;% sqrt() #&gt; [1] 71.06335 Essas opera√ß√µes ainda est√£o simples, vamos torn√°-las mais complexas com v√°rias fun√ß√µes compostas. √â nesses casos que a propriedade organizacional do uso do pipe emerge: podemos facilmente ver o encadeamento de opera√ß√µes, onde cada fun√ß√£o √© disposta numa linha. Apenas um adendo: a fun√ß√£o set.seed() que fixa a amostragem de fun√ß√µes que geram valores aleat√≥rio, como √© o caso da fun√ß√£o rpois(). ## Fixar amostragem set.seed(42) ## Base R - sem pipe ve &lt;- sum(sqrt(sort(log10(rpois(100, 10))))) ve #&gt; [1] 99.91426 ## Fixar amostragem set.seed(42) ## Tidyverse - com pipe ve &lt;- rpois(100, 10) %&gt;% log10() %&gt;% sort() %&gt;% sqrt() %&gt;% sum() ve #&gt; [1] 99.91426 O uso do pipe vai se tornar especialmente √∫til quando seguirmos para os pacotes das pr√≥ximas duas se√ß√µes: tidyr e dplyr. Com esses pacotes faremos opera√ß√µes em linhas e colunas de nossos dados tabulares, ent√£o podemos encadear uma s√©rie de fun√ß√µes para manipula√ß√£o, limpeza e an√°lise de dados. H√° ainda tr√™s outras varia√ß√µes do pipe que podem ser √∫teis em alguns momentos, mas que para funcionar precisam que o pacotemagrittr seja carregado: %T&gt;%: retorna o lado esquerdo em vez do lado direito %$%: ‚Äúexplode‚Äù as vari√°veis em um quadro de dados %&lt;&gt;%: permite atribui√ß√£o usando pipes Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 18 Pipes de Wickham and Grolemund (2017). Observa√ß√£o: A partir da vers√£o do R 4.1+ (18/05/2021), o operador pipe se tornou nativo do R. Entretanto, o operador foi atualizado para |&gt;, podendo ser inserido com o mesmo atalho Ctrl + Shift + M, mas necessitando uma mudan√ßa de op√ß√£o em Tools &gt; Global Options &gt; Code &gt; [x] Use native pipe operator, |&gt; (requires R 4.1+), necessitando que o RStudio esteja numa vers√£o igual ou superior a 1.4.17+. 5.7 tidyr Os conjuntos de dados tidy (organizados) s√£o mais f√°ceis de manipular, modelar e visualizar. Um conjunto de dados est√° no formato tidy ou n√£o, dependendo de como linhas, colunas e c√©lulas s√£o combinadas com observa√ß√µes, vari√°veis e valores. Nos dados tidy, as vari√°veis est√£o nas colunas, observa√ß√µes est√£o nas linhas e valores est√£o nas c√©lulas, sendo que para esse √∫ltimo, n√£o deve haver mais de um valor por c√©lula (Figura 5.2). Cada vari√°vel em uma coluna Cada observa√ß√£o em uma linha Cada valor como uma c√©lula Figura 5.2: As tr√™s regras que tornam um conjunto de dados tidy. Adaptado de: Wickham and Grolemund (2017). Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. Para realizar diversas transforma√ß√µes nos dados, a fim de ajust√°-los ao formato tidy existe uma s√©rie de fun√ß√µes, para: unir colunas, separar colunas, lidar com valores faltantes (NA), transformar a base de dados de formato longo para largo (ou vice-e-versa), al√©m de outras fun√ß√µes espec√≠ficas. unite(): junta dados de m√∫ltiplas colunas em uma coluna separate(): separa caracteres em m√∫ltiplas colunas separate_rows(): separa caracteres em m√∫ltiplas colunas e linhas drop_na(): retira linhas com NA do conjunto de dados replace_na(): substitui NA do conjunto de dados pivot_wider(): transforma um conjunto de dados longo (long) para largo (wide) pivot_longer(): transforma um conjunto de dados largo (wide) para longo (long) 5.7.1 palmerpenguins Para exemplificar o funcionamento dessas fun√ß√µes, usaremos os dados de medidas de pinguins chamados palmerpenguins, dispon√≠veis no pacote palmerpenguins. ## Instalar o pacote install.packages(&quot;palmerpenguins&quot;) Esses dados foram coletados e disponibilizados pela Dra. Kristen Gorman e pela Palmer Station, Antarctica LTER, membro da Long Term Ecological Research Network. O pacote palmerpenguins cont√©m dois conjuntos de dados. Um √© chamado de penguins, e √© uma vers√£o simplificada dos dados brutos. O segundo conjunto de dados √© penguins_raw e cont√©m todas as vari√°veis e nomes originais baixados. Ambos os conjuntos de dados cont√™m dados para 344 pinguins, de tr√™s esp√©cies diferentes, coletados em tr√™s ilhas no arquip√©lago de Palmer, na Ant√°rtica. Destacamos tamb√©m a vers√£o traduzida desses dados para o portugu√™s, dispon√≠vel no pacote dados. Vamos utilizar principalmente o conjunto de dados penguins_raw, que √© a vers√£o dos dados brutos. ## Carregar o pacote palmerpenguins library(palmerpenguins) ## Ajuda dos dados ?penguins ?penguins_raw 5.7.2 glimpse() Primeiramente, vamos observar os dados e utilizar a fun√ß√£o tibble::glimpse() para ter uma no√ß√£o geral. ## Visualizar os dados penguins_raw #&gt; # A tibble: 344 √ó 17 #&gt; studyName `Sample Number` Species Region Island Stage `Individual ID` `Clutch Complet‚Ä¶ #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 PAL0708 1 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N1A1 Yes #&gt; 2 PAL0708 2 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N1A2 Yes #&gt; 3 PAL0708 3 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N2A1 Yes #&gt; 4 PAL0708 4 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N2A2 Yes #&gt; 5 PAL0708 5 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N3A1 Yes #&gt; 6 PAL0708 6 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N3A2 Yes #&gt; 7 PAL0708 7 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N4A1 No #&gt; 8 PAL0708 8 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N4A2 No #&gt; 9 PAL0708 9 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N5A1 Yes #&gt; 10 PAL0708 10 Adelie Pe‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N5A2 Yes #&gt; # ‚Ä¶ with 334 more rows, and 9 more variables: Date Egg &lt;date&gt;, Culmen Length (mm) &lt;dbl&gt;, #&gt; # Culmen Depth (mm) &lt;dbl&gt;, Flipper Length (mm) &lt;dbl&gt;, Body Mass (g) &lt;dbl&gt;, Sex &lt;chr&gt;, #&gt; # Delta 15 N (o/oo) &lt;dbl&gt;, Delta 13 C (o/oo) &lt;dbl&gt;, Comments &lt;chr&gt; ## Espiar os dados dplyr::glimpse(penguins_raw) #&gt; Rows: 344 #&gt; Columns: 17 #&gt; $ studyName &lt;chr&gt; &quot;PAL0708&quot;, &quot;PAL0708&quot;, &quot;PAL0708&quot;, &quot;PAL0708&quot;, &quot;PAL0708&quot;, &quot;PAL070‚Ä¶ #&gt; $ `Sample Number` &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,‚Ä¶ #&gt; $ Species &lt;chr&gt; &quot;Adelie Penguin (Pygoscelis adeliae)&quot;, &quot;Adelie Penguin (Pygosc‚Ä¶ #&gt; $ Region &lt;chr&gt; &quot;Anvers&quot;, &quot;Anvers&quot;, &quot;Anvers&quot;, &quot;Anvers&quot;, &quot;Anvers&quot;, &quot;Anvers&quot;, &quot;A‚Ä¶ #&gt; $ Island &lt;chr&gt; &quot;Torgersen&quot;, &quot;Torgersen&quot;, &quot;Torgersen&quot;, &quot;Torgersen&quot;, &quot;Torgersen‚Ä¶ #&gt; $ Stage &lt;chr&gt; &quot;Adult, 1 Egg Stage&quot;, &quot;Adult, 1 Egg Stage&quot;, &quot;Adult, 1 Egg Stag‚Ä¶ #&gt; $ `Individual ID` &lt;chr&gt; &quot;N1A1&quot;, &quot;N1A2&quot;, &quot;N2A1&quot;, &quot;N2A2&quot;, &quot;N3A1&quot;, &quot;N3A2&quot;, &quot;N4A1&quot;, &quot;N4A2&quot;‚Ä¶ #&gt; $ `Clutch Completion` &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;‚Ä¶ #&gt; $ `Date Egg` &lt;date&gt; 2007-11-11, 2007-11-11, 2007-11-16, 2007-11-16, 2007-11-16, 2‚Ä¶ #&gt; $ `Culmen Length (mm)` &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0, 37.8‚Ä¶ #&gt; $ `Culmen Depth (mm)` &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2, 17.1‚Ä¶ #&gt; $ `Flipper Length (mm)` &lt;dbl&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186, 180, 182‚Ä¶ #&gt; $ `Body Mass (g)` &lt;dbl&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, 3300‚Ä¶ #&gt; $ Sex &lt;chr&gt; &quot;MALE&quot;, &quot;FEMALE&quot;, &quot;FEMALE&quot;, NA, &quot;FEMALE&quot;, &quot;MALE&quot;, &quot;FEMALE&quot;, &quot;M‚Ä¶ #&gt; $ `Delta 15 N (o/oo)` &lt;dbl&gt; NA, 8.94956, 8.36821, NA, 8.76651, 8.66496, 9.18718, 9.46060, ‚Ä¶ #&gt; $ `Delta 13 C (o/oo)` &lt;dbl&gt; NA, -24.69454, -25.33302, NA, -25.32426, -25.29805, -25.21799,‚Ä¶ #&gt; $ Comments &lt;chr&gt; &quot;Not enough blood for isotopes.&quot;, NA, NA, &quot;Adult not sampled.&quot;‚Ä¶ 5.7.3 unite() Primeiramente, vamos exemplificar como juntar e separar colunas. Vamos utilizar a fun√ß√£o tidyr::unite() para unir as colunas. H√° diversos par√¢metros para alterar como essa fun√ß√£o funciona, entretanto, √© importante destacar tr√™s deles: col nome da coluna que vai receber as colunas unidas, sep indicando o caracter separador das colunas unidas, e remove para uma resposta l√≥gica se as colunas unidas s√£o removidas ou n√£o. Vamos unir as colunas ‚ÄúRegion‚Äù e ‚ÄúIsland‚Äù na nova coluna ‚Äúregion_island.‚Äù ## Unir colunas penguins_raw_unir &lt;- tidyr::unite(data = penguins_raw, col = &quot;region_island&quot;, Region:Island, sep = &quot;, &quot;, remove = FALSE) head(penguins_raw_unir[, c(&quot;Region&quot;, &quot;Island&quot;, &quot;region_island&quot;)]) #&gt; # A tibble: 6 √ó 3 #&gt; Region Island region_island #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Anvers Torgersen Anvers, Torgersen #&gt; 2 Anvers Torgersen Anvers, Torgersen #&gt; 3 Anvers Torgersen Anvers, Torgersen #&gt; 4 Anvers Torgersen Anvers, Torgersen #&gt; 5 Anvers Torgersen Anvers, Torgersen #&gt; 6 Anvers Torgersen Anvers, Torgersen 5.7.4 separate() De forma contr√°ria, podemos utilizar as fun√ß√µes tidyr::separate() e tidyr::separate_rows() para separar elementos de uma coluna em mais colunas. Respectivamente, a primeira fun√ß√£o separa uma coluna em novas colunas conforme a separa√ß√£o, e a segunda fun√ß√£o separa uma coluna, distribuindo os elementos tamb√©m nas linhas. Novamente, h√° diversos par√¢metros para mudar o comportamento dessas fun√ß√µes, mas destacaremos aqui quatro deles: col coluna a ser separada, into os nomes das novas colunas, sep indicando o caractere separador das colunas, e remove para uma resposta l√≥gica se as colunas separadas s√£o removidas ou n√£o. Vamos separar a coluna ‚ÄúStage‚Äù nas colunas ‚Äústage‚Äù e ‚Äúegg_stage.‚Äù ## Separar colunas penguins_raw_separar &lt;- tidyr::separate(data = penguins_raw, col = Stage, into = c(&quot;stage&quot;, &quot;egg_stage&quot;), sep = &quot;, &quot;, remove = FALSE) head(penguins_raw_separar[, c(&quot;Stage&quot;, &quot;stage&quot;, &quot;egg_stage&quot;)]) #&gt; # A tibble: 6 √ó 3 #&gt; Stage stage egg_stage #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Adult, 1 Egg Stage Adult 1 Egg Stage #&gt; 2 Adult, 1 Egg Stage Adult 1 Egg Stage #&gt; 3 Adult, 1 Egg Stage Adult 1 Egg Stage #&gt; 4 Adult, 1 Egg Stage Adult 1 Egg Stage #&gt; 5 Adult, 1 Egg Stage Adult 1 Egg Stage #&gt; 6 Adult, 1 Egg Stage Adult 1 Egg Stage ## Separar colunas em novas linhas penguins_raw_separar_linhas &lt;- tidyr::separate_rows(data = penguins_raw, Stage, sep = &quot;, &quot;) head(penguins_raw_separar_linhas[, c(&quot;studyName&quot;, &quot;Sample Number&quot;, &quot;Species&quot;, &quot;Region&quot;, &quot;Island&quot;, &quot;Stage&quot;)]) #&gt; # A tibble: 6 √ó 6 #&gt; studyName `Sample Number` Species Region Island Stage #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 PAL0708 1 Adelie Penguin (Pygoscelis adeliae) Anvers Torgersen Adult #&gt; 2 PAL0708 1 Adelie Penguin (Pygoscelis adeliae) Anvers Torgersen 1 Egg Stage #&gt; 3 PAL0708 2 Adelie Penguin (Pygoscelis adeliae) Anvers Torgersen Adult #&gt; 4 PAL0708 2 Adelie Penguin (Pygoscelis adeliae) Anvers Torgersen 1 Egg Stage #&gt; 5 PAL0708 3 Adelie Penguin (Pygoscelis adeliae) Anvers Torgersen Adult #&gt; 6 PAL0708 3 Adelie Penguin (Pygoscelis adeliae) Anvers Torgersen 1 Egg Stage 5.7.5 drop_na() e replace_na() Valores faltantes (NA) √© um tipo especial de elemento que discutimos no Cap√≠tulo 4, e s√£o relativamente comuns em conjuntos de dados. Em Base R, vimos algumas formas de lidar com esse tipo de elemento. No formato tidyverse, existem v√°rias formas de lidar com eles, mas aqui focaremos nas fun√ß√µes tidyr::drop_na() e tidyr::replace_na(), para retirar linhas e substitui-los, respectivamente. ## Remover todas as linhas com NAs penguins_raw_todas_na &lt;- tidyr::drop_na(data = penguins_raw) head(penguins_raw_todas_na) #&gt; # A tibble: 6 √ó 17 #&gt; studyName `Sample Number` Species Region Island Stage `Individual ID` `Clutch Complet‚Ä¶ #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 PAL0708 7 Adelie Pen‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N4A1 No #&gt; 2 PAL0708 8 Adelie Pen‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N4A2 No #&gt; 3 PAL0708 29 Adelie Pen‚Ä¶ Anvers Biscoe Adult‚Ä¶ N18A1 No #&gt; 4 PAL0708 30 Adelie Pen‚Ä¶ Anvers Biscoe Adult‚Ä¶ N18A2 No #&gt; 5 PAL0708 39 Adelie Pen‚Ä¶ Anvers Dream Adult‚Ä¶ N25A1 No #&gt; 6 PAL0809 69 Adelie Pen‚Ä¶ Anvers Torger‚Ä¶ Adult‚Ä¶ N32A1 No #&gt; # ‚Ä¶ with 9 more variables: Date Egg &lt;date&gt;, Culmen Length (mm) &lt;dbl&gt;, #&gt; # Culmen Depth (mm) &lt;dbl&gt;, Flipper Length (mm) &lt;dbl&gt;, Body Mass (g) &lt;dbl&gt;, Sex &lt;chr&gt;, #&gt; # Delta 15 N (o/oo) &lt;dbl&gt;, Delta 13 C (o/oo) &lt;dbl&gt;, Comments &lt;chr&gt; ## Remover linhas de colunas espec√≠ficas com NAs penguins_raw_colunas_na &lt;- tidyr::drop_na(data = penguins_raw, any_of(&quot;Comments&quot;)) head(penguins_raw_colunas_na[, &quot;Comments&quot;]) #&gt; # A tibble: 6 √ó 1 #&gt; Comments #&gt; &lt;chr&gt; #&gt; 1 Not enough blood for isotopes. #&gt; 2 Adult not sampled. #&gt; 3 Nest never observed with full clutch. #&gt; 4 Nest never observed with full clutch. #&gt; 5 No blood sample obtained. #&gt; 6 No blood sample obtained for sexing. ## Substituir NAs por outro valor penguins_raw_subs_na &lt;- tidyr::replace_na(data = penguins_raw, list(Comments = &quot;Unknown&quot;)) head(penguins_raw_subs_na[, &quot;Comments&quot;]) #&gt; # A tibble: 6 √ó 1 #&gt; Comments #&gt; &lt;chr&gt; #&gt; 1 Not enough blood for isotopes. #&gt; 2 Unknown #&gt; 3 Unknown #&gt; 4 Adult not sampled. #&gt; 5 Unknown #&gt; 6 Unknown 5.7.6 pivot_longer() e pivot_wider() Por fim, trataremos da pivotagem ou remodelagem de dados. Veremos como mudar o formato do nosso conjunto de dados de longo (long) para largo (wide) e vice-versa. Essa √© uma opera√ß√£o semelhante √† ‚ÄúTabela Din√¢mica‚Äù das planilhas eletr√¥nicas. Consiste em usar uma coluna para distribuir seus valores em outras colunas, de modo que os valores dos elementos s√£o preenchidos corretamente, reduzindo assim o n√∫mero de linhas. Essa opera√ß√£o √© bastante comum em Ecologia de Comunidades, quando queremos transformar uma lista de esp√©cies em uma matriz de comunidades, com v√°rias esp√©cies nas colunas. Para realizar essa opera√ß√£o, usarmos a fun√ß√£o tidyr::pivot_wider(). Dos diversos par√¢metros que podem compor essa fun√ß√£o, dois deles s√£o fundamentais: names_from que indica a coluna de onde os nomes ser√£o usados e values_from a coluna com os valores. ## Selecionar colunas penguins_raw_sel_col &lt;- penguins_raw[, c(2, 3, 13)] head(penguins_raw_sel_col) #&gt; # A tibble: 6 √ó 3 #&gt; `Sample Number` Species `Body Mass (g)` #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 Adelie Penguin (Pygoscelis adeliae) 3750 #&gt; 2 2 Adelie Penguin (Pygoscelis adeliae) 3800 #&gt; 3 3 Adelie Penguin (Pygoscelis adeliae) 3250 #&gt; 4 4 Adelie Penguin (Pygoscelis adeliae) NA #&gt; 5 5 Adelie Penguin (Pygoscelis adeliae) 3450 #&gt; 6 6 Adelie Penguin (Pygoscelis adeliae) 3650 ## Pivotar para largo penguins_raw_pivot_wider &lt;- tidyr::pivot_wider(data = penguins_raw_sel_col, names_from = Species, values_from = `Body Mass (g)`) head(penguins_raw_pivot_wider) #&gt; # A tibble: 6 √ó 4 #&gt; `Sample Number` `Adelie Penguin (Pygoscelis adeliae)` `Gentoo penguin (P‚Ä¶ `Chinstrap pengui‚Ä¶ #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 3750 4500 3500 #&gt; 2 2 3800 5700 3900 #&gt; 3 3 3250 4450 3650 #&gt; 4 4 NA 5700 3525 #&gt; 5 5 3450 5400 3725 #&gt; 6 6 3650 4550 3950 De modo oposto, podemos partir de um conjunto de dados largo (wide), ou seja, com v√°rias colunas, e queremos que essas colunas preencham uma √∫nica coluna, e que os valores antes espalhados nessas v√°rias colunas sejam adicionados um embaixo do outro, numa √∫nica coluna. Para essa opera√ß√£o, podemos utilizar a fun√ß√£o tidyr::pivot_longer(). Novamente, dos diversos par√¢metros que podem compor essa fun√ß√£o, tr√™s deles s√£o fundamentais: cols indicando as colunas que ser√£o usadas para serem pivotadas, names_to que indica a coluna de onde os nomes ser√£o usados e values_to a coluna com os valores. ## Selecionar colunas penguins_raw_sel_col &lt;- penguins_raw[, c(2, 3, 10:13)] head(penguins_raw_sel_col) #&gt; # A tibble: 6 √ó 6 #&gt; `Sample Number` Species `Culmen Length ‚Ä¶ `Culmen Depth (‚Ä¶ `Flipper Length‚Ä¶ `Body Mass (g)` #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 Adelie P‚Ä¶ 39.1 18.7 181 3750 #&gt; 2 2 Adelie P‚Ä¶ 39.5 17.4 186 3800 #&gt; 3 3 Adelie P‚Ä¶ 40.3 18 195 3250 #&gt; 4 4 Adelie P‚Ä¶ NA NA NA NA #&gt; 5 5 Adelie P‚Ä¶ 36.7 19.3 193 3450 #&gt; 6 6 Adelie P‚Ä¶ 39.3 20.6 190 3650 ## Pivotar para largo penguins_raw_pivot_longer &lt;- tidyr::pivot_longer(data = penguins_raw_sel_col, cols = `Culmen Length (mm)`:`Body Mass (g)`, names_to = &quot;medidas&quot;, values_to = &quot;valores&quot;) head(penguins_raw_pivot_longer) #&gt; # A tibble: 6 √ó 4 #&gt; `Sample Number` Species medidas valores #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 Adelie Penguin (Pygoscelis adeliae) Culmen Length (mm) 39.1 #&gt; 2 1 Adelie Penguin (Pygoscelis adeliae) Culmen Depth (mm) 18.7 #&gt; 3 1 Adelie Penguin (Pygoscelis adeliae) Flipper Length (mm) 181 #&gt; 4 1 Adelie Penguin (Pygoscelis adeliae) Body Mass (g) 3750 #&gt; 5 2 Adelie Penguin (Pygoscelis adeliae) Culmen Length (mm) 39.5 #&gt; 6 2 Adelie Penguin (Pygoscelis adeliae) Culmen Depth (mm) 17.4 Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 12 Tidy data de Wickham and Grolemund (2017). 5.8 dplyr O dplyr √© um pacote que facilita a manipula√ß√£o de dados, com uma gram√°tica simples e flex√≠vel (por exemplo, como filtragem, reordenamento, sele√ß√£o, entre outras). Ele foi constru√≠do com o intuito de obter uma forma mais r√°pida e expressiva de manipular dados tabulares. O tibble √© a vers√£o de data frame mais conveniente para se usar com pacote dplyr. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. 5.8.1 Gram√°tica Sua gram√°tica simples cont√©m fun√ß√µes verbais para manipula√ß√£o de dados, baseada em: Verbos: mutate(), select(), filter(), arrange(), summarise(), slice(), rename(), etc. Replica√ß√£o: across(), if_any(), if_all(), where(), starts_with(), ends_with(), contains(), etc. Agrupamento: group_by() e ungroup() Jun√ß√µes: inner_join(), full_join(), left_join(), right_join(), etc. Combina√ß√µes: bind_rows() e bind_cols() Resumos, contagem e sele√ß√£o: n(), n_distinct(), first(), last(), nth(), etc. Existe uma s√©rie de fun√ß√µes para realizar a manipula√ß√£o dos dados, com diversas finalidades: manipula√ß√£o de uma tabela, manipula√ß√£o de duas tabelas, replica√ß√£o, agrupamento, fun√ß√µes de vetores, al√©m de muitas outras fun√ß√µes espec√≠ficas. relocate(): muda a ordem das colunas rename(): muda o nome das colunas select(): seleciona colunas pelo nome ou posi√ß√£o pull(): seleciona uma coluna como vetor mutate(): adiciona novas colunas ou resultados em colunas existentes arrange(): reordena as linhas com base nos valores de colunas filter(): seleciona linhas com base em valores de colunas slice(): seleciona linhas de diferente formas distinct(): remove linhas com valores repetidos com base nos valores de colunas count(): conta observa√ß√µes para um grupo group_by(): agrupa linhas pelos valores das colunas summarise(): resume os dados atrav√©s de fun√ß√µes considerando valores das colunas *_join(): fun√ß√µes que juntam dados de duas tabelas atrav√©s de uma coluna chave 5.8.2 Sintaxe As fun√ß√µes do dplyr podem seguir uma mesma sintaxe: o tibble ser√° sempre o primeiro argumento dessas fun√ß√µes, seguido de um pipe e pelo nome da fun√ß√£o que ir√° fazer a manipula√ß√£o nesses dados. Isso permite o encadeamento de v√°rias opera√ß√µes consecutivas mantendo a estrutura do dado original e acrescentando mudan√ßas num encadeamento l√≥gico. Sendo assim, as fun√ß√µes verbais n√£o precisam modificar necessariamente o tibble original, sendo que as opera√ß√µes de manipula√ß√µes podem e devem ser atribu√≠das a um novo objeto. ## Sintaxe tb_dplyr &lt;- tb %&gt;% funcao_verbal1(argumento1, argumento2, ...) %&gt;% funcao_verbal2(argumento1, argumento2, ...) %&gt;% funcao_verbal3(argumento1, argumento2, ...) Al√©m de data.frames e tibbles, a manipula√ß√£o pelo formato dplyr torna o trabalho com outros formatos de classes e dados acess√≠veis e eficientes como data.table, SQL e Apache Spark, para os quais existem pacotes espec√≠ficos. dtplyr: manipular conjuntos de dados data.table dbplyr: manipular conjuntos de dados SQL sparklyr: manipular conjuntos de dados no Apache Spark 5.8.3 palmerpenguins Para nossos exemplos, vamos utilizar novamente os dados de pinguins palmerpenguins. Esses dados est√£o dispon√≠veis no pacote palmerpenguins. Vamos utilizar principalmente o conjunto de dados penguins, que √© a vers√£o simplificada dos dados brutos penguins_raw. ## Carrega o pacote palmerpenguins library(palmerpenguins) 5.8.4 relocate() Primeiramente, vamos reordenar as colunas com a fun√ß√£o dplyr::relocate(), onde simplesmente listamos as colunas que queremos mudar de posi√ß√£o e para onde elas devem ir. Para esse √∫ltimo passo h√° dois argumentos: .before que indica qual a coluna que as colunas realocadas devem se mover antes, e o argumento .after indicando onde devem se mover depois. Ambos podem ser informados com os nomes ou posi√ß√µes dessas colunas com n√∫meros. ## Reordenar colunas - nome penguins_relocate_col &lt;- penguins %&gt;% dplyr::relocate(sex, year, .after = island) head(penguins_relocate_col) #&gt; # A tibble: 6 √ó 8 #&gt; species island sex year bill_length_mm bill_depth_mm flipper_length_mm body_mass_g #&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen male 2007 39.1 18.7 181 3750 #&gt; 2 Adelie Torgersen female 2007 39.5 17.4 186 3800 #&gt; 3 Adelie Torgersen female 2007 40.3 18 195 3250 #&gt; 4 Adelie Torgersen &lt;NA&gt; 2007 NA NA NA NA #&gt; 5 Adelie Torgersen female 2007 36.7 19.3 193 3450 #&gt; 6 Adelie Torgersen male 2007 39.3 20.6 190 3650 ## Reordenar colunas - posi√ß√£o penguins_relocate_ncol &lt;- penguins %&gt;% dplyr::relocate(sex, year, .after = 2) head(penguins_relocate_ncol) #&gt; # A tibble: 6 √ó 8 #&gt; species island sex year bill_length_mm bill_depth_mm flipper_length_mm body_mass_g #&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen male 2007 39.1 18.7 181 3750 #&gt; 2 Adelie Torgersen female 2007 39.5 17.4 186 3800 #&gt; 3 Adelie Torgersen female 2007 40.3 18 195 3250 #&gt; 4 Adelie Torgersen &lt;NA&gt; 2007 NA NA NA NA #&gt; 5 Adelie Torgersen female 2007 36.7 19.3 193 3450 #&gt; 6 Adelie Torgersen male 2007 39.3 20.6 190 3650 5.8.5 rename() Podemos ainda renomear colunas facilmente com a fun√ß√£o dplyr::rename(), onde primeiramente informamos o nome que queremos que a coluna tenha, seguido do operador = e a coluna do nosso dado (‚Äúnova_coluna = antiga_coluna‚Äù). Tamb√©m podemos utilizar a fun√ß√£o dplyr::rename_with(), que faz a mudan√ßa do nome em m√∫ltiplas colunas, que pode depender ou n√£o de resultados booleanos. ## Renomear as colunas penguins_rename &lt;- penguins %&gt;% dplyr::rename(bill_length = bill_length_mm, bill_depth = bill_depth_mm, flipper_length = flipper_length_mm, body_mass = body_mass_g) head(penguins_rename) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length bill_depth flipper_length body_mass sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 ## mudar o nome de todas as colunas penguins_rename_with &lt;- penguins %&gt;% dplyr::rename_with(toupper) head(penguins_rename_with) #&gt; # A tibble: 6 √ó 8 #&gt; SPECIES ISLAND BILL_LENGTH_MM BILL_DEPTH_MM FLIPPER_LENGTH_MM BODY_MASS_G SEX YEAR #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 5.8.6 select() Outra opera√ß√£o bastante usual dentro da manipula√ß√£o de dados tabulares √© a sele√ß√£o de colunas. Podemos fazer essa opera√ß√£o com a fun√ß√£o dplyr::select(), que seleciona colunas pelo nome ou pela sua posi√ß√£o. Aqui h√° uma s√©rie de possibilidades de sele√ß√£o de colunas, desde utilizar operadores como : para selecionar intervalos de colunas, ! para tomar o complemento (todas menos as listadas), al√©m de fun√ß√µes como dplyr::starts_with(), dplyr::ends_with(), dplyr::contains() para procurar colunas com um padr√£o de texto. ## Selecionar colunas por posi√ß√£o penguins_select_position &lt;- penguins %&gt;% dplyr::select(3:6) head(penguins_select_position) #&gt; # A tibble: 6 √ó 4 #&gt; bill_length_mm bill_depth_mm flipper_length_mm body_mass_g #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 39.1 18.7 181 3750 #&gt; 2 39.5 17.4 186 3800 #&gt; 3 40.3 18 195 3250 #&gt; 4 NA NA NA NA #&gt; 5 36.7 19.3 193 3450 #&gt; 6 39.3 20.6 190 3650 ## Selecionar colunas por nomes penguins_select_names &lt;- penguins %&gt;% dplyr::select(bill_length_mm:body_mass_g) head(penguins_select_names) #&gt; # A tibble: 6 √ó 4 #&gt; bill_length_mm bill_depth_mm flipper_length_mm body_mass_g #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 39.1 18.7 181 3750 #&gt; 2 39.5 17.4 186 3800 #&gt; 3 40.3 18 195 3250 #&gt; 4 NA NA NA NA #&gt; 5 36.7 19.3 193 3450 #&gt; 6 39.3 20.6 190 3650 ## Selecionar colunas por padr√£o penguins_select_contains &lt;- penguins %&gt;% dplyr::select(contains(&quot;_mm&quot;)) head(penguins_select_contains) #&gt; # A tibble: 6 √ó 3 #&gt; bill_length_mm bill_depth_mm flipper_length_mm #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 39.1 18.7 181 #&gt; 2 39.5 17.4 186 #&gt; 3 40.3 18 195 #&gt; 4 NA NA NA #&gt; 5 36.7 19.3 193 #&gt; 6 39.3 20.6 190 5.8.7 pull() Quando usamos a fun√ß√£o dplyr::select(), mesmo que para uma coluna, o retorno √© sempre um tibble. Caso precisemos que essa coluna se torne um vetor dentro do encadeamento dos pipes, usamos a fun√ß√£o dplyr::pull() que extrai uma √∫nica coluna como vetor. ## Coluna como vetor penguins_select_pull &lt;- penguins %&gt;% dplyr::pull(bill_length_mm) head(penguins_select_pull, 15) #&gt; [1] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42.0 37.8 37.8 41.1 38.6 34.6 5.8.8 mutate() Uma das opera√ß√µes mais √∫teis dentre as opera√ß√µes para colunas √© adicionar ou atualizar os valores de colunas. Para essa opera√ß√£o, usaremos a fun√ß√£o dplyr::mutate(). Podemos ainda usar os argumentos .before e .after para indicar onde a nova coluna deve ficar, al√©m do par√¢metro .keep com diversas possibilidades de manter colunas depois de usar a fun√ß√£o dplyr::mutate(). Por fim, √© fundamental destacar o uso das fun√ß√µes de replica√ß√£o: dplyr::across(), dplyr::if_any() e dplyr::if_all(), para os quais a fun√ß√£o far√° altera√ß√µes em m√∫ltiplas colunas de uma vez, dependendo de resultados booleanos. ## Adicionar colunas penguins_mutate &lt;- penguins %&gt;% dplyr::mutate(body_mass_kg = body_mass_g/1e3, .before = sex) head(penguins_mutate) #&gt; # A tibble: 6 √ó 9 #&gt; species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g body_mass_kg sex #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 Adelie Torger‚Ä¶ 39.1 18.7 181 3750 3.75 male #&gt; 2 Adelie Torger‚Ä¶ 39.5 17.4 186 3800 3.8 fema‚Ä¶ #&gt; 3 Adelie Torger‚Ä¶ 40.3 18 195 3250 3.25 fema‚Ä¶ #&gt; 4 Adelie Torger‚Ä¶ NA NA NA NA NA &lt;NA&gt; #&gt; 5 Adelie Torger‚Ä¶ 36.7 19.3 193 3450 3.45 fema‚Ä¶ #&gt; 6 Adelie Torger‚Ä¶ 39.3 20.6 190 3650 3.65 male #&gt; # ‚Ä¶ with 1 more variable: year &lt;int&gt; ## Modificar v√°rias colunas penguins_mutate_across &lt;- penguins %&gt;% dplyr::mutate(across(where(is.factor), as.character)) head(penguins_mutate_across) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 5.8.9 arrange() Al√©m de opera√ß√µes em colunas, podemos fazer opera√ß√µes em linhas. Vamos come√ßar com a reordena√ß√£o das linhas com base nos valores das colunas. Para essa opera√ß√£o, usamos a fun√ß√£o dplyr::arrange(). Podemos reordenar por uma ou mais colunas de forma crescente ou de forma decrescente usando a fun√ß√£o desc() ou o operador -. Da mesma forma que na fun√ß√£o dplyr::mutate(), podemos usar as fun√ß√µes de replica√ß√£o para ordenar as linhas para v√°rias colunas de uma vez, dependendo de resultados booleanos. ## Reordenar linhas - crescente penguins_arrange &lt;- penguins %&gt;% dplyr::arrange(body_mass_g) head(penguins_arrange) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Chinstrap Dream 46.9 16.6 192 2700 female 2008 #&gt; 2 Adelie Biscoe 36.5 16.6 181 2850 female 2008 #&gt; 3 Adelie Biscoe 36.4 17.1 184 2850 female 2008 #&gt; 4 Adelie Biscoe 34.5 18.1 187 2900 female 2008 #&gt; 5 Adelie Dream 33.1 16.1 178 2900 female 2008 #&gt; 6 Adelie Torgersen 38.6 17 188 2900 female 2009 ## Reordenar linhas - decrescente penguins_arrange_desc &lt;- penguins %&gt;% dplyr::arrange(desc(body_mass_g)) head(penguins_arrange_desc) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Gentoo Biscoe 49.2 15.2 221 6300 male 2007 #&gt; 2 Gentoo Biscoe 59.6 17 230 6050 male 2007 #&gt; 3 Gentoo Biscoe 51.1 16.3 220 6000 male 2008 #&gt; 4 Gentoo Biscoe 48.8 16.2 222 6000 male 2009 #&gt; 5 Gentoo Biscoe 45.2 16.4 223 5950 male 2008 #&gt; 6 Gentoo Biscoe 49.8 15.9 229 5950 male 2009 ## Reordenar linhas - decrescente penguins_arrange_desc_m &lt;- penguins %&gt;% dplyr::arrange(-body_mass_g) head(penguins_arrange_desc_m) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Gentoo Biscoe 49.2 15.2 221 6300 male 2007 #&gt; 2 Gentoo Biscoe 59.6 17 230 6050 male 2007 #&gt; 3 Gentoo Biscoe 51.1 16.3 220 6000 male 2008 #&gt; 4 Gentoo Biscoe 48.8 16.2 222 6000 male 2009 #&gt; 5 Gentoo Biscoe 45.2 16.4 223 5950 male 2008 #&gt; 6 Gentoo Biscoe 49.8 15.9 229 5950 male 2009 ## Reordenar linhas - multiplas colunas penguins_arrange_across &lt;- penguins %&gt;% dplyr::arrange(across(where(is.numeric))) head(penguins_arrange_across) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Dream 32.1 15.5 188 3050 female 2009 #&gt; 2 Adelie Dream 33.1 16.1 178 2900 female 2008 #&gt; 3 Adelie Torgersen 33.5 19 190 3600 female 2008 #&gt; 4 Adelie Dream 34 17.1 185 3400 female 2008 #&gt; 5 Adelie Torgersen 34.1 18.1 193 3475 &lt;NA&gt; 2007 #&gt; 6 Adelie Torgersen 34.4 18.4 184 3325 female 2007 5.8.10 filter() Uma das principais e mais usuais opera√ß√µes que podemos realizar em linhas √© a sele√ß√£o de linhas atrav√©s do filtro por valores de uma ou mais colunas, utilizando a fun√ß√£o dplyr::filter(). Para realizar os filtros utilizaremos grande parte dos operadores relacionais e l√≥gicos que listamos na Tabela 4.1, especialmente os l√≥gicos para combina√ß√µes de filtros em mais de uma coluna. Al√©m desses operadores, podemos utilizar a fun√ß√£o is.na() para filtros em elementos faltantes, e as fun√ß√µes dplyr::between() e dplyr::near() para filtros entre valores, e para valores pr√≥ximos com certa toler√¢ncia, respectivamente. Por fim, podemos usar as fun√ß√µes de replica√ß√£o para filtro das linhas para mais de uma coluna, dependendo de resultados booleanos. ## Filtrar linhas penguins_filter &lt;- penguins %&gt;% dplyr::filter(species == &quot;Adelie&quot;) head(penguins_filter) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 ## Filtrar linhas penguins_filter_two &lt;- penguins %&gt;% dplyr::filter(species == &quot;Adelie&quot; &amp; sex == &quot;female&quot;) head(penguins_filter_two) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 2 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 3 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 4 Adelie Torgersen 38.9 17.8 181 3625 female 2007 #&gt; 5 Adelie Torgersen 41.1 17.6 182 3200 female 2007 #&gt; 6 Adelie Torgersen 36.6 17.8 185 3700 female 2007 ## Filtrar linhas penguins_filter_in &lt;- penguins %&gt;% dplyr::filter(species %in% c(&quot;Adelie&quot;, &quot;Gentoo&quot;), sex == &quot;female&quot;) head(penguins_filter_in) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 2 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 3 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 4 Adelie Torgersen 38.9 17.8 181 3625 female 2007 #&gt; 5 Adelie Torgersen 41.1 17.6 182 3200 female 2007 #&gt; 6 Adelie Torgersen 36.6 17.8 185 3700 female 2007 ## Filtrar linhas - NA penguins_filter_na &lt;- penguins %&gt;% dplyr::filter(!is.na(sex) == TRUE) head(penguins_filter_na) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 5 Adelie Torgersen 39.3 20.6 190 3650 male 2007 #&gt; 6 Adelie Torgersen 38.9 17.8 181 3625 female 2007 ## Filtrar linhas - intervalos penguins_filter_between &lt;- penguins %&gt;% dplyr::filter(between(body_mass_g, 3000, 4000)) head(penguins_filter_between) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 5 Adelie Torgersen 39.3 20.6 190 3650 male 2007 #&gt; 6 Adelie Torgersen 38.9 17.8 181 3625 female 2007 ## Filtrar linhas por v√°rias colunas penguins_filter_if &lt;- penguins %&gt;% dplyr::filter(if_all(where(is.integer), ~ . &gt; 200)) head(penguins_filter_if) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Dream 35.7 18 202 3550 female 2008 #&gt; 2 Adelie Dream 41.1 18.1 205 4300 male 2008 #&gt; 3 Adelie Dream 40.8 18.9 208 4300 male 2008 #&gt; 4 Adelie Biscoe 41 20 203 4725 male 2009 #&gt; 5 Adelie Torgersen 41.4 18.5 202 3875 male 2009 #&gt; 6 Adelie Torgersen 44.1 18 210 4000 male 2009 5.8.11 slice() Al√©m da sele√ß√£o de linhas por filtros, podemos fazer a sele√ß√£o das linhas por intervalos, indicando quais linhas desejamos, usando a fun√ß√£o dplyr::slice(), e informando o argumento n para o n√∫mero da linha ou intervalo das linhas. Essa fun√ß√£o possui varia√ß√µes no sufixo muito interessantes: dplyr::slice_head() e dplyr::slice_tail() seleciona as primeiras e √∫ltimas linhas, dplyr::slice_min() e dplyr::slice_max() seleciona linhas com os maiores e menores valores de uma coluna, e dplyr::slice_sample() seleciona linhas aleatoriamente. ## Seleciona linhas penguins_slice &lt;- penguins %&gt;% dplyr::slice(n = c(1, 3, 300:n())) head(penguins_slice) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 3 Chinstrap Dream 50.6 19.4 193 3800 male 2007 #&gt; 4 Chinstrap Dream 46.7 17.9 195 3300 female 2007 #&gt; 5 Chinstrap Dream 52 19 197 4150 male 2007 #&gt; 6 Chinstrap Dream 50.5 18.4 200 3400 female 2008 ## Seleciona linhas - head penguins_slice_head &lt;- penguins %&gt;% dplyr::slice_head(n = 5) head(penguins_slice_head) #&gt; # A tibble: 5 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 ## Seleciona linhas - max penguins_slice_max &lt;- penguins %&gt;% dplyr::slice_max(body_mass_g, n = 5) head(penguins_slice_max) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Gentoo Biscoe 49.2 15.2 221 6300 male 2007 #&gt; 2 Gentoo Biscoe 59.6 17 230 6050 male 2007 #&gt; 3 Gentoo Biscoe 51.1 16.3 220 6000 male 2008 #&gt; 4 Gentoo Biscoe 48.8 16.2 222 6000 male 2009 #&gt; 5 Gentoo Biscoe 45.2 16.4 223 5950 male 2008 #&gt; 6 Gentoo Biscoe 49.8 15.9 229 5950 male 2009 ## Seleciona linhas - sample penguins_slice_sample &lt;- penguins %&gt;% dplyr::slice_sample(n = 30) head(penguins_slice_sample) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Biscoe 41.3 21.1 195 4400 male 2008 #&gt; 2 Gentoo Biscoe 44.5 15.7 217 4875 &lt;NA&gt; 2009 #&gt; 3 Adelie Torgersen 41.4 18.5 202 3875 male 2009 #&gt; 4 Adelie Biscoe 37.6 17 185 3600 female 2008 #&gt; 5 Adelie Dream 36 17.9 190 3450 female 2007 #&gt; 6 Adelie Biscoe 35.7 16.9 185 3150 female 2008 5.8.12 distinct() A √∫ltima opera√ß√£o que apresentaremos para linhas √© a retirada de linhas com valores repetidos com base nos valores de colunas, utilizando a fun√ß√£o dplyr::distinct(). Essa fun√ß√£o por padr√£o retorna apenas a coluna utilizada para retirar as linhas com valores repetidos, sendo necess√°rio acrescentar o argumento .keep_all = TRUE para retornar todas as colunas. Por fim, podemos usar as fun√ß√µes de replica√ß√£o para retirar linhas com valores repetidos para mais de uma coluna, dependendo de resultados booleanos. ## Retirar linhas com valores repetidos penguins_distinct &lt;- penguins %&gt;% dplyr::distinct(body_mass_g) head(penguins_distinct) #&gt; # A tibble: 6 √ó 1 #&gt; body_mass_g #&gt; &lt;int&gt; #&gt; 1 3750 #&gt; 2 3800 #&gt; 3 3250 #&gt; 4 NA #&gt; 5 3450 #&gt; 6 3650 ## Retirar linhas com valores repetidos - manter as outras colunas penguins_distinct_keep_all &lt;- penguins %&gt;% dplyr::distinct(body_mass_g, .keep_all = TRUE) head(penguins_distinct_keep_all) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 ## Retirar linhas com valores repetidos para v√°rias colunas penguins_distinct_keep_all_across &lt;- penguins %&gt;% dplyr::distinct(across(where(is.integer)), .keep_all = TRUE) head(penguins_distinct_keep_all_across) #&gt; # A tibble: 6 √ó 8 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 5.8.13 count() Agora entraremos no assunto de resumo das observa√ß√µes. Podemos fazer contagens resumos dos nossos dados, utilizando para isso a fun√ß√£o dplyr::count(). Essa fun√ß√£o contar√° valores de uma ou mais colunas, geralmente para vari√°veis categ√≥ricas, semelhante √† fun√ß√£o Base R table(), mas num contexto tidyverse. ## Contagens de valores para uma coluna penguins_count &lt;- penguins %&gt;% dplyr::count(species) penguins_count #&gt; # A tibble: 3 √ó 2 #&gt; species n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie 152 #&gt; 2 Chinstrap 68 #&gt; 3 Gentoo 124 ## Contagens de valores para mais de uma coluna penguins_count_two &lt;- penguins %&gt;% dplyr::count(species, island) penguins_count_two #&gt; # A tibble: 5 √ó 3 #&gt; species island n #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Biscoe 44 #&gt; 2 Adelie Dream 56 #&gt; 3 Adelie Torgersen 52 #&gt; 4 Chinstrap Dream 68 #&gt; 5 Gentoo Biscoe 124 5.8.14 group_by() Uma grande parte das opera√ß√µes feitas nos dados s√£o realizadas em grupos definidos por valores de colunas ou vari√°veis categ√≥ricas. A fun√ß√£o dplyr::group_by() transforma um tibble em um tibble agrupado, onde as opera√ß√µes s√£o realizadas ‚Äúpor grupo.‚Äù Essa fun√ß√£o √© utilizada geralmente junto com a fun√ß√£o dplyr::summarise(), que veremos logo em seguida. O agrupamento n√£o altera a apar√™ncia dos dados (al√©m de informar como est√£o agrupados). A fun√ß√£o dplyr::ungroup() remove o agrupamento. Podemos ainda usar fun√ß√µes de replica√ß√£o para fazer os agrupamentos para mais de uma coluna, dependendo de resultados booleanos. ## Agrupamento penguins_group_by &lt;- penguins %&gt;% dplyr::group_by(species) head(penguins_group_by) #&gt; # A tibble: 6 √ó 8 #&gt; # Groups: species [1] #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 ## Agrupamento de v√°rias colunas penguins_group_by_across &lt;- penguins %&gt;% dplyr::group_by(across(where(is.factor))) head(penguins_group_by_across) #&gt; # A tibble: 6 √ó 8 #&gt; # Groups: species, island, sex [3] #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 5.8.15 summarise() Como dissemos, muitas vezes queremos resumir nossos dados, principalmente para ter uma no√ß√£o geral das vari√°veis (colunas) ou mesmo come√ßar a an√°lise explorat√≥ria resumindo vari√°veis cont√≠nuas por grupos de vari√°veis categ√≥ricas. Dessa forma, ao utilizar a fun√ß√£o dplyr::summarise() teremos um novo tibble com os dados resumidos, que √© a agrega√ß√£o ou resumo dos dados atrav√©s de fun√ß√µes. Da mesma forma que outras fun√ß√µes, podemos usar fun√ß√µes de replica√ß√£o para resumir valores para mais de uma coluna, dependendo de resultados booleanos. ## Resumo penguins_summarise &lt;- penguins %&gt;% dplyr::group_by(species) %&gt;% dplyr::summarize(body_mass_g_mean = mean(body_mass_g, na.rm = TRUE), body_mass_g_sd = sd(body_mass_g, na.rm = TRUE)) penguins_summarise #&gt; # A tibble: 3 √ó 3 #&gt; species body_mass_g_mean body_mass_g_sd #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Adelie 3701. 459. #&gt; 2 Chinstrap 3733. 384. #&gt; 3 Gentoo 5076. 504. ## Resumo para v√°rias colunas penguins_summarise_across &lt;- penguins %&gt;% dplyr::group_by(species) %&gt;% dplyr::summarize(across(where(is.numeric), ~ mean(.x, na.rm = TRUE))) penguins_summarise_across #&gt; # A tibble: 3 √ó 6 #&gt; species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Adelie 38.8 18.3 190. 3701. 2008. #&gt; 2 Chinstrap 48.8 18.4 196. 3733. 2008. #&gt; 3 Gentoo 47.5 15.0 217. 5076. 2008. 5.8.16 bind_rows() e bind_cols() Muitas vezes teremos de combinar duas ou mais tabelas de dados. Podemos utilizar as fun√ß√µes Base R rbind() e cbind(), como vimos. Entretanto, pode ser interessante avan√ßar para as fun√ß√µes dplyr::bind_rows() e dplyr::bind_cols() do formato tidyverse. A ideia √© muito semelhante: a primeira fun√ß√£o combina dados por linhas e a segunda por colunas. Entretanto, h√° vantagens no uso dessas fun√ß√µes, como a identifica√ß√£o das linhas pelo argumento .id para a primeira fun√ß√£o, e a confer√™ncia do nome das colunas pelo argumento .name_repair para a segunda fun√ß√£o. ## Selecionar as linhas para dois tibbles penguins_01 &lt;- dplyr::slice(penguins, 1:5) penguins_02 &lt;- dplyr::slice(penguins, 51:55) ## Combinar as linhas penguins_bind_rows &lt;- dplyr::bind_rows(penguins_01, penguins_02, .id = &quot;id&quot;) head(penguins_bind_rows) #&gt; # A tibble: 6 √ó 9 #&gt; id species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g sex year #&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 1 Adelie Torgers‚Ä¶ 39.1 18.7 181 3750 male 2007 #&gt; 2 1 Adelie Torgers‚Ä¶ 39.5 17.4 186 3800 fema‚Ä¶ 2007 #&gt; 3 1 Adelie Torgers‚Ä¶ 40.3 18 195 3250 fema‚Ä¶ 2007 #&gt; 4 1 Adelie Torgers‚Ä¶ NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 1 Adelie Torgers‚Ä¶ 36.7 19.3 193 3450 fema‚Ä¶ 2007 #&gt; 6 2 Adelie Biscoe 39.6 17.7 186 3500 fema‚Ä¶ 2008 ## Combinar as colunas penguins_bind_cols &lt;- dplyr::bind_cols(penguins_01, penguins_02, .name_repair = &quot;unique&quot;) head(penguins_bind_cols) #&gt; # A tibble: 5 √ó 16 #&gt; species...1 island...2 bill_length_mm...3 bill_depth_mm...4 flipper_length_‚Ä¶ body_mass_g...6 #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 #&gt; 4 Adelie Torgersen NA NA NA NA #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 #&gt; # ‚Ä¶ with 10 more variables: sex...7 &lt;fct&gt;, year...8 &lt;int&gt;, species...9 &lt;fct&gt;, #&gt; # island...10 &lt;fct&gt;, bill_length_mm...11 &lt;dbl&gt;, bill_depth_mm...12 &lt;dbl&gt;, #&gt; # flipper_length_mm...13 &lt;int&gt;, body_mass_g...14 &lt;int&gt;, sex...15 &lt;fct&gt;, year...16 &lt;int&gt; 5.8.17 *_join() Finalmente, veremos o √∫ltimo conjunto de fun√ß√µes do pacote dplyr, a jun√ß√£o de tabelas. Nessa opera√ß√£o, fazemos a combina√ß√£o de pares de conjunto de dados tabulares por uma ou mais colunas chaves. H√° dois tipos de jun√ß√µes: jun√ß√£o de muta√ß√£o e jun√ß√£o de filtragem. A jun√ß√£o de muta√ß√£o primeiro combina as observa√ß√µes por suas chaves e, em seguida, copia as vari√°veis (colunas) de uma tabela para a outra. √â fundamental destacar a import√¢ncia da coluna chave, que √© indicada pelo argumento by. Essa coluna deve conter elementos que sejam comuns √†s duas tabelas para que haja a combina√ß√£o dos elementos. Existem quatro tipos de jun√ß√µes, que s√£o realizadas pelas fun√ß√µes: dplyr::inner_join(), dplyr::left_join(), dplyr::full_join() e dplyr::right_join(), e que podem ser representadas na Figura 5.3. Figura 5.3: Diferentes tipos de joins, representados com um diagrama de Venn. Adaptado de: Wickham and Grolemund (2017). Considerando a nomenclatura de duas tabelas de dados por x e y, temos: inner_join(x, y): mant√©m apenas as observa√ß√µes em x e em y left_join(x, y): mant√©m todas as observa√ß√µes em x right_join(x, y): mant√©m todas as observa√ß√µes em y full_join(x, y): mant√©m todas as observa√ß√µes em x e em y Aqui, vamos demostrar apenas a fun√ß√£o dplyr::left_join(), combinando um tibble de coordenadas geogr√°ficas das ilhas com o conjunto de dados do penguins. ## Adicionar uma coluna chave de ids penguin_islands &lt;- tibble( island = c(&quot;Torgersen&quot;, &quot;Biscoe&quot;, &quot;Dream&quot;, &quot;Alpha&quot;), longitude = c(-64.083333, -63.775636, -64.233333, -63), latitude = c(-64.766667, -64.818569, -64.733333, -64.316667)) ## Jun√ß√£o - left penguins_left_join &lt;- dplyr::left_join(penguins, penguin_islands, by = &quot;island&quot;) head(penguins_left_join) #&gt; # A tibble: 6 √ó 10 #&gt; species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year #&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 #&gt; 2 Adelie Torgersen 39.5 17.4 186 3800 female 2007 #&gt; 3 Adelie Torgersen 40.3 18 195 3250 female 2007 #&gt; 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 #&gt; 5 Adelie Torgersen 36.7 19.3 193 3450 female 2007 #&gt; 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 #&gt; # ‚Ä¶ with 2 more variables: longitude &lt;dbl&gt;, latitude &lt;dbl&gt; J√° a jun√ß√£o de filtragem combina as observa√ß√µes da mesma maneira que as jun√ß√µes de muta√ß√£o, mas afetam as observa√ß√µes (linhas), n√£o as vari√°veis (colunas). Existem dois tipos. semi_join(x, y): mant√©m todas as observa√ß√µes em x que t√™m uma correspond√™ncia em y anti_join(x, y): elimina todas as observa√ß√µes em x que t√™m uma correspond√™ncia em y Semi-joins s√£o √∫teis para corresponder tabelas de resumo filtradas de volta √†s linhas originais, removendo as linhas que n√£o estavam antes do join. Anti-joins s√£o √∫teis para diagnosticar incompatibilidades de jun√ß√£o, por exemplo, ao verificar os elementos que n√£o combinam entre duas tabelas de dados. 5.8.18 Opera√ß√µes de conjuntos e compara√ß√£o de dados Temos ainda opera√ß√µes de conjuntos e compara√ß√£o de dados. union(x, y): retorna todas as linhas que aparecem em x, y ou mais dos conjuntos de dados interesect(x, y): retorna apenas as linhas que aparecem em x e em y setdiff(x, y): retorna as linhas que aparecem x, mas n√£o em y setequal(x, y): retorna se x e y s√£o iguais e quais suas diferen√ßas Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 13 Relational data de Wickham and Grolemund (2017). 5.9 stringr O pacote stringr fornece um conjunto de fun√ß√µes para a manipula√ß√£o de caracteres ou strings. O pacote concentra-se nas fun√ß√µes de manipula√ß√£o mais importantes e comumente usadas. Para fun√ß√µes mais espec√≠ficas, recomenda-se usar o pacote stringi, que fornece um conjunto mais abrangente de fun√ß√µes. As fun√ß√µes do stringr podem ser agrupadas em algumas opera√ß√µes para tarefas espec√≠ficas como correspond√™ncia de padr√µes, retirar e acrescentar espa√ßos em branco, mudar mai√∫sculas e min√∫sculas, al√©m de outras opera√ß√µes. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. Demonstraremos algumas fun√ß√µes para algumas opera√ß√µes mais comuns, utilizando um vetor de um elemento, com o string ‚Äúpenguins.‚Äù Podemos explorar o comprimento de strings com a fun√ß√£o stringr::str_length(). ## Comprimento stringr::str_length(string = &quot;penguins&quot;) #&gt; [1] 8 Extrair um string por sua posi√ß√£o usando a fun√ß√£o stringr::str_sub() ou por um padr√£o com stringr::str_extract(). ## Extrair pela posi√ß√£o stringr::str_sub(string = &quot;penguins&quot;, end = 3) #&gt; [1] &quot;pen&quot; ## Extrair por padr√£o stringr::str_extract(string = &quot;penguins&quot;, pattern = &quot;p&quot;) #&gt; [1] &quot;p&quot; Substituir strings por outros strings com stringr::str_replace(). ## Substituir stringr::str_replace(string = &quot;penguins&quot;, pattern = &quot;i&quot;, replacement = &quot;y&quot;) #&gt; [1] &quot;penguyns&quot; Separar strings por um padr√£o com a fun√ß√£o stringr::str_split(). ## Separar stringr::str_split(string = &quot;p-e-n-g-u-i-n-s&quot;, pattern = &quot;-&quot;, simplify = TRUE) #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #&gt; [1,] &quot;p&quot; &quot;e&quot; &quot;n&quot; &quot;g&quot; &quot;u&quot; &quot;i&quot; &quot;n&quot; &quot;s&quot; Inserir espa√ßos em brancos pela esquerda, direita ou ambos com a fun√ß√£o stringr::str_pad(). ## Inserir espacos em branco stringr::str_pad(string = &quot;penguins&quot;, width = 10, side = &quot;left&quot;) #&gt; [1] &quot; penguins&quot; stringr::str_pad(string = &quot;penguins&quot;, width = 10, side = &quot;right&quot;) #&gt; [1] &quot;penguins &quot; stringr::str_pad(string = &quot;penguins&quot;, width = 10, side = &quot;both&quot;) #&gt; [1] &quot; penguins &quot; Tamb√©m podemos remover espa√ßos em branco da esquerda, direita ou ambos, utilizando stringr::str_trim(). ## Remover espacos em branco stringr::str_trim(string = &quot; penguins &quot;, side = &quot;left&quot;) #&gt; [1] &quot;penguins &quot; stringr::str_trim(string = &quot; penguins &quot;, side = &quot;right&quot;) #&gt; [1] &quot; penguins&quot; stringr::str_trim(string = &quot; penguins &quot;, side = &quot;both&quot;) #&gt; [1] &quot;penguins&quot; Podemos tamb√©m alterar min√∫sculas e mai√∫sculas em diferentes posi√ß√µes do string, com v√°rias fun√ß√µes. ## Alterar min√∫sculas e mai√∫sculas stringr::str_to_lower(string = &quot;Penguins&quot;) #&gt; [1] &quot;penguins&quot; stringr::str_to_upper(string = &quot;penguins&quot;) #&gt; [1] &quot;PENGUINS&quot; stringr::str_to_sentence(string = &quot;penGuins&quot;) #&gt; [1] &quot;Penguins&quot; stringr::str_to_title(string = &quot;penGuins&quot;) #&gt; [1] &quot;Penguins&quot; Podemos ainda ordenar os elementos de um vetor por ordem alfab√©tica de forma crescente ou decrescente, usando stringr::str_sort(). ## Ordenar stringr::str_sort(x = letters) #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot; &quot;t&quot; &quot;u&quot; &quot;v&quot; #&gt; [23] &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; stringr::str_sort(x = letters, dec = TRUE) #&gt; [1] &quot;z&quot; &quot;y&quot; &quot;x&quot; &quot;w&quot; &quot;v&quot; &quot;u&quot; &quot;t&quot; &quot;s&quot; &quot;r&quot; &quot;q&quot; &quot;p&quot; &quot;o&quot; &quot;n&quot; &quot;m&quot; &quot;l&quot; &quot;k&quot; &quot;j&quot; &quot;i&quot; &quot;h&quot; &quot;g&quot; &quot;f&quot; &quot;e&quot; #&gt; [23] &quot;d&quot; &quot;c&quot; &quot;b&quot; &quot;a&quot; Podemos ainda utilizar essas fun√ß√µes em complemento com o pacote dplyr, para alterar os strings de colunas ou nome das colunas. ## Alterar valores das colunas penguins_stringr_valores &lt;- penguins %&gt;% dplyr::mutate(species = stringr::str_to_lower(species)) ## Alterar nome das colunas penguins_stringr_nomes &lt;- penguins %&gt;% dplyr::rename_with(stringr::str_to_title) Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 14 Strings de Wickham and Grolemund (2017). 5.10 forcats O pacote forcats fornece um conjunto de ferramentas √∫teis para facilitar a manipula√ß√£o de fatores. Como dito anteriormente, usamos fatores geralmente quando temos dados categ√≥ricos, que s√£o vari√°veis que possuem um conjunto de valores fixos e conhecidos. As fun√ß√µes s√£o utilizadas principalmente para: mudar a ordem dos n√≠veis, mudar os valores dos n√≠veis, adicionar e remover n√≠veis, combinar m√∫ltiplos n√≠veis, al√©m de outras opera√ß√µes. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. Vamos utilizar ainda os dados penguins e penguins_raw para exemplificar o uso do pacote forcats. ## Carregar o pacote palmerpenguins library(palmerpenguins) Primeiramente, vamos converter dados de string para fator, utilizando a fun√ß√£o forcats::as_factor(). ## String forcats::as_factor(penguins_raw$Species) %&gt;% head() #&gt; [1] Adelie Penguin (Pygoscelis adeliae) Adelie Penguin (Pygoscelis adeliae) #&gt; [3] Adelie Penguin (Pygoscelis adeliae) Adelie Penguin (Pygoscelis adeliae) #&gt; [5] Adelie Penguin (Pygoscelis adeliae) Adelie Penguin (Pygoscelis adeliae) #&gt; 3 Levels: Adelie Penguin (Pygoscelis adeliae) ... Chinstrap penguin (Pygoscelis antarctica) Podemos facilmente mudar o nome dos n√≠veis utilizando a fun√ß√£o forcats::fct_recode(). ## Mudar o nome dos n√≠veis forcats::fct_recode(penguins$species, a = &quot;Adelie&quot;, c = &quot;Chinstrap&quot;, g = &quot;Gentoo&quot;) %&gt;% head() #&gt; [1] a a a a a a #&gt; Levels: a c g Para inverter os n√≠veis, usamos a fun√ß√£o forcats::fct_rev(). ## Inverter os n√≠veis forcats::fct_rev(penguins$species) %&gt;% head() #&gt; [1] Adelie Adelie Adelie Adelie Adelie Adelie #&gt; Levels: Gentoo Chinstrap Adelie Uma opera√ß√£o muito comum com fatores √© mudar a ordem dos n√≠veis. Quando precisamos especificar a ordem dos n√≠veis, podemos fazer essa opera√ß√£o manualmente com a fun√ß√£o forcats::fct_relevel(). ## Especificar a ordem dos n√≠veis forcats::fct_relevel(penguins$species, &quot;Chinstrap&quot;, &quot;Gentoo&quot;, &quot;Adelie&quot;) %&gt;% head() #&gt; [1] Adelie Adelie Adelie Adelie Adelie Adelie #&gt; Levels: Chinstrap Gentoo Adelie Como vimos, a reordena√ß√£o dos n√≠veis pode ser feita manualmente. Mas existem outras formas autom√°ticas de reordena√ß√£o seguindo algumas regras, para as quais existem fun√ß√µes espec√≠ficas. forcats::fct_inorder(): pela ordem em que aparecem pela primeira vez forcats::fct_infreq(): por n√∫mero de observa√ß√µes com cada n√≠vel (decrescente, i.e., o maior primeiro) forcats::fct_inseq(): pelo valor num√©rico do n√≠vel ## N√≠veis pela ordem em que aparecem forcats::fct_inorder(penguins$species) %&gt;% head() #&gt; [1] Adelie Adelie Adelie Adelie Adelie Adelie #&gt; Levels: Adelie Gentoo Chinstrap ## Ordem (decrescente) de frequ√™ncia forcats::fct_infreq(penguins$species) %&gt;% head() #&gt; [1] Adelie Adelie Adelie Adelie Adelie Adelie #&gt; Levels: Adelie Gentoo Chinstrap Por fim, podemos fazer a agrega√ß√£o de n√≠veis raros em um n√≠vel utilizando a fun√ß√£o forcats::fct_lump(). ## Agrega√ß√£o de n√≠veis raros em um n√≠vel forcats::fct_lump(penguins$species) %&gt;% head() #&gt; [1] Adelie Adelie Adelie Adelie Adelie Adelie #&gt; Levels: Adelie Gentoo Other Podemos ainda utilizar essas fun√ß√µes em complemento com o pacote dplyr para fazer manipula√ß√µes de fatores nas colunas de tibbles. ## Transformar v√°rias colunas em fator penguins_raw_multi_factor &lt;- penguins_raw %&gt;% dplyr::mutate(across(where(is.character), forcats::as_factor)) Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 15 Factors de Wickham and Grolemund (2017). 5.11 lubridate O pacote lubridate fornece um conjunto de fun√ß√µes para a manipula√ß√£o de dados de data e hor√°rio. Dessa forma, esse pacote facilita a manipula√ß√£o dessa classe de dado no R, pois geralmente esses dados n√£o s√£o intuitivos e mudam dependendo do tipo de objeto de data e hor√°rio. Al√©m disso, os m√©todos que usam datas e hor√°rios devem levar em considera√ß√£o fusos hor√°rios, anos bissextos, hor√°rios de ver√£o, al√©m de outras particularidades. Existem diversas fun√ß√µes nesse pacote, sendo as mesmas focadas em: transforma√ß√µes de data/hor√°rio, componentes, arredondamentos, dura√ß√µes, per√≠odos, intervalos, al√©m de muitas outras fun√ß√µes espec√≠ficas. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. Apesar de estar inserido no escopo do tidyverse, este pacote n√£o √© carregado com os demais, requisitando seu carregamento solo. ## Carregar library(lubridate) Existem tr√™s tipos de dados data/hor√°rio: Data: tempo em dias, meses e anos &lt;date&gt; Hor√°rio: tempo dentro de um dia &lt;time&gt; Data-hor√°rio: tempo em um instante (data mais tempo) &lt;dttm&gt; Para trabalhar exclusivamente com hor√°rios, podemos utilizar o pacote hms. √â fundamental tamb√©m destacar que algumas letras ter√£o um significado temporal, sendo abrevia√ß√µes de diferentes per√≠odos em ingl√™s: year (ano), month (m√™s), weak (semana), day (dia), hour (hora), minute (minuto), e second (segundo). Para acessar a informa√ß√£o da data e hor√°rios atuais podemos utilizar as fun√ß√µes lubridate::today() e lubridate::now(). ## Extrair a data nesse instante lubridate::today() #&gt; [1] &quot;2021-11-04&quot; ## Extrair a data e tempo nesse instante lubridate::now() #&gt; [1] &quot;2021-11-04 14:17:54 CET&quot; Al√©m dessas informa√ß√µes instant√¢neas, existem tr√™s maneiras de criar um dado de data/hor√°rio. De um string De componentes individuais de data e hor√°rio De um objeto de data/hor√°rio existente Os dados de data/hor√°rio geralmente est√£o no formato de strings. Podemos transformar os dados especificando a ordem dos seus componentes, ou seja, a ordem em que ano, m√™s e dia aparecem no string, usando as letras y (ano), m (m√™s) e d (dia) na mesma ordem, por exemplo, lubridate::dmy(). ## Strings e n√∫meros para datas lubridate::dmy(&quot;03-03-2021&quot;) #&gt; [1] &quot;2021-03-03&quot; Essas fun√ß√µes tamb√©m aceitam n√∫meros sem aspas, al√©m de serem muito vers√°teis e funcionarem em outros diversos formatos. ## Strings e n√∫meros para datas lubridate::dmy(&quot;03-Mar-2021&quot;) lubridate::dmy(03032021) lubridate::dmy(&quot;03032021&quot;) lubridate::dmy(&quot;03/03/2021&quot;) lubridate::dmy(&quot;03.03.2021&quot;) Al√©m da data, podemos especificar hor√°rios atrelados a essas datas. Para criar uma data com hor√°rio adicionamos um underscore (_) e os h (hora), m (minuto) e s (segundo) ao nome da fun√ß√£o, al√©m do argumento tz para especificar o fuso hor√°rio (tema tratado mais adiante nessa se√ß√£o). ## Especificar hor√°rios e fuso hor√°rio lubridate::dmy_h(&quot;03-03-2021 13&quot;) #&gt; [1] &quot;2021-03-03 13:00:00 UTC&quot; lubridate::dmy_hm(&quot;03-03-2021 13:32&quot;) #&gt; [1] &quot;2021-03-03 13:32:00 UTC&quot; lubridate::dmy_hms(&quot;03-03-2021 13:32:01&quot;) #&gt; [1] &quot;2021-03-03 13:32:01 UTC&quot; lubridate::dmy_hms(&quot;03-03-2021 13:32:01&quot;, tz = &quot;America/Sao_Paulo&quot;) #&gt; [1] &quot;2021-03-03 13:32:01 -03&quot; Podemos ainda ter componentes individuais de data/hor√°rio em m√∫ltiplas colunas. Para realizar essa transforma√ß√£o, podemos usar as fun√ß√µes lubridate::make_date() e lubridate::make_datetime(). ## Dados com componentes individuais dados &lt;- tibble::tibble( ano = c(2021, 2021, 2021), mes = c(1, 2, 3), dia = c(12, 20, 31), hora = c(2, 14, 18), minuto = c(2, 44, 55)) ## Data de componentes individuais dados %&gt;% dplyr::mutate(data = lubridate::make_datetime(ano, mes, dia, hora, minuto)) #&gt; # A tibble: 3 √ó 6 #&gt; ano mes dia hora minuto data #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; #&gt; 1 2021 1 12 2 2 2021-01-12 02:02:00 #&gt; 2 2021 2 20 14 44 2021-02-20 14:44:00 #&gt; 3 2021 3 31 18 55 2021-03-31 18:55:00 Por fim, podemo criar datas modificando entre data/hor√°rio e data, utilizando as fun√ß√µes lubridate::as_datetime() e lubridate::as_date(). ## Data para data-hor√°rio lubridate::as_datetime(today()) #&gt; [1] &quot;2021-11-04 UTC&quot; ## Data-hor√°rio para data lubridate::as_date(now()) #&gt; [1] &quot;2021-11-04&quot; Uma vez que entendemos como podemos criar dados de data/hor√°rio, podemos explorar fun√ß√µes para acessar e definir componentes individuais. Para essa tarefa existe uma grande quantidade de fun√ß√µes para acessar de partes espec√≠ficas de datas e hor√°rios. year(): acessa o ano month(): acessa o m√™s month(): acessa o dia yday(): acessa o dia do ano mday(): acessa o dia do m√™s wday(): acessa o dia da semana hour(): acessa as horas minute(): acessa os minutos second(): acessa os segundos ## Extrair lubridate::year(now()) #&gt; [1] 2021 lubridate::month(now()) #&gt; [1] 11 lubridate::month(now(), label = TRUE) #&gt; [1] Nov #&gt; Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; Oct &lt; Nov &lt; Dec lubridate::day(now()) #&gt; [1] 4 lubridate::wday(now()) #&gt; [1] 5 lubridate::wday(now(), label = TRUE) #&gt; [1] Thu #&gt; Levels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat lubridate::second(now()) #&gt; [1] 54.56615 Al√©m de acessar componentes de datas e hor√°rios, podemos usar essas fun√ß√µes para fazer a inclus√£o de informa√ß√µes de datas e hor√°rios. ## Data data &lt;- dmy_hms(&quot;04-03-2021 01:04:56&quot;) ## Incluir lubridate::year(data) &lt;- 2020 lubridate::month(data) &lt;- 01 lubridate::hour(data) &lt;- 13 Mais convenientemente, podemos utilizar a fun√ß√£o update() para alterar v√°rios valores de uma vez. ## Incluir v√°rios valores update(data, year = 2020, month = 1, mday = 1, hour = 1) #&gt; [1] &quot;2020-01-01 01:04:56 UTC&quot; Muitas vezes precisamos fazer opera√ß√µes com datas, como a aritm√©tica com datas: subtra√ß√£o, adi√ß√£o e divis√£o. Para tanto, √© preciso entender tr√™s classes importantes que representam intervalos de tempo. Dura√ß√µes: representam um n√∫mero exato de segundos Per√≠odos: representam unidades humanas como semanas e meses Intervalos: representam um ponto inicial e final Quando fazemos uma subtra√ß√£o de datas, criamos um objeto da classe difftime. Essa classe pode ser um pouco complicada de trabalhar, ent√£o dentro do lubridate, podemos usar fun√ß√µes que convertem essa classe em dura√ß√£o, da classe Duration. As dura√ß√µes sempre registram o intervalo de tempo em segundos, com alguma unidade de tempo maior entre par√™nteses. H√° uma s√©rie de fun√ß√µes para tratar dessa classe. duration(): cria data em dura√ß√£o as.duration(): converte datas em dura√ß√£o dyears(): dura√ß√£o de anos dmonths(): dura√ß√£o de meses dweeks(): dura√ß√£o de semanas ddays(): dura√ß√£o de dias dhours(): dura√ß√£o de horas dminutes(): dura√ß√£o de minutos dseconds(): dura√ß√£o de segundos ## Subtra√ß√£o de datas tempo_estudando_r &lt;- lubridate::today() - lubridate::dmy(&quot;30-11-2011&quot;) ## Convers√£o para dura√ß√£o tempo_estudando_r_dur &lt;- lubridate::as.duration(tempo_estudando_r) ## Criando dura√ß√µes lubridate::duration(90, &quot;seconds&quot;) #&gt; [1] &quot;90s (~1.5 minutes)&quot; lubridate::duration(1.5, &quot;minutes&quot;) #&gt; [1] &quot;90s (~1.5 minutes)&quot; lubridate::duration(1, &quot;days&quot;) #&gt; [1] &quot;86400s (~1 days)&quot; ## Transforma√ß√£o da dura√ß√£o lubridate::dseconds(100) #&gt; [1] &quot;100s (~1.67 minutes)&quot; lubridate::dminutes(100) #&gt; [1] &quot;6000s (~1.67 hours)&quot; lubridate::dhours(100) #&gt; [1] &quot;360000s (~4.17 days)&quot; lubridate::ddays(100) #&gt; [1] &quot;8640000s (~14.29 weeks)&quot; lubridate::dweeks(100) #&gt; [1] &quot;60480000s (~1.92 years)&quot; lubridate::dyears(100) #&gt; [1] &quot;3155760000s (~100 years)&quot; Podemos ainda utilizar as dura√ß√µes para fazer opera√ß√µes aritm√©ticas com datas como adi√ß√£o, subtra√ß√£o e multiplica√ß√£o. ## Somando dura√ß√µes a datas lubridate::today() + lubridate::ddays(1) #&gt; [1] &quot;2021-11-05&quot; ## Subtraindo dura√ß√µes de datas lubridate::today() - lubridate::dyears(1) #&gt; [1] &quot;2020-11-03 18:00:00 UTC&quot; ## Multiplicando dura√ß√µes 2 * dyears(2) #&gt; [1] &quot;126230400s (~4 years)&quot; Al√©m das dura√ß√µes, podemos usar per√≠odos, que s√£o extens√µes de tempo n√£o fixados em segundos como as dura√ß√µes, mas flex√≠veis, com o tempo em dias, semanas, meses ou anos, permitindo uma interpreta√ß√£o mais intuitiva das datas. Novamente, h√° uma s√©rie de fun√ß√µes para realizar essas opera√ß√µes. period(): cria data em per√≠odo as.period(): converte datas em per√≠odo seconds(): per√≠odo em segundos minutes(): per√≠odo em minutos hours(): per√≠odo em horas days(): per√≠odo em dias weeks(): per√≠odo em semanas months(): per√≠odo em meses years(): per√≠odo em anos ## Criando per√≠odos period(c(90, 5), c(&quot;second&quot;, &quot;minute&quot;)) #&gt; [1] &quot;5M 90S&quot; period(c(3, 1, 2, 13, 1), c(&quot;second&quot;, &quot;minute&quot;, &quot;hour&quot;, &quot;day&quot;, &quot;week&quot;)) #&gt; [1] &quot;20d 2H 1M 3S&quot; ## Transforma√ß√£o de per√≠odos lubridate::seconds(100) #&gt; [1] &quot;100S&quot; lubridate::minutes(100) #&gt; [1] &quot;100M 0S&quot; lubridate::hours(100) #&gt; [1] &quot;100H 0M 0S&quot; lubridate::days(100) #&gt; [1] &quot;100d 0H 0M 0S&quot; lubridate::weeks(100) #&gt; [1] &quot;700d 0H 0M 0S&quot; lubridate::years(100) #&gt; [1] &quot;100y 0m 0d 0H 0M 0S&quot; Al√©m disso, podemos fazer opera√ß√µes com os per√≠odos, somando e subtraindo. ## Somando datas lubridate::today() + lubridate::weeks(10) #&gt; [1] &quot;2022-01-13&quot; ## Subtraindo datas lubridate::today() - lubridate::weeks(10) #&gt; [1] &quot;2021-08-26&quot; ## Criando datas recorrentes lubridate::today() + lubridate::weeks(0:10) #&gt; [1] &quot;2021-11-04&quot; &quot;2021-11-11&quot; &quot;2021-11-18&quot; &quot;2021-11-25&quot; &quot;2021-12-02&quot; &quot;2021-12-09&quot; #&gt; [7] &quot;2021-12-16&quot; &quot;2021-12-23&quot; &quot;2021-12-30&quot; &quot;2022-01-06&quot; &quot;2022-01-13&quot; Por fim, intervalos s√£o per√≠odos de tempo limitados por duas datas, possuindo uma dura√ß√£o com um ponto de partida, que o faz preciso para determinar uma dura√ß√£o. Intervalos s√£o objetos da classe Interval. Da mesma forma que para dura√ß√£o e per√≠odos, h√° uma s√©rie de fun√ß√µes para realizar essas opera√ß√µes. interval(): cria data em intervalo %--%: cria data em intervalo as.interval(): converte datas em intervalo int_start(): acessa ou atribui data inicial de um intervalo int_end(): acessa ou atribui data final de um intervalo int_length(): comprimento de um intervalo em segundos int_flip(): inverte a ordem da data de in√≠cio e da data de t√©rmino em um intervalo int_shift(): desloca as datas de in√≠cio e t√©rmino de um intervalo int_aligns(): testa se dois intervalos compartilham um ponto final int_standardize(): garante que todos os intervalos sejam positivos int_diff(): retorna os intervalos que ocorrem entre os elementos de data/hor√°rio int_overlaps(): testa se dois intervalos se sobrep√µem %within%: testa se o primeiro intervalo est√° contido no segundo ## Criando duas datas - in√≠cio de estudos do R e nascimento do meu filho r_inicio &lt;- lubridate::dmy(&quot;30-11-2011&quot;) filho_nascimento &lt;- lubridate::dmy(&quot;26-09-2013&quot;) r_hoje &lt;- lubridate::today() ## Criando intervalos - interval r_intervalo &lt;- lubridate::interval(r_inicio, r_hoje) ## Criando intervalos - interval %--% filho_intervalo &lt;- filho_nascimento %--% lubridate::today() ## Opera√ß√µes com intervalos lubridate::int_start(r_intervalo) #&gt; [1] &quot;2011-11-30 UTC&quot; lubridate::int_end(r_intervalo) #&gt; [1] &quot;2021-11-04 UTC&quot; lubridate::int_length(r_intervalo) #&gt; [1] 313372800 lubridate::int_flip(r_intervalo) #&gt; [1] 2021-11-04 UTC--2011-11-30 UTC lubridate::int_shift(r_intervalo, duration(days = 30)) #&gt; [1] 2011-12-30 UTC--2021-12-04 UTC Uma opera√ß√£o de destaque √© verificar a sobreposi√ß√£o entre dois intervalos. ## Verificar sobreposi√ß√£o - int_overlaps lubridate::int_overlaps(r_intervalo, filho_intervalo) #&gt; [1] TRUE ## Verificar se intervalo est√° contido r_intervalo %within% filho_intervalo #&gt; [1] FALSE filho_intervalo %within% r_intervalo #&gt; [1] TRUE Podemos ainda calcular quantos per√≠odos existem dentro de um intervalo, utilizando as opera√ß√µes de / e %/%. ## Per√≠odos dentro de um intervalo - anos r_intervalo / lubridate::years() #&gt; [1] 9.928767 r_intervalo %/% lubridate::years() #&gt; [1] 9 ## Per√≠odos dentro de um intervalo - dias e semandas filho_intervalo / lubridate::days() #&gt; [1] 2961 filho_intervalo / lubridate::weeks() #&gt; [1] 423 Ainda podemos fazer transforma√ß√µes dos dados para per√≠odos e ter todas as unidades de data e tempo que o intervalo compreende. ## Tempo total estudando R lubridate::as.period(r_intervalo) #&gt; [1] &quot;9y 11m 5d 0H 0M 0S&quot; ## Idade do meu filho lubridate::as.period(filho_intervalo) #&gt; [1] &quot;8y 1m 9d 0H 0M 0S&quot; Por fim, fusos hor√°rios tendem a ser um fator complicador quando precisamos analisar informa√ß√µes instant√¢neas de tempo (hor√°rio) de outras partes do planeta, ou mesmo fazer convers√µes dos hor√°rios. No lubridate h√° fun√ß√µes para ajudar nesse sentido. Para isso, podemos utilizar a fun√ß√£o lubridate::with_tz(), e no argumento tzone informar o fuso hor√°rio para a transforma√ß√£o do hor√°rio. Podemos descobrir o fuso hor√°rio que o R est√° considerando com a fun√ß√£o Sys.timezone(). ## Fuso hor√°rio no R Sys.timezone() #&gt; [1] &quot;Europe/Berlin&quot; No R h√° uma listagem dos nomes dos fusos hor√°rios que podemos utilizar no argumento tzone para diferentes fusos hor√°rios. ## Verificar os fuso hor√°rios length(OlsonNames()) #&gt; [1] 608 head(OlsonNames()) #&gt; [1] &quot;Africa/Abidjan&quot; &quot;Africa/Accra&quot; &quot;Africa/Addis_Ababa&quot; &quot;Africa/Algiers&quot; #&gt; [5] &quot;Africa/Asmara&quot; &quot;Africa/Asmera&quot; Podemos nos perguntar que horas s√£o em outra parte do globo ou fazer as convers√µes facilmente no lubridate. ## Que horas s√£o em... lubridate::with_tz(lubridate::now(), tzone = &quot;America/Sao_Paulo&quot;) #&gt; [1] &quot;2021-11-04 10:17:55 -03&quot; lubridate::with_tz(lubridate::now(), tzone = &quot;GMT&quot;) #&gt; [1] &quot;2021-11-04 13:17:55 GMT&quot; lubridate::with_tz(lubridate::now(), tzone = &quot;Europe/Berlin&quot;) #&gt; [1] &quot;2021-11-04 14:17:55 CET&quot; ## Altera o fuso sem mudar a hora lubridate::force_tz(lubridate::now(), tzone = &quot;GMT&quot;) #&gt; [1] &quot;2021-11-04 14:17:55 GMT&quot; Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 16 Dates and times de Wickham and Grolemund (2017). 5.12 purrr O pacote purrr implementa a Programa√ß√£o Funcional no R, fornecendo um conjunto completo e consistente de ferramentas para trabalhar com fun√ß√µes e vetores. A programa√ß√£o funcional √© um assunto bastante extenso, sendo mais conhecido no R pela fam√≠lia de fun√ß√µes purrr::map(), que permite substituir muitos loops for por um c√≥digo mais sucinto e f√°cil de ler. N√£o focaremos aqui nas outras fun√ß√µes. Todas as fun√ß√µes deste pacote s√£o listadas na p√°gina de refer√™ncia do pacote. Um loop for pode ser entendido como uma itera√ß√£o: um bloco de c√≥digos √© repetido mudando um contador de uma lista de possibilidades. Vamos exemplificar com uma itera√ß√£o bem simples, onde imprimiremos no console os valores de 1 a 10, utilizando a fun√ß√£o for(), um contador i em um vetor de dez n√∫meros 1:10 que ser√° iterado, no bloco de c√≥digos definido entre {}, usando a fun√ß√£o print() para imprimir os valores. A ideia √© bastante simples: a fun√ß√£o for() vai atribuir o primeiro valor da lista ao contador i, esse contador ser√° utilizado em todo o bloco de c√≥digos. Quando o bloco terminar, o segundo valor √© atribu√≠do ao contador i e entra no bloco de c√≥digos, repetindo esse processo at√© que todos os elementos da lista tenham sido atribu√≠dos ao contador. ## Loop for for(i in 1:10){ print(i) } #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 #&gt; [1] 4 #&gt; [1] 5 #&gt; [1] 6 #&gt; [1] 7 #&gt; [1] 8 #&gt; [1] 9 #&gt; [1] 10 Com essa ideia em mente, a programa√ß√£o funcional utilizando a fun√ß√£o purrr::map(). O mesmo for ficaria dessa forma. ## Loop for com map purrr::map(.x = 1:10, .f = print) #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 #&gt; [1] 4 #&gt; [1] 5 #&gt; [1] 6 #&gt; [1] 7 #&gt; [1] 8 #&gt; [1] 9 #&gt; [1] 10 #&gt; [[1]] #&gt; [1] 1 #&gt; #&gt; [[2]] #&gt; [1] 2 #&gt; #&gt; [[3]] #&gt; [1] 3 #&gt; #&gt; [[4]] #&gt; [1] 4 #&gt; #&gt; [[5]] #&gt; [1] 5 #&gt; #&gt; [[6]] #&gt; [1] 6 #&gt; #&gt; [[7]] #&gt; [1] 7 #&gt; #&gt; [[8]] #&gt; [1] 8 #&gt; #&gt; [[9]] #&gt; [1] 9 #&gt; #&gt; [[10]] #&gt; [1] 10 Nessa estrutura, temos: map(.x, .f) .x: um vetor, lista ou data frame .f: uma fun√ß√£o Num outro exemplo, aplicaremos a fun√ß√£o sum() para somar os valores de v√°rios elementos de uma lista. ## Fun√ß√£o map x &lt;- list(1:5, c(4, 5, 7), c(1, 1, 1), c(2, 2, 2, 2, 2)) purrr::map(x, sum) #&gt; [[1]] #&gt; [1] 15 #&gt; #&gt; [[2]] #&gt; [1] 16 #&gt; #&gt; [[3]] #&gt; [1] 3 #&gt; #&gt; [[4]] #&gt; [1] 10 H√° diferente tipos de retornos da fam√≠lia purrr::map(). map(): retorna uma lista map_chr(): retorna um vetor de strings map_dbl(): retorna um vetor num√©rico (double) map_int(): retorna um vetor num√©rico (integer) map_lgl(): retorna um vetor l√≥gico map_dfr(): retorna um data frame (por linhas) map_dfc(): retorna um data frame (por colunas) ## Varia√ß√µes da fun√ß√£o map purrr::map_dbl(x, sum) #&gt; [1] 15 16 3 10 purrr::map_chr(x, paste, collapse = &quot; &quot;) #&gt; [1] &quot;1 2 3 4 5&quot; &quot;4 5 7&quot; &quot;1 1 1&quot; &quot;2 2 2 2 2&quot; Essas funcionalidades j√° eram conhecidas no Base R pelas fun√ß√µes da fam√≠lia apply: apply(), lapply(), sapply(), vapply(), mapply(), rapply() e tapply(). Essas fun√ß√µes formam a base de combina√ß√µes mais complexas e ajudam a realizar opera√ß√µes com poucas linhas de c√≥digo, para diferentes retornos. Temos ainda duas variantes da fun√ß√£o map(): purrr::map2() e purrr::pmap(), para duas ou mais listas, respectivamente. Como vimos para a primeira fun√ß√£o, existem v√°rias varia√ß√µes do sufixo para modificar o retorno da fun√ß√£o. ## Listas x &lt;- list(3, 5, 0, 1) y &lt;- list(3, 5, 0, 1) z &lt;- list(3, 5, 0, 1) ## Fun√ß√£o map2 purrr::map2_dbl(x, y, prod) #&gt; [1] 9 25 0 1 ## Fun√ß√£o pmap purrr::pmap_dbl(list(x, y, z), prod) #&gt; [1] 27 125 0 1 Essas fun√ß√µes podem ser usadas em conjunto para implementar rotinas de manipula√ß√£o e an√°lise de dados com poucas linhas de c√≥digo, mas que n√£o exploraremos em sua completude aqui. Listamos dois exemplos simples. ## Resumo dos dados penguins %&gt;% dplyr::select(where(is.numeric)) %&gt;% tidyr::drop_na() %&gt;% purrr::map_dbl(mean) #&gt; bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year #&gt; 43.92193 17.15117 200.91520 4201.75439 2008.02924 ## An√°lise dos dados penguins %&gt;% dplyr::group_split(island, species) %&gt;% purrr::map(~ lm(bill_depth_mm ~ bill_length_mm, data = .x)) %&gt;% purrr::map(summary) %&gt;% purrr::map(&quot;r.squared&quot;) #&gt; [[1]] #&gt; [1] 0.2192052 #&gt; #&gt; [[2]] #&gt; [1] 0.4139429 #&gt; #&gt; [[3]] #&gt; [1] 0.2579242 #&gt; #&gt; [[4]] #&gt; [1] 0.4271096 #&gt; #&gt; [[5]] #&gt; [1] 0.06198376 Para se aprofundar no tema, recomendamos a leitura do Cap√≠tulo 21 Iteration de Wickham and Grolemund (2017). 5.13 Exerc√≠cios Reescreva as opera√ß√µes abaixo utilizando pipes %&gt;%. log10(cumsum(1:100)) sum(sqrt(abs(rnorm(100)))) sum(sort(sample(1:10, 10000, rep = TRUE))) Use a fun√ß√£o download.file() e unzip() para baixar e extrair o arquivo do data paper de m√©dios e grandes mam√≠feros: ATLANTIC MAMMALS. Em seguinda, importe para o R, usando a fun√ß√£o readxl::read_excel(). Use a fun√ß√£o tibble::glimpse() para ter uma no√ß√£o geral dos dados importados no item anterior. Compare os dados de penguins (palmerpenguins::penguins_raw e palmerpenguins::penguins). Monte uma s√©rie de fun√ß√µes dos pacotes tidyr e dplyr para fazer limpar os dados e fazer com que o primeiro dado seja igual ao segundo. Usando os dados de penguins (palmerpenguins::penguins), calcule a correla√ß√£o de Pearson entre comprimento e profundidade do bico para cada esp√©cie e para todas as esp√©cies. Compare os √≠ndices de correla√ß√£o para exemplificar o Paradoxo de Simpsom. Oficialmente a pandemia de COVID-19 come√ßou no Brasil com o primeiro caso no dia 26 de fevereiro de 2020. Calcule quantos anos, meses, dias, semanas, horas, minutos e segundos se passou desde ent√£o. Calcule tamb√©m quanto tempo se passou at√© voc√™ ser vacinado. 5.14 Para se aprofundar Listamos a seguir livros que recomendamos para seguir com sua aprendizagem em R e tidyverse. Portugu√™s Damiani A, Milz B, Lente C, Falbel D, Correa F, Trecenti J, Luduvice N, Amorim W. 2021. Ci√™ncia de Dados em R. [https://livro.curso-r.com/] Faria PD, Parga JPFA. 2020. Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. [https://www.researchgate.net/publication/345985082_Introducao_a_Linguagem_R_seus_fundamentos_e_sua_pratica] Oliveira PF, Guerra S, Mcdonnell, R. 2018. Ci√™ncia de dados com R ‚Äì Introdu√ß√£o. IBPAD. [https://cdr.ibpad.com.br/] Ingl√™s Grolemund G. 2017. The Essentials of Data Science: Knowledge Discovery Using R. Chapman and Hall/CRC. Holmes S, Huber W. 2019. Modern Statistics for Modern Biology. Cambridge University Press. [https://www.huber.embl.de/msmb/] Irizarry RA. 2019. Introduction to Data Science: Data Analysis and Prediction Algorithms with R. Chapman and Hall/CRC. [https://rafalab.github.io/dsbook/] Ismay C., Kim AY. 2019. Statistical Inference via Data Science: A ModernDive into R and the Tidyverse. Chapman and Hall/CRC. [https://moderndive.com/] Peng DP. 2020. R Programming for Data Science. [https://bookdown.org/rdpeng/rprogdatascience/] Wickham H, Grolemund G. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O‚ÄôReilly Media. [https://r4ds.had.co.nz/] Wright C, Ellis S, Hicks S &amp; Peng R D. 2021. Tidyverse Skills for Data Science in R. [https://jhudatascience.org/tidyversecourse/] Zumel N, Mount J. 2014. Practical Data Science with R Paperback. Manning. Refer√™ncias "],["cap6.html", "Cap√≠tulo 6 Guia de bolso de gr√°ficos no R 6.1 1. Introdu√ß√£o 6.2 2. Pacotes necess√°rios 6.3 Principais pacotes 6.4 3. Gr√°matica dos gr√°ficos 6.5 4. Tipos de gr√°ficos 6.6 4.7. Gr√°fico de dispers√£o (scatter plot) 6.7 4.8. Visualiza√ß√£o de m√∫ltiplos gr√°ficos pareados 6.8 5. Erros comuns dos usu√°rios do ggplot2 e como evit√°-los 6.9 6. Finaliza√ß√£o de gr√°ficos para publica√ß√£o 6.10 Check-list para garantir bons gr√°ficos 6.11 Para se aprofundar", " Cap√≠tulo 6 Guia de bolso de gr√°ficos no R 6.1 1. Introdu√ß√£o A visualiza√ß√£o de dados atrav√©s de gr√°ficos geralmente √© a melhor forma de apresentar e interpretar as informa√ß√µes contidas em seus estudos, fazendo uma uma s√≠ntese para melhor entendimento de padr√µes. Geralmente, os gr√°ficos s√£o necess√°rios em quase todas as an√°lises estat√≠sticas, al√©m de enriquecer a argumenta√ß√£o e discuss√£o de hip√≥teses levatandas para publica√ß√µes, trabalhos de consultoria, TCC, disserta√ß√£o, tese, entre outros. Existem v√°rios tipos de gr√°ficos para representar os padr√µes em seus dados para diferentes tipos de finalidades. Esses diferentes tipos de gr√°ficos podem at√© mesmo ser usados para representar o mesmo tipo de dado. Nesta se√ß√£o, focaremos nos gr√°ficos mais simples, para representar uma ou duas vari√°veis (i.e., gr√°ficos bidimensionais). Os gr√°ficos mais indicados para representar um conunto de dados mudam dependendo do tipo de vari√°vel (categ√≥rica ou cont√≠nua - veja os tipos no Cap√≠tulo 3). De forma simplificada, os gr√°ficos s√£o representa√ß√µes dos nossos dados tabulares. Os eixos de um gr√°fico representam as colunas (vari√°veis) e as atributos est√©ticos (asesthetics: pontos, linhas, barras, caixas, etc.) representam as linhas da tabela. Geralmente, os gr√°ficos v√£o ser a representa√ß√£o de uma ou duas colunas, quando muito tr√™s, em gr√°ficos de tr√™s dimens√µes. Para mais colunas, partimos para dados agregados que s√£o vistos nos cap√≠tulo de an√°lise multivariada. Al√©m disso, a utiliza√ß√£o de mais de duas colunas pode estar relacionado com outros atributos est√©ticos (aes()) do gr√°fico como cor, forma e tamanho de pontos e linhas. Dessa forma, dedicamos esse cap√≠tulo inteiramente a apresentar os principais conceitos, como a gram√°tica de gr√°ficos, e uma apresenta√ß√£o geral que pode funcionar como ‚Äúum guia de bolso‚Äù de gr√°ficos, uma vez que apresentamos os principais tipos de gr√°ficos para an√°lises ecol√≥gicas. Al√©m disso, no √∫ltimo t√≥pico deste cap√≠tulo focamos na finaliza√ß√£o (ajustes finos) de gr√°ficos para publica√ß√£o. Este cap√≠tulo fornece as bases conceitual e pr√°tica necess√°ria para enteder a visualiza√ß√£o gr√°fica apresentada nos cap√≠tulos 6 a 14. Existe uma ampla gama de pacotes para fazer gr√°ficos no R, sendo esse um ponto muito forte dessa linguagem. Al√©m disso, a ampla disponibilidade de pacotes e fun√ß√µes permitem a visualiza√ß√£o dos mais diferentes tipos de dados, o que torna a linguagem R com alta praticidade, uma vez que a maior parte dos pacotes possui uma sintaxe relativamente simples para a apresenta√ß√£o de gr√°ficos excelentes e de √≥tima qualidade. Mais adiante no Cap√≠tulo 14, ampliamos a discuss√£o da visualiza√ß√£o gr√°fica com ferramentas para constru√ß√£o de mapas no R. Este cap√≠tulo foi organizdo em quatro partes: (i) principais pacotes, (ii) gram√°ticas dos gr√°ficos, (iii) um guia de bolso para visualiza√ß√£o de v√°rios gr√°ficos no R, e (iv) edi√ß√£o de gr√°fico com qualidade para publica√ß√£o. Portanto, apesar de apresentarmos diferentes pacotes com grande potencial para visualiza√ß√£o gr√°fica, nest cap√≠tulo iremos focar no pacote ggplot2. Usaremos os dados de medidas de pinguins chamados palmerpenguins para exemplicar as fun√ß√µes do ggplot2 que geram diferentes tipos de gr√°ficos . Esses dados est√£o dispon√≠veis no pacote palmerpenguins, que foram coletados e disponibilizados pela Dra. Kristen Gorman e Palmer Station, Antarctica LTER, ambas do Long Term Ecological Research Network. O pacote palmerpenguins cont√©m dois conjuntos de dados. Um √© chamado de penguins e √© uma vers√£o simplificada dos dados brutos. O segundo conjunto de dados √© penguins_raw e cont√©m todas as vari√°veis e nomes originais baixados. Ambos os conjuntos de dados cont√™m dados para 344 pinguins, de tr√™s esp√©cies diferentes, coletados em tr√™s ilhas no arquip√©lago de Palmer, na Ant√°rtica. 6.2 2. Pacotes necess√°rios library(ggplot2) library(tidyverse) library(palmerpenguins) library(datasauRus) library(Rmisc) library(gridExtra) Apesar do foco no ggplot2, abaixo detalhamos os principais pacotes e suas fun√ß√µes para visualiza√ß√£o gr√°fica: 6.3 Principais pacotes A seguir, apresentamos uma listagem dos principais pacotes para fazer gr√°ficos no R e, al√©m disso, incluimos as principais fun√ß√µes desses pacotes: graphics: √© o pacote default do R para produzir gr√°fios simples, por√©m √∫til para visualiza√ß√µes r√°pidas de quase todos as classes de objetos. Possui fun√ß√µes como: plot(), hist(), barplot(), boxplot(), abline(), points(), lines() e polygon(). ggplot2: pacote integrado ao tidyverse (Cap√≠tulo ??), possui uma sintaxe pr√≥pria baseada na gr√°tica de gr√°ficos por camadas (layers), necessitando de fun√ß√µes espec√≠ficas para objetos de classes diferentes, demandando geralmente mais tempo para realiza√ß√£o. Possui fun√ß√µes como ggplot(), aes(), geom_*(), facet_*(), stats_*(), coord_*() e theme_*(), que s√£o conectadas pelo operador +. ggplot2 extentions: conjunto de pacotes que adicionam diversas expans√µes ao pacote ggplot2. Exemplos: gganimate, GGally e esquisse. visdat: Crie visualiza√ß√µes preliminares de dados explorat√≥rios de um conjunto de dados inteiro para identificar problemas ou recursos inesperados usando ‚Äòggplot2.‚Äô Possui diversas fun√ß√µes espec√≠ficas: vis_dat() - vis√£o geral dos dados, vis_miss() - vis√£o de dados faltantes (NA), vis_compare() - visualiza a diferen√ßa entre dados. ggpubr: pacote que fornece fun√ß√µes simplificadas para criar e personalizar gr√°ficos para publica√ß√£o baseados no ‚Äúggplot2.‚Äù Possui fun√ß√µes espec√≠ficas: gghistogram(), ggdensity(), ggboxplot(), ggviolin(), ggbarplot() e ggscatter(). pacthwork: pacote que permite combinar v√°rios gr√°ficos em um s√≥ de forma extremamente simples e com alta qualidade. plotly: pacote para criar gr√°ficos interativos da web por meio da biblioteca gr√°fica de JavaScript de c√≥digo aberto plotly.js. Tamb√©m possui fun√ß√µes espec√≠ficas: plot_ly(), add_histogram(), add_bars(), add_boxplot(), add_markers(), add_paths(), add_lines() e add_polygons(). 6.4 3. Gr√°matica dos gr√°ficos No livro A Gram√°tica do Gr√°fico, Leland Wilkinson (2005) utiliza uma analogia da lingu√≠stica para criar esta ‚Äúgram√°tica‚Äù para a visualiza√ß√£ gr√°fica. Segundo ele, a l√≠ngua se torna expressiva pelo fato da gram√°tica criar um sistema de regras que tornam as declara√ß√µes com significado conhecido. De maneira semelhante, a ideia da gram√°tica dos gr√°ficos cria regras para representa√ß√£o gr√°fica dos dados a partir de atributos est√©ticos (do ingl√™s aesthetic) como cor, forma e tamanho que definem a geometria dos objetos, como pontos, linhas e barras (Wickham 2009). Al√©m disso, esta gram√°tica reconhece que tais elementos podem ser organizados em camadas, tal como constru√≠mos um mapa com diferentes camadas como eleva√ß√£o, hidrografia, rodovias, limites pol√≠ticos, etc. Inspirado pela Gr√°matica do Gr√°fico proposta por Wilkinson, Hadley Wickham crious o pacote ggplot2, onde ‚Äúgg‚Äù representa a contra√ß√£o de Grammar of Graphics (Wickham 2009). As camadas nesta gram√°tica s√£o organizadas da seguinte forma: Camada 1 - dados brutos: as colunas da matriz s√£o usadas para guiar os dados usados nas diferentes camadas, em especial aes(), stat(), facet() e scale() Camada 2 - mapeamento: atributos est√©ticos, aes(), define quais colunas ser√£o associadas com qual eixo e determina o tamanho, forma, cor, preenchimento e transpar√™ncia dos atributos est√©ticos Camada 3 - transforma√ß√µes estat√≠sticas, stat(), modificam, quando necess√°rio, os dados que ser√£o inclu√≠dos no gr√°fico (ex. calculando a m√©dia por grupo) Camada 4 - defini√ß√£o da geometria, geom(): define o tipo de geometria que √© plotada no gr√°fico, como pontos, boxplots, violino, linhas, pol√≠gonos, entre outros Camada 5 - sistema de coordenadas (coordinate function): define o sistema de ccordenadas do gr√°fico e como o eixo Y e X se relacionam (padr√£o √© o sistema cartesiano). Camada 6 - facetas: especifica como a visualiza√ß√£o dos elementos aes() s√£o divididos em diferentes ‚Äújanelas gr√°ficas‚Äù Camada 7 - escala: permite o controle das caracter√≠sticas visuais (cor, forma e tamanho) dos elementos declarados em aes() Camada 8 - temas: controla a apar√™ncia visual dos elementos do gr√°fico Figura 6.1: Esquema gr√°fico ilustrando as camadas que definem a strutura de organiza√ß√£o aditiva da gram√°tica dos gr√°ficos (ggplot2). No exemplo, a partir de uma banco de dados, o mapeamento de quais colunas representam o eixo Y e X e de um atributo gr√°fico (pontos) √© poss√≠vel construir um gr√°fico de dispers√£o que ilustra a rela√ß√£o quantitativa entre a vari√°vel Y e X. Em resumo, o mapeamento gr√°fico do ggplot2 segue a seguinte estrutura: ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;( mapping = aes(&lt;MAPPINGS&gt;), stat = &lt;STAT&gt;, position = &lt;POSITION&gt; ) + &lt;COORDINATE_FUNCTION&gt; + &lt;FACET_FUNCTION&gt; + &lt;SCALE_FUNCTION&gt; + &lt;THEME_FUNCTION&gt; 6.5 4. Tipos de gr√°ficos Nesta se√ß√£o, listamos os principais gr√°ficos, e uma descri√ß√£o de quantas colunas e o tipo de vari√°vel que eles representam. Histograma (do ingl√™s histogram): distribui√ß√£o de frequ√™ncia de uma coluna para dados cont√≠nuos (cores diferentes podem representar esp√©cies, popula√ß√µes ou grupos distintos) Gr√°fico de densidade (density plot): distribui√ß√£o da densidade de uma coluna para dados cont√≠nuos (assim como no histograma, cores diferentes podem ser utilizadas para representar esp√©cies, popula√ß√µes ou grupos distintos) Gr√°fico de dispers√£o (scatter plot) e gr√°fico de linha: rela√ß√£o entre valores de duas colunas para dados cont√≠nuos (X e Y) Diagrama de pontos (dot plot): distribui√ß√£o da quantidade de valores agrupados de uma coluna para dados cont√≠nuos Gr√°fico de setores (pie chart e donut chart): representa√ß√£o da quantidade de valores de uma coluna para dados categ√≥ricos, geralmente em propor√ß√£o ou porcentagem Gr√°fico de barras (bar plot): representa√ß√£o da quantidade de valores de uma ou mais colunas para dados categ√≥ricos Gr√°fico de caixa (box plot e violin plot): distribui√ß√£o de valores cont√≠nuos de uma coluna (Y) para dois ou mais fatores categ√≥ricos de outra coluna (X) no formato de caixas e tamb√©m no formato de ‚Äúviolinos‚Äù (considerando a varia√ß√£o) Gr√°fico pareado (pairs plot): rela√ß√£o entre valores de duas colunas para dados cont√≠nuos (X e Y), para colunas par a par Para facilitar a compreens√£o das regras da gram√°tica dos dados, cada tipo de gr√°fico segue a mesma estrutura de organiza√ß√£o, que respeita as camadas de informa√ß√£o descritas anteriormente. O leitor vai perceber, portanto, que algumas camadas n√£o s√£o necess√°rias dependendo do tipo de gr√°fico e do conjunto de dados que pretende analisar. Nos exemplos, a vers√£o padr√£o se refere √† representa√ß√£o determinada no ‚Äúdefault‚Äù da fun√ß√£o. Deste modo, somente informamos as vari√°veis que ser√£o utilizadas dentro de cada camada e a forma geom√©trica (i.e., tipo de gr√°fico) desejada. Por√©m, para cada tipo gr√°fico apresentamos fun√ß√µes e argumentos para ajustes finos e personalizados. 6.5.1 4.1. Histograma (histogram) O histograma √© um gr√°fico extremamente popular e bastante √∫til para visualizar a distribui√ß√£o de vari√°veis cont√≠nuas. √â bem prov√°vel que voc√™ j√° tenha visto um histograma quando aprendeu pela primeira vez a famosa distribui√ß√£o normal. # histograma de uma variavel continua dist_normal &lt;- data.frame(x = rnorm(50000, mean = 100, sd = 5)) ggplot(data = dist_normal, aes(x = x)) + geom_histogram() Neste histograma √© poss√≠vel entender que a maioria dos valores da vari√°vel x no data.frame dist_normal est√£o pr√≥ximos ao valor da m√©dia, i.e., 100. Em ecologia, os histogramas s√£o utilizados para visualizar, por exemplo, a varia√ß√£o morfol√≥gica entre esp√©cies (subesp√©cies, g√™nero, fam√≠lias, etc.), varia√ß√£o de par√¢metros populacionais entre diferentes esp√©cies ou dentro da mesma esp√©cies em diferentes localidades. 6.5.1.1 4.1.1. Vers√£o padr√£o Vamos utilizar o conjunto de dados palmerpenguins para construir um histograma da distribui√ß√£o da vari√°vel flipper_length_mm com a fun√ß√£o geom_hitogram(). Esta fun√ß√£o utiliza uma vari√°vel cont√≠nua no eixo x e a frequ√™ncia de cada categoria no eixo y. O gr√°fico a seguir representa a frequ√™ncia de uma vari√°vel (neste caso, a medida de todos os pinguins, independente da esp√©cie). ggplot(data = penguins, aes(x = flipper_length_mm)) + geom_histogram() 6.5.1.2 4.1.2. Definindo o n√∫mero de classes Vamos utilizar o argumento bins para definir em quantas classes a vari√°vel x deve ser dividida. # histograma com 10 classes ggplot(data = penguins, aes(x = flipper_length_mm)) + geom_histogram(bins = 10) + labs(title = &quot;10 classes&quot;) # histograma com 30 classes ggplot(data = penguins, aes(x = flipper_length_mm)) + geom_histogram(bins = 30) + labs(title = &quot;30 classes&quot;) 6.5.1.3 4.1.3. Comparando m√∫ltiplas categorias Se quisermos comparar a distribui√ß√£o de uma vari√°vel cont√≠nua entre diferentes categorias, podemos utilizar o argumento fill para colorir o gr√°fico. No exemplo abaixo, utilizamos cores diferentes para ilustrar a distribui√ß√£o da vari√°vel x entre esp√©cies diferentes (fill = species). # histograma com cores para diferentes categorias com sobreposicao ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_histogram(alpha = .5) + ggtitle(&quot;Com sobreposi√ßao&quot;) # Histograma com cores para diferentes categorias sem sobreposi√ß√£o ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_histogram(position = &quot;dodge&quot;) + ggtitle(&quot;Sem sobreposi√ßao&quot;) 6.5.1.4 4.1.4. Ajustes finos (vers√£o personalizada) # Histogram example: flipper length by species penguins %&gt;% ggplot(aes(x = flipper_length_mm, fill = species)) + geom_histogram(alpha = .5, position = &quot;identity&quot;) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(x = &quot;Comprimento da nadadeira (mm)&quot;, y = &quot;Frequ√™ncia (%)&quot;, fill = &quot;Esp√©cies&quot;) 6.5.1.5 4.1.5. Principais camadas utilizadas na fun√ß√£o geom_histogram() aes(): Eixo X: vari√°vel cont√≠nua (flipper_length_mm) Preenchimento (fill): vari√°vel categ√≥rica (species) que define as cores tendo como base o n√∫mero de n√≠veis dentro desta categoria geom(): geom_histogram() Transpar√™ncia dos pontos (alpha): 0,5 (varia de 0, traspar√™ncia m√°xima, a 1, sem traspar√™ncia) Posi√ß√£o das barras: o argumento position define se as barras devem ser inseridas de maneira sobreposta (position = \"identity\") ou n√£o (position = \"dodge\") scale():scale_fill_manual() para definir manualmente as cores de prefer√™ncia do usu√°rio theme(): theme_bw()para selecionar o tema com fundo branco e labs() para personalizar o t√≠tulos dos eixos X e Y. 6.5.2 4.2 Gr√°fico de densidade (density plot) Nesta se√ß√£o iremos aprender a criar um gr√°fico de densidade no R utilizando o ggplot2. Assim como o histograma, o gr√°fico de densidade √© utilizado para visualizar a distribui√ß√£o de uma vari√°vel cont√≠nua em intervalos. Esse gr√°fico √© uma varia√ß√£o do Histograma (ver se√ß√£o ??) que utiliza Kernel Smoother e, al√©m de ser muito √∫til para visualizar distribui√ß√µes, pode ser usado para testar v√°rias hip√≥teses ecol√≥gicas, como descrito no Cap√≠tulo 14 (Diversidade Funcional). 6.5.2.1 4.2.1.Vers√£o padr√£o Vamos utilizar o conjunto de dados palmerpenguins, para plotar a distribui√ß√£o da vari√°vel flipper_length_mm em um Gr√°fico de densidade. Utilizaremos a fun√ß√£o geom_density() para plotar uma vari√°vel no eixo x. ggplot(data = penguins, aes(x = flipper_length_mm)) + geom_density() Al√©m da vers√£o de densidade em linha, √© poss√≠vel utilizar o argumento fill para definir a cor de preenchimento do gr√°fico e o argumento alpha para definir a transpar√™ncia do preenchimento. Utilizamos ainda o argumento color para definir a cor da linha. # Argumento fill ggplot(data = penguins, aes(x = flipper_length_mm)) + geom_density(fill = &quot;tomato&quot;) # Argumento fill, color e alpha ggplot(data = penguins, aes(x = flipper_length_mm)) + geom_density(fill = &quot;steelblue&quot;, color = &quot;black&quot;, alpha = .5) 6.5.2.2 4.2.2. Comparando m√∫ltiplas categorias Em algumas situa√ß√µes, queremos comparar a distribui√ß√£o de uma vari√°vel cont√≠nua entre diferentes categorias. Dessa forma, podemos utilizar o argumento fill para colorir o gr√°fico. No exemplo abaixo, utilizamos cores diferentes para ilustrar a distribui√ß√£o da vari√°vel x entre esp√©cies diferentes (fill = species). # O argumento fill preenche cada n√≠vel da coluna &quot;species&quot; (sem transpar√™ncia: alpha = 1) ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_density() + labs(title = &quot;Sem transpar√™ncia&quot;) # Gr√°fico de densidade com cores para diferentes categorias com sobreposicao ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_density(alpha = .5) + labs(title = &quot;Com transpar√™ncia&quot;) 6.5.2.3 4.2.3. Ajustes finos (vers√£o personalizada) ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_density(alpha = .5) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + scale_x_continuous(breaks = seq(from = 160, to = 240, by = 10), limits = c(160, 240)) + scale_y_continuous(breaks = seq(from = 0, to = .07, by = .01)) + theme_bw(base_size = 16) + labs(x = &quot;Comprimento da nadadeira (mm)&quot;, y = &quot;Frequ√™ncia&quot;, fill = &quot;Esp√©cie&quot;) 6.5.2.4 4.2.4. Principais camadas utilizadas na fun√ß√£o geom_density() aes(): Eixo X: vari√°vel cont√≠nua (flipper_length_mm) Preenchimento (fill): vari√°vel categ√≥rica (species) que define as cores tendo como base o n√∫mero de n√≠veis dentro desta categoria geom(): geom_density() Transpar√™ncia dos pontos (alpha): 0,5 (varia de 0, traspar√™ncia m√°xima, a 1, sem traspar√™ncia) Posi√ß√£o das barras: o argumento position() define se as barras devem ser inseridas de maneira sobreposta (position = \"identity\") ou n√£o (position = \"dodge\") scale(): scale_fill_manual() para definir manualmente as cores de prefer√™ncia do usu√°rio scale_x_continuous() e scale_y_continuous() determinam os limites (valor m√≠nimo e m√°ximo) para os dois eixos e, al√©m disso, os intervalos entre os valores (breaks) theme(): theme_bw()para selecionar o tema com fundo branco e labs() para personalizar o t√≠tulos dos eixos X e Y, e da legenda. 6.5.3 4.3. Diagrama de pontos (dot plot) Uma alternativa ao gr√°fico de densidade e histograma √© o diagrama de pontos (Dot plot), apesar de ser relativamente menos usado em ecologia. 6.5.3.1 4.3.1. Vers√£o padr√£o Vamos utilizar o conjunto de dados palmerpenguins para visualizar a distribui√ß√£o da vari√°vel flipper_length_mm com o diagrama de pontos com a fun√ß√£o geom_dotplot(). ggplot(data = penguins, aes(x = flipper_length_mm)) + geom_dotplot() 6.5.3.2 4.3.2. Comparando m√∫ltiplas categorias Assim como nas fun√ß√µes geom_histogram() e geom_density(), √© poss√≠vel comparar categorias na fun√ß√£o geom_dotplot() utilizando o argumento fill, bem como os argumentos color, alpha e dotsize. ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_dotplot(dotsize=1) ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_dotplot(dotsize=0.7, color = &quot;black&quot;, alpha = 0.5) 6.5.3.3 4.3.3. Ajustes finos (vers√£o personalizada) ggplot(data = penguins, aes(x = flipper_length_mm, fill = species)) + geom_dotplot(color = &quot;black&quot;, alpha = .7) + theme_bw(base_size = 16) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + scale_x_continuous(breaks = seq(from = 170, to = 240, by = 10), limits = c(170, 240)) + scale_y_continuous(breaks = seq(from = 0, to = 1.4, by = .2), limits = c(0, 1.4)) + labs(x = &quot;Comprimento da nadadeira (mm)&quot;, y = &quot;Frequ√™ncia&quot;, fill = &quot;Esp√©cies&quot;) Uma das limita√ß√µes do dotplot √© que a sobreposi√ß√£o dos pontos n√£o permite a visualiza√ß√£o apropriada desses valores sobrepostos entre diferentes grupos comparados. 6.5.3.4 4.3.4. Principais camadas utilizadas na fun√ß√£o geom_dotplot() aes(): Eixo X: vari√°vel cont√≠nua (flipper_length_mm) Preenchimento (fill): vari√°vel categ√≥rica (species) que define as cores tendo como base o n√∫mero de n√≠veis dentro desta categoria geom(): geom_dotplot() Transpar√™ncia dos pontos (alpha): 0,5 (varia de 0, traspar√™ncia m√°xima, a 1, sem traspar√™ncia) Cor da linha do ponto (color): valor padr√£o (se n√£o for especificado) √© black Tamanho dos pontos (dotsize): valor padr√£o (se n√£o for especificado) √© 1 Posi√ß√£o dos pontos: o argumento position define se as barras devem ser inseridas de maneira sobreposta (position = \"identity\") ou n√£o (position = \"dodge\") scale(): scale_fill_manual() para definir manualmente as cores de prefer√™ncia do usu√°rio scale_x_continuous() e scale_y_continuous() determinam os limites (valor m√≠nimo e m√°ximo) para os dois eixos e, al√©m disso, os intervalos entre os valores (breaks) theme(): theme_bw()para selecionar o tema com fundo branco e labs() para personalizar o t√≠tulos dos eixos X e Y, e da legenda. 6.5.4 4.4. Gr√°fico de barras (bar plot) O gr√°fico de barras √© um dos mais usados em artigos e livros da ecologia, uma vez que permite comparar valores absolutos ou m√©dios (combinados com alguma medida de varia√ß√£o como desvio padr√£o) de uma vari√°vel continua entre diferentes n√≠veis de uma vari√°vel categ√≥rica. 6.5.4.1 4.4.1. Vers√£o padr√£o O gr√°fico de barras utiliza ret√¢ngulos para representar uma vari√°vel cont√≠nua ou a contagem de uma vari√°vel categ√≥rica, sendo que o comprimeno dos ret√¢ngulos √© proporcional ao valor que ele representa. Por exemplo, √© poss√≠vel comparar qual a quantidade de indiv√≠duos medidos para cada esp√©cie de pinguim. # N√∫mero de indiv√≠duos coletados penguins_count &lt;- penguins %&gt;% dplyr::count(species) # grafico de barras ggplot(data = penguins_count, aes(x = species, y = n)) + geom_bar(stat = &quot;identity&quot;) Al√©m disso, √© poss√≠vel alterar as cores (color) e preenchimento (fill) das barras, bem como sua transpar√™ncia (alpha) e largura (width), como demonstrado nos pr√≥ximos quatro gr√°ficos.1 # modificando preenchimento ggplot(data = penguins_count, aes(x = species, y = n)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;steelblue&quot;) # Modificando cor e preenchimento ggplot(data = penguins_count, aes(x = species, y = n)) + geom_bar(stat = &quot;identity&quot;, color = &quot;steelblue&quot;, fill = &quot;white&quot;) # Modificando a largura da barra = 0.75 ggplot(data = penguins_count, aes(x = species, y = n)) + geom_bar(stat = &quot;identity&quot;, width = 0.75) + labs(title = &quot;largura = 0.75&quot;) # Modificando a largura da barra = 0.25 ggplot(data = penguins_count, aes(x = species, y = n)) + geom_bar(stat = &quot;identity&quot;, width = 0.25) + labs(title = &quot;largura = 0.25&quot;) Outra possibilidade para representa√ß√£o do gr√°fico de barras √© inverter a dire√ß√£o das barras com a fun√ß√£o coord_flip(). # Barras vertical ggplot(data = penguins_count, aes(x = species, y = n)) + geom_bar(stat = &quot;identity&quot;, width = 0.6) # Barras horizontal ggplot(data = penguins_count, aes(x = species, y = n)) + geom_bar(stat = &quot;identity&quot;, width = 0.6) + coord_flip() √â poss√≠vel utilizar vari√°veis categ√≥ricas para definir cores e preenchimento e ilustrar, por exemplo, tratamentos ou esp√©cies diferentes com os argumentos fill e color. # grafico de barras com preenchimento colorido ggplot(data = penguins_count, aes(x = species, y = n, fill = species)) + geom_bar(stat = &quot;identity&quot;) 6.5.4.2 4.4.2. Adicionando medidas de varia√ß√£o Em algumas compara√ß√µes, utilizar somente os valores absolutos pode n√£o ser a visualiza√ß√£o mais apropriadas como, por exemplo, em desenho de ANOVA (Cap√≠tulo 7). Desse modo, ao inv√©s do valor m√°ximo da barra representar o valor absoluto (e.g., n√∫mero de indiv√≠duos de uma esp√©cies), ele vai representar o valor m√©dio. Al√©m disso, linhas adicionais (chamadas barras de erro) v√£o representar alguma medida de varia√ß√£o como desvio padr√£o, erro padr√£o, intervalo de confian√ßa, entre outros. A fun√ß√£o Rmisc::summarySE() permite realizar esses c√°lculos de maneira simples, como demonstrado no exemplo abaixo. # Calculando m√©dia e desvio padr√£o por grupo penguins2 &lt;- penguins %&gt;% drop_na(flipper_length_mm) # remover valores ausentes na vari√°vel (NAs) penguins_mean &lt;- summarySE(penguins2, measurevar = &quot;flipper_length_mm&quot;, groupvars = &quot;species&quot;) head(penguins_mean) #&gt; species N flipper_length_mm sd se ci #&gt; 1 Adelie 151 189.9536 6.539457 0.5321735 1.051524 #&gt; 2 Chinstrap 68 195.8235 7.131894 0.8648692 1.726286 #&gt; 3 Gentoo 123 217.1870 6.484976 0.5847306 1.157533 # Gr√°fico de barras com desvio padr√£o ggplot(data = penguins_mean, aes(x = species, y = flipper_length_mm, fill = species)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.4) + geom_errorbar(aes(ymin = flipper_length_mm - sd, ymax = flipper_length_mm + sd), width = 0.1) + geom_point() + labs(title = &quot;Barra de erro com desvio padr√£o&quot;) # Gr√°fico de barras com intervalo de confi√¢n√ßa ggplot(data = penguins_mean, aes(x = species, y = flipper_length_mm, fill = species)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.4) + geom_errorbar(aes(ymin = flipper_length_mm - se, ymax = flipper_length_mm + se), width = 0.1) + geom_point() + labs(title = &quot;Barra de erro com erro padr√£o&quot;) 6.5.4.3 4.4.3. Ajustes finos (vers√£o personalizada) ggplot(data = penguins_count, aes(x = species, y = n, fill = species)) + geom_bar(stat = &quot;identity&quot;) + geom_label(aes(label = n), fill = &quot;white&quot;) + theme_bw(base_size = 16) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + labs(x = &quot;Esp√©cie&quot;, y = &quot;N√∫mero de indiv√≠duos&quot;, fill = &quot;Esp√©cie&quot;) 6.5.5 4.5. Gr√°fico de setores (pie chart e donut chart) Al√©m do gr√°fico de barras, o gr√°fico de setores representa uma alternativa para comparar a propor√ß√£o entre categorias. Tais gr√°ficos podem ser representados como pie charts ou donut charts, como demonstrado abaixo. No exemplo abaixo, utilizamos a mesma compara√ß√£o realizada no item 4.3.3 acima. Por√©m, os valores de contagem (n√∫mero de indiv√≠duos por esp√©cie) devem ser transformados previamente em propor√ß√£o. 6.5.5.1 4.5.1. Gr√°fico de setores (pie chart) # C√°lculo da propor√ß√£o penguins_prop &lt;- penguins %&gt;% dplyr::count(species) %&gt;% dplyr::mutate(prop = round(n/sum(n), 4)*100) # Pie chart ggplot(data = penguins_prop, aes(x = &quot;&quot;, y = prop, fill = species)) + geom_bar(stat = &quot;identity&quot;, color = &quot;white&quot;) + coord_polar(&quot;y&quot;, start = 0) + geom_text(aes(label = paste0(prop, &quot;%&quot;)), color = &quot;white&quot;, position = position_stack(vjust = 0.5), size = 8) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_void() + labs(fill = &quot;Esp√©cie&quot;) 6.5.5.2 4.5.2. Gr√°fico de setores (donut chart) ggplot(data = penguins_prop, aes(x = 2, y = prop, fill = species)) + geom_bar(stat = &quot;identity&quot;) + coord_polar(theta = &quot;y&quot;, start = 0) + geom_text(aes(label = paste0(prop, &quot;%&quot;)), color = &quot;white&quot;, position = position_stack(vjust = .5), size = 5) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + xlim(0, 2.5) + theme_void() + theme(legend.position = c(.5, .5), legend.title = element_text(size = 20), legend.text = element_text(size = 15)) + labs(fill = &quot;Esp√©cie&quot;) 6.5.5.3 4.5.3. Comparando gr√°ficos de setores com gr√°fico de barras O mesmo conjunto de dados pode ser visualizado de diferentes formas. N√£o diferente, a compara√ß√£o da propor√ß√£o de ocorr√™ncias de diferentes categorias pode ser feita de v√°rias maneiras. Abaixo, fizemos a compara√ß√£o da propor√ß√£o de indiv√≠duos por cada uma das tr√™s esp√©cies dos dados penguins. ggplot(data = penguins_prop, aes(x = &quot;&quot;, y = prop, fill = species)) + geom_bar(stat = &quot;identity&quot;, color = &quot;white&quot;) + coord_polar(&quot;y&quot;, start = 0) + geom_text(aes(label = paste0(prop, &quot;%&quot;)), color = &quot;white&quot;, position = position_stack(vjust = 0.5), size = 3) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_void() + labs(title = &quot;Pie chart&quot;, fill = &quot;Esp√©cies&quot;) -&gt; g_pie ggplot(data = penguins_prop, aes(x = 2, y = prop, fill = species)) + geom_bar(stat = &quot;identity&quot;) + coord_polar(theta = &quot;y&quot;, start = 0) + geom_text(aes(label = paste0(prop, &quot;%&quot;)), color = &quot;white&quot;, position = position_stack(vjust = .5), size =3) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + xlim(0, 2.5) + theme_void() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Donut chart&quot;, fill = &quot;Esp√©cies&quot;) -&gt; g_donut ggplot(data = penguins_prop, aes(x = species, y = prop, fill = species)) + geom_bar(stat = &quot;identity&quot;) + geom_label(aes(label = prop), fill = &quot;white&quot;) + theme_bw() + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + labs(title = &quot;Gr√°fico de Barras (Horizonal)&quot;, x = &quot;Esp√©cies&quot;, y = &quot;N√∫mero de indiv√≠duos&quot;, fill = &quot;Esp√©cies&quot;)+ theme(legend.position = &quot;none&quot;)-&gt; g_bar_h ggplot(data = penguins_prop, aes(x = species, y = prop, fill = species)) + geom_bar(stat = &quot;identity&quot;) + geom_label(aes(label = prop), fill = &quot;white&quot;) + theme_bw() + coord_flip()+ scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + labs(title = &quot;Gr√°fico de Barras (Vertical)&quot;, x = &quot;Esp√©cies&quot;, y = &quot;N√∫mero de indiv√≠duos&quot;, fill = &quot;Esp√©cies&quot;) + theme(legend.position = &quot;none&quot;)-&gt; g_bar_v grid.arrange(g_pie, g_donut, g_bar_h, g_bar_v, nrow=2) 6.5.5.4 4.5.4. Principais camadas utilizadas no gr√°fico de barras e de setores: geom_bar() aes(): Eixo X: vari√°vel categ√≥rica (species) Eixo Y: vari√°vel cont√≠nua (flipper_length_mm) Preenchimento (fill): a vari√°vel categ√≥rica (species) define a cor do preenchimento e os n√≠veis dentro desta categoria determinam o n√∫mero de cores que devem ser indicadas no scale_fill_manual(). geom(): geom_bar() Transpar√™ncia das barras (alpha): 0,4 (varia de 0, traspar√™ncia m√°xima, a 1, sem traspar√™ncia) stat: √© necess√°rio usar o argumento ‚Äúidentity‚Äù quando os valores do eixo Y s√£o adicionados pelo usu√°rio geom_label() forma geom√©trica que adiciona r√≥tulo dos valores absolutos das barras por categoria (species) geom_errorbar() ymine ymaxdelimitam os valores m√≠nimos e m√°ximos, respectivamente, das barras de erro. Tais valores s√£o representados pelo valor da m√©dia menos (no caso do ymin) ou mais (no caso do ymax) o valor do intervalo de confian√ßa, desvio ou erro padr√£o. coord_polar(): sistema de coordenadas para gerar barras circulares sobrepostas (stacked) que s√£o usadas nos gr√°ficos de setores (pie chart e donut chart) o argumento start = 0 indica o local de in√≠cio do gr√°fico que, neste caso, come√ßa na ‚Äúhora‚Äù 0 em um ‚Äúrel√≥gio‚Äù de 12 horas. scale(): scale_fill_manual() para definir manualmente as cores de prefer√™ncia do usu√°rio theme(): theme_bw()para selecionar o tema com fundo branco e labs() para personalizar o t√≠tulos dos eixos X e Y, e da legenda. 6.5.6 4.6. Gr√°fico de caixa (boxplot) O boxplot, conhecido amplamente nos artigos e livros de ecologia, √© uma visualiza√ß√£o gr√°fica que sintetiza informa√ß√µes importantes de dados cont√≠nuos como mediana e varia√ß√£o (quartil 1-3, ver Figura 2). Figura 6.2: Estrutura e elementos do boxplot 6.5.6.1 4.6.1. Vers√£o padr√£o Vamos plotar uma vari√°vel cont√≠nua (flipper_length_mm) no eixo y em fun√ß√£o de uma vari√°vel categ√≥rica no eixo x (species). A defini√ß√£o de qual coluna do banco de dados √© a x e qual √© a y √© feita dentro do comendo aes(). ggplot(penguins, aes(y = flipper_length_mm, x = species)) + geom_boxplot() √â poss√≠vel destacar os pontos referentes aos outliers (se houver) com o argumento outlier.color. Caso tenha interesse, √© poss√≠vel tamb√©m remover os outliers do gr√°fico. ggplot(penguins, aes(y = flipper_length_mm, x = species)) + geom_boxplot(outlier.color = &quot;red&quot;)+ labs(title = &quot;outliers vermelhos&quot;) ggplot(penguins, aes(y = flipper_length_mm, x = species)) + geom_boxplot(outlier.shape = NA)+ labs(title = &quot;outliers removidos&quot;) Outra alternativa para os gr√°ficos do tipo boxplot √© utilizar o argumento notch = TRUE para produzir diagramas de caixa entalhados (notched). Estes diagramas s√£o √∫teis para inferir de forma aproximada se exite diferen√ßa significativa entre as medias dos grupos. ggplot(penguins, aes(y = flipper_length_mm, x = species)) + geom_boxplot(notch = TRUE) 6.5.6.2 4.6.2. Comparando m√∫ltiplas categorias No exemplo abaixo, utilizamos cores diferentes para ilustrar esp√©cies diferentes atrav√©s do argumento fill = species. ggplot(penguins, aes(y = flipper_length_mm, x = species, fill = species)) + geom_boxplot() 6.5.6.3 4.6.3. Combinando boxplot com pontos (jitter) Podemos ainda acrescentar pontos para mostrar a distribui√ß√£o dos dados. # boxplot com jitters ggplot(penguins, aes(y = flipper_length_mm, x = species, fill = species)) + geom_boxplot() + geom_jitter(size = .6, width = .2) 6.5.6.4 4.6.4. Gr√°fico de violino (violin plot) como alternativa ao boxplot Al√©m das caixas, podemos utilizar o formato de ‚Äúviolino‚Äù para representar a varia√ß√£o de dados cont√≠nuos entre categorias. A informa√ß√£o adicional ao boxplot que o gr√°fico de violino permite visualizar √© a densidade dos pontos, assim como apresentamos acima no gr√°fico de densidades geom_density(). A diferen√ßa √© que a densidade √© espelhada e, desse modo, podemos visualizar os intervalores dos dados com maior ou menor concentra√ß√£o de valores. # violino com jitters ggplot(penguins, aes(y = flipper_length_mm, x = species, fill = species)) + geom_violin() + geom_jitter(size = .6, width = .2) √â poss√≠vel tamb√©m combinar boxplot e gr√°fico de violino em um √∫nico gr√°fico. # violino com boxplot ggplot(penguins, aes(y = flipper_length_mm, x = species, fill = species)) + geom_violin() + geom_boxplot(width = 0.1, fill = &quot;grey&quot;) 6.5.6.5 4.6.5. Ajustes finos (vers√£o personalizada) ### geom_boxplot() ggplot(data = penguins, aes(x = species, y = flipper_length_mm, fill = species)) + geom_boxplot(width = .3, show.legend = FALSE) + geom_jitter(alpha = .5, show.legend = FALSE, position = position_jitter(width = .1, seed = 0)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;) # geom_violin() ggplot(data = penguins, aes(x = species, y = flipper_length_mm, fill = species)) + geom_violin(width = .3, show.legend = FALSE) + geom_point(alpha = .5, show.legend = FALSE) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;Pontos sem jitter&quot;, x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;) # geom_violin() ggplot(data = penguins, aes(x = species, y = flipper_length_mm, fill = species)) + geom_violin(width = .3, show.legend = FALSE) + geom_jitter(alpha = .5, show.legend = FALSE, position = position_jitter(width = .1, seed = 0)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;Pontos com jitter&quot;,, x = &quot;Species&quot;, y = &quot;Flipper length (mm)&quot;) 6.5.6.6 4.6.6. Principais camadas utilizadas no geom_boxplot()e geom_violin() aes(): Eixo X: vari√°vel categ√≥rica (species) Eixo Y: vari√°vel cont√≠nua (flipper_length_mm) Preenchimento (fill): a vari√°vel categ√≥rica (species) define a cor do preenchimento e os n√≠veis dentro desta categoria determinam o n√∫mero de cores que devem ser indicadas no scale_fill_manual(). geom(): geom_boxplot() width: largura das barras (valor padr√£o: width = 1) fill: pode definir uma cor padr√£o (caso n√£o tenha utilizado o fill dentro do argumento aes()) como fill = \"grey\" notch: a escolha padr√£o da fun√ß√£o geom_boxplot() √© notch = FALSE; para utilizar a caixa entalhada o argumento deve ser notch = TRUE geom_violin() assim como nas outras formas geom√©tricas, √© poss√≠vel controlar largura, cor, preenchimento e transpar√™ncias dos violinos geom_jitter() esta fun√ß√£o basicamente ‚Äúagita‚Äù aleat√≥riamente os pontos para evitar a sobreposi√ß√£o de valores id√™nticos. Esta fun√ß√£o produz a mesma representa√ß√£o se usar a fun√ß√£o geom_point(position = \"jitter\") scale(): scale_fill_manual() para definir manualmente as cores de prefer√™ncia do usu√°rio theme(): theme_bw()para selecionar o tema com fundo branco e labs() para personalizar o t√≠tulos dos eixos X e Y, e da legenda. 6.6 4.7. Gr√°fico de dispers√£o (scatter plot) O gr√°fico de dispers√£o (em ingl~es, scatterplot) √© famoso na ecologia por ser a visualiza√ß√£o preferida para prepresentar a rela√ß√£o entre √°rea e riqueza de esp√©cies. Neste gr√°fico, os eixos X e Y s√£o representados por vari√°veis cont√≠nuas. Em especial, os gr√°ficos de dispers√£o s√£o usados para representar os resultados testados por an√°lises estat√≠sticas como regress√£o linear, ancova, mantel, PCA, PCoA, entre outros (Cap√≠tulos 7-14, ). 6.6.1 4.7.1. Vers√£o padr√£o ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point() 6.6.2 4.7.2. Definindo a cor, tamanho, forma e preenchimento dos pontos # Cor e tamanho dos pontos ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(color = &quot;royalblue&quot;, size = 3)+ labs(title = &quot;Sem transpar√™ncia&quot;) # Cor e tamanho dos pontos ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(color = &quot;red&quot;, size = 4, alpha = 0.5)+ labs(title = &quot;Com transpar√™ncia&quot;) A forma dos pontos permite dois controles importantes: a forma em si (s√≠mbolos como c√≠rculo, quadrado, etc.) e a possibilidade de preenchimento da forma. A figura a seguir discrimina esses s√≠mbolos e o valor que deve ser utilizado para desenhar a forma preferida. √â importante notar que os s√≠mbolos 21 a 25 possuem dois argumentos: (i) cor (que, na verdade, √© a cor da linha do s√≠mbolo) e (ii) fill (cor que define o preenchimento do s√≠mbolo). O tipo de s√≠mbolo √© definido pelo argumento shape. Figura 6.3: Figura 3. Tipos de s√≠mbolos dispon√≠veis. Assim, √© poss√≠vel controlar cores, formas e preenchimento combinado os argumentos shape, fille colorcom a fun√ß√£o scale_manual(). √â importante notar que para os s√≠mbolos entre 15 e 20 s√≥ podemos controlar o argumento cor, enquanto os s√≠mbolos entre 21 e 25 podemos controlar a cor e o preenchimento. # shape = 1 e size = 2 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(shape = 1, size = 2) # shape = 19 (s√≠mbolo padr√£o da fun√ß√£o) e size = 3 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_point(shape = 19, size = 3) # shape = 21 e size = 4 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, fill = species)) + geom_point(shape = 21, size = 4, color = &quot;black&quot;) 6.6.3 4.7.3. Definindo linhas de ajuste Quando usamos modelos estat√≠sticos como, por exemplo, lm(), glm(), gam(), entre outros, podemos utilizar os valores preditos para demonstrar a rela√ß√£o entre as vari√°veis X e Y. No ggplot2 a fun√ß√£o geom_smooth() faz esse ajuste com certa simplicidade. Al√©m disso, incluir a cor da esp√©cie dentro do aes() essa informa√ß√£o √© herdada para as pr√≥ximas camadas. Neste caso, uma regress√£o linear √© plotada para o subconjunto de dados que representa cada esp√©cie. # shape = 21 e size = 4 ggplot(penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) + geom_point(size = 4, alpha = .5)+ geom_smooth(method= lm) 6.6.4 4.7.4. Ajustes finos (vers√£o personalizada) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;) Al√©m disso, podemos relacionar dados n√£o t√£o usuais. Recomendamos a leitura do artigo de Matejka &amp; Fitzmaurice (2017) que apresenta as armadilhas t√≠picas que dados podem gerar quando evitamos de visualiz√°-los previmamente. # data + plot datasaurus_dozen %&gt;% dplyr::filter(dataset == &quot;dino&quot;) %&gt;% ggplot() + aes(x = x, y = y) + geom_point(colour = &quot;black&quot;, fill = &quot;black&quot;, size = 5, alpha = .75, pch = 21) + theme_bw() + theme(axis.title = element_text(size = 24), axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20)) 6.7 4.8. Visualiza√ß√£o de m√∫ltiplos gr√°ficos pareados Muitas vezes precisamos compreender a correla√ß√£o entre m√∫ltiplas vari√°veis, sendo comuum que essas vari√°veis sejam de mais de um tipo (cont√≠nua, categ√≥rica, etc). A solu√ß√£o mais indicada para termos uma vis√£o geral do conjunto de dados e de suas interrela√ß√µes √© o gr√°fico generalizado pareado (Emerson et al. 2013). 6.7.1 4.8.1. Gr√°fico pareado com vari√°veis cont√≠nuas A fun√ß√£o ggpairs()do pacote GGally permite criar m√∫ltiplos gr√°ficos pareados comparando as vari√°veis cont√≠nuas no seu conjunto de dados. Al√©m de plotar gr√°ficos de dispers√£o de cada par de vari√°veis, ela apresenta gr√°ficos de densidade de cada vari√°vel individualmente e, al√©m disso, os valores de correla√ß√£o entre os pares analisados com ou sem uma potencial vari√°vel categ√≥rica (neste caso, species) penguins %&gt;% dplyr::select(body_mass_g, ends_with(&quot;_mm&quot;)) %&gt;% GGally::ggpairs(aes(color = penguins$species)) + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw() 6.7.2 4.8.2. Gr√°fico pareado com v√°rios tipos de vari√°veis Como alternativa, a fun√ß√£o ggpairs() permite tamb√©m incluir vari√°veis categ√≥ricas nas compara√ß√µes. Neste caso, ela reconhece o tipo de gr√°fico (boxplot, dispers√£o, etc‚Ä¶) a partir da classe das vari√°veis. penguins %&gt;% dplyr::select(species, sex, body_mass_g, ends_with(&quot;_mm&quot;)) %&gt;% GGally::ggpairs(aes(color = species)) + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw() 6.8 5. Erros comuns dos usu√°rios do ggplot2 e como evit√°-los Abaixo, apresentamos uma lista n√£o exaustiva dos erros mais comuns que cometemos (e vimos muitos usu√°rios cometerem) ao fazer gr√°ficos no ggplot2: Utilizar ajuste manual nas fun√ß√µes scale_shape_manual(), scale_color_manual() ou scale_fill_manual() sem indicar no argumento aes() as vari√°veis que devem definir cada um desses elementos gr√°ficos. Definir a cor ou preenchimento de um geom dentro do aes() global (ggplot(aes(color = \"black¬®)) quando no fundo essa defini√ß√£o deveria ser dento do geom (geom_point(color = \"black\"). Utilizar ajuste manual na fun√ß√£o scale_size_manual() indicando uma vari√°vel categ√≥rica ao inv√©s de num√©rica. N√∫mero de cores indicadas como valores no scale_fill_manual() ou scale_color_manual(): ao definir as cores de maneira personalizada (ou seja, n√£o usando o padr√£o da fun√ß√£o) √© muito comum utilizarmos o n√∫mero de cores usados por algum tutorial ou livro. Com frequ√™ncia, o exemplo seguido e seus dados n√£o possuem o mesmo n√∫mero de cores. Deste modo, voc√™ pode usar comando no R para ajudar a quantificar o n√∫mero de cores necess√°rias. Por exemplo, para os dados penguins, o comando a seguir indica o n√∫mero de cores necess√°rias: length(levels(penguins$species)). Assim, ser√° necess√°rio indicar tr√™s cores diferentes dentro da fun√ß√£o scale_(). Fun√ß√£o geom_smooth(): como falado acima, a fun√ß√£o geom_smooth() √© muito √∫til (e simples) para gerar as linhas de ajuste (best fit) t√≠picas de modelos lineares e n√£o lineares. Por√©m, fique alerta que ao usar, por exemplo, geom_smooth(method = lm), o modelo linear utilizado para testar sua predi√ß√£o foi o lm(). Se tiver utilizado glm()ou gam() o ajuste deve ser produzido a partir desses modelos. Uso incorreto da classe das vari√°veis: neste caso, o usu√°rio utilizar uma vari√°vel num√©rica (por exemplo, 1, 2 e 3) como vari√°vel categ√≥rica. Neste caso, √© preciso transformar a vari√°vel num√©rica em vari√°vel categ√≥ricas (antes de fazer o ggplot2 ou dentro do aes()). Veja exemplos abaixo: penguins %&gt;% ggplot(aes(x = year, y = bill_length_mm))+ geom_boxplot() + theme_bw()+ labs(title = &quot;Figura incorreta&quot;) penguins %&gt;% ggplot(aes(x = factor(year), y = bill_length_mm))+ geom_boxplot() + theme_bw()+ labs(title = &quot;Figura correta com transforma√ß√£o interna&quot;) penguins %&gt;% mutate(year_f = as.factor(year)) %&gt;% ggplot(aes(x = year_f, y = bill_length_mm))+ geom_boxplot() + theme_bw()+ labs(title = &quot;Figura correta com transforma√ß√£o pr√©via&quot;) 6.9 6. Finaliza√ß√£o de gr√°ficos para publica√ß√£o 6.9.1 6.1. Posi√ß√£o, cores e fonte da legenda √â poss√≠vel controlar a posi√ß√£o, cores e fonte da legenda em diversos locais com alguns argumentos dentro da fun√ß√£o theme(): legend.positioncontrola a posi√ß√£o na √°rea do gr√°fico: top, right, bottom, left ou none. Al√©m disso, √© poss√≠vel inserir a legenda internamente no gr√°fico indicando as posi√ß√µes nos eixos X e Y legend.boxdetermina as caracter√≠scas do ret√¢ngulo onde a legenda √© inserida: legend.box.background (combinado com element_rect()) e legend.box.margin (combinado com margin()) legend.text controla a cor e tamanho da legenda (as duas informa√ß√µes devem ser inseridas dentro da fun√ß√£o element_text()) legend.title personaliza a cor e tamanho da legenda tamb√©m dentro da fun√ß√£o element_text() ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;Legenda acima do gr√°fico&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;) + theme(legend.position = &quot;top&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;Legenda abaixo do gr√°fico&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;)+ theme(legend.position = &quot;bottom&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;Sem legenda&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;)+ theme(legend.position = &quot;none&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;Legenda personalizada&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;)+ theme(legend.position = &quot;right&quot;, legend.text = element_text(size = 14, colour = &quot;red&quot;), legend.title = element_text(face = &quot;bold&quot;), legend.box.background = element_rect(color=&quot;red&quot;, size=2), legend.margin = margin(6, 6, 6, 6)) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;Legenda interna&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;)+ theme(legend.position = c(0.1, 0.1), legend.title = element_blank(), legend.key = element_blank(), legend.background = element_blank(), legend.text = element_text(size = 12, face = &quot;bold&quot;)) 6.9.2 6.2. Elementos gr√°ficos: eixo, fonte, grid O gr√°fico padronizado (sem edi√ß√£o extra) geralmente n√£o traz elementos m√≠nimos para publica√ß√£o em revistas, livros e peri√≥dicos. Al√©m do controle da posi√ß√£o, cor e tamanho da legenda, √© fundamental personalizar os seguintes elementos: eixo, fonte e grid. Eixos Varia√ß√£o: define limites m√≠nimos e m√°ximos para os eixos X (xlim()) e Y (ylim()) Intervalo: define o valor intervalo entre os n√∫meros dos eixos X e Y Escala ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + ylim(0, 22) + xlim(0, 60) + labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + scale_x_continuous(limits = c(20, 60), breaks = seq(20, 60, 2))+ labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + scale_x_continuous(limits = c(20, 60), breaks = seq(20, 60, 10))+ labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) Fonte dos eixos X e Y Tipo Tamanho Cor Face (it√°lico, negrito, etc.) √Çngulo ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + theme(axis.title.x = element_text(face = &quot;bold&quot;, size = 20, colour = &quot;royalblue&quot;), axis.text.x = element_text(size = 14), axis.title.y = element_text(face = &quot;bold&quot;, size = 20, colour = &quot;royalblue&quot;), axis.text.y = element_text(size = 14))+ labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + scale_x_continuous(limits = c(20, 60), breaks = seq(20, 60, 2))+ theme(axis.title.x = element_text(face = &quot;bold&quot;, size = 20, colour = &quot;royalblue&quot;), axis.text.x = element_text(size = 14, angle = 45), axis.title.y = element_text(face = &quot;bold&quot;, size = 20, colour = &quot;royalblue&quot;), axis.text.y = element_text(size = 14))+ labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) Grid Linhas de grade principais (panel.grid.major) Linhas de grade secund√°rias (panel.grid.minor) Borda do gr√°fico (panel.border) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + scale_x_continuous(limits = c(30, 60), breaks = seq(30, 60, 5))+ theme(axis.title.x = element_text(face = &quot;bold&quot;, size = 16), axis.text.x = element_text(size = 12), axis.title.y = element_text(face = &quot;bold&quot;, size = 16), axis.text.y = element_text(size = 12), panel.grid.minor = element_blank())+ labs(title=&quot;Linhas de grade principais&quot;, x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + scale_x_continuous(limits = c(30, 60), breaks = seq(30, 60, 5))+ theme(axis.title.x = element_text(face = &quot;bold&quot;, size = 16), axis.text.x = element_text(size = 12), axis.title.y = element_text(face = &quot;bold&quot;, size = 16), axis.text.y = element_text(size = 12), panel.grid.minor = element_blank(), panel.grid.major = element_blank())+ labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + scale_x_continuous(limits = c(30, 60), breaks = seq(30, 60, 5))+ theme(axis.title.x = element_text(face = &quot;bold&quot;, size = 16), axis.text.x = element_text(size = 12), axis.title.y = element_text(face = &quot;bold&quot;, size = 16), axis.text.y = element_text(size = 12), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.border = element_rect(size = 2, colour = &quot;black&quot;, fill = NA))+ labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 4, alpha = 0.5) + scale_x_continuous(limits = c(30, 60), breaks = seq(30, 60, 5))+ theme(axis.title.x = element_text(face = &quot;bold&quot;, size = 16), axis.text.x = element_text(size = 12), axis.title.y = element_text(face = &quot;bold&quot;, size = 16), axis.text.y = element_text(size = 12), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), axis.line = element_line(size = 1))+ labs(x = &quot;Eixo X&quot;, y = &quot;Eixo Y&quot;) 6.9.3 6.3. Temas personalizados ggtheme() Existem v√°rios temas criados dentro do universo ggtheme() que podem facilitar Existem v√°rios temas criados dentro do universo ggtheme() que podem facilitar a escolha de um modelo com √≥tima qualidade para publica√ß√£o. Abaixo, demonstramos os modelos mais utilizados. ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_gray(base_size = 16) + labs(title = &quot;theme_gray()&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_bw(base_size = 16) + labs(title = &quot;theme_bw()&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;) ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + theme_classic(base_size = 16) + labs(title = &quot;theme_classic()&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;) 6.9.4 6.4. Criando seu pr√≥prio theme_custom() Por fim, √© poss√≠vel criar um tema personalizado como uma fun√ß√£o dentro do R. Assim, o usu√°rio pode controlar todos os elementos gr√°ficos em um √∫nico comando. O maior benef√≠cio de personalizar uma fun√ß√£o √© que n√£o ser√° necess√°rios fazer os ajustes finos em todos os gr√°ficos que tiver construindo, o que pode representar grande economia de tempo. Esse tipo de padroniza√ß√£o √© fundamental para que todos os gr√°ficos de um artigo tenham consit√™ncia e harmonia est√©tica. theme_book &lt;- function(){ # escolha uma fonte font &lt;- &quot;Times&quot; # digite names(pdfFonts()) no console do R para ver a lista theme( # Defina elementos do grid panel.grid.major = element_line(colour = &quot;#d3d3d3&quot;), panel.grid.minor = element_blank(), axis.ticks = element_blank(), panel.border = element_rect(colour = &quot;black&quot;, fill = NA, size = .5), # Defina elementos textuais plot.title = element_text( # t√≠tulo family = font, #set font family size = 20, #set font size face = &#39;bold&#39;, #bold typeface hjust = 0, #left align vjust = 2), #raise slightly plot.subtitle = element_text( #subtitle family = font, #font family size = 14), #font size plot.caption = element_text( #caption family = font, #font family size = 14, #font size hjust = 1), #right align axis.title = element_text( #axis titles family = font, #font family size = 14), #font size axis.text = element_text( #axis text family = font, #axis famuly size = 14), #font size axis.text.x = element_text( #margin for axis text margin=margin(5, b = 10)) #since the legend often requires manual tweaking #based on plot content, don&#39;t define it here ) } ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + labs(title = &quot;Tema personalizado&quot;, x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;) + theme_book() 6.9.5 6.5. Exportando dados com alta qualidade com a fun√ß√£o ggsave() O √∫ltimo passo para construir gr√°ficos com qualidade de publica√ß√£o √© exportar em um formato espec√≠fico, como png, pdf ou svg (entre outros). A fun√ß√£o ggsave() n√£o s√≥ permite que voc√™ tenha o controle sobre o formato, mas tamb√©m sobre a qualidade e tamanho desejados com os seguintes argumentos: width = largura do gr√°fico height = altura do gr√°fico units = a unidade (cm, mm) que do gr√°fico para definir largura e tamanho dpi = qualidade da imagem (padr√£o = 300) g1 &lt;- ggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, color = species, shape = species)) + geom_point(size = 3, alpha = 0.8) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_shape_manual(values = c(19, 15, 17))+ scale_color_manual(values = c(&quot;darkorange&quot;, &quot;purple&quot;, &quot;cyan4&quot;)) + labs(x = &quot;Comprimento do bico (mm)&quot;, y = &quot;Profundidade do bico (mm)&quot;, color = &quot;Esp√©cies&quot;, shape = &quot;Esp√©cies&quot;) + theme(legend.position = c(0.1, 0.1), legend.title = element_blank(), legend.key = element_blank(), legend.background = element_blank())+ theme_book() g1 ggsave(&quot;g1.pdf&quot;, g1, width = 15, height = 15, dpi =300, units = &quot;cm&quot;) ggsave(&quot;g1.png&quot;, g1, width = 15, height = 15, dpi =300, units = &quot;cm&quot;) ggsave(&quot;g1.svg&quot;, g1, width = 15, height = 15, dpi =300, units = &quot;cm&quot;) 6.10 Check-list para garantir bons gr√°ficos Os eixos (Y e X) est√£o nomeados correatmente? As unidades de ambos os eixos (Y e X) est√£o indicadas corretamente? O tamanho da fonte dos eixos est√° adequado? A escala e os intervalos dos eixos est√£o corretos? O gr√°fico est√° proporcional (sem distor√ß√µes: achatado em algum dos eixo)? As cores utilizadas possuem uma l√≥gica clara e agregam valor na compreens√£o e interpreta√ß√£o do gr√°fico? Pare por um minuto e avalie se a mensagem principal do gr√°fico est√° clara. 6.11 Para se aprofundar 6.11.1 Livros Chang W. 2018. R Graphics Cookbook. [http://www.cookbook-r.com/Graphs/] Healy K. 2019. Data Visualization: a practical introduction. Princeton University Press. [https://socviz.co/¬¥] Kabacoff R. 2020. Data Visualization with R. [https://rkabacoff.github.io/datavis/] Rahlf T. 2019. Data Visualisation with R: 111 Examples. 2ed. Springer. [http://www.datavisualisation-r.com/] Sievert C. 2019. Interactive web-based data visualization with R, plotly, and shiny. Chapman &amp; Hall/CRC. [https://plotly-r.com/] Wickham H. 2016. ggplot2: elegant graphics for data analysis. Springer. [https://ggplot2-book.org/] Wilke C O. 2019. Fundamentals of Data Visualization. O‚ÄôReilly Media. [https://clauswilke.com/dataviz/] Wilkinson L, Wills D, Rope D, Norton A, Dubbs R. 2005. The Grammar of Graphics. Springer. 6.11.2 Links The R Graph Gallery From Data to Viz Data Viz Project Color Brewer2 "],["cap7.html", "Cap√≠tulo 7 Modelos lineares 7.1 Teste T (de Student) para duas amostras independentes 7.2 Teste T para amostras pareadas 7.3 Correla√ß√£o de Pearson 7.4 Regress√£o Linear Simples 7.5 Regress√£o Linear M√∫ltipla 7.6 An√°lises de Vari√¢ncia (ANOVA) 7.7 ANOVA de um fator 7.8 ANOVA com dois fatores ou ANOVA fatorial 7.9 ANOVA em blocos aleatorizados 7.10 An√°lise de covari√¢ncia (ANCOVA)", " Cap√≠tulo 7 Modelos lineares Pr√©-requisitos do cap√≠tulo ## Pacotes library(ecodados) library(car) library(ggplot2) library(&quot;ggpubr&quot;) library(ggforce) library(lsmeans) library(lmtest) library(sjPlot) ## Dados necess√°rios CRC_PN_macho &lt;- ecodados::teste_t_var_igual CRC_LP_femea &lt;- ecodados::teste_t_var_diferente Pareado &lt;- ecodados::teste_t_pareado correlacao_arbustos &lt;- ecodados::correlacao dados_regressao &lt;- ecodados::regressoes dados_regressao_mul &lt;- ecodados::regressoes dados_anova_simples &lt;- ecodados::anova_simples dados_dois_fatores &lt;- ecodados::anova_dois_fatores dados_dois_fatores_interacao &lt;- ecodados::anova_dois_fatores dados_dois_fatores_interacao2 &lt;- ecodados::anova_dois_fatores_interacao2 dados_bloco &lt;- ecodados::anova_bloco dados_ancova &lt;- ecodados::ancova üìù Importante Estat√≠sticas frequentistas como as que ser√£o abordadas neste cap√≠tulo s√£o baseadas em testes estat√≠sticos (e.g.¬†F, t, ùõò2, etc‚Ä¶), que s√£o resultados n√∫mericos do teste, e um valor de probabilidade (valor de P) que √© associado com o teste estat√≠stico (Nicholas J. Gotelli and Ellison 2012). O valor de P mede a probabilidade que os valores observados ou mais extremos seriam encontrados caso a hip√≥tese nula seja verdadeira (veja @{cap3}). Ao longo do livro usaremos o crit√©rio convencional de rejeitar a hip√≥tese nula quando P &lt; 0.05. Contudo, sugerimos a leitura destes artigos (White et al. 2013; Barber and Ogle 2014; Burnham and Anderson 2014b; Murtaugh 2014; Halsey 2019) que discutemas limita√ß√µes e problemas associados ao valor de P . 7.1 Teste T (de Student) para duas amostras independentes Uma das perguntas mais comuns em estat√≠stica √© saber se h√° diferen√ßa entre as m√©dias de dois grupos ou tratamentos. Para responder a esta pergunta, William Sealy Gosset, qu√≠mico da cervejaria Guinness em 1908, desenvolveu o Teste T que √© uma est√°tistica que segue uma distribui√ß√£o t de Student para rejeitar ou n√£o uma hip√≥tese nula de m√©dias iguais entre os grupos. \\[ t = \\frac{(\\bar{X}_1 - \\bar{X}_2)}{\\sqrt{\\frac{2S^2_p}{n}}}\\] Onde: \\(\\bar{X}\\)1 - \\(\\bar{X}\\)2 = diferen√ßa entre as m√©dias de duas amostras, S2p = desvio padr√£o das amostras, n = tamanho das amostras. Premissas do Teste t : As amostras devem ser independentes; As unidades amostrais s√£o selecionadas aleatoriamente; Distribui√ß√£o normal (gaussiana) dos res√≠duos. Observa√ß√£o: Zar (2010) indica que o Test T √© robusto mesmo com moderada viola√ß√£o da normalidade, principalmente se o tamanho amostral for alto. Homogeneidade da vari√¢ncia. Observa√ß√£o: Caso as vari√¢ncias n√£o sejam homog√™neas, isso deve ser informado na linha de comando, pois o denominador da f√≥rmula acima ser√° corrigido. Avalia√ß√£o das premissas: Uma das maneiras de avaliarmos as premissas de normalidade e homogeneidade da vari√¢ncia relacionadas √†s an√°lises do teste T, ANOVA e regress√µes lineares simples e m√∫ltiplas √© o uso da inspe√ß√£o gr√°fica da distribui√ß√£o dos res√≠duos (Figura 1) (Zuur, Ieno, and Elphick 2009a). A homegeneidade da vari√¢ncia utiliza um gr√°fico dos res√≠duos pelos valores preditos (Figura 1A). A distribui√ß√£o dos res√≠duos ser√° homog√™nea se n√£o observarmos nenhum padr√£o na distribui√ß√£o dos pontos (i.e.¬†forma em V, U ou funil). A normalidade dos res√≠duos utiliza um gr√°fico de quantis-quantis (QQ-plots). A distribui√ß√£o dos res√≠duos ser√° normal se os pontos estiverem pr√≥ximos √† reta (Figure 1B). Inspe√ß√£o gr√°fica da homogeneidade da vari√¢ncia (A) e normalidade (B) dos res√≠duos. Os s√≠mbolos verdes indicam que os gr√°ficos em que os res√≠duos apresentam distribui√ß√£o homog√™nea e normal, enquanto os s√≠mbolos vermelhos indicam os gr√°ficos em que os res√≠duos violam as premissas do teste. ¬† 7.1.0.1 Exemplo pr√°tico 1 - Teste T para duas amostras com vari√¢ncias iguais Explica√ß√£o dos dados Neste exemplo avaliaremos o comprimento rostro-cloacal (CRC em mil√≠metros) de machos de Physalaemus nattereri (Anura:Leptodactylidae) amostrados em diferentes esta√ß√µes do ano com armadilhas de intercepta√ß√£o e queda na Regi√£o Noroeste do estado de S√£o Paulo (da Silva and Rossa-Feres 2010). Pergunta: O CRC dos machos de P. nattereri √© maior na esta√ß√£o chuvosa do que na esta√ß√£o seca? Predi√ß√µes O CRC dos machos ser√° maior na esta√ß√£o chuvosa porque h√° uma vantangem seletiva para os indiv√≠duos maiores durante a atividade reprodutiva. Vari√°veis Vari√°veis resposta e preditoras Dataframe com os indiv√≠duos (unidade amostral) nas linhas e CRC (mm - vari√°vel resposta cont√≠nua) e esta√ß√£o (vari√°vel preditora categ√≥rica) como colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. An√°lise Vamos olhar os dados usando a fun√ß√£o head head(CRC_PN_macho) #&gt; CRC Estacao #&gt; 1 3.82 Chuvosa #&gt; 2 3.57 Chuvosa #&gt; 3 3.67 Chuvosa #&gt; 4 3.72 Chuvosa #&gt; 5 3.75 Chuvosa #&gt; 6 3.83 Chuvosa Vamos verificar a normalidade dos res√≠duos usando o QQ-plot. ## Teste de normalidade residuos &lt;- lm(CRC ~ Estacao, data = CRC_PN_macho) qqPlot(residuos) #&gt; [1] 22 26 Os pontos est√£o pr√≥ximos a reta indicando que a distribui√ß√£o dos res√≠duos √© normal (Figura 1). Outra possibilidade √© usar os testes de Shapiro-Wilk e Levene para verificar a normalidade e a homogeneidade da vari√¢ncia respectivamente. üìù Importante Hip√≥tese nula destes testes √© que a distribui√ß√£o √© normal ou homog√™nea: Valor de p &lt; 0.05 significa que os dados n√£o apresentam distribui√ß√£o normal ou homog√™nea; valor de p &gt; 0.05 significa que os dados apresentam distribui√ß√£o normal ou homog√™nea. # Teste de Shapiro shapiro.test (CRC_PN_macho$CRC) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: CRC_PN_macho$CRC #&gt; W = 0.95559, p-value = 0.05417 Teste de Levene para homogeneidade de vari√¢ncia. ## Teste de homogeneidade de vari√¢ncia leveneTest(CRC ~ Estacao, data = CRC_PN_macho) #&gt; Levene&#39;s Test for Homogeneity of Variance (center = median) #&gt; Df F value Pr(&gt;F) #&gt; group 1 1.1677 0.2852 #&gt; 49 Percebam que a distribui√ß√£o dos res√≠duos foi normal e homog√™nea na inspe√ß√£o gr√°fica, assim como nos testes de Shapiro e Levene, respectivamente. Agora podemos realizar a an√°lise sabendo que os dados seguem as premissas requeridas pelo test T. Vamos para os comandos da an√°lise do Teste T amostrans indenpendentes e vari√¢ncias iguais. ## An√°lise Teste T t.test(CRC ~ Estacao, data = CRC_PN_macho, var.equal = TRUE) #&gt; #&gt; Two Sample t-test #&gt; #&gt; data: CRC by Estacao #&gt; t = 4.1524, df = 49, p-value = 0.000131 #&gt; alternative hypothesis: true difference in means between group Chuvosa and group Seca is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.2242132 0.6447619 #&gt; sample estimates: #&gt; mean in group Chuvosa mean in group Seca #&gt; 3.695357 3.260870 Quatro valores devem ser apresentados ao leitores: i ) estat√≠stica do teste - representada por t = 4,15; ii) valor de significancia - representado por p-value = 0,0001; iii) graus de liberdade - representado por df = 49; e iv) diferen√ßa entre as m√©dias. Veja abaixo como descrever os resultados no seu trabalho. Visualizar os resultados em gr√°fico. ## Gr√°fico ggplot(data = CRC_PN_macho, aes(x = Estacao, y = CRC, color = Estacao)) + labs(x = &quot;Esta√ß√µes&quot;, y = &quot;CRC (mm) - P. nattereri&quot;) + geom_boxplot(fill = c(&quot;darkorange&quot;, &quot;cyan4&quot;), color = &quot;black&quot;, outlier.shape = NA) + geom_jitter(shape = 16, position = position_jitter(0.1), cex = 5, alpha = 0.7) + scale_color_manual(values = c(&quot;black&quot;, &quot;black&quot;)) + tema_livro() + theme(legend.position = &quot;none&quot;) Interpreta√ß√£o dos resultados Neste exemplo, rejeitamos a hip√≥tese nula de que as m√©dias do CRC dos machos entre as esta√ß√µes seca e chuvosa s√£o iguais. Os resultados mostram que os machos de P. nattereri coletados na esta√ß√£o chuvosa foram em m√©dia 0,43 mm maiores do que os coletados na esta√ß√£o seca (t49 = 4,15, P &lt; 0,001). ¬† 7.1.0.2 Exemplo pr√°tico 2 - Teste T para duas amostras independentes com vari√¢ncias diferentes Explica√ß√£o dos dados Neste exemplo, avaliaremos o comprimento rostro-cloacal (CRC - mil√≠metros) de f√™meas de Leptodactylus podicipinus amostradas em diferentes esta√ß√µes do ano com armadilhas de intercepta√ß√£o e queda na Regi√£o Noroeste do estado de S√£o Paulo (da Silva and Rossa-Feres 2010). Observa√ß√£o: Os dados foram alterados em rela√ß√£o a publica√ß√£o original para se enquadrarem no exemplo de amostras com vari√¢ncias diferentes. Pergunta: O CRC das f√™meas de L. podicipinus √© maior na esta√ß√£o chuvosa do que na esta√ß√£o seca? Predi√ß√µes O CRC das f√™meas ser√° maior na esta√ß√£o chuvosa porque h√° uma vantangem seletiva para os indiv√≠duos maiores durante a atividade reprodutiva. Vari√°veis Vari√°veis resposta e preditoras Dataframe com os indiv√≠duos (unidade amostral) nas linhas e CRC (mm - vari√°vel resposta cont√≠nua) e esta√ß√£o (vari√°vel preditora categ√≥rica) como colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. An√°lise Olhar os dados usando a fun√ß√£ohead head(CRC_LP_femea) #&gt; CRC Estacao #&gt; 1 2.72 Chuvosa #&gt; 2 2.10 Chuvosa #&gt; 3 3.42 Chuvosa #&gt; 4 1.50 Chuvosa #&gt; 5 3.90 Chuvosa #&gt; 6 4.00 Chuvosa Vamos avaliar as premissas do teste. Comen√ßando com o teste de normalidade. ## Teste de normalidade usando QQ-plot residuos_LP &lt;- lm(CRC ~ Estacao, data = CRC_LP_femea) qqPlot(residuos_LP) #&gt; [1] 4 6 Os res√≠duos apresentam distribui√ß√£o normal. Agora vamos avaliar a homogeneidade da vari√¢ncia. # Teste de homogeneidade da vari√¢ncia leveneTest(CRC ~ Estacao, data = CRC_LP_femea) #&gt; Levene&#39;s Test for Homogeneity of Variance (center = median) #&gt; Df F value Pr(&gt;F) #&gt; group 1 9.8527 0.01053 * #&gt; 10 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Os res√≠duos n√£o apresentam distribui√ß√£o homog√™nea. Portanto, vamos realizazr o teste T com vari√¢ncias diferentes. Para isso, use o argumento var.equal = FALSE t.test(CRC ~ Estacao, data = CRC_LP_femea, var.equal = FALSE) #&gt; #&gt; Welch Two Sample t-test #&gt; #&gt; data: CRC by Estacao #&gt; t = -1.7633, df = 6.4998, p-value = 0.1245 #&gt; alternative hypothesis: true difference in means between group Chuvosa and group Seca is not equal to 0 #&gt; 95 percent confidence interval: #&gt; -1.5489301 0.2375016 #&gt; sample estimates: #&gt; mean in group Chuvosa mean in group Seca #&gt; 2.834286 3.490000 Neste exemplo, n√£o rejeitamos a hip√≥tese nula e consideramos que as m√©dias do CRC das f√™meas entre as esta√ß√µes seca e chuvosa s√£o iguais (t6,49 = 1,76, P = 0,12). Visualizar os resultados em gr√°fico. ## Gr√°fico ggplot(data = CRC_LP_femea, aes(x = Estacao, y = CRC, color = Estacao)) + labs(x = &quot;Esta√ß√µes&quot;, y = &quot;CRC (mm) - L. podicipinus&quot;, size = 15) + geom_boxplot(fill=c(&quot;darkorange&quot;, &quot;cyan4&quot;), color=&quot;black&quot;, outlier.shape = NA) + geom_jitter(shape = 16, position=position_jitter(0.2), cex = 5, alpha = 0.7) + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;)) + tema_livro() + theme(legend.position = &quot;none&quot;) Interpreta√ß√£o dos resultados Os resultados mostram que as f√™meas de L. podicipinus coletadas na esta√ß√£o chuvosa n√£o s√£o maiores do que as f√™meas coletadas na esta√ß√£o seca, apesar de possuirem maior vari√¢ncia, o que pode ser biologicamente interessante. ¬† 7.2 Teste T para amostras pareadas O Teste T Pareado √© uma estat√≠stica que usa dados medidos duas vezes na mesma unidade amostral, resultando em pares de observa√ß√µes para cada amostra (amostras pareadas). Ele determina se a diferen√ßa da m√©dia entre duas observa√ß√µes √© zero. \\[ t = \\frac{\\bar{d}}{S_{\\bar{d}}}\\] Onde: \\(\\bar{d}\\) = m√©dia da diferen√ßa das medidas pareadas. Observe que o teste n√£o usa as medidas originais, e sim, a diferen√ßa para cada par, S\\(\\bar{d}\\) = erro padr√£o da diferen√ßa das medidas pareadas. Premissas do Teste t para amostras pareadas: As unidades amostrais s√£o selecionadas aleatoriamente; As observa√ß√µes n√£o s√£o independentes; Distribui√ß√£o normal (gaussiana) dos valores da diferen√ßa para cada par. ¬† 7.2.0.1 Exemplo pr√°tico 1 - Teste T para amostras pareadas Explica√ß√£o dos dados Neste exemplo avaliaremos a diferen√ßa na riqueza de esp√©cies de artr√≥podes registradas em 27 localidades. Todas as localidades foram amostradas duas vezes. A primeira amostragem foi realizada na localidade antes da pertuba√ß√£o e a segunda amostragem foi realizada ap√≥s a localidade ter sofrido uma queimada. Portanto, existe uma depend√™ncia temporal uma vez que amostramos a mesma localidade antes e depois da queimada. Pergunta: A riqueza de esp√©cies de artr√≥podes √© prejudicada pelas queimadas? Predi√ß√µes A riqueza de esp√©cies de artr√≥podes ser√° maior antes da queimada devido a extin√ß√£o local das esp√©cies. Vari√°veis Vari√°veis resposta e preditoras Dataframe com as localidades nas linhas e riqueza de esp√©cies (vari√°vel resposta cont√≠nua) e estado (Pre-queimada ou P√≥s-queimada - vari√°vel preditora categ√≥rica) da localidade nas colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. An√°lise Olhando os dados com a fun√ß√£o head head(Pareado) #&gt; Areas Riqueza Estado #&gt; 1 1 92 Pre-Queimada #&gt; 2 2 74 Pre-Queimada #&gt; 3 3 96 Pre-Queimada #&gt; 4 4 89 Pre-Queimada #&gt; 5 5 76 Pre-Queimada #&gt; 6 6 80 Pre-Queimada C√°lculo do Teste T com amostras pareadas. ## An√°lise Teste T Pareado # O uso do [] √© para selecionar dentro do vetor/coluna *Riqueza* os 27 # primeiros n√∫meros [1:27] que representam as localidades antes da # queimada e os √∫ltimos 27 n√∫meros [28:54] que representam as mesmas # localidades p√≥s-queimada. t.test(Pareado$Riqueza[1:27], Pareado$Riqueza[28:54], paired = TRUE) #&gt; #&gt; Paired t-test #&gt; #&gt; data: Pareado$Riqueza[1:27] and Pareado$Riqueza[28:54] #&gt; t = 7.5788, df = 26, p-value = 4.803e-08 #&gt; alternative hypothesis: true difference in means is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 32.47117 56.63994 #&gt; sample estimates: #&gt; mean of the differences #&gt; 44.55556 Neste exemplo, rejeitamos a hip√≥tese nula de que a riqueza de esp√©cies de artr√≥podes √© igual antes e depois da queimada (t26 = 7,57, P &lt; 0,001). Visualizar os resultados em gr√°fico. ## Gr√°fico ggpaired(Pareado, x = &quot;Estado&quot;, y = &quot;Riqueza&quot;, color = &quot;Estado&quot;, line.color = &quot;gray&quot;, line.size = 0.8, palette = c(&quot;darkorange&quot;, &quot;cyan4&quot;), width = 0.8, point.size = 4, xlab = &quot;Estado das localidades&quot;, ylab = &quot;Riqueza de Esp√©cies&quot;) + expand_limits(y=c(0,150)) + tema_livro() Interpreta√ß√£o dos resultados Os resultados mostram que as localidades ap√≥s as queimadas apresentam em m√©dia 44,5 esp√©cies de artr√≥podes a menos do que antes das queimadas. ¬† 7.3 Correla√ß√£o de Pearson √â um teste que mede a for√ßa relativa da rela√ß√£o linear entre duas vari√°veis cont√≠nuas (X e Y). Importante ressaltar que a an√°lise de correla√ß√£o n√£o assume que a vari√°vel X influencie a vari√°vel Y ou que exista uma rela√ß√£o de causa e efeito entre elas (Zar 2010). A an√°lise √© definida em termos da vari√¢ncia de X, a vari√¢ncia de Y, e a covari√¢ncia de X e Y (i.e.¬†como elas variam juntas). \\[ r = \\frac{\\sum{XY} - \\frac{\\sum{X} \\sum{Y}}{n}}{\\sqrt{\\left(\\sum{X^2} - \\frac{\\sum{X}^2}{n}\\right)\\left(\\sum{Y^2} - \\frac{\\sum{Y}^2}{n}\\right)}} \\] Onde: r = coeficiente de correla√ß√£o que indica a for√ßa da rela√ß√£o linear entre as duas vari√°veis. Seu limite de valores est√° entre -1 \\(\\leq\\) r \\(\\le\\) 1. A correla√ß√£o positiva indica que o aumento no valor de uma das vari√°veis √© acompanhado pelo aumento no valor da outra vari√°vel. A correla√ß√£o negativa indica que o aumento no valor de uma das vari√°veis √© acompanhado pela diminui√ß√£o no valor da outra vari√°vel. Se r √© igual a zero, n√£o existe correla√ß√£o entre as vari√°veis (Figura 2). Premissas da Correla√ß√£o de Person: As amostras devem ser independentes e pareadas (i.e.¬†as duas vari√°veis devem ser medidas na mesma unidade amostral); As unidades amostrais s√£o selecionadas aleatoriamente; A rela√ß√£o entre as vari√°veis tem que ser linear. Exemplo de correla√ß√µes negativa (A), positiva (B) e nula (C) e vari√°veis que n√£o apresentam rela√ß√µes lineares entre si (D-E). ¬† 7.3.0.1 Exemplo pr√°tico 1 - Correla√ß√£o de Pearson Explica√ß√£o dos dados Neste exemplo, avaliaremos a correla√ß√£o entre a altura do tronco e o tamanho da raiz medidos em 35 indiv√≠duos de uma esp√©cie vegetal arbustiva. Pergunta: Existe correla√ß√£o entre a altura do tronco e o tamanho da raiz dos arbustos? Predi√ß√µes A altura do tronco √© positivamente correlacionada com o tamanho da raiz. Vari√°veis Vari√°veis Dataframe com os indiv√≠duos (unidade amostral) nas linhas e altura do tronco e tamanho da raiz (duas vari√°veis tem que ser cont√≠nuas) como colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. An√°lise Vamos plhar os dados com a fun√ß√£o head. head(correlacao_arbustos) #&gt; Tamanho_raiz Tamanho_tronco #&gt; 1 10.177049 19.54383 #&gt; 2 6.622634 17.13558 #&gt; 3 7.773629 19.50681 #&gt; 4 11.055257 21.57085 #&gt; 5 4.487274 13.22763 #&gt; 6 11.190216 21.62902 C√°lculo do Teste de Correla√ß√£o de Pearson. Para outros testes de correla√ß√£o como Kendall ou Spearman √© s√≥ alterar na # linha de comando a op√ß√£o *method* e inserir o teste desejado. ## Corre√ß√£o de Person cor.test(correlacao_arbustos$Tamanho_raiz, correlacao_arbustos$Tamanho_tronco, method = &quot;pearson&quot;) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: correlacao_arbustos$Tamanho_raiz and correlacao_arbustos$Tamanho_tronco #&gt; t = 11.49, df = 33, p-value = 4.474e-13 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.7995083 0.9457816 #&gt; sample estimates: #&gt; cor #&gt; 0.8944449 Neste exemplo, rejeitamos a hip√≥tese nula de que as vari√°veis n√£o s√£o correlacionadas (r = 0.89, P &lt; 0,001). Visualizar os resultados em gr√°fico. ## Gr√°fico ggplot(data = correlacao_arbustos, aes(x = Tamanho_raiz, y = Tamanho_tronco)) + labs(x = &quot;Tamanho da raiz&quot;, y = &quot;Altura do tronco&quot;) + geom_point(size = 4, shape = 21, fill = &quot;darkorange&quot;, alpha = 0.7) + geom_text(x = 14, y = 14, label = &quot;r = 0.89, P &lt; 0.001&quot;, color = &quot;black&quot;, size = 5) + tema_livro() + theme(legend.position = &quot;none&quot;) + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;, linetype =&quot;dashed&quot;) üìù Importante: a linha de tend√™ncia tracejada no gr√°fico √© apenas para ilustrar a rela√ß√£o positiva entre as vari√°veis. Ela n√£o √© gerada pela an√°lise de correla√ß√£o. Interpreta√ß√£o dos resultados Os resultados mostram que o aumento na altura dos arbutos √© acompanhado pelo aumento no tamanho da raiz. ¬† 7.4 Regress√£o Linear Simples A regress√£o linear simples √© usada para analisar a rela√ß√£o entre uma vari√°vel preditora (plotada no eixo-X) e uma vari√°vel resposta (plotada no eixo-Y). As duas vari√°veis devem ser cont√≠nuas. Diferente das correla√ß√µes, a regress√£o assume uma rela√ß√£o de causa e efeito entre as vari√°veis. O valor da vari√°vel preditora (X) causa, direta ou indiretamente, o valor da vari√°vel resposta (Y). Assim, Y √© uma fun√ß√£o linear de X: \\[ Y = \\beta_0 + \\beta_{1}X_i + \\epsilon_i \\] Onde: \\(\\beta_0\\) = intercepto (intercept) que representa o valor da fun√ß√£o quando X = 0, \\(\\beta_{1}\\) = inclina√ß√£o (slope) que mede a mudan√ßa na vari√°vel Y para cada mudan√ßa de unidade da vari√°vel X. \\(\\epsilon_{1}\\) = erro aleat√≥rio referente √† vari√°vel Y que n√£o pode ser explicado pela vari√°vel X. Premissas da Regress√£o Linear Simples: As amostras devem ser independentes; As unidades amostrais s√£o selecionadas aleatoriamente; Distribui√ß√£o normal (gaussiana) dos res√≠duos; Homogeneidade da vari√¢ncia. ¬† 7.4.0.1 Exemplo pr√°tico 1 - Regress√£o linear simples Explica√ß√£o dos dados Neste exemplo, avaliaremos a rela√ß√£o entre o gradiente de temperatura m√©dia anual (¬∞C) e o tamanho m√©dio do comprimento rostro-cloacal (CRC em mm) de popula√ß√µes de Dendropsophus minutus (Anura:Hylidae) amostradas em 109 localidades no Brasil (Boaratti and da Silva 2015). Pergunta: H√° rela√ß√£o de depend√™ncia entre o tamanho do CRC das popula√ß√µes e a temperatura das localidades onde os indiv√≠duos ocorrem? Predi√ß√µes O CRC das popula√ß√µes ser√£o menores em localidades mais quentes do que em localidades mais frias de acordo com a Hip√≥tese do balan√ßo de calor (Olalla-T√°rraga and Rodr√≠guez 2007). Vari√°veis Vari√°veis resposta e preditoras Dataframe com as popula√ß√µes (unidade amostral) nas linhas e CRC (vari√°vel resposta) m√©dio (mm) e temperatura m√©dia anual (vari√°vel preditora) como colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. An√°lise Olhando os dados com a fun√ß√£o head head(dados_regressao) #&gt; Municipio CRC Temperatura Precipitacao #&gt; 1 Acorizal 22.98816 24.13000 1228.2 #&gt; 2 Alpinopolis 22.91788 20.09417 1487.6 #&gt; 3 Alto_Paraiso 21.97629 21.86167 1812.4 #&gt; 4 Americana 23.32453 20.28333 1266.2 #&gt; 5 Apiacas 22.83651 25.47333 2154.0 #&gt; 6 Arianopolis 20.86989 20.12167 1269.2 Vamos calcular a regress√£o linear simples. ## Regress√£o simples modelo_regressao &lt;- lm(CRC ~ Temperatura, data = dados_regressao) Antes de vermos os resultados, vamos verificar a normalidade e homogeneidade das vari√¢ncias ## Verificar as premissas do teste par(mfrow = c(2, 2), oma = c(0, 0, 2, 0)) plot(modelo_regressao) dev.off() # volta a configura√ß√£o dos gr√°ficos para o formato padr√£o #&gt; null device #&gt; 1 Os gr√°ficos Residuals vs Fitted, Scale-Location, e Residual vs Leverage est√£o relacionados com a homogeneidade da vari√¢ncia. Nestes gr√°ficos, esperamos ver os pontos dispersos no espa√ßo sem padr√µes com formatos em U ou funil. Podemos observar que tanto a normalidade como a homogeneidade do res√≠duos est√£o dentro dos padr√µes esperados. Vamos ver os resultados da regress√£o simples usando as fun√ß√µes anova e summary. A fun√ß√£o anova retorna uma tabela contendo o grau de liberdade (df), soma dos quadrados, valor de F e o valor de P. ## Resultados usando a fun√ß√£o anova anova(modelo_regressao) #&gt; Analysis of Variance Table #&gt; #&gt; Response: CRC #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Temperatura 1 80.931 80.931 38.92 9.011e-09 *** #&gt; Residuals 107 222.500 2.079 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 A fun√ß√£o summary retorna uma tabela contendo o valor do intercepto, inclina√ß√£o da reta (slope) e o coeficiente de determina√ß√£o (R2) que indica a propor√ß√£o da varia√ß√£o na vari√°vel Y que pode ser atribu√≠da √† varia√ß√£o na vari√°vel X. Percebam que a parte final dos resultados apresentados no summary, s√£o os mesmo apresentados pela fun√ß√£o anova. # Resultados usando a fun√ß√£o summary summary(modelo_regressao) #&gt; #&gt; Call: #&gt; lm(formula = CRC ~ Temperatura, data = dados_regressao) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -3.4535 -0.7784 0.0888 0.9168 3.1868 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 16.23467 0.91368 17.768 &lt; 2e-16 *** #&gt; Temperatura 0.26905 0.04313 6.239 9.01e-09 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 1.442 on 107 degrees of freedom #&gt; Multiple R-squared: 0.2667, Adjusted R-squared: 0.2599 #&gt; F-statistic: 38.92 on 1 and 107 DF, p-value: 9.011e-09 Vamos visualizar os resultados em gr√°fico. ## Gr√°fico ggplot(data = dados_regressao, aes(x = Temperatura, y = CRC)) + labs(x = &quot;Temperatura m√©dia anual (¬∞C)&quot;, y = &quot;Comprimento rostro-cloacal (mm)&quot;) + geom_point(size = 4, shape = 21, fill = &quot;darkorange&quot;, alpha = 0.7) + tema_livro() + theme(legend.position = &quot;none&quot;) + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) Interpreta√ß√£o dos resultados Neste exemplo, rejeitamos a hip√≥tese nula de que n√£o existe rela√ß√£o entre o tamanho do CRC das popula√ß√µes de D. minutus e a temperatura da localidade onde elas ocorrem (F1,107 = 38,92, P &lt; 0,001). Os resultados mostram que o tamanho do CRC das popula√ß√µes tem uma rela√ß√£o positiva com a temperatura das localidades. Assim, popula√ß√µes de D. minutus em localidades mais quentes apresentam maior CRC do que as popula√ß√µes em localidades mais frias. ¬† 7.5 Regress√£o Linear M√∫ltipla A regress√£o linear m√∫ltipla √© uma extens√£o da regress√£o linear simples. Ela √© usada quando queremos determinar o valor da vari√°vel resposta (Y) com base nos valores de duas ou mais vari√°veis preditoras (X1, X2, Xn). \\[ Y = \\beta_0 + \\beta_{1}X_1 + \\beta_{n}X_n + \\epsilon_i \\] Onde: \\(\\beta_0\\) = intercepto (intercept) que representa o valor da fun√ß√£o quando X = 0; \\(\\beta_{n}\\) = inclina√ß√£o (slope) que mede a mudan√ßa na vari√°vel Y para cada mudan√ßa de unidade das vari√°veis Xn; \\(\\epsilon_{1}\\) = erro aleat√≥rio referente a vari√°vel Y que n√£o pode ser explicado pelas vari√°veis preditoras. Premissas da Regress√£o Linear M√∫ltipla: As amostras devem ser independentes; As unidades amostrais s√£o selecionadas aleatoriamente; Distribui√ß√£o normal (gaussiana) dos res√≠duos; Homogeneidade da vari√¢ncia. ¬† 7.5.0.1 Exemplo pr√°tico 1 - Regress√£o linear m√∫ltipla Explica√ß√£o dos dados Utilizaremos o mesmo exemplo da regress√£o linear simples. Contudo, al√©m do gradiente de temperatura m√©dia anual (¬∞C), incluiremos o gradiente de precipita√ß√£o anual (mm) como outra vari√°vel preditora do tamanho m√©dio do comprimento rostro-cloacal (CRC em mm) de popula√ß√µes de Dendropsophus minutus (Anura:Hylidae) amostradas em 109 localidades no Brasil (Boaratti and da Silva 2015). Pergunta: O tamanho do CRC das popula√ß√µes de D. minutus √© influ√™nciado pela temperatura e precipita√ß√£o das localidades onde os indiv√≠duos ocorrem? Predi√ß√µes O CRC das popula√ß√µes ser√£o menores em localidades com clima quente e chuvoso do que em localidades com clima frio e seco. Vari√°veis Vari√°veis resposta e preditoras Dataframe com as popula√ß√µes (unidade amostral) nas linhas e CRC (vari√°vel resposta) m√©dio (mm) e temperatura e precipita√ß√£o (vari√°veis preditoras) como colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. An√°lise Olhando os dados usando a fun√ß√£o head head(dados_regressao_mul) #&gt; Municipio CRC Temperatura Precipitacao #&gt; 1 Acorizal 22.98816 24.13000 1228.2 #&gt; 2 Alpinopolis 22.91788 20.09417 1487.6 #&gt; 3 Alto_Paraiso 21.97629 21.86167 1812.4 #&gt; 4 Americana 23.32453 20.28333 1266.2 #&gt; 5 Apiacas 22.83651 25.47333 2154.0 #&gt; 6 Arianopolis 20.86989 20.12167 1269.2 Comandos para o modelo de regress√£o m√∫ltipla. ## Regress√£o m√∫ltipla modelo_regressao_mul &lt;- lm(CRC ~ Temperatura + Precipitacao, data = dados_regressao_mul) üìù Importante Multicolinearidade ocorre quando as vari√°veis preditoras s√£o correlacionadas. Essa correla√ß√£o √© um problema porque as vari√°veis preditoras deveriam ser independentes. O Fator de Infla√ß√£o da Vari√¢ncia (VIF) √© um teste que identifica a correla√ß√£o entre as vari√°veis e mostra a for√ßa dessa correla√ß√£o. Alguns autores consideram valores de VIF acima de 10 como fortemente correlacionadas, outros mais conservadores consideram o valor de 3. Vamos analisar se as vari√°veis apresentam multicolinearidade. # Multicolinearidade vif(modelo_regressao_mul) #&gt; Temperatura Precipitacao #&gt; 1.041265 1.041265 Os valores s√£o menores que 3 indicando que n√£o h√° multicolinearidade. Agora vamos verificar as premissas de normalidade e homogeneidade das vari√¢ncias. ## Normalidade e homogeneidade par(mfrow = c(2, 2), oma = c(0, 0, 2, 0)) plot(modelo_regressao_mul) dev.off() #&gt; null device #&gt; 1 Os res√≠duos apresentam distribui√ß√£o normal e vari√¢ncias homog√™neas. Podemos ver os resultados da an√°lise. ## Regress√£o m√∫ltipla summary(modelo_regressao_mul) #&gt; #&gt; Call: #&gt; lm(formula = CRC ~ Temperatura + Precipitacao, data = dados_regressao_mul) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -3.4351 -0.8026 0.0140 0.9420 3.4300 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 16.7162571 1.0108674 16.537 &lt; 2e-16 *** #&gt; Temperatura 0.2787445 0.0439601 6.341 5.71e-09 *** #&gt; Precipitacao -0.0004270 0.0003852 -1.108 0.27 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 1.44 on 106 degrees of freedom #&gt; Multiple R-squared: 0.2751, Adjusted R-squared: 0.2614 #&gt; F-statistic: 20.12 on 2 and 106 DF, p-value: 3.927e-08 Percebam que a temperatura tem uma rela√ß√£o significativa e positiva com o tamanho do CRC das popula√ß√µes (P &lt; 0.001), enquanto que a precipita√ß√£o n√£o apresenta rela√ß√£o com o CRC (P = 0.27). Neste caso, √© interessante saber se um modelo mais simples (e.g.¬†contendo apenas temperatura) explicaria a distribui√ß√£o t√£o bem ou melhor do que este modelo mais complexo considerando duas vari√°veis (temperatura e precipita√ß√£o). Para isso, podemos utilizar a Likelihood Ratio Test (LRT) para comparar modelos. A LRT compara dois modelos aninhados, testando se os par√¢metros do modelo mais complexo diferem significativamente do modelo mais simples. Em outras palavras, ele testa se h√° necessidade de se incluir uma vari√°vel extra no modelo para explicar os dados. ## Criando os modelos aninhados modelo_regressao_mul &lt;- lm(CRC ~ Temperatura + Precipitacao, data = dados_regressao_mul) modelo_regressao &lt;- lm(CRC ~ Temperatura, data = dados_regressao_mul) ## Likelihood Ratio Test (LRT) lrtest(modelo_regressao_mul, modelo_regressao) #&gt; Likelihood ratio test #&gt; #&gt; Model 1: CRC ~ Temperatura + Precipitacao #&gt; Model 2: CRC ~ Temperatura #&gt; #Df LogLik Df Chisq Pr(&gt;Chisq) #&gt; 1 4 -192.93 #&gt; 2 3 -193.55 -1 1.2558 0.2624 üìù Importante Hip√≥tese nula √© que o modelo mais simples √© o melhor Valor de p &lt; 0.05 rejeita a hip√≥tese nula e o modelo mais complexo √© o melhor; valor de p &gt; 0.05 n√£o rejeita a hip√≥tese nula e o modelo mais simples √© o melhor. ## Comparando com o modelo somente com o intercepto # Criando um modelo sem vari√°veis, s√≥ o intercepto. modelo_intercepto &lt;- lm(CRC ~ 1, data = dados_regressao_mul) lrtest(modelo_regressao, modelo_intercepto) #&gt; Likelihood ratio test #&gt; #&gt; Model 1: CRC ~ Temperatura #&gt; Model 2: CRC ~ 1 #&gt; #Df LogLik Df Chisq Pr(&gt;Chisq) #&gt; 1 3 -193.55 #&gt; 2 2 -210.46 -1 33.815 6.061e-09 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Interpreta√ß√£o dos resultados Neste exemplo, a precipita√ß√£o n√£o est√° associada com a varia√ß√£o no tamanho do CRC das popula√ß√µes de D. minutus. Por outro lado, a temperatura explicou 26% da varia√ß√£o do tamanho do CRC das popula√ß√µes. ¬† 7.6 An√°lises de Vari√¢ncia (ANOVA) ANOVA refere-se a uma variedade de delineamentos experimentais nos quais a vari√°vel preditora √© categ√≥rica e a vari√°vel resposta √© cont√≠nua (Nicholas J. Gotelli and Ellison 2012). Exemplos desses delineamentos experimentais s√£o: ANOVA de um fator, ANOVA de dois fatores, ANOVA em blocos aleatorizados, ANOVA de medidas repetidas e ANOVA split-splot. De forma geral, a ANOVA √© um teste estat√≠stico usado para comparar a m√©dia entre grupos amostrados independentemente. Para isso, o teste leva em conta, al√©m das m√©dias dos grupos, a varia√ß√£o dos dados dentro e entre os grupos. Neste cap√≠tulo, iremos demonstrar as linhas de comandos para alguns dos principais delineamentos experimentais. Premissas da ANOVA: As amostras devem ser independentes. Observa√ß√£o: ANOVA de medidas repetidas e ANOVA split-plot s√£o designs experimentais que apresentam depend√™ncia entre as amostras, mas controlam esse deped√™ncia nas suas formula√ß√µes matem√°tcas; As unidades amostrais s√£o selecionadas aleatoriamente; Distribui√ß√£o normal (gaussiana) dos res√≠duos; Homogeneidade da vari√¢ncia. ¬† 7.7 ANOVA de um fator Este teste considera delineamentos experimentais com apenas um fator (ou tratamento) que pode ser composto por tr√™s ou mais grupos (ou n√≠veis). 7.7.0.1 Exemplo pr√°tico 1 - Anova de um fator Explica√ß√£o dos dados Neste exemplo, avaliaremos se o adubo X-2020 disponibilizado recentemente no mercado melhora o crescimento dos indiv√≠duos de Coffea arabica como divulgado pela empresa respons√°vel pela venda do produto. Para isso, foi realizado um experimento com indiv√≠duos de C. arabica cultivados em tr√™s grupos: i) grupo controle onde os indiv√≠duos n√£o receberam aduba√ß√£o, ii) grupo onde os indiv√≠duos receberam a adi√ß√£o do adubo tradicional mais utilizado pelos produtores de C. arabica, e iii) grupo onde os indiv√≠duos receberam a adi√ß√£o do adubo X-2020. Pergunta: O crescimento dos indiv√≠duos de C. arabica √© melhorado pela adi√ß√£o do adubo X-2020? Predi√ß√µes O crescimento dos indiv√≠duos de C. arabica ser√° maior no grupo que recebeu o adubo X-2020. Vari√°veis Vari√°veis resposta e preditoras Dataframe com as plantas (unidade amostral) nas linhas e o crescimento dos indiv√≠duos de C. arabica (vari√°vel resposta) e os tratamentos (vari√°vel preditora) nas colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°vel preditora e resposta nas colunas. 7.7.1 An√°lise Olhando os dados e criando o modelo para Anova de um fator. head(dados_anova_simples) #&gt; Crescimento Tratamento #&gt; 1 7.190 Controle #&gt; 2 6.758 Controle #&gt; 3 6.101 Controle #&gt; 4 4.758 Controle #&gt; 5 6.542 Controle #&gt; 6 7.667 Controle ## An√°lise ANOVA de um fator Modelo_anova &lt;- aov(Crescimento ~ Tratamento, data = dados_anova_simples) Vamos verificar a normalidade e homogeneidade da vari√¢ncia usando os testes de Shapiro-Wilk e bartett.test respectivamente. ## Normalidade shapiro.test(dados_anova_simples$Crescimento[1:12]) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: dados_anova_simples$Crescimento[1:12] #&gt; W = 0.96731, p-value = 0.8806 shapiro.test(dados_anova_simples$Crescimento[13:24]) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: dados_anova_simples$Crescimento[13:24] #&gt; W = 0.87324, p-value = 0.07184 shapiro.test(dados_anova_simples$Crescimento[25:36]) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: dados_anova_simples$Crescimento[25:36] #&gt; W = 0.9294, p-value = 0.3738 ## Normalidade bartlett.test(Crescimento ~ Tratamento, data = dados_anova_simples) #&gt; #&gt; Bartlett test of homogeneity of variances #&gt; #&gt; data: Crescimento by Tratamento #&gt; Bartlett&#39;s K-squared = 0.61835, df = 2, p-value = 0.7341 Os res√≠duos apresentam distribui√ß√£o normal e vari√¢ncia homog√™neas. Vamos ver os resultados da an√°lise. ## Resultados anova anova(Modelo_anova) #&gt; Analysis of Variance Table #&gt; #&gt; Response: Crescimento #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Tratamento 2 340.32 170.160 77.989 3.124e-13 *** #&gt; Residuals 33 72.00 2.182 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Percebam que o resultado da ANOVA (Pr(&gt;F) &lt; 0.001) indica que devemos rejeitar a hip√≥tese nula que n√£o h√° diferen√ßa entre as m√©dias dos grupos. Contudo, os resultados n√£o mostram quais s√£o os grupos que apresentam diferen√ßas. Para isso, temos que realizar testes de compara√ß√µes m√∫ltiplas post-hoc para detectar os grupos que apresentam diferen√ßas significativas entre as m√©dias. üìù Importante Os testes post-hoc s√≥ devem ser utilizados quando rejeitamos a hip√≥tese nula (P &lt; 0.05) no teste da ANOVA. ## Diferen√ßas entre os tratamentos # Teste de Tuckey&#39;s honest significant difference TukeyHSD(Modelo_anova) #&gt; Tukey multiple comparisons of means #&gt; 95% family-wise confidence level #&gt; #&gt; Fit: aov(formula = Crescimento ~ Tratamento, data = dados_anova_simples) #&gt; #&gt; $Tratamento #&gt; diff lwr upr p adj #&gt; Adubo_X-2020-Adubo_Tradicional 0.04991667 -1.429784 1.529617 0.9962299 #&gt; Controle-Adubo_Tradicional -6.49716667 -7.976867 -5.017466 0.0000000 #&gt; Controle-Adubo_X-2020 -6.54708333 -8.026784 -5.067383 0.0000000 Visualizar os resultados em gr√°fico. # Reordenando a ordem que os grupos ir√£o aparecer no gr√°fico dados_anova_simples$Tratamento &lt;- factor(dados_anova_simples$Tratamento , levels=c(&quot;Controle&quot;, &quot;Adubo_Tradicional&quot;, &quot;Adubo_X-2020&quot;)) # Gr√°fico ggplot(data = dados_anova_simples, aes(x = Tratamento, y = Crescimento, color = Tratamento)) + labs(x = &quot;Aduba√ß√£o&quot;, y = &quot;Crescimento Coffea arabica (cm)&quot;, size = 20) + geom_boxplot(fill = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;), color = &quot;black&quot;, show.legend = FALSE, alpha = 0.4) + geom_jitter(shape = 16, position = position_jitter(0.1), cex = 4, alpha = 0.7) + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + scale_y_continuous(limits = c(0, 20), breaks = c(0, 5, 10, 15, 20)) + geom_text(x = 1, y = 12, label = &quot;ab&quot;, color = &quot;black&quot;, size = 5) + geom_text(x = 2, y = 17, label = &quot;a&quot;, color = &quot;black&quot;, size = 5) + geom_text(x = 3, y = 17, label = &quot;b&quot;, color = &quot;black&quot;, size = 5) + scale_x_discrete(labels = c(&quot;Sem adubo&quot;,&quot;Tradicional&quot;,&quot;X-2020&quot;)) + tema_livro() + theme(legend.position = &quot;none&quot;) Interpreta√ß√£o dos resultados Neste exemplo, os indiv√≠duos de C. arabica que receberam aduba√ß√£o (tradicional e X-2020) apresentaram maior crescimento do que os indiv√≠duos que n√£o receberam aduba√ß√£o. Contudo, diferente do que foi divulgado pela empresa, o adubo X-2020 n√£o apresentou melhor desempenho que o adubo tradicional j√° utilizado pelos produtores. ¬† 7.8 ANOVA com dois fatores ou ANOVA fatorial Este teste considera delineamentos amostrais com dois fatores (ou tratamentos) que podem ser compostos por dois ou mais grupos (ou n√≠veis). Esta an√°lise tem uma vantagem, pois permite avaliar o efeito da intera√ß√£o entre os fatores na vari√°vel resposta. Quando a intera√ß√£o est√° presente, o impacto de um fator depende do n√≠vel (ou grupo) do outro fator. 7.8.0.1 Exemplo pr√°tico 1 - ANOVA com dois fatores Explica√ß√£o dos dados Neste exemplo, avaliaremos se o tempo que o corpo leva para eliminar uma droga utilizada em exames de resson√¢ncia magn√©tica est√° relacionado com o sistema XY de determina√ß√£o do sexo e/ou com a idade dos pacientes. Para isso, foi realizado um experimento com 40 pacientes distribu√≠dos da seguinte maneira: i) 10 indiv√≠duos XX - jovens, ii) 10 indiv√≠duos XX - idosas, iii) 10 indiv√≠duos XY - jovens, e iv) 10 indiv√≠duos XY - idosos. Pergunta: O tempo de elimina√ß√£o da droga √© dependente do sistema XY de determina√ß√£o do sexo e idade dos pacientes? Predi√ß√µes O tempo de elimina√ß√£o da droga vai ser mais r√°pido nas pacientes XX e jovens. Vari√°veis Vari√°veis resposta e preditoras Dataframe com os pacientes (unidade amostral) nas linhas e o tempo de elimina√ß√£o da droga (vari√°vel resposta) e os tratamentos sexo e idade dos pacientes (vari√°veis preditoras) nas colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e as vari√°veis preditoras e respostas nas colunas. 7.8.1 An√°lise Olhando os dados usando a fun√ß√£o head head(dados_dois_fatores) #&gt; Tempo Pessoas Idade #&gt; 1 18.952 XX Jovem #&gt; 2 16.513 XX Jovem #&gt; 3 17.981 XX Jovem #&gt; 4 21.371 XX Jovem #&gt; 5 14.470 XX Jovem #&gt; 6 19.130 XX Jovem Comandos da ANOVA com dois fatores. ## An√°lise Anova de dois fatores # A intera√ß√£o entre os fatores √© representada por * Modelo1 &lt;- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores) # Olhando os resultados anova(Modelo1) #&gt; Analysis of Variance Table #&gt; #&gt; Response: Tempo #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Pessoas 1 716.72 716.72 178.8538 1.56e-15 *** #&gt; Idade 1 1663.73 1663.73 415.1724 &lt; 2.2e-16 *** #&gt; Pessoas:Idade 1 4.77 4.77 1.1903 0.2825 #&gt; Residuals 36 144.26 4.01 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Percebam que a intera√ß√£o n√£o apresenta um efeito significativo (P &gt; 0.05). Assim, iremos retirar a intera√ß√£o e verificar, usando Likelihood Ratio Test, se o modelo mais simples √© melhor. # Criando modelo sem intera√ß√£o. Modelo2 &lt;- aov(Tempo ~ Pessoas + Idade, data = dados_dois_fatores) ## LRT lrtest(Modelo1, Modelo2) #&gt; Likelihood ratio test #&gt; #&gt; Model 1: Tempo ~ Pessoas * Idade #&gt; Model 2: Tempo ~ Pessoas + Idade #&gt; #Df LogLik Df Chisq Pr(&gt;Chisq) #&gt; 1 5 -82.413 #&gt; 2 4 -83.063 -1 1.3012 0.254 A intera√ß√£o n√£o √© importante. Ent√£o podemos seguir com o modelo mais simples. Vamos verficiar a normalidade e homogeneidade da vari√¢ncia. # Verificando as premissas do teste. par(mfrow = c(2, 2), oma = c(0, 0, 2, 0)) plot(Modelo2) dev.off() #&gt; null device #&gt; 1 Dois pontos est√£o fugindo da reta e chamam aten√ß√£o sobre a normalidade da distribui√ß√£o dos res√≠duos. A homogeneidade da vari√¢ncia est√° adequada. Por enquanto, vamos seguir a an√°lise, mas veja o ?? para entender como lidar como modelos que os res√≠duos n√£o apresentam distribui√ß√£o normal. # Resultados do modelo anova(Modelo2) #&gt; Analysis of Variance Table #&gt; #&gt; Response: Tempo #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Pessoas 1 716.72 716.72 177.94 1.041e-15 *** #&gt; Idade 1 1663.73 1663.73 413.05 &lt; 2.2e-16 *** #&gt; Residuals 37 149.03 4.03 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Percebam que o resultado da ANOVA (Pr(&gt;F) &lt; 0.001) indica que devemos rejeitar a hip√≥tese nula de que n√£o h√° diferen√ßa entre as m√©dias dos sistema XY e idade dos pacientes. Neste caso, n√£o precisamos realizar testes de compara√ß√µes m√∫ltiplas post-hoc porque os fatores apresentam apenas dois n√≠veis. Contudo, se no seu delineamento experimental um dos fatores apresentar tr√™s ou mais n√≠veis, voc√™ dever√° utilizar os testes de compara√ß√µes post-hoc para determinar as diferen√ßas entre os grupos. Visualizar os resultados em gr√°fico. Interpreta√ß√£o dos resultados Neste exemplo, o sistema XY de determina√ß√£o do sexo e a idade dos pacientes t√™m um efeito no tempo de elimina√ß√£o da droga do organismo. Os pacientes XX e jovens apresentaram elimina√ß√£o mais r√°pida da droga do que pacientes XY e idosos. ¬† 7.8.1.1 Exemplo pr√°tico 2 - ANOVA com dois fatores com efeito da intera√ß√£o Explica√ß√£o dos dados Neste exemplo, usaremos os mesmos dados do exemplo anterior. Neste caso, alteramos os dados para que a intera√ß√£o seja significativa. head(dados_dois_fatores_interacao) #&gt; Tempo Pessoas Idade #&gt; 1 18.952 XX Jovem #&gt; 2 16.513 XX Jovem #&gt; 3 17.981 XX Jovem #&gt; 4 21.371 XX Jovem #&gt; 5 14.470 XX Jovem #&gt; 6 19.130 XX Jovem ## An√°lise ANOVA com dois fatores Modelo_interacao1 &lt;- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores_interacao) ## Olhando os resultados anova(Modelo_interacao1) #&gt; Analysis of Variance Table #&gt; #&gt; Response: Tempo #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Pessoas 1 716.72 716.72 178.8538 1.56e-15 *** #&gt; Idade 1 1663.73 1663.73 415.1724 &lt; 2.2e-16 *** #&gt; Pessoas:Idade 1 4.77 4.77 1.1903 0.2825 #&gt; Residuals 36 144.26 4.01 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Percebam que a intera√ß√£o √© significativa (P &lt; 0.05). Agora nossa interpreta√ß√£o precisa ser baseada na intera√ß√£o entre os fatores. Vamos visualizar os resultados em gr√°fico. ## Gr√°fico ggplot(data = dados_dois_fatores_interacao, aes(y = Tempo, x = Pessoas, color = Idade)) + geom_boxplot() + stat_summary(fun = mean, geom =&quot;point&quot;, aes(group = Idade, x = Pessoas), color = &quot;black&quot;, position = position_dodge(0.7), size = 4) + geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 40), color = &quot;darkorange&quot;, lwd = 1.3, linetype = 2) + geom_link(aes(x = 1.2, y = 28.5, xend = 2.2, yend = 26.5), color = &quot;cyan4&quot;, lwd = 1.3, linetype = 2) + labs(x = &quot;Sistema XY de determina√ß√£o do sexo&quot;, y = &quot;Tempo (horas) para eliminar a droga&quot;) + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;, &quot;darkorange&quot;, &quot;cyan4&quot;)) + scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) + tema_livro() Interpreta√ß√£o dos resultados Percebam que para saber a resposta do fator idade (jovem ou idoso) na elimina√ß√£o da droga, voc√™ precisa saber com qual pessoa (XX ou XY) ele est√° associado. Isso porque a resposta de um fator, depende do outro fator. Jovens eliminam a droga do corpo mais r√°pido nas pessoas XY, enquanto os idosos eliminam a droga mais r√°pido nas pessoas XX. ¬† 7.8.1.2 Exemplo pr√°tico 3 - ANOVA com dois fatores com efeito da intera√ß√£o Explica√ß√£o dos dados Neste exemplo, usaremos os mesmos dados do exemplo anterior. Entretanto, alteramos os dados para que a intera√ß√£o seja significativa. # Olhando os dados head(dados_dois_fatores_interacao2) #&gt; Tempo Pessoas Idade #&gt; 1 18.952 XX Jovem #&gt; 2 16.513 XX Jovem #&gt; 3 17.981 XX Jovem #&gt; 4 21.371 XX Jovem #&gt; 5 14.470 XX Jovem #&gt; 6 19.130 XX Jovem ## An√°lise anova de dois fatores Modelo_interacao2 &lt;- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores_interacao2) ## Olhando os resultados anova(Modelo_interacao2) #&gt; Analysis of Variance Table #&gt; #&gt; Response: Tempo #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Pessoas 1 716.72 716.72 178.8538 1.56e-15 *** #&gt; Idade 1 4.77 4.77 1.1903 0.2825 #&gt; Pessoas:Idade 1 1663.73 1663.73 415.1724 &lt; 2.2e-16 *** #&gt; Residuals 36 144.26 4.01 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Percebam que a intera√ß√£o √© significativa (P &lt; 0.05), mas a idade n√£o √© significativa. Nossa interpreta√ß√£o precisa ser baseada na intera√ß√£o entre os fatores. Vamos visualizar os resultados em gr√°fico. ## Gr√°fico ggplot(data = dados_dois_fatores_interacao2, aes(y = Tempo, x = Pessoas, color = Idade)) + geom_boxplot() + stat_summary(fun = mean, geom =&quot;point&quot;, aes(group = Idade, x = Pessoas), color = &quot;black&quot;, position = position_dodge(0.7), size = 4) + geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 27), color = &quot;darkorange&quot;, lwd = 1.3, linetype = 2) + geom_link(aes(x = 1.2, y = 19, xend = 2.2, yend = 41), color = &quot;cyan4&quot;, lwd = 1.3, linetype = 2) + labs(x = &quot;Sistema XY de determina√ß√£o do sexo&quot;, y = &quot;Tempo (horas) para eliminar a droga&quot;) + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;, &quot;darkorange&quot;, &quot;cyan4&quot;)) + scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) + tema_livro() Interpreta√ß√£o dos resultados Percebam que as linhas se cruzam. Esse √© um exemplo cl√°ssico de intera√ß√£o. Novamente, para saber a resposta do fator idade (jovem ou idoso), voc√™ precisa saber com qual pessoa (XX ou XY) ele est√° associado. Jovens s√£o mais r√°pidos para eliminarem a droga em pessoas XX, enquanto os idosos s√£o mais r√°pidos para eliminarem a droga nas pessoas XY. ¬† 7.9 ANOVA em blocos aleatorizados No delineamento experimental com blocos aleatorizados, cada fator √© agrupado em blocos, com r√©plicas de cada n√≠vel do fator representado em cada bloco (Nicholas J. Gotelli and Ellison 2012). O bloco √© uma √°rea ou per√≠odo de tempo dentro do qual as condi√ß√µes ambientais s√£o relativamente homog√™neas. O objetivo do uso dos blocos √© controlar fontes de varia√ß√µes indesejadas na vari√°vel dependente que n√£o s√£o de interesse do pesquisador. Desta maneira, podemos retirar dos res√≠duos os efeitos das varia√ß√µes indesejadas que n√£o s√£o do nosso interesse, e testar com maior poder estat√≠stico os efeitos dos tratamentos de interesse. Importante, os blocos devem ser arranjados de forma que as condi√ß√µes ambientais sejam mais similares dentro dos blocos do que entre os blocos. ¬† 7.9.0.1 Exemplo pr√°tico 1 - ANOVA em blocos aleatorizados Explica√ß√£o dos dados Neste exemplo, avaliaremos a riqueza de esp√©cies de anuros amostradas em po√ßas artificiais instaladas a diferentes dist√¢ncias de seis fragmentos florestais no sudeste do Brasil (da Silva et al. 2011). Os fragmentos florestais apresentam diferen√ßas entre si que n√£o s√£o do interesse do pesquisador. Por isso, eles foram inclu√≠dos como blocos nas an√°lises. As po√ßas artificiais foram instaladas em todos os fragmentos florestais com base no seguinte delineamento experimental (da Silva et al. 2011): i) quatro po√ßas no interior do fragmento a 100 m de dist√¢ncia da borda do fragmento; ii) quatro po√ßas no interior no fragmento a 50 m de dist√¢ncia da borda do fragmento; iii) quatro po√ßas na borda do fragmento; iv) quatro po√ßas na matriz de pastagem a 50 m de dist√¢ncia da borda do fragmento; e v) quatro po√ßas na matriz de pastagem a 100 m de dist√¢ncia da borda do fragmento. Percebam que todos os tratamentos foram instalados em todos os blocos. Pergunta: A dist√¢ncia da po√ßa artifical ao fragmento florestal influencia a riqueza de esp√©cies anuros? Predi√ß√µes Po√ßas na borda do fragmento florestal apresentar√£o maior riqueza de esp√©cies do que po√ßas distantes da borda. Vari√°veis Vari√°veis resposta e preditoras Dataframe com as po√ßas (unidade amostral) nas linhas e a riqueza de esp√©cies (vari√°vel reposta), dist√¢ncia dos fragmentos florestais (vari√°vel preditora categ√≥rica) e fragmentos florestais (blocos) nas colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. An√°lise Olhando os dados usando a fun√ß√£o head. head(dados_bloco) #&gt; Riqueza Blocos Pocas #&gt; 1 90 A Int-50m #&gt; 2 95 A Int-100m #&gt; 3 107 A Borda #&gt; 4 92 A Mat-50m #&gt; 5 89 A Mat-100m #&gt; 6 92 B Int-50m H√° duas formas de incluir os efeitos dos blocos nos modelos. ## An√°lise Anova em blocos aleatorizados model_bloco1 &lt;- aov(Riqueza ~ Pocas + Blocos, data = dados_bloco) summary(model_bloco1) #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Pocas 4 1504 376.1 2.907 0.0478 * #&gt; Blocos 5 1089 217.8 1.683 0.1846 #&gt; Residuals 20 2588 129.4 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 model_bloco2 &lt;- aov(Riqueza ~ Pocas + Error(Blocos), data = dados_bloco) summary(model_bloco2) #&gt; #&gt; Error: Blocos #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Residuals 5 1089 217.8 #&gt; #&gt; Error: Within #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Pocas 4 1504 376.1 2.907 0.0478 * #&gt; Residuals 20 2588 129.4 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Percebam que as duas formas apresentam os mesmos resultados para o efeito #‚Äô da dist√¢ncia das po√ßas que √© o fator de interesse no estudo. Lembre-se que nos delineamentos experimentais em bloco, o pesquisador n√£o est√° interessado no efeito do bloco, mas sim em controlar a varia√ß√£o associada a ele. O que n√£o pode acontecer √© ignorar o efeito do bloco que √© incorporado pelos res√≠duos quando n√£o informado no modelo. Veja abaixo a forma errada de analisar delineamento experimental com blocos. ## Forma errada de an√°lisar Anova em blocos modelo_errado &lt;- aov(Riqueza ~ Pocas, data = dados_bloco) anova(modelo_errado) #&gt; Analysis of Variance Table #&gt; #&gt; Response: Riqueza #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Pocas 4 1504.5 376.12 2.5576 0.06359 . #&gt; Residuals 25 3676.5 147.06 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 O resultado da ANOVA (Pr(&gt;F) &lt; 0.001) indica que devemos rejeitar a hip√≥tese nula que n√£o h√° diferen√ßa entre as m√©dias dos grupos. Contudo, os resultados n√£o mostram quais s√£o os grupos que apresentam diferen√ßas. Para isso, temos que realizar testes de compara√ß√µes m√∫ltiplas post-hoc para detectar os grupos que apresentam diferen√ßas significativas entre as m√©dias. ## Teste de Tuckey&#39;s honest significant difference pairs(lsmeans(model_bloco1, &quot;Pocas&quot;), adjust = &quot;tukey&quot;) #&gt; contrast estimate SE df t.ratio p.value #&gt; Borda - (Int-100m) 16.000 6.57 20 2.436 0.1463 #&gt; Borda - (Int-50m) 19.833 6.57 20 3.020 0.0472 #&gt; Borda - (Mat-100m) 15.833 6.57 20 2.411 0.1531 #&gt; Borda - (Mat-50m) 8.167 6.57 20 1.244 0.7269 #&gt; (Int-100m) - (Int-50m) 3.833 6.57 20 0.584 0.9760 #&gt; (Int-100m) - (Mat-100m) -0.167 6.57 20 -0.025 1.0000 #&gt; (Int-100m) - (Mat-50m) -7.833 6.57 20 -1.193 0.7553 #&gt; (Int-50m) - (Mat-100m) -4.000 6.57 20 -0.609 0.9720 #&gt; (Int-50m) - (Mat-50m) -11.667 6.57 20 -1.777 0.4135 #&gt; (Mat-100m) - (Mat-50m) -7.667 6.57 20 -1.167 0.7692 #&gt; #&gt; Results are averaged over the levels of: Blocos #&gt; P value adjustment: tukey method for comparing a family of 5 estimates Visualizar os resultados em gr√°fico. # Reordenando a ordem que os grupos ir√£o aparecer no gr√°fico. dados_bloco$Pocas &lt;- factor(dados_bloco$Pocas, levels = c(&quot;Int-100m&quot;, &quot;Int-50m&quot;, &quot;Borda&quot;, &quot;Mat-50m&quot;, &quot;Mat-100m&quot;)) ## Gr√°fico ggplot(data = dados_bloco, aes(x = Pocas, y = Riqueza)) + labs(x = &quot;Po√ßas artificiais&quot;, y = &quot;Riqueza de esp√©cies de anuros&quot;) + geom_boxplot(color = &quot;black&quot;, show.legend = FALSE, alpha = 0.4) + geom_jitter(shape = 16, position = position_jitter(0.1), cex = 4, alpha = 0.7) + scale_x_discrete(labels = c(&quot;-100m&quot;,&quot;-50m&quot;,&quot;Borda&quot;, &quot;50m&quot;, &quot;100m&quot;)) + tema_livro() + theme(legend.position = &quot;none&quot;) Interpreta√ß√£o dos resultados Neste exemplo, rejeitamos a hip√≥tese nula de que a dist√¢ncia das po√ßas artificiais at√© as bordas dos fragmentos florestais n√£o influ√™ncia a riqueza de esp√©cies de anuros. As po√ßas artificiais instaladas nas bordas dos fragmentos florestais apresentaram maior riqueza de esp√©cies do que as po√ßas distantes. ¬† 7.10 An√°lise de covari√¢ncia (ANCOVA) A ANCOVA pode ser compreendida como uma extens√£o da ANOVA com a adi√ß√£o de vari√°vel cont√≠nua (covari√°vel) medida em todas as unidades amostrais (Nicholas J. Gotelli and Ellison 2012). A ideia √© que a covari√°vel tamb√©m afete os valores da vari√°vel resposta. N√£o incluir a covari√°vel ir√° fazer com que a varia√ß√£o n√£o explicada pelo modelo concentre-se nos res√≠duos. Incluindo a covari√°vel, o tamanho do res√≠duo √© menor, e o teste para avaliar as diferen√ßas nos tratamentos, que √© o interesse do pesquisador, ter√° mais poder estat√≠stico. ¬† 7.10.0.1 Exemplo pr√°tico 1 - ANCOVA Explica√ß√£o dos dados Neste exemplo, avaliaremos o efeito da herbivoria na biomassa dos frutos de uma esp√©cie de √°rvore na Mata Atl√¢ntica. O delineamento experimental permitiu que alguns indiv√≠duos sofressem herbivoria e outros n√£o. Os pesquisadores tamb√©m mediram o tamanho da raiz dos ind√≠viduos para inseri-la como uma covari√°vel no modelo. Pergunta: A herbivoria diminiu a biomassa dos frutos? Predi√ß√µes Os indiv√≠duos que sofreram herbivoria ir√£o produzir frutos com menor biomassa do que os indiv√≠duos sem herbivoria. Vari√°veis Vari√°veis resposta e preditoras Dataframe com as indiv√≠duos da esp√©cie de planta (unidade amostral) nas linhas e a biomassa dos frutos (vari√°vel resposta), herbivoria (vari√°vel preditora categ√≥rica) e tamanho da raiz (covari√°vel cont√≠nua) nas colunas. Checklist Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas. 7.10.1 An√°lise Olhando os dados usando a fun√ß√£o head head(dados_ancova) #&gt; Raiz Biomassa Herbivoria #&gt; 1 6.225 59.77 Sem_herb #&gt; 2 6.487 60.98 Sem_herb #&gt; 3 4.919 14.73 Sem_herb #&gt; 4 5.130 19.28 Sem_herb #&gt; 5 5.417 34.25 Sem_herb #&gt; 6 5.359 35.53 Sem_herb C√°lculo da ANCOVA. ## Ancova modelo_ancova &lt;- lm(Biomassa ~ Herbivoria * Raiz, data = dados_ancova) # Verificando as premissas da Anova. plot_grid(plot_model(modelo_ancova, type = &quot;diag&quot;)) As premissas da anova est√£o adequadas. Vamos olhar os resultados do modelo. ## Resultados do modelo anova(modelo_ancova) #&gt; Analysis of Variance Table #&gt; #&gt; Response: Biomassa #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Herbivoria 1 1941.9 1941.9 35.101 8.764e-07 *** #&gt; Raiz 1 17434.1 17434.1 315.124 &lt; 2.2e-16 *** #&gt; Herbivoria:Raiz 1 136.7 136.7 2.471 0.1247 #&gt; Residuals 36 1991.7 55.3 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Percebam que o resultado da ANCOVA (Pr(&gt;F) &lt; 0.001) indica que tanto a herbivoria como o tamanho da raiz (covari√°vel) t√™m efeitos significativos na biomassa dos frutos. Contudo, a intera√ß√£o entre as vari√°veis n√£o foi signigicativa. Vamos usar o Likelihood ratio test (LRT) para ver se podemos seguir com um modelo mais simples (sem intera√ß√£o). ## Criando modelo sem intera√ß√£o modelo_ancova2 &lt;- lm(Biomassa ~ Herbivoria + Raiz, data = dados_ancova) ## Likelihood Rate Test lrtest(modelo_ancova, modelo_ancova2) #&gt; Likelihood ratio test #&gt; #&gt; Model 1: Biomassa ~ Herbivoria * Raiz #&gt; Model 2: Biomassa ~ Herbivoria + Raiz #&gt; #Df LogLik Df Chisq Pr(&gt;Chisq) #&gt; 1 5 -134.91 #&gt; 2 4 -136.24 -1 2.6554 0.1032 A intera√ß√£o n√£o √© importante. Seguiremos com o modelo mais simples. Visualizar os resultados em gr√°fico. ## Gr√°fico ggplot(data = dados_ancova, aes(x = Raiz, y = Biomassa, fill = Herbivoria)) + labs(x = &quot;Tamanho da raiz (cm)&quot;, y = &quot;Biomassa dos frutos (g)&quot;) + geom_point(size = 4, shape = 21, alpha = 0.7) + tema_livro() + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;), labels = c(&quot;Com herbivoria&quot;, &quot;Sem herbivoria&quot;)) + geom_smooth(aes(color = Herbivoria), method = &quot;lm&quot;, show.legend = FALSE) Interpreta√ß√£o dos resultados Neste exemplo, o tamanho da raiz (covari√°vel) tem uma rela√ß√£o positiva com a biomassa dos frutos. Quanto maior o tamanho da raiz, maior a biomassa dos frutos. Usando a ANCOVA e controlando o efeito da covari√°vel, percebemos que a herbivoria tamb√©m afeta a biomassa dos frutos. Os indiv√≠duos com mesmo tamanho de raiz que n√£o sofreram herbivoria produziram frutos com maior biomassa do que os indiv√≠duos com herbivoria. ¬† 7.10.2 Para se aprofundar Recomendamos aos interessados os livros: i) Zar (2010) Biostatiscal analysis; ii) Gotelli &amp; Ellison (2012) A primer of ecological statistics; e iii) Quinn &amp; Keough (2002) Experimental design and data analysis for biologists. Refer√™ncias "],["cap8.html", "Cap√≠tulo 8 Cap. 8 - An√°lises univariadas (modelos lineares mistos generalizados) 8.1 Introdu√ß√£o 8.2 Como um GLM funciona? 8.3 Como escolher a distribui√ß√£o correta para seus dados? 8.4 Dados de contagem: a distribui√ß√£o de Poisson 8.5 Dados de contagem: modelos quasi-likelihood 8.6 Dados de contagem: a distribui√ß√£o Binomial 8.7 An√°lise com dados de incid√™ncia 8.8 Dados de contagem com excesso de zeros 8.9 Dados ordinais: os modelos cumulative link 8.10 Dados cont√≠nuos: distribui√ß√£o beta 8.11 Leituras recomendadas", " Cap√≠tulo 8 Cap. 8 - An√°lises univariadas (modelos lineares mistos generalizados) Pr√©-requisitos do cap√≠tulo library(ecodados) library(visdat) library(tidyverse) library(lattice) library(RVAideMemoire) library(DHARMa) library(performance) library(MuMIn) library(piecewiseSEM) library(MASS) library(ggExtra) library(sciplot) library(emmeans) library(sjPlot) library(bbmle) library(glmmTMB) library(ordinal) library(car) 8.1 Introdu√ß√£o No cap√≠tulo anterior descrevemos sobre os modelos lineares (tamb√©m chamados de Modelos Lineares Gerais) que podem ser descritos pelo mesmo modelo matem√°tico de uma equa√ß√£o da reta do tipo:: Yi = a + b*xi + erro no qual o que difere uma regress√£o linear de uma an√°lise de vari√¢ncia √© a natureza do elemento xi, vari√°vel cont√≠nua para regress√£o, vari√°vel categ√≥rica no caso da ANOVA (que √© codificada numa matriz design para desenhos mais complexos). Nesse sentido, o que todos esses m√©todos t√™m em comum √© a vari√°vel resposta Y que √© um vetor num√©rico cont√≠nuo. Outro elemento em comum desses m√©todos √© a distribui√ß√£o de frequ√™ncia do erro. Se quiser mais detalhes como sobre modelos lineares podem ser escritos na forma de matrizes, consulte a introdu√ß√£o de (Fox, Negrete-Yankelevich, and Sosa 2015). Todos os modelos lineares assumem que a distribui√ß√£o do erro seja Gaussiana (ou Normal). Isso de certa forma limita o tipo de dado que pode ser usado como vari√°vel resposta por estas an√°lises. Por exemplo, dados de contagem (e.g., riqueza e abund√¢ncia de esp√©cies), frequ√™ncia (e.g., frequ√™ncia de ocorr√™ncia, porcentagem de cobertura vegetal), incid√™ncia (e.g., presen√ßa ou aus√™ncia de uma esp√©cie) ou propor√ß√£o (e.g., n√∫meros de animais infectados a cada 1000 animais) n√£o s√£o adequados para serem utilizados como vari√°veis resposta em modelos lineares. Uma pr√°tica comum quando nossos dados n√£o s√£o Normais √© transformar por log ou raiz quadrada. No entanto, para dados de contagem isso n√£o √© recomendado (veja (O‚ÄôHara and Kotze 2010), (Ives 2015), (Warton 2018)). Nestes casos devemos recorrer a um conjunto de modelos chamados Modelos Lineares Generalizados (GLM). Nestes modelos, o usu√°rio especifica a distribui√ß√£o de frequ√™ncia que deseja utilizar para modelar a vari√°vel resposta. Esta distribui√ß√£o de frequ√™ncia deve pertencer √† fam√≠lia exponencial, que inclui a distribui√ß√£o de Poisson, Gaussiana, Binomial, Binomial Negativa, Gamma, Bernoulli e Beta. Ainda √© poss√≠vel utilizar Cumulative Link Models para modelar dados ordinais (fatores cuja ordem dos elementos importa, tais como muito baixo, baixo, alto e muito alto). Abaixo vamos ver um pouco sobre como um GLM funciona e exemplos com cada uma destas distribui√ß√µes. 8.2 Como um GLM funciona? Diferentemente do modelo linear, um GLM estima os par√¢metros por meio de M√°xima Verossimilhan√ßa (ML) ao inv√©s dos m√≠nimos quadrados comuns (OLS). Portanto, um GLM relaciona a distribui√ß√£o da vari√°vel resposta aos preditores lineares por meio de uma fun√ß√£o de liga√ß√£o. Por exemplo, no caso da distribui√ß√£o de Poisson usa-se uma liga√ß√£o logar√≠tmica (tamb√©m chamada de log link) que garante que o valores ajustados s√£o sempre n√£o negativos. Portanto, um GLM √© composto por esses 3 componentes: fun√ß√£o de distribui√ß√£o, preditor linear e fun√ß√£o de liga√ß√£o. A fun√ß√£o de distribui√ß√£o √© uma hip√≥tese sobre a distribui√ß√£o da vari√°vel resposta Yi. Isso tamb√©m define a m√©dia e a vari√¢ncia de Yi. J√° a fun√ß√£o de liga√ß√£o define a rela√ß√£o entre o valor m√©dio de Yi e da parte sistem√°tica. Esta √© tamb√©m chamada de liga√ß√£o entre a m√©dia e a parte sistem√°tica do modelo. Existem tr√™s tipos de fun√ß√£o de liga√ß√£o: ‚Ä¢Identity link, que √© definido por g(¬µ)= Œº, e modela a m√©dia ou valor esperado de Y. Usado em modelos lineares padr√£o. ‚Ä¢Log link, que √© g(Œº)=log(Œº), e modela o log da m√©dia. √â usado para dados de contagem (que n√£o podem assumir valores negativos) em modelos log-linear ‚Ä¢Logit link, que √© g(Œº)=log[Œº /(1-Œº )], e √© usado para dados bin√°rios e regress√£o log√≠stica Logo, um modelo linear pode ser visto como um caso particular de um GLM em que utiliza distribui√ß√£o Gaussiana, com identity link 8.3 Como escolher a distribui√ß√£o correta para seus dados? 8.3.1 Para dados cont√≠nuos Se Y √© uma vari√°vel cont√≠nua, a sua distribui√ß√£o de probabilidade deve ser normal. Nesses casos as distribui√ß√µes recomendadas s√£o a Gaussiana (Normal) ou Gamma. Para essas distribui√ß√µes, o par√¢metro de dispers√£o √© estimado separadamente da m√©dia e √© √†s vezes, chamado de nuisance parameter. Uma particularidade da distribui√ß√£o Gamma √© que ela s√≥ aceita valores cont√≠nuos positivos. 8.3.2 Para dados de contagem Se Y √© bin√°rio (e.g., vivo ou morto), a distribui√ß√£o de probabilidade deve ser binomial. Se Y √© uma contagem (e.g., abund√¢ncia ou riqueza de esp√©cies), ent√£o a distribui√ß√£o de probabilidade deve ser Poisson ou Binomial Negativa. Existem tamb√©m corre√ß√µes dessas distribui√ß√µes quando apresentam sobredispers√£o, tais como quasi-Poisson ou quasi-Negative binomial. Falaremos delas no momento certo. Para distribui√ß√µes tais como binomial e Poisson, a vari√¢ncia deve ser igual √† media e o par√¢metro de dispers√£o √© sempre 1. Na maioria dos dados ecol√≥gicos esse pressuposto n√£o √© cumprido, veremos estrat√©gias para lidar com isso logo √† frente. As fun√ß√µes Ord_plot e goodfit do pacote vcd podem auxiliar na escolha da distribui√ß√£o para dados de contagem. 8.4 Dados de contagem: a distribui√ß√£o de Poisson Para casos em que estamos interessados em quantificar uma vari√°vel discreta, ou seja, uma vari√°vel positiva, representada sempre por n√∫meros inteiros, contendo um n√∫mero finito de possibilidades, devemos utilizar a distribui√ß√£o de Poisson. Esta distribui√ß√£o √© peculiar por ser descrita apenas por um par√¢metro livre (\\(\\lambda\\)). Isso quer dizer que tanto a m√©dia quanto a vari√¢ncia dos dados s√£o descritos por um √∫nico par√¢metro, o que implica em dizer que a m√©dia e a vari√¢ncia t√™m de ser iguais. Vamos ver um exemplo com dados reais. 8.4.0.1 Exemplo 1 Explica√ß√£o dos dados Neste exemplo iremos utilizar dados de riqueza de anf√≠bios anuros coletados em 40 po√ßas, a√ßudes e brejos ao redor de fragmentos florestais no Noroeste Paulista (Prado and Rossa-Feres 2014). Os autores mediram seis vari√°veis em escala local e outras tr√™s em escala de paisagem. Pergunta A dist√¢ncia linear para o corpo d‚Äô√°gua mais pr√≥ximo influencia a abund√¢ncia total de esp√©cies de anuros? Predi√ß√µes Corpos d‚Äô√°gua mais conectados permitem que indiv√≠duos dispersem entre eles com maior facilidade, suportando melhor din√¢micas de metapopula√ß√µes. Portanto, espero que po√ßas que estejam mais conectadas entre si tenham maior riqueza total de sapos. Vari√°veis ‚Ä¢ Vari√°vel reposta: riqueza de sapos em 40 po√ßas. ‚Ä¢ Vari√°vel preditora: dist√¢ncia da po√ßa focal para a mais pr√≥xima na escala da paisagem Checklist ‚Ä¢ Verificar se o seu dataframe est√° com as unidades amostrais nas linhas (neste caso po√ßas) e vari√°veis nas colunas. Antes de come√ßar com a an√°lise, vamos primeiro explorar os dados. head(fragmentos) #&gt; locality site Riqueza_obs Riqueza_HB Bsc Dne Dnm Dnn Dns Hal Hra Lfu Lla Lpo Eun Pce Pcu #&gt; 1 MAC MacAc1 3 6 0 0 0 0 0 0 0 0 0 0 1 0 0 #&gt; 2 MAC MacAc2 11 13 1 0 1 1 0 0 1 1 0 1 0 0 1 #&gt; 3 MAC MacAc3 10 12 1 0 0 0 0 0 1 1 0 1 1 0 1 #&gt; 4 MAC MacAc4 10 13 1 1 1 1 0 1 1 0 0 1 0 0 1 #&gt; 5 MAC MacAc5 3 6 0 0 0 0 0 0 0 1 0 0 1 0 1 #&gt; 6 MAC MacBr1 9 12 0 0 0 1 0 1 1 1 1 0 1 0 1 #&gt; Pfa1 Ppa Sfm Sfv Ebi Esp hydrop hydrop2 vegcov nveg fish area #&gt; 1 0 0 0 1 0 1 -2.553590 -2.23573 -1.461851 -1.965130 -1.508310 -2.418270 #&gt; 2 1 1 1 0 1 0 0.573255 0.60630 -1.145775 -0.158114 0.646419 0.147353 #&gt; 3 1 0 1 1 0 0 0.573255 0.60630 -0.987737 -1.061622 -1.508310 -0.564022 #&gt; 4 1 0 1 0 0 0 0.573255 0.60630 0.908718 -0.158114 0.646419 -0.348279 #&gt; 5 0 0 0 0 0 0 -2.553590 -2.23573 -1.461851 -1.965130 -1.508310 -2.315159 #&gt; 6 1 0 0 0 0 1 0.573255 0.60630 1.382832 -0.158114 -1.508310 -0.601947 #&gt; area2 depth forcov forcov2 forcov10 dfrag dfrag2 dwater dwater2 #&gt; 1 -1.884470 -1.232668 -0.604596 -0.672774 -6.045965 0.410084 0.166782 1.198175 1.166645 #&gt; 2 0.019560 0.821168 -0.020849 -0.152952 -0.208489 -0.097045 -0.381401 0.970207 0.864035 #&gt; 3 -0.699829 -0.704539 -0.013816 -0.146124 -0.138159 -1.242271 -1.059858 -0.121245 -0.299232 #&gt; 4 -0.497176 0.821168 -0.171663 -0.296136 -1.716633 -1.242271 -1.059858 -0.087507 -0.270350 #&gt; 5 -1.844802 -1.306019 0.203364 0.071358 2.033643 -0.471888 -0.688845 0.162610 -0.042156 #&gt; 6 -0.734057 -1.306019 0.203364 0.071358 2.033643 -1.242271 -1.059858 -0.121245 -0.299232 #&gt; X Y #&gt; 1 -49.9376 -20.7408 #&gt; 2 -49.9353 -20.7410 #&gt; 3 -49.9348 -20.7419 #&gt; 4 -49.9334 -20.7462 #&gt; 5 -49.9270 -20.7453 #&gt; 6 -49.9271 -20.7451 glimpse(fragmentos) #&gt; Rows: 40 #&gt; Columns: 40 #&gt; $ locality &lt;chr&gt; &quot;MAC&quot;, &quot;MAC&quot;, &quot;MAC&quot;, &quot;MAC&quot;, &quot;MAC&quot;, &quot;MAC&quot;, &quot;NOV&quot;, &quot;NOV&quot;, &quot;NOV&quot;, &quot;NOV&quot;, &quot;P‚Ä¶ #&gt; $ site &lt;chr&gt; &quot;MacAc1&quot;, &quot;MacAc2&quot;, &quot;MacAc3&quot;, &quot;MacAc4&quot;, &quot;MacAc5&quot;, &quot;MacBr1&quot;, &quot;NovBr1&quot;, &quot;N‚Ä¶ #&gt; $ Riqueza_obs &lt;int&gt; 3, 11, 10, 10, 3, 9, 2, 8, 9, 8, 6, 4, 8, 8, 6, 17, 15, 13, 8, 10, 12, 1‚Ä¶ #&gt; $ Riqueza_HB &lt;int&gt; 6, 13, 12, 13, 6, 12, 5, 11, 12, 11, 8, 7, 10, 11, 9, 18, 17, 15, 11, 13‚Ä¶ #&gt; $ Bsc &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, ‚Ä¶ #&gt; $ Dne &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, ‚Ä¶ #&gt; $ Dnm &lt;int&gt; 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, ‚Ä¶ #&gt; $ Dnn &lt;int&gt; 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶ #&gt; $ Dns &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, ‚Ä¶ #&gt; $ Hal &lt;int&gt; 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, ‚Ä¶ #&gt; $ Hra &lt;int&gt; 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, ‚Ä¶ #&gt; $ Lfu &lt;int&gt; 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶ #&gt; $ Lla &lt;int&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ‚Ä¶ #&gt; $ Lpo &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ‚Ä¶ #&gt; $ Eun &lt;int&gt; 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, ‚Ä¶ #&gt; $ Pce &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, ‚Ä¶ #&gt; $ Pcu &lt;int&gt; 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶ #&gt; $ Pfa1 &lt;int&gt; 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶ #&gt; $ Ppa &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, ‚Ä¶ #&gt; $ Sfm &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, ‚Ä¶ #&gt; $ Sfv &lt;int&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, ‚Ä¶ #&gt; $ Ebi &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, ‚Ä¶ #&gt; $ Esp &lt;int&gt; 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ‚Ä¶ #&gt; $ hydrop &lt;dbl&gt; -2.553590, 0.573255, 0.573255, 0.573255, -2.553590, 0.573255, 0.573255, ‚Ä¶ #&gt; $ hydrop2 &lt;dbl&gt; -2.235730, 0.606300, 0.606300, 0.606300, -2.235730, 0.606300, 0.606300, ‚Ä¶ #&gt; $ vegcov &lt;dbl&gt; -1.461851, -1.145775, -0.987737, 0.908718, -1.461851, 1.382832, 1.382832‚Ä¶ #&gt; $ nveg &lt;dbl&gt; -1.965130, -0.158114, -1.061622, -0.158114, -1.965130, -0.158114, 0.7453‚Ä¶ #&gt; $ fish &lt;dbl&gt; -1.508310, 0.646419, -1.508310, 0.646419, -1.508310, -1.508310, 0.646419‚Ä¶ #&gt; $ area &lt;dbl&gt; -2.418270, 0.147353, -0.564022, -0.348279, -2.315159, -0.601947, 1.55619‚Ä¶ #&gt; $ area2 &lt;dbl&gt; -1.884470, 0.019560, -0.699829, -0.497176, -1.844802, -0.734057, 1.87782‚Ä¶ #&gt; $ depth &lt;dbl&gt; -1.232668, 0.821168, -0.704539, 0.821168, -1.306019, -1.306019, -0.64585‚Ä¶ #&gt; $ forcov &lt;dbl&gt; -0.604596, -0.020849, -0.013816, -0.171663, 0.203364, 0.203364, 0.562496‚Ä¶ #&gt; $ forcov2 &lt;dbl&gt; -0.672774, -0.152952, -0.146124, -0.296136, 0.071358, 0.071358, 0.459151‚Ä¶ #&gt; $ forcov10 &lt;dbl&gt; -6.045965, -0.208489, -0.138159, -1.716633, 2.033643, 2.033643, 5.624958‚Ä¶ #&gt; $ dfrag &lt;dbl&gt; 0.410084, -0.097045, -1.242271, -1.242271, -0.471888, -1.242271, 1.30793‚Ä¶ #&gt; $ dfrag2 &lt;dbl&gt; 0.166782, -0.381401, -1.059858, -1.059858, -0.688845, -1.059858, 1.51027‚Ä¶ #&gt; $ dwater &lt;dbl&gt; 1.198175, 0.970207, -0.121245, -0.087507, 0.162610, -0.121245, -0.087507‚Ä¶ #&gt; $ dwater2 &lt;dbl&gt; 1.166645, 0.864035, -0.299232, -0.270350, -0.042156, -0.299232, -0.27035‚Ä¶ #&gt; $ X &lt;dbl&gt; -49.9376, -49.9353, -49.9348, -49.9334, -49.9270, -49.9271, -49.2742, -4‚Ä¶ #&gt; $ Y &lt;dbl&gt; -20.7408, -20.7410, -20.7419, -20.7462, -20.7453, -20.7451, -21.5187, -2‚Ä¶ Percebam que o data frame cont√©m 40 colunas. Neste conjunto de dados as vari√°veis preditoras j√° est√£o padronizadas com m√©dia 0 e desvio padr√£o 1. As vari√°veis com ‚Äú2‚Äù indicam vari√°veis quadr√°ticas (podem ser usadas para se testar rela√ß√µes n√£o lineares). Tamb√©m temos a riqueza observada e a estimada (Riqueza_HB) e as coordenadas geogr√°ficas (X e Y). Vamos agora explorar os dados e ver como √© a rela√ß√£o entre riqueza e dist√¢ncia para a po√ßa mais pr√≥xima. Sempre √© recomendado visualizar os dados antes de efetivamente os modelar para se ter uma id√©ia da rela√ß√£o entre as vari√°veis: # ------------------------------------------------------------------------- ggplot(fragmentos, aes(dfrag, Riqueza_obs))+ geom_point(size=4, alpha = 0.7)+ stat_smooth(method = &quot;lm&quot;) Aqui vemos que h√° de fato uma rela√ß√£o linear positiva entre as duas vari√°veis. A partir de agora vamos sempre usar uma mesma estrutura para realizar nossos exerc√≠cios de modelagem: Primeiro vamos especificar o modelo; Depois realizar a diagnose; Por √∫ltimo realizar infer√™ncia a partir do nosso modelo. 8.4.0.1.1 Modelagem O primeiro argumento da fun√ß√£o glm√© uma f√≥rmula, em que na parte esquerda temos a vari√°vel resposta seguida do s√≠mbolo ~ (l√™-se: modelado em fun√ß√£o de) seguido pelas vari√°veis preditoras. Aqui podemos usar uma ou mais vari√°veis e testar o seu efeito aditivo (usando o sinal de +) ou a intera√ß√£o entre elas (usando o sinal de *). Um bom resumo sobre como especificar o seu modelo pode ser encontrada aqui neste blog. Aqui optamos por um modelo bem simples modelando a riqueza de anf√≠bios apenas em fun√ß√£o da dist√¢ncia para o fragmento mais pr√≥ximo. mod_pois &lt;- glm(Riqueza_obs~dfrag, family = poisson(link = &quot;log&quot;), data = fragmentos) Assim como modelos lineares que vimos no Cap√≠tulo 6, GLMs com distribui√ß√£o de Poisson requerem que se teste os pressupostos, incluindo sobredispers√£o e infla√ß√£o de zeros. 8.4.0.1.2 Diagnose b√°sica dos res√≠duos do modelo Iremos realizar tr√™s diagnoses b√°sicas dos GLMs, avaliando diferentes aspectos do modelo: Heterogeneidade da vari√¢ncia e normalidade dos res√≠duos Overdispersion Zero-inflation Vamos come√ßar avaliando as heterogeneidade da vari√¢ncia e normalidade dos res√≠duos: plotresid(mod_pois, shapiro = TRUE)#S√ì O PLOT DE RES√çDUOS par(mfrow=c(2,2)) plot(mod_pois)#TODOS OS 4 PLOTS par(mfrow=c(1,1)) Aqui vemos quatro gr√°ficos. Na primeira coluna temos dois gr√°ficos dos valores preditos (brutos ou padronizados pela raiz quadrada) contra os res√≠duos. Eles medem desvio em rela√ß√£o √† homogeneidade de vari√¢ncia. Os quatro gr√°ficos n√£o devem ter nenhum padr√£o aparente, ou seja, os pontos devem cair em cima da linha pontilhada. Neste caso, vemos que as linhas vermelhas (que indicam a tend√™ncia dos dados) est√£o praticamente retas seguindo a linha pontilhada, sugerindo que n√£o exista heterogeneidade de vari√¢ncia dos res√≠duos. O gr√°fico superior direito √© o plot de quantis que mede desvios da normalidade. No gr√°fico inferior direito, os valores extremos s√£o todos aqueles que estejam a mais de uma unidade da dist√¢ncia de Cook (linha pontilhada vermelha). Tamb√©m n√£o temos problemas com esse pressuposto do modelo aqui. Vemos que nos quatro plots alguns dados, 1, 7 e 30 (referem-se √†s linhas do data.frame) aparecem identificados, pois apresentam ligeiro desvio da normalidade e est√£o distantes da m√©dia. No entanto, n√£o √© algo para nos preocuparmos pois n√£o s√£o valores muito extremos. Portanto, a diagnose indicou que o modelo com Poisson parece ser adequado para modelar estes dados, ao menos em termos de homogeneidade de vari√¢ncia. 8.4.0.1.3 Diagnose avan√ßada Alguns pacotes permitem calcular outros aspectos do modelo que facilitam a diagnose, ou seja, se podemos de fato confiar nos par√¢metros estimados por eles, incluindo valores de signific√¢ncia. Um pressuposto importante dos modelos de contagem (incluindo Poisson) √© a overdispersion (sobredispers√£o). Vejamos como o pacote DHARMa funciona: simulationOutput &lt;- simulateResiduals(fittedModel = mod_pois, plot = TRUE) O plot claramente indica que h√° problema com overdispersion, mas n√£o em termos de desvios de normalidade (KS test) ou outlier, j√° que apenas o primeiro foi significativo (aparece em vermelho). 8.4.0.1.4 Detectando e lidando com overdispersion O que √© sobredispers√£o (ou overdispersion)? Ela ocorre quando a vari√¢ncia observada √© muito maior do que aquela predita pelo modelo. Para modelos que utilizam a distribui√ß√£o de Poisson, isso ocorre quando a vari√¢ncia aumenta com a m√©dia. Lembre-se de que esta distribui√ß√£o tem apenas um √∫nico par√¢metro para descrever tanto a m√©dia quanto a vari√¢ncia (\\(\\lambda\\)). Portanto, a vari√¢ncia tem de ser igual √† m√©dia. No entanto, se a vari√¢ncia nos dados observados for muito maior do que a m√©dia, dizemos que h√° sobredispers√£o nos dados. Existem duas formas de diagnosticar overdispersion que est√£o implementadas na maioria dos pacotes. Aqui vamos demonstr√°-las usando as fun√ß√µes check_overdispersion e testDispersion dispon√≠veis nos pacotes performance e DHARMa, respectivamente. A fun√ß√£o testDispersion do DHARMa utiliza um m√©todo de aleatoriza√ß√£o dos res√≠duos para determinar se h√° overdispersion nos dados, cuja vantagem √© que aborda diretamente a varia√ß√£o nos dados, ao inv√©s de medir o ajuste do modelo em si, com outros testes. par(mfrow=c(1,1)) testDispersion(mod_pois)#modelo tem overdispersion #&gt; #&gt; DHARMa nonparametric dispersion test via sd of residuals fitted vs. simulated #&gt; #&gt; data: simulationOutput #&gt; dispersion = 1.6489, p-value &lt; 2.2e-16 #&gt; alternative hypothesis: two.sided Aqui temos um gr√°fico e o resultado novamente do teste de overdispersion (que j√° aparecia no gr√°fico anterior) mostrando que de fato h√° overdispersion: perceba que o valor de P √© significativo. O gr√°fico nos motra em preto a distribui√ß√£o dos res√≠duos aleatorizados e a linha vermelha o valor observado da estat√≠stica. J√° que a linha est√° bem √† direita da distribui√ß√£o, isso indica overdispersion, se estivese √† esquerda seria o caso de underdispersion. Agora vamos utilizar a fun√ß√£o check_overdisperion que utiliza uma distribui√ß√£o qui-quadradado e o valor de dispersion ratio para testar a presen√ßa de overdispersion no modelo. Esse teste tamb√©m pode ser feito com a fun√ß√£o acima ao se especificar o argumento type=\"PearsonChisq\" check_overdispersion(mod_pois)#modelo tem overdispersion #&gt; # Overdispersion test #&gt; #&gt; dispersion ratio = 1.657 #&gt; Pearson&#39;s Chi-Squared = 62.951 #&gt; p-value = 0.007 Quando este resultado √© significativo, como vimos na √∫ltima linha acima, isso indica overdispersion. summary(mod_pois) #&gt; #&gt; Call: #&gt; glm(formula = Riqueza_obs ~ dfrag, family = poisson(link = &quot;log&quot;), #&gt; data = fragmentos) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -3.3467 -0.9110 0.0942 0.8336 2.2773 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 2.3051 0.0500 46.101 &lt;2e-16 *** #&gt; dfrag 0.0718 0.0507 1.416 0.157 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for poisson family taken to be 1) #&gt; #&gt; Null deviance: 70.868 on 39 degrees of freedom #&gt; Residual deviance: 68.856 on 38 degrees of freedom #&gt; AIC: 235.29 #&gt; #&gt; Number of Fisher Scoring iterations: 4 Na parte de baixo do output da fun√ß√£o summary tamb√©m podemos calcular o dispersion parameter dividindo o residual deviance pelos graus de liberdade dos res√≠duos. Esta √© outra maneira f√°cil e r√°pida de detectar overdispersion. Neste exemplo temos que Dispersion parameter = 1.8119903. Quando esse valor √© pr√≥ximo de 1 isso sugere que n√£o h√° overdispersion. No entanto, se ele for maior que 1.5 isso sugere que o modelo sofre de overdispersion e que devemos usar outra distribui√ß√£o, tal como a distribui√ß√£o binomial negativa. Al√©m disso, uma outra forma de diagnosticar o modelo podemos √© calcular os res√≠duos de Pearson (res√≠duos normalizados), que √© basicamente a raiz quadrada da vari√¢ncia da vari√°vel resposta. 8.4.0.1.5 Infla√ß√£o de zeros Qualquer das formas mostradas acima de diagnosticar overdispersion pode ser usada na maioria das vezes, com exce√ß√£o de dados com muitos zeros (pouca vari√¢ncia). Por isso devemos tamb√©m testar se o nosso modelo sofre de infla√ß√£o de zeros. Vejamos como isso funciona usando as fun√ß√µes check_zeroinflation no pacote performanace e testZeroInflation no pacote DHARMa: check_zeroinflation(mod_pois)#para diagnosticar se o modelo sofre de zero inflation #&gt; Model has no observed zeros in the response variable. #&gt; NULL e no DHARMa testZeroInflation(mod_pois) # para testar se existe zero inflation #&gt; #&gt; DHARMa zero-inflation test via comparison to expected zeros with simulation under #&gt; H0 = fitted model #&gt; #&gt; data: simulationOutput #&gt; ratioObsSim = NaN, p-value = 1 #&gt; alternative hypothesis: two.sided Tanto a fun√ß√£o do DHARMa quanto do performance conseguiram detectar que o modelo tem problemas com overdispersion, ou sobre dispers√£o, mas isso n√£o √© causado pelo excesso de zeros. Como j√° dissemos acima, no caso da distribui√ß√£o Poisson, tanto a m√©dia quanto a vari√¢ncia s√£o modeladas pelo mesmo par√¢metro (\\(\\lambda\\)). Isso faz com que esta distribui√ß√£o n√£o seja muito √∫til para modelar dados de contagem em que haja muita vari√¢ncia em torno da m√©dia. Esse infelizmente √© o caso da grande maioria dos dados ecol√≥gicos. Por estes motivos n√£o podemos fazer infer√™ncia com este modelo porque os par√¢metros estimados n√£o s√£o confi√°veis. Mas vejamos como seria feita essa infer√™ncia caso este modelo fosse adequado. 8.4.0.1.6 Infer√™ncia Aqui iremos apresentar v√°rias fun√ß√µes para calcular o coeficiente de determina√ß√£o (R2). No caso de GLM(M)s, n√£o h√° um consenso sobre como se calcula este coeficiente, havendo v√°rias propostas que utilizam maneiras diferentes de estimar a heterogeneidade de vari√¢ncia e covari√¢ncia entre observa√ß√µes dos res√≠duos, veja (Nakagawa, Johnson, and Schielzeth 2017) e (Ives 2015) para maiores detalhes, assim como o help das respectivas fun√ß√µes. ## Coeficientes estimados pelo modelo summary(mod_pois) #&gt; #&gt; Call: #&gt; glm(formula = Riqueza_obs ~ dfrag, family = poisson(link = &quot;log&quot;), #&gt; data = fragmentos) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -3.3467 -0.9110 0.0942 0.8336 2.2773 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 2.3051 0.0500 46.101 &lt;2e-16 *** #&gt; dfrag 0.0718 0.0507 1.416 0.157 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for poisson family taken to be 1) #&gt; #&gt; Null deviance: 70.868 on 39 degrees of freedom #&gt; Residual deviance: 68.856 on 38 degrees of freedom #&gt; AIC: 235.29 #&gt; #&gt; Number of Fisher Scoring iterations: 4 ## Calculando o R2 do modelo r.squaredGLMM(mod_pois) #&gt; R2m R2c #&gt; delta 0.04925800 0.04925800 #&gt; lognormal 0.05154558 0.05154558 #&gt; trigamma 0.04696308 0.04696308 rsquared(mod_pois) #&gt; Response family link method R.squared #&gt; 1 Riqueza_obs poisson log nagelkerke 0.04919844 r2(mod_pois) #&gt; # R2 for Generalized Linear Regression #&gt; Nagelkerke&#39;s R2: 0.059 Podemos ver que os valores de R2 s√£o bem baixos (em torno de 4 - 5%), independente do m√©todo que usamos pra calcul√°-lo. 8.4.0.1.7 Plot do modelo predito a1 &lt;- ggplot(fragmentos, aes(dfrag, Riqueza_obs))+ geom_point(cex = 4,alpha = 0.7)+ geom_smooth(method = &quot;glm&quot;, formula = y~x, method.args = list(family =&quot;poisson&quot;), se=TRUE)+ labs(x=&quot;Dist√¢ncia para o fragmento mais pr√≥ximo&quot;, y=&quot;Riqueza observada&quot;) ggMarginal(a1, fill=&quot;red&quot;) üìù Importante Aqui vemos que h√° uma leve tend√™ncia na rela√ß√£o positiva entre dist√¢ncia para o fragmento mais pr√≥ximo e a riqueza de anf√≠bios observada. No entanto, h√° uma grande dispers√£o nos dados ao redor da reta do modelo, fazendo com que a rela√ß√£o n√£o seja de fato significativa e tenhamos um R2 bem baixo. Caso pud√©ssemos confiar nos par√¢metros deste modelo poder√≠amos dizer que existe uma leve tend√™ncia a um aumento da riqueza observada de anf√≠bios anuros √† medida que aumenta a dist√¢ncia da po√ßa para o fragmento mais pr√≥ximo. 8.4.1 O que causa a overdispersion? Existem dois conjuntos de causas: aparente ou real. As causas aparentes s√£o geradas pela m√° especifica√ß√£o do modelo, tais como: 1. n√£o inclus√£o de covari√°veis ou intera√ß√µes no modelo; presen√ßa de outliers na vari√°vel resposta, efeitos n√£o lineares da covari√°vel (X2, X3‚Ä¶); escolha errada da fun√ß√£o de liga√ß√£o (link function). As causas reais incluem: vari√¢ncia maior que a m√©dia; muitos zeros; agrega√ß√£o de observa√ß√µes; correla√ß√£o entre observa√ß√µes (n√£o independ√™ncia). 8.4.2 O que fazer se seu modelo tiver overdispersion? Depois de tentar corrigir poss√≠veis m√°s especifica√ß√µes, como as listadas acima, existem duas alternativas: usar outra distribui√ß√£o, tal como Binomial negativa caso o dispersion parameter seja maior que 15 ou 20; ou Usar um modelo com corre√ß√£o de erro da sobredispers√£o, caso 1.5 &lt; dispersion &gt; 15. Vejamos agora as caracter√≠sticas da distribui√ß√£o Binomial negativa. Geralmente, dados de contagem em estudos ecol√≥gicos n√£o seguem uma distribui√ß√£o Poisson, pois h√° muita dispers√£o (vari√¢ncia) nos dados. Logo, o pressuposto da distribui√ß√£o Poisson, i.e., de que a m√©dia e vari√¢ncia s√£o descritas por um mesmo par√¢metro (\\(\\lambda\\)) √© quebrado. Como vimos, overdispersion (ou sobredispers√£o) √© um problema comum ao analisar dados ecol√≥gicos e deve necessariamente ser diagnosticado no modelo. Uma maneira de lidar com esse tipo de problema √© utilizar uma outra distribui√ß√£o diferente da Poisson. A binomial negativa pode ser entendida como uma mistura da distibui√ß√£o Poisson e Gamma, ou seja, ela aceita dados de contagem que sejam positivos, mas sem zero. A grande vantagem desta distribui√ß√£o √© que, diferentemente da Poisson, ela tem um par√¢metro para modelar a m√©dia (\\(\\lambda\\)) e outro para modelar a vari√¢ncia (k). Logo, ela permite modelar dados em que a m√©dia √© diferente da vari√¢ncia. Vejamos um exemplo. Aqui vamos continuar com estes dados para ver como o modelo se comporta com essa nova distribui√ß√£o especificada. Para isso vamos utilizar a fun√ß√£o glm.nb do pacote MASS: 8.4.2.1 Modelagem mod_nb &lt;- glm.nb(Riqueza_obs~dfrag, data = fragmentos) 8.4.2.1.1 Diagnose res√≠duos Assim como fizemos com o modelo com Poisson, vamos agora diagnosticar os res√≠duos: par(mfrow=c(2,2)) plot(mod_nb) par(mfrow=c(1,1)) (chat &lt;- deviance(mod_nb) / df.residual(mod_nb))#DISPERSION PARAMETER #&gt; [1] 1.126184 Compare estes gr√°ficos com os do modelo anterior com distribui√ß√£o Poisson. Eles s√£o praticamente id√™nticos, ou seja, o modelo com Poisson j√° n√£o tinha heterogeneidade de vari√¢ncia nem problemas com normalidade dos res√≠duos. Agora vejamos se o problema com overdispersion foi resolvido: simulationOutput &lt;- simulateResiduals(fittedModel = mod_nb, plot = TRUE) Na diagnose do modelo pelo DHARMa vemos que bastou mudar a distribui√ß√£o de probabilidade que o problema de overdispersion foi resolvido (nenhum teste foi significativo no quadro da esquerda), e como j√° sab√≠amos, n√£o h√° problemas com heterogeneidade de vari√¢ncia (plot da direita mostrando a tend√™ncia entre o predito e res√≠duos pra cada quantil), nem de outliers. O dispersion parameter √© mais pr√≥ximo de 1 do que no modelo com Poisson. Agora sim podemos levar em conta o R2 ‚Ä¶ 8.4.2.1.2 Infer√™ncia rsquared(mod_nb) #&gt; Response family link method R.squared #&gt; 1 Riqueza_obs Negative Binomial(14.7068) log nagelkerke 0.02935674 ‚Ä¶que parece um pouco menor do que anteriormente. Perceba que aqui utilizamos somente uma das fun√ß√µes apresentadas anteriormente, j√° que se trata de um modelo GLM com binomial negativa, calculamos o R2 pelo m√©todo de Nagelkerke. 8.4.2.1.3 Interpreta√ß√£o dos resultados summary(mod_nb) #&gt; #&gt; Call: #&gt; glm.nb(formula = Riqueza_obs ~ dfrag, data = fragmentos, init.theta = 14.70679964, #&gt; link = log) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.7569 -0.7068 0.0694 0.6194 1.6546 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 2.30504 0.06481 35.567 &lt;2e-16 *** #&gt; dfrag 0.07248 0.06571 1.103 0.27 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for Negative Binomial(14.7068) family taken to be 1) #&gt; #&gt; Null deviance: 44.002 on 39 degrees of freedom #&gt; Residual deviance: 42.795 on 38 degrees of freedom #&gt; AIC: 231.68 #&gt; #&gt; Number of Fisher Scoring iterations: 1 #&gt; #&gt; #&gt; Theta: 14.71 #&gt; Std. Err.: 8.62 #&gt; #&gt; 2 x log-likelihood: -225.68 üìù Importante Aqui vemos que o resultado em termos de valor de P n√£o mudou, ou seja, a dist√¢ncia par ao fragmento mais pr√≥ximo n√£o foi significativo. Mas vejam que o coeficiente (slope) mudou um pouco, antes era 0.0718 (SE=0.0507) e com binomial negativa passa a ser 0.07248 (SE=0.06571). 8.4.2.1.4 Plot do modelo predito ggplot(fragmentos, aes(dfrag, Riqueza_obs))+ geom_point(size=4, alpha=0.7)+ geom_smooth(method = &quot;glm.nb&quot;, formula = y~x, se=TRUE)+ labs(x=&quot;Dist√¢ncia para o fragmento mais pr√≥ximo&quot;, y=&quot;Riqueza observada&quot;) Aqui vemos que a reta predita pelo modelo √© muito similar ao que tivemos com o Poisson. No entanto, agora que sabemos que este modelo com binomial negativa foi corretamente especificado e podemos confiar nos par√¢metros estimados. 8.5 Dados de contagem: modelos quasi-likelihood Como dissemos acima, uma outra alternativa para ajustar modelos GLM a dados de contagem s√£o os chamados ‚Äúquasi-likelihood,‚Äù tais como quasi-Poisson e quasi-binomial. Dependendo do valor do dispersion parameter, pode ser √∫til escolher este tipo de modelo. No entanto, eles v√™m com uma desvantagem: n√£o √© poss√≠vel calcular o valor de Akaike Information Criterion (AIC) porque estes modelos n√£o retornam um valor de likelihood (verosimilhan√ßa). Este par√¢metro √© comumente utilizado em abordagens estat√≠sticas de teoria da informa√ß√£o para selecionar o melhor modelo que se ajusta aos dados. Neste caso, precisamos utilizar outras fun√ß√µes dispon√≠veis nos pacotes MuMIn, AICcmodavg, e bbmle para calcular o QAIC. Para mais detalhes sobre esses modelos, veja o vignette sobre o assunto do pacote bbmle. 8.5.0.1 An√°lise Aqui vamos apenas exemplificar como um modelo com distribui√ß√£o quasi-poisson pode ser especificado. mod_quasipois &lt;- glm(Riqueza_obs~dfrag, family = quasipoisson(link = &quot;log&quot;), data = fragmentos) 8.5.0.1.1 Diagnose dos res√≠duos A fun√ß√£o resid n√£o leva em conta a sobredispers√£o e temos de calcular manualmente o par√¢metro de dispers√£o e inclui-lo no plot. Portanto, n√£o podemos realizar a diagnose de modelos quasi-Poisson apenas com a fun√ß√£o plot como faz√≠amos at√© ent√£o. Ent√£o, calculamos primeiramente os res√≠duos de Pearson e depois dividindo-o pela raiz quadrada do par√¢metro de dispers√£o, veja abaixo: EP &lt;- resid(mod_quasipois, type = &quot;pearson&quot;) ED &lt;- resid(mod_quasipois, type = &quot;deviance&quot;) mu &lt;- predict(mod_quasipois, type = &quot;response&quot;) E &lt;- fragmentos$Riqueza_obs - mu EP2 &lt;- E / sqrt(1.65662 * mu)#dispersion parameter da quasipoisson op &lt;- par(mfrow = c(2, 2)) plot(x = mu, y = E, main = &quot;Response residuals&quot;) plot(x = mu, y = EP, main = &quot;Pearson residuals&quot;) plot(x = mu, y = EP2, main = &quot;Pearson residuals scaled&quot;) plot(x = mu, y = ED, main = &quot;Deviance residuals&quot;) par(op) par(mfrow=c(1,1)) Aqui vemos que n√£o existe um padr√£o claro nos res√≠duos, muito similar ao que t√≠nhamos anteriormente. Devido √†s limita√ß√µes de distribui√ß√µes ‚Äúquasi‚Äù e dado que j√° temos um modelo adequado com binomial negativa, sugerimos interpretar apenas o modelo anterior com binomial negativa. 8.6 Dados de contagem: a distribui√ß√£o Binomial Quando temos dados de propor√ß√£o (e.g., n√∫mero de doentes por 1000 habitantes) ou incid√™ncia (i.e., presen√ßa ou aus√™ncia), a distribui√ß√£o mais adequada para modelar os dados √© a distribui√ß√£o binomial. No entanto, temos que especificar o modelo de acordo com o tipo dos dados no argumento formula. Vejamos dois exemplos: 8.6.1 An√°lise com dados de propor√ß√£o Neste exemplo vamos ver como podemos modelar a propor√ß√£o de c√©lulas sangu√≠neas em fun√ß√£o do tipo de tratamento. Explica√ß√£o dos dados Este conjunto de dados foi coletado por (Franco-Belussi, De Oliveira, and Sk√∂ld 2018). Os autores utilizaram um desenho experimental t√≠pico de uma 2x5 ANOVA fatorial (ou two-way ANOVA) em que temos dois tratamentos (fatores): pigmenta√ß√£o do girino com dois n√≠veis (Yes e No) e Tempo de exposi√ß√£o com cinco n√≠veis (controle sem UV, 6 h, 12 h, 18 h e 24 h de exposi√ß√£o √† UV). Pergunta A melanina proteje girinos contra os efeitos da radia√ß√£o ultravioleta? Predi√ß√µes Como a melanina participa do sistema imune inato, ela desempenharia um papel na resposta do organismo √† radia√ß√£o UV, auxiliando as c√©lulas imunes a combater os seus efeitos delet√©rios. Vari√°veis ‚Ä¢ Vari√°vel resposta: Contagem diferencial de eosin√≥filos ‚Äì Dataframe com 10 girinos em cada tratamento, totalizando 50 girinos glimpse(uv_cells) #&gt; Rows: 50 #&gt; Columns: 8 #&gt; $ UV &lt;chr&gt; &quot;1.CT&quot;, &quot;1.CT&quot;, &quot;1.CT&quot;, &quot;1.CT&quot;, &quot;1.CT&quot;, &quot;2.6h&quot;, &quot;2.6h&quot;, &quot;2.6h&quot;, &quot;2.6h&quot;,‚Ä¶ #&gt; $ Pigmentation &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;‚Ä¶ #&gt; $ Total_Cell &lt;int&gt; 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1‚Ä¶ #&gt; $ Lymphocyte &lt;int&gt; 80, 74, 78, 87, 74, 95, 73, 77, 61, 81, 90, 80, 92, 76, 51, 62, 88, 59,‚Ä¶ #&gt; $ Neutrophil &lt;int&gt; 18, 17, 22, 13, 21, 4, 16, 20, 27, 4, 7, 17, 5, 21, 44, 27, 4, 41, 21, ‚Ä¶ #&gt; $ Basophil &lt;int&gt; 0, 6, 0, 0, 1, 0, 9, 4, 11, 0, 0, 0, 3, 3, 1, 5, 3, 0, 0, 21, 0, 3, 0, ‚Ä¶ #&gt; $ Monocyte &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 5, 3, 0, 14, 1, 5, 0, 0, 1‚Ä¶ #&gt; $ Eosinophil &lt;int&gt; 2, 3, 0, 0, 4, 1, 2, 0, 1, 3, 3, 3, 0, 0, 3, 1, 2, 0, 14, 0, 6, 1, 1, 1‚Ä¶ Vamos explorar os dados para tentar entender como s√£o as rela√ß√µes: lineplot.CI(UV, Eosinophil, Pigmentation, data=uv_cells) Aqui vemos que a quantidade de eosin√≥filos √© muito maior nos girinos sem pigmenta√ß√£o (‚Äúalbinos‚Äù). J√° que estes animais n√£o t√™m pigmenta√ß√£o mel√¢nica, as c√©lulas brancas do sangue s√£o a √∫nica ferramenta de combate aos efeitos delet√©rios da UV. 8.6.1.1 Modelagem Aqui vamos usar o cbind no argumento formula para dizer que queremos modelar a contagem de eosin√≥filos em rela√ß√£o ao n√∫mero total de c√©lulas, ou seja, sua propor√ß√£o. Aqui temos a contagem do n√∫mero de eusin√≥filos (um tipo de c√©lula da s√©rie branca do sangue) em l√¢minas histol√≥gicas de girinos da r√£-touro (Lithobates catesbeianus) num total de 1000 c√©lulas: mod1&lt;-glm(cbind(Eosinophil, Total_Cell)~UV*Pigmentation, family=binomial, data=uv_cells) 8.6.1.2 Diagnose b√°sica dos res√≠duos do modelo par(mfrow=c(2,2)) plot(mod1) par(mfrow=c(1,1)) Parece que os res√≠duos n√£o sofrem de heterogeneidade de vari√¢ncia (linha vermelha est√° reta), mas parece haver um pequeno desvio da normalidade (veja pontos 19, 29 e 32 destacados no plot de quantis e no de outliers). Vejamos o que o DHARMa nos diz: simulationBion &lt;- simulateResiduals(fittedModel = mod1, plot = TRUE) binned_residuals(mod1) #&gt; Warning: Probably bad model fit. Only about 29% of the residuals are inside the error bounds. Aqui j√° n√£o resta d√∫vidas de que os res√≠duos deste modelo sofrem tanto com heterogeneidade de vari√¢ncia, quanto overdispersion e problemas com outliers. Provavelmente o problema com outliers ocorreu por conta do pequeno tamanho amostral. 8.6.1.3 Infer√™ncia Sabemos que o modelo n√£o parece ser adequado para os dados, mas vamos interpret√°-lo mesmo assim para que possamos entender o output do summary e os contrastes entre os n√≠veis dos fatores: summary(mod1) #&gt; #&gt; Call: #&gt; glm(formula = cbind(Eosinophil, Total_Cell) ~ UV * Pigmentation, #&gt; family = binomial, data = uv_cells) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -5.4165 -2.5266 -1.0148 0.8068 8.8233 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -1.84516 0.12107 -15.241 &lt; 2e-16 *** #&gt; UV2.6h -0.17979 0.17835 -1.008 0.3134 #&gt; UV3.12h 0.38414 0.15899 2.416 0.0157 * #&gt; UV4.18h -0.49825 0.19363 -2.573 0.0101 * #&gt; UV5.24h -0.39916 0.18848 -2.118 0.0342 * #&gt; PigmentationYes -2.17222 0.35745 -6.077 1.22e-09 *** #&gt; UV2.6h:PigmentationYes -0.07152 0.53831 -0.133 0.8943 #&gt; UV3.12h:PigmentationYes -0.38414 0.50150 -0.766 0.4437 #&gt; UV4.18h:PigmentationYes 1.13424 0.45981 2.467 0.0136 * #&gt; UV5.24h:PigmentationYes 0.68684 0.48370 1.420 0.1556 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 737.36 on 49 degrees of freedom #&gt; Residual deviance: 460.85 on 40 degrees of freedom #&gt; AIC: 610.35 #&gt; #&gt; Number of Fisher Scoring iterations: 5 anova(mod1) #&gt; Analysis of Deviance Table #&gt; #&gt; Model: binomial, link: logit #&gt; #&gt; Response: cbind(Eosinophil, Total_Cell) #&gt; #&gt; Terms added sequentially (first to last) #&gt; #&gt; #&gt; Df Deviance Resid. Df Resid. Dev #&gt; NULL 49 737.36 #&gt; UV 4 26.034 45 711.32 #&gt; Pigmentation 1 235.682 44 475.64 #&gt; UV:Pigmentation 4 14.789 40 460.85 Aqui temos tanto a tabela com os resultados por n√≠veis dos fatores (summary) quanto a tabela com a Deviance que mostra os fatores e suas intera√ß√µes (anova). Vemos que nenhum fator foi significativo. Caso houvesse algum fator significativo poder√≠amos testar a signific√¢ncia de cada n√≠vel dos fatores usando contrastes, desta forma: pairs(emmeans(mod1, ~ UV|Pigmentation)) #&gt; Pigmentation = No: #&gt; contrast estimate SE df z.ratio p.value #&gt; 1.CT - 2.6h 0.1798 0.178 Inf 1.008 0.8518 #&gt; 1.CT - 3.12h -0.3841 0.159 Inf -2.416 0.1109 #&gt; 1.CT - 4.18h 0.4982 0.194 Inf 2.573 0.0753 #&gt; 1.CT - 5.24h 0.3992 0.188 Inf 2.118 0.2124 #&gt; 2.6h - 3.12h -0.5639 0.167 Inf -3.384 0.0064 #&gt; 2.6h - 4.18h 0.3185 0.200 Inf 1.593 0.5021 #&gt; 2.6h - 5.24h 0.2194 0.195 Inf 1.125 0.7933 #&gt; 3.12h - 4.18h 0.8824 0.183 Inf 4.824 &lt;.0001 #&gt; 3.12h - 5.24h 0.7833 0.177 Inf 4.414 0.0001 #&gt; 4.18h - 5.24h -0.0991 0.209 Inf -0.474 0.9897 #&gt; #&gt; Pigmentation = Yes: #&gt; contrast estimate SE df z.ratio p.value #&gt; 1.CT - 2.6h 0.2513 0.508 Inf 0.495 0.9879 #&gt; 1.CT - 3.12h 0.0000 0.476 Inf 0.000 1.0000 #&gt; 1.CT - 4.18h -0.6360 0.417 Inf -1.525 0.5461 #&gt; 1.CT - 5.24h -0.2877 0.445 Inf -0.646 0.9675 #&gt; 2.6h - 3.12h -0.2513 0.508 Inf -0.495 0.9879 #&gt; 2.6h - 4.18h -0.8873 0.454 Inf -1.957 0.2876 #&gt; 2.6h - 5.24h -0.5390 0.480 Inf -1.123 0.7942 #&gt; 3.12h - 4.18h -0.6360 0.417 Inf -1.525 0.5461 #&gt; 3.12h - 5.24h -0.2877 0.445 Inf -0.646 0.9675 #&gt; 4.18h - 5.24h 0.3483 0.382 Inf 0.911 0.8928 #&gt; #&gt; Results are given on the log odds ratio (not the response) scale. #&gt; P value adjustment: tukey method for comparing a family of 5 estimates Aqui temos o valor de cada combina√ß√£o de n√≠veis dos fatores, com seu respectivo valor de contraste e o valor de P. Vemos que para girinos sem pigmenta√ß√£o apenas 3 contrastes foram significativos. 8.6.1.3.1 Plot do modelo predito ggplot(uv_cells, aes(UV, Eosinophil)) + geom_violin(aes(color=Pigmentation))+ geom_jitter(shape = 16, position = position_jitter(0.1), cex = 4, alpha = 0.7) Usando o geom_violin podemos perceber que existe uma dispers√£o maior nos tratamentos que utilizaram girinos sem pigmenta√ß√£o do que nos tratamentos com girinos pigmentados. 8.7 An√°lise com dados de incid√™ncia Uma outra aplica√ß√£o da distribui√ß√£o binomial √© quando temos dados de incid√™ncia, ou seja, presen√ßa ou aus√™ncia, de alguma vari√°vel. Por exemplo, presen√ßa ou aus√™ncia de uma esp√©cie ou indiv√≠duo num local. Neste caso a formula √© diferente e o modelo √© similar a uma regress√£o log√≠stica, vejamos. Aqui vamos utilizar os dados do trabalho de (Oliveira et al. 2020). Pergunta A probabilidade de lagartos da esp√©cie Coleodactylus meridionalis perderem (autotomizarem) a cauda aumenta com o tamanho do corpo e de acordo com o sexo dos lagarto? Predi√ß√µes Quanto maior o lagarto, maior a probabilidade de autotomia da cauda e que esta resposta poderia tamb√©m diferir entre sexos devido ao dimorfismo sexual. Vari√°veis ‚Ä¢ Vari√°vel resposta: Presen√ßa ou aus√™ncia de cauda autotomizada em lagartos encontrados por busca ativa. Explora√ß√£o dos dados Este conjunto de dados possui muitas entradas faltantes (codificadas como NA). Primeiro vamos visualizar o conjunto de dados, e depois precisamos remover as linhas que cont√™m dados faltantes. Aqui podemos usar a fun√ß√£o interna do ggplot2::remove_missing para remover linhas cujas vari√°veis informadas no argumento estejam faltando, vejamos: head(lagartos) #&gt; Numero Sex SVL Intact_tail_length Autotomized_tail_length Tail_state #&gt; 1 2 Male 20.70 NA 12.88 0 #&gt; 2 3 Male 21.10 NA 13.07 0 #&gt; 3 6 Female 23.72 NA 17.56 0 #&gt; 4 9 Male 18.84 17.38 NA 1 #&gt; 5 21 Male 22.20 NA 16.50 0 #&gt; 6 22 &lt;NA&gt; 20.59 NA 12.46 0 vis_dat(lagartos) vis_miss(lagartos,cluster = TRUE)#22.9% dos dados est√£o faltando dados_semNA&lt;-remove_missing(lagartos, vars = &quot;Sex&quot;)#excluindo linhas com dados faltantes para a vari√°vel Sex vis_miss(dados_semNA) dim(dados_semNA)#verificar as dimens√µes da tabela depois que os dados tiverem sido exclu√≠dos #&gt; [1] 139 6 Agora, seguindo o que j√° estamos acostumados a fazer, vamos vizualisar os dados com a nossa hip√≥tese: ggplot(dados_semNA, aes(SVL, Tail_state))+ geom_point(aes(shape=Sex, color=Sex), size = 4, alpha = 0.4)+ geom_smooth(method = &quot;glm&quot;, method.args=list(family=&quot;binomial&quot;))+ labs(y=&quot;Estado da Cauda&quot;, x=&quot;Comprimento Rostro-Cloacal (mm)&quot;) 8.7.0.1 Modelagem Aqui vamos construir dois modelos com a mesma distribui√ß√£o binomial, mas com dois link function: logit e probit. A fun√ß√£o logit possui caudas um pouco mais achatadas, isto √©, a curva probit se aproxima dos eixos mais rapidamente que a logit. Geralmente n√£o h√° muita diferen√ßa entre elas. Como n√£o temos nenhuma expectativa de qual dos dois link function √© o melhor, podemos fazer uma sele√ß√£o de modelos: mod_log&lt;-glm(Tail_state~SVL*Sex, data=dados_semNA, family = binomial(link=&quot;logit&quot;)) mod_pro&lt;-glm(Tail_state~SVL*Sex, data=dados_semNA, family = binomial(link=&quot;probit&quot;)) AICctab(mod_log, mod_pro, nobs=139) #&gt; dAICc df #&gt; mod_pro 0.0 4 #&gt; mod_log 0.1 4 Existe pouca diferen√ßa entre o modelo probit e logit. Como o modelo logit √© mais simples vamos interpret√°-lo apenas. 8.7.0.2 Diagnose dos res√≠duos do modelo simulationBion &lt;- simulateResiduals(fittedModel = mod_log, plot = T) binned_residuals(mod_log) #&gt; Warning: About 92% of the residuals are inside the error bounds (~95% or higher would be good). 8.7.0.3 Infer√™ncia anova(mod_log, test=&quot;Chisq&quot; ) #&gt; Analysis of Deviance Table #&gt; #&gt; Model: binomial, link: logit #&gt; #&gt; Response: Tail_state #&gt; #&gt; Terms added sequentially (first to last) #&gt; #&gt; #&gt; Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi) #&gt; NULL 138 191.07 #&gt; SVL 1 9.2563 137 181.82 0.002347 ** #&gt; Sex 1 0.3920 136 181.43 0.531262 #&gt; SVL:Sex 1 0.0454 135 181.38 0.831292 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para modelos com par√¢metro de dispers√£o conhecida (e.g., binomial e Poisson), o chi-quadrado √© a estat√≠stica mais apropriada. 8.7.0.4 Interpreta√ß√£o dos resultados üìù Importante A interpreta√ß√£o dos resultados √© que o tamanho de corpo (SVL) afeta negativamente a probabilidade da cauda estar intacta, i.e., com o aumento do tamanho, a probabilidade da cauda permanecer intacta diminui. A intera√ß√£o n√£o foi significativa, ent√£o o efeito √© independente do sexo dos lagartos. 8.8 Dados de contagem com excesso de zeros Quando se analisa abund√¢ncia ou riqueza de esp√©cies √© comum que tenhamos dados com muitos zeros. Esse fen√¥meno pode ser causado por v√°rios processos ecol√≥gicos, tais como locais fora do nicho da esp√©cie, falha na detec√ß√£o, amostras feitas fora do h√°bitat ou em locais onde n√£o se espera encontrar a esp√©cie ((Blasco‚ÄêMoreno et al. 2019)). Esse tipo de dado √© problem√°tico porque rompe com os pressupostos da distribui√ß√£o Poisson e binomial negativa, podendo inclusive ser uma das causas da overdispersion. Nesses casos, temos de ajustar modelos que levam em conta esse excesso de zeros nos dados. Esses modelos s√£o chamados de zero-inflated e hurdle models (tamb√©m chamados de zero-altered models), dependendo de como o processo que causou os zeros √© modelado. Hurdle models (ou zero-altered models) modelam os dados dividindo-os em dois subconjuntos: um no qual reduzimos os dados √† presen√ßa-aus√™ncia, ou seja, todos os dados maiores que 1 s√£o transformados em 1 e usamos por exemplo uma distribui√ß√£o binomial; e uma outra parte que s√≥ considera os valores positivos sem zero, utilizando uma Poisson ou binomial negativa truncadas. Ao fazer isso, a distribui√ß√£o truncada assume que os zeros s√£o gerados tanto por processos ecol√≥gicos quanto erros de amostragem (ou seja, √© imposs√≠vel distinguir entre essas duas fontes). Portanto, esses zeros s√£o exclu√≠dos da distribui√ß√£o com dados de contagem. Por exemplo, se uma distribui√ß√£o binomial negativa for usada para modelar a parte quantitativa, chamamos o modelo de Zero-altered Negative Binomial. A interpreta√ß√£o dos modelos deve ser feita de forma conjunta. Modelos com zero inflados funcionam de maneira similar, mas permitem que a distribui√ß√£o Poisson contenha zeros, ou seja, n√£o √© utilizada uma distribui√ß√£o truncada. Ao fazer isso, esta distribui√ß√£o de Poisson pressup√µe que os zeros foram gerados por um processo ecol√≥gico real, tal como, aus√™ncia de h√°bitat adequado. Para ilustrar como podemos lidar com conjuntos de dados complexos vamos utilizar os dados coletados por (Lima et al. 2018). Pergunta Quais atributos de hist√≥ria de vida dos lagartos s√£o relacionados com o volume (load) de infec√ß√£o, tais como tamanho e sexo? Predi√ß√µes Quanto maior o lagarto, maior o n√∫mero de parasitas encontrados, esta resposta poderia tamb√©m diferir entre sexos devido ao dimorfismo sexual. Vari√°veis ‚Ä¢ Vari√°vel resposta: N√∫mero do parasita Raillietiella mottae, que √© um crust√°ceo parasita, infectando o aparelho respirat√≥rio e intestinal de lagartos. ‚Äì Os autores registraram essa esp√©cie infectando duas esp√©cies de lagartos que ocorrem no nordeste Brasileiro. Ao todo, 63 indiv√≠duos de Hemidactylus agrius e 132 de Phyllopezus pollicaris foram amostrados. head(parasitas) #&gt; Especie Sexo CRC Raillietiella_mottae #&gt; W124 Phyllopezus_pollicaris F 61 3 #&gt; W125 Phyllopezus_pollicaris F 56 0 #&gt; W127 Phyllopezus_pollicaris M 61 0 #&gt; W128 Phyllopezus_pollicaris M 48 0 #&gt; W129 Phyllopezus_pollicaris F 40 0 #&gt; W130 Phyllopezus_pollicaris M 62 0 Explorando os dados ggplot(parasitas, aes(Raillietiella_mottae))+ geom_density(aes(fill=&quot;red&quot;))+ facet_grid(Especie~Sexo)+ theme(legend.position = &quot;none&quot;) ggplot(parasitas, aes(CRC, Raillietiella_mottae)) + geom_point(size = 4 , alpha = 0.4) + facet_grid(Sexo~ Especie) Os gr√°fico acima mostra a contagem do parasita Raillietiella mottae nos dois sexos (F e M para f√™mea e macho) nas duas esp√©cies de lagartos, tanto na forma de uma distribui√ß√£o de densidade quanto de gr√°fico de dispers√£o. Aqui podemos ver que de fato existe um excesso de zeros principalmente em P. pollicaris. Quando nos deparamos com dados complexos assim, a estrat√©gia √© sempre come√ßar com um modelo simples e depois adicionar mais par√¢metros. Portanto, vamos iniciar com um modelo Poisson, mesmo sabendo que ele muito provavelmente n√£o ser√° adequado para modelar estes dados: 8.8.0.1 Modelagem pois_plain&lt;-glm(Raillietiella_mottae~CRC+Sexo*Especie, data=parasitas, family=&quot;poisson&quot;) 8.8.0.2 Diagnose Aqui vamos utilizar as fun√ß√µes do pacote performance novamente: check_zeroinflation(pois_plain)#para diagnosticar se o modelo sofre de zero inflation #&gt; # Check for zero-inflation #&gt; #&gt; Observed zeros: 156 #&gt; Predicted zeros: 140 #&gt; Ratio: 0.90 check_overdispersion(pois_plain) #&gt; # Overdispersion test #&gt; #&gt; dispersion ratio = 1.932 #&gt; Pearson&#39;s Chi-Squared = 367.133 #&gt; p-value = &lt; 0.001 A diagnose n√£o s√≥ nos disse que o modelo possui overdispersion, como tamb√©m de zero-inflation, como j√° esper√°vamos. Vejamos ent√£o como melhorar o nosso modelo para lidar com esses dois problemas. Especificamente, vamos utilizar um modelo Hurdle com binomial negativa truncada (ou seja, desconsiderando os zeros), e um outro modelo zero-inflated usando uma distribui√ß√£o binomial negativa. Aqui vamos utilizar o pacote glmmTMB : hur_NB &lt;- glmmTMB(Raillietiella_mottae~CRC+Sexo*Especie, zi=~., data=parasitas, family=truncated_nbinom2)#Hurdle model ziNB_mod2 &lt;- glmmTMB(Raillietiella_mottae~CRC+Sexo*Especie, zi=~., data=parasitas, family=nbinom2)#zero-inflated Poisson ziP_mod2 &lt;- glmmTMB(Raillietiella_mottae~CRC+Sexo*Especie, zi=~., data=parasitas, family=poisson)#zero-inflated Negative Binomial 8.8.0.3 Diagnose check_zeroinflation(hur_NB)#prediz melhor os zeros #&gt; # Check for zero-inflation #&gt; #&gt; Observed zeros: 156 #&gt; Predicted zeros: 156 #&gt; Ratio: 1.00 check_zeroinflation(ziP_mod2) #&gt; # Check for zero-inflation #&gt; #&gt; Observed zeros: 156 #&gt; Predicted zeros: 140 #&gt; Ratio: 0.90 check_zeroinflation(ziNB_mod2) #&gt; # Check for zero-inflation #&gt; #&gt; Observed zeros: 156 #&gt; Predicted zeros: 140 #&gt; Ratio: 0.90 Aqui vemos que o modelo zero-altered (Hurdle Model) conseguiu predizer exatamente a quantidade de zeros observada, fazendo com que o modelo seja suficiente para usarmos com esses dados. ICtab(pois_plain, hur_NB,ziP_mod2,ziNB_mod2, type=c(&quot;AICc&quot;), weights = TRUE) #&gt; dAICc df weight #&gt; ziP_mod2 0.0 10 0.62 #&gt; ziNB_mod2 1.6 11 0.28 #&gt; hur_NB 3.6 11 0.10 #&gt; pois_plain 44.6 5 &lt;0.001 Mas quando comparamos o AICc entre modelos, os modelos zero-inflated (tanto Poisson, quanto binomial negativa) que tem menos par√¢metros, s√£o ranqueados ligeiramente melhor do que o modelo binomial negativa zero-altered (ou hurdle). N√£o podemos distinguir entre os dois modelos com zero-inflated porque o dAIC &lt; 2, ou seja, o ajuste deles aos dados s√£o praticamente iguais. Vejam que a diferen√ßa de Akaike Weights entre os dois primeiros modelos e o hurdle √© bastante substancial (0.52). Al√©m disso, vemos que os modelos que levam em conta o excesso de zeros se ajustam bem melhor aos dados do que o modelo simples com distribui√ß√£o Poisson. Vamos ver como os modelos se saem em rela√ß√£o aos outros pressupostos: simulationOutput &lt;- simulateResiduals(fittedModel = hur_NB, plot = T) simulationOutput &lt;- simulateResiduals(fittedModel = ziNB_mod2, plot = T)#tem um outlier nos res√≠duos (asterisco vermelho) Os gr√°ficos de diagnose do DHARMa s√£o outra evid√™ncia de que tanto o modelo hurdle quanto o zero-inflated Poisson s√£o adequados para os dados, em termos de heterogeneidade de vari√¢ncia, outliers e overdispersion. 8.8.0.4 Interpreta√ß√£o dos resultados Apesar de n√£o ter um ajuste t√£o bom aos dados, o modelo hurdle prediz melhor a quantidade de zeros. Portanto, vamos interpretar os coeficientes apenas deste modelo: summary(hur_NB) #&gt; Family: truncated_nbinom2 ( log ) #&gt; Formula: Raillietiella_mottae ~ CRC + Sexo * Especie #&gt; Zero inflation: ~. #&gt; Data: parasitas #&gt; #&gt; AIC BIC logLik deviance df.resid #&gt; 277.8 313.8 -127.9 255.8 184 #&gt; #&gt; #&gt; Dispersion parameter for truncated_nbinom2 family (): 4.64 #&gt; #&gt; Conditional model: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 3.03428 2.36511 1.283 0.1995 #&gt; CRC -0.05041 0.04861 -1.037 0.2997 #&gt; SexoM -1.49505 0.71440 -2.093 0.0364 * #&gt; EspeciePhyllopezus_pollicaris 0.68945 1.09380 0.630 0.5285 #&gt; SexoM:EspeciePhyllopezus_pollicaris 1.75281 0.94217 1.860 0.0628 . #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Zero-inflation model: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 7.6283 1.8529 4.117 3.84e-05 *** #&gt; CRC -0.1291 0.0369 -3.499 0.000468 *** #&gt; SexoM -1.0893 0.5867 -1.856 0.063386 . #&gt; EspeciePhyllopezus_pollicaris 2.2701 0.9140 2.484 0.013003 * #&gt; SexoM:EspeciePhyllopezus_pollicaris 2.2002 0.8192 2.686 0.007239 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Para maiores detalhes na interpreta√ß√£o deste tipo de modelo, sugerimos fortemente consultar p.¬†382-3 de Brooks et al. (2017). Para fatores com mais de um n√≠vel, o summary mostra os resultados usando contraste, para isto toma como refer√™ncia um dos n√≠veis do fator (o primeiro em ordem alfab√©tica) e o compara com os outros. Note que na parte com excesso de zeros o contraste √© positivo para Esp√©cie. Ou seja, o P. pollicaris tem maior chance de ter aus√™ncia de parasitas que H. agrius. O contraste para esp√©cie continua sendo positivo na parte condicional do modelo, mas o valor do par√¢metro n√£o √© t√£o alto. Isso quer dizer que P. pollicaris tem abund√¢ncia de parasitas em m√©dia ligeiramente maior que H. agrius. Vemos que a intera√ß√£o √© significativa entre sexo e esp√©cie na parte do modelo com excesso de zeros, mas apenas marginalmente significativa na parte condicional. Portanto, a influ√™ncia do sexo na incid√™ncia, mas n√£o na abund√¢ncia, do parasita depende conjuntamente da esp√©cie. No entanto, o CRC s√≥ passa a ser significativo na parte de excesso de zeros, ou seja, quando modelamos apenas a incid√™ncia (presen√ßa-aus√™ncia) do parasita. Portanto, o CRC determina se o lagarto vai ou n√£o ser infectado, mas n√£o o quanto vai receber de parasitas. J√° tanto o sexo quanto a esp√©cie foram significativas em ambas as partes do modelo, ou seja, esses fatores n√£o influenciam diferentemente a infec√ß√£o e a quantidade de parasitas. Agora vejamos como podemos plotar as predi√ß√µes deste modelo: parasitas$phat &lt;- predict(hur_NB, type=&quot;response&quot;) parasitas &lt;- parasitas[with(parasitas, order(Sexo, Especie)), ] ggplot(parasitas, aes(x = CRC, y = phat, colour = Especie,shape = Sexo, linetype = Sexo)) + geom_point(aes(y = Raillietiella_mottae), size=4, alpha=.7, position=position_jitter(h=.2)) + geom_line(size = 1) + labs(x = &quot;Comprimento Rostro-Cloacal&quot;, y = expression(paste(&quot;Abund√¢ncia de &quot;, italic(&quot;Raillietiella mottae&quot;)))) 8.9 Dados ordinais: os modelos cumulative link Uma outra maneira de codificarmos os dados √© utilizando categorias ordenadas, tais como ranques. Exemplos incluem a escala de Likert, scores, intervalos (e.g., de idade). Para este exemplo, iremos utilizar um outro conjunto de dados do artigo de (Franco-Belussi, De Oliveira, and Sk√∂ld 2018) que manipulou in vitro a concentra√ß√£o do horm√¥nio noradrenalina (NA) nos olhos de peixes esgana-gato (Gasterosteus aculeatus) e avaliaram a express√£o de v√°rias cores conferidas por tipos de c√©lulas (cromat√≥foros). Aqui vamos usar os dados do efeito do NA na cor vermelha em machos. Pergunta A NA causa uma diminui√ß√£o da colora√ß√£o vermelha, via agrega√ß√£o dos pigmentos? Predi√ß√µes A presen√ßa de NA causa a agrega√ß√£o dos pigmentos, permitindo que os horm√¥nios reprodutivos atuem. Vari√°veis ‚Ä¢ Vari√°vel resposta: Escala de intensidade de cor. Para mais detalhes veja o artigo original. cores &lt;- read.csv2(&quot;https://ndownloader.figshare.com/files/10250700&quot;, h=TRUE) head(cores) #&gt; Animal Treatment Time Sex Black Red #&gt; 1 1 CT 0h M 5 5 #&gt; 2 1 CT 1h M 5 5 #&gt; 3 1 CT 2h M 5 5 #&gt; 4 1 CT 3h M 5 5 #&gt; 5 2 CT 0h M 5 4 #&gt; 6 2 CT 1h M 5 4 ## Filtrando dados - Red Male redmale&lt;- filter(cores, Sex==&quot;M&quot;) head(redmale) #&gt; Animal Treatment Time Sex Black Red #&gt; 1 1 CT 0h M 5 5 #&gt; 2 1 CT 1h M 5 5 #&gt; 3 1 CT 2h M 5 5 #&gt; 4 1 CT 3h M 5 5 #&gt; 5 2 CT 0h M 5 4 #&gt; 6 2 CT 1h M 5 4 Esses dados no entanto tem de ser codificados como um fator ordenado antes de entrarmos com eles no modelo. redmale$Animal&lt;-factor(redmale$Animal) redmale$Red&lt;-factor(redmale$Red, levels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;), ordered = TRUE) str(redmale) #&gt; &#39;data.frame&#39;: 40 obs. of 6 variables: #&gt; $ Animal : Factor w/ 5 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 1 2 2 2 2 3 3 ... #&gt; $ Treatment: chr &quot;CT&quot; &quot;CT&quot; &quot;CT&quot; &quot;CT&quot; ... #&gt; $ Time : chr &quot;0h&quot; &quot;1h&quot; &quot;2h&quot; &quot;3h&quot; ... #&gt; $ Sex : chr &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; ... #&gt; $ Black : int 5 5 5 5 5 5 5 5 4 4 ... #&gt; $ Red : Ord.factor w/ 5 levels &quot;1&quot;&lt;&quot;2&quot;&lt;&quot;3&quot;&lt;&quot;4&quot;&lt;..: 5 5 5 5 4 4 4 4 4 4 ... Repare que a classe do objeto muda e temos agora que Red √© um Ordered factor. 8.9.0.1 Modelagem mod3&lt;-clmm(Red~Treatment+Time+(1|Animal), data=redmale, threshold = &quot;equidistant&quot;) 8.9.0.2 Diagnose Infelizmente, o pacote ordinal n√£o fornece m√©todos para lidar com modelos mistos, como o nosso. Ent√£o, montamos um modelo fixo apenas para entrar nas duas fun√ß√µes de diagnose. Essas duas fun√ß√µes scale_test e nominal_test testam a qualidade do ajuste (goodness-of-fit) do modelo, similar aos likelihood ratio tests s√≥ que para dados ordinais. assumption3 &lt;- clm(Red~Treatment+Time, data=redmale, threshold = &quot;equidistant&quot;) scale_test(assumption3) #&gt; Tests of scale effects #&gt; #&gt; formula: Red ~ Treatment + Time #&gt; Df logLik AIC LRT Pr(&gt;Chi) #&gt; &lt;none&gt; -24.301 60.602 #&gt; Treatment 1 -24.293 62.586 0.015248 0.9017 #&gt; Time nominal_test(assumption3) #&gt; Tests of nominal effects #&gt; #&gt; formula: Red ~ Treatment + Time #&gt; Df logLik AIC LRT Pr(&gt;Chi) #&gt; &lt;none&gt; -24.301 60.602 #&gt; Treatment 1 -19.749 53.499 9.1031 0.002552 ** #&gt; Time 3 -22.803 63.606 2.9953 0.392356 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Parece que n√£o h√° problemas com o efeito de escala do dado ordinal, mas a diagnose sugere que possa haver evid√™ncia de rompimento do pressuposto de probabilidades proporcionais em rela√ß√£o ao tratamento. Esse √© um pressuposto importante de modelos ordinais, os quais assumem que os efeitos de qualquer uma das vari√°veis explicativas s√£o consistentes (proporcionais) ao longo de diferentes thresholds (que s√£o as quebras entre cada par de categorias da vari√°vel resposta ordinal). Isto provavelmente se deve ao baixo tamanho amostral. Por quest√£o de brevidade vamos apenas ignorar este aspecto e interpretar o resultado do modelo mesmo assim. Mas se o seu modelo apresentar este problema, a solu√ß√£o deve ser realizar regress√µes log√≠sticas separadamente. 8.9.0.3 Infer√™ncia summary(mod3) #&gt; Cumulative Link Mixed Model fitted with the Laplace approximation #&gt; #&gt; formula: Red ~ Treatment + Time + (1 | Animal) #&gt; data: redmale #&gt; #&gt; link threshold nobs logLik AIC niter max.grad cond.H #&gt; logit equidistant 40 -22.89 59.77 226(681) 1.04e-05 4.1e+01 #&gt; #&gt; Random effects: #&gt; Groups Name Variance Std.Dev. #&gt; Animal (Intercept) 1.438 1.199 #&gt; Number of groups: Animal 5 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; TreatmentNA10uM -4.602 1.228 -3.748 0.000178 *** #&gt; Time1h -3.602 1.377 -2.616 0.008894 ** #&gt; Time2h -3.602 1.377 -2.616 0.008894 ** #&gt; Time3h -3.602 1.377 -2.616 0.008894 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Threshold coefficients: #&gt; Estimate Std. Error z value #&gt; threshold.1 -6.198 1.722 -3.60 #&gt; spacing 4.978 1.254 3.97 anova(assumption3) #&gt; Type I Analysis of Deviance Table with Wald chi-square tests #&gt; #&gt; Df Chisq Pr(&gt;Chisq) #&gt; Treatment 1 15.3616 8.877e-05 *** #&gt; Time 3 9.1992 0.02676 * #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 pairs(emmeans(mod3, ~ Treatment|Time, adjust= &quot;tukey&quot;)) #&gt; Time = 0h: #&gt; contrast estimate SE df z.ratio p.value #&gt; CT - NA10uM 4.6 1.23 Inf 3.748 0.0002 #&gt; #&gt; Time = 1h: #&gt; contrast estimate SE df z.ratio p.value #&gt; CT - NA10uM 4.6 1.23 Inf 3.748 0.0002 #&gt; #&gt; Time = 2h: #&gt; contrast estimate SE df z.ratio p.value #&gt; CT - NA10uM 4.6 1.23 Inf 3.748 0.0002 #&gt; #&gt; Time = 3h: #&gt; contrast estimate SE df z.ratio p.value #&gt; CT - NA10uM 4.6 1.23 Inf 3.748 0.0002 Aqui vemos que tanto o tratamento quanto o tempo de exposi√ß√£o foram significativos. 8.9.0.4 Interpreta√ß√£o dos resultados lineplot.CI(Time, as.numeric(Red), Treatment, data=redmale, cex = 1, xlab = &quot;Experimental time (hours)&quot;, ylab = &quot;Erythrophore Index (EI)&quot;, cex.lab = 1.5, x.leg = 1, y.leg = 1.2, cex.leg = 1.3, cex.axis = 1.5, col = c(&quot;#EE6363&quot;,&quot;#79CDCD&quot;), pch = c(12,12), lwd = 1.5, ylim= c(0,5)) 8.10 Dados cont√≠nuos: distribui√ß√£o beta Aqui vamos utilizar como exemplo os dados do artigo de (Franco-Belussi, De Oliveira, and Sk√∂ld 2018). Os pesquisadores fizeram um experimento in vivo com peixes esgana-gato (Gasterosteus aculeatus) para testar como a colora√ß√£o dos animais respondem ao f√°rmaco ioimbina (YOH), que bloqueia a colora√ß√£o t√≠pica que os machos exibem na √©poca de acasalamento, e o tempo de exposi√ß√£o ao mesmo (al√©m de um controle), num desenho de ANOVA fatorial. Como as medidas foram feitas repetidamente no mesmo animal, iremos incluir o Animal como um fator aleat√≥rio no modelo. Pergunta A YOH aumenta a colora√ß√£o escura no olho e mand√≠bula dos peixes via dispers√£o dos pigmentos? Predi√ß√µes A YOH promover√° um escurecimento do corpo do animal, j√° que ela inibe a a√ß√£o NorAdrenalia (NA). Vari√°veis ‚Ä¢ Vari√°vel resposta: A intensidade de colora√ß√£o escura em peixes machos. Esses dados s√£o expressos em termos de porcentagem e variam continuamente de 0 a 100%. Para facilitar a modelagem e nos adequarmos √† maneira com que a fun√ß√£o requer os dados, vamos simplesmente dividir por 100 para que os dados variem entre 0 e 1. Para modelar os dados vamos utilizar a fun√ß√£o glmmTMB ##Filtrando dados fish$Animal&lt;-factor(fish$Animal) fish$Sex&lt;-factor(fish$Sex) darknessmale&lt;- dplyr::filter(fish, Sex==&quot;M&quot;) ggplot(darknessmale, aes(Darkness/100)) + geom_density(colour=&quot;red&quot;, fill=&quot;red&quot;) + theme(legend.position=&quot;none&quot;) No histograma podemos ver que os dados de fato variam continuamente no intervalo entre 0 e 1, tendo uma distribui√ß√£o notadamente bimodal. 8.10.0.1 Modelagem mod2&lt;-glmmTMB(Darkness/100~Treatment*Time+(1|Animal), family= beta_family, data=darknessmale) 8.10.0.2 Diagnose Aqui utilizaremos o mesmo pacote DHARMa para realizar a diagnose do modelo: simulationOutput &lt;- simulateResiduals(fittedModel = mod2, plot = TRUE) Podemos ver que o modelo n√£o sofre de heterogeneidade de dispers√£o, overdispersion, nem problemas com outlier. 8.10.0.3 Interpreta√ß√£o dos resultados Agora que podemos interpretar o output com confian√ßa, vamos obter a tabela de anova em que teremos os testes de cada fator do modelo: Anova(mod2) #&gt; Analysis of Deviance Table (Type II Wald chisquare tests) #&gt; #&gt; Response: Darkness/100 #&gt; Chisq Df Pr(&gt;Chisq) #&gt; Treatment 105.546 1 &lt; 2.2e-16 *** #&gt; Time 40.719 3 7.499e-09 *** #&gt; Treatment:Time 49.262 3 1.147e-10 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 üìù Importante aqui vemos que a intera√ß√£o √© significativa. Portanto, temos de interpretar os n√≠veis do fator da combina√ß√£o, fazemos isso no pacote emmeans colocando a barra | : pairs(emmeans(mod2, ~ Treatment|Time)) #&gt; Time = 0h: #&gt; contrast estimate SE df t.ratio p.value #&gt; CT - YOH 0.0283 0.160 30 0.177 0.8609 #&gt; #&gt; Time = 1h: #&gt; contrast estimate SE df t.ratio p.value #&gt; CT - YOH -1.3068 0.181 30 -7.210 &lt;.0001 #&gt; #&gt; Time = 2h: #&gt; contrast estimate SE df t.ratio p.value #&gt; CT - YOH -1.2286 0.182 30 -6.763 &lt;.0001 #&gt; #&gt; Time = 3h: #&gt; contrast estimate SE df t.ratio p.value #&gt; CT - YOH -1.4025 0.185 30 -7.582 &lt;.0001 #&gt; #&gt; Results are given on the log odds ratio (not the response) scale. üìù Importante e ent√£o podemos perceber que a diferen√ßa entre o controle e o tratado s√≥ passa a ser significativa depois de 1 h de exposi√ß√£o. Isso fica mais evidente quando plotamos os dados lineplot.CI(Time, Darkness, Treatment, data=darknessmale, cex = 1, xlab = &quot;Tempo experimental (horas)&quot;, ylab = &quot;Escurid√£o do corpo de machos (%)&quot;, cex.lab = 1, x.leg = 1, col = c(&quot;#EE6363&quot;,&quot;#79CDCD&quot;), pch = c(12,12), lwd = 1.5) 8.11 Leituras recomendadas Neste cap√≠tulo apenas fizemos uma breve introdu√ß√£o aos modelos lineares generalizados. Para conhecer um pouco mais a fundo todos os detalhes recomendamos a consulta dos livros (Zuur, Ieno, and Elphick 2009b) e (Pinheiro and Bates 2000a) que s√£o as refer√™ncias cl√°ssicas sobre GLM com aplica√ß√µes em ecologia. Para dados ordinais, sugerimos os livros do Alan Agresti, tais como (Agresti 2010) e Categorical Data Analysis, 3rd Edition, do mesmo autor. Refer√™ncias "],["cap9.html", "Cap√≠tulo 9 An√°lises Multidimensionais Pr√©-requisitos do cap√≠tulo 9.1 Aspectos te√≥ricos 9.2 An√°lise de agrupamento hier√°rquico 9.3 K-means e agrupamentos n√£o-hier√°rquicos 9.4 Esp√©cies indicadoras 9.5 An√°lises de Ordena√ß√£o 9.6 PCR - Regress√£o de Componentes Principais 9.7 Ordena√ß√£o restrita 9.8 PERMANOVA", " Cap√≠tulo 9 An√°lises Multidimensionais Pr√©-requisitos do cap√≠tulo ## Pacotes library(ade4) library(ecodados) library(tidyverse) library(vegan) library(pvclust) library(BiodiversityR) library(labdsv) library(ggplot2) library(gridExtra) library(ape) library(FactoMineR) library(factoextra) library(FD) library(palmerpenguins) library(GGally) library(ade4) library(ggord) library(adespatial) library(spdep) ## Dados necess√°rios sp_compos &lt;- ecodados::bocaina species &lt;- ecodados::com_birds env &lt;- ecodados::env_birds xy &lt;- ecodados::birds.xy data(mite) data(doubs) data(mite.env) data(package = &#39;palmerpenguins&#39;) 9.1 Aspectos te√≥ricos Em geral, an√°lises multivariadas t√™m tr√™s principais utilidades: reduzir a dimensionalidade dos dados e encontrar a principal dire√ß√£o de varia√ß√£o dos dados, testar rela√ß√µes entre matrizes, ou ainda encontrar diferen√ßas entre grupos. Apesar dessas an√°lises tamb√©m serem utilizadas como an√°lises explorat√≥rias e para descrever padr√µes em estudos ecol√≥gicos, a necessidade de se ter hip√≥teses, ou ao menos expectativas a priori, n√£o pode ser ignorada. Antes de entrar de cabe√ßa nas an√°lises multivariadas, tamb√©m sugerimos fortemente o estudo de m√©todos de amostragem e como fazer boas perguntas. An√°lises multivariadas podem ser divididas, grosseiramente, em dois tipos: agrupamento e ordena√ß√£o. An√°lises de agrupamento em geral tentam agrupar objetos (observa√ß√µes) ou descritores em grupos de maneira que objetos do mesmo grupo sejam mais semelhantes entre si do que objetos de outros grupos (P. Legendre and Legendre 2012a). Por exemplo, os objetos podem ser localidades como ‚Äúparcelas,‚Äù ‚Äúriachos‚Äù ou ‚Äúflorestas,‚Äù enquanto os descritores s√£o as difentes vari√°veis coletadas nesses objetos (e.g., esp√©cies, vari√°veis ambientais). A an√°lise de ordena√ß√£o, por sua vez, √© uma opera√ß√£o pela qual os objetos (ou descritores) s√£o posicionados num espa√ßo que cont√©m menos dimens√µes que o conjunto de dados original; a posi√ß√£o dos objetos ou descritores em rela√ß√£o aos outros tamb√©m podem ser usadas para agrup√°-los. Vamos come√ßar com an√°lises de agrupamento. Aqui vamos exemplificar dois m√©todos: uma t√©cnica de agrupamento hierarquica (dendrograma) e outra n√£o-hierarquica (k-means). 9.1.1 Coeficientes de associa√ß√£o Assim chamados genericamente, os coeficientes de associa√ß√£o medem o qu√£o parecidos objetos ou descritores s√£o entre si. Quando analisamos a rela√ß√£o entre objetos fazemos uma an√°lise no modo Q, ao passo que o modo R √© quando analisamos a rela√ß√£o entre descritores. Coeficientes de associa√ß√£o do modo Q s√£o medidas de (dis)similaridade ou dist√¢ncia, enquanto para o modo R utilizamos covari√¢ncia ou correla√ß√£o. Como j√° tratamos neste livro sobre covari√¢ncia e correla√ß√£o, neste t√≥pico vamos falar sobre √≠ndices de dist√¢ncia e similaridade. Mas qual a defini√ß√£o destas duas quantitades? Similaridade s√£o m√°ximas (S=1) quando dois objetos s√£o id√™nticos Dist√¢ncias s√£o o contr√°rio da similaridade (D=1-S) e n√£o t√™m limites superiores (dependem da unidade de medida) Existem ao menos 26 √≠ndices de similaridade que podem ser agrupados de acordo com o tipo de dado (qualitativos ou quantitativos), a maneira com que lidam com duplos zeros (sim√©tricos ou assim√©tricos). Do seu lado, as dist√¢ncias s√≥ se aplicam a dados quantitativos e t√™m como caracter√≠sticas serem m√©tricas, semi-m√©tricas ou n√£o-m√©tricas. Vejamos agora os principais √≠ndices de similaridade e dist√¢ncia de cada tipo. 9.1.2 M√©tricas de dist√¢ncia O principal coeficiente de dist√¢ncia usado em ecologia √© a dist√¢ncia euclidiana. Al√©m disso temos ainda Canberra, Mahalanobis (calcula a dist√¢ncia entre dois pontos num espa√ßo n√£o ortogonal, levando em considera√ß√£o a covari√¢ncia entre descritores), Manhattan, Chord (elimina diferen√ßas entre abund√¢ncia total de esp√©cies), ùúí2 (d√° peso maior para esp√©cies raras), Hellinger (n√£o d√° peso para esp√©cies raras). Essas dist√¢ncias s√£o recomendada nos casos em que as vari√°veis de estudo forem cont√≠nuas, como por exemplo vari√°veis morfom√©tricas ou descritores ambientais. Uma caracter√≠stica comum de conjuntos de dados ecol√≥gicos s√£o os v√°rios zeros encontrados em matrizes de composi√ß√£o. Eles surgem porque n√£o encontramos nenhum indiv√≠duo de uma determinada esp√©cie num local, seja porque aquele local n√£o tem as condi√ß√µes ambientais adequadas a ela, falha na detectabilidade, ou din√¢micas demogr√°ficas estoc√°sticas de coloniza√ß√£o-extin√ß√£o. Logo, quando dois locais compartilham aus√™ncia de esp√©cies, n√£o √© poss√≠vel atribuir uma √∫nica raz√£o da dupla aus√™ncia. Como essas medidas de dist√¢ncia apresentadas acima assumem que os dados s√£o quantitativos e n√£o de contagem, elas n√£o s√£o adequadas para lidar com dados de abund√¢ncia ou incid√™ncia de esp√©cies, porque atribuem um grau de parec√™n√ßa a pares de locais que compartilham zeros (P. Legendre and Legendre 2012a). Por esse motivo precisamos de coeficientes que desconsiderem os duplos zeros. Eles s√£o chamados de assim√©tricos. 9.1.2.1 Coeficientes assim√©tricos bin√°rios para objetos Esses coeficientes (ou √≠ndices) s√£o apropriados para dados de incid√™ncia de esp√©cies (presen√ßa-aus√™ncia) e desconsideram as duplas aus√™ncias. Os √≠ndices deste tipo mais comuns utilizados em ecologia s√£o S√∏rensen, Jaccard, e Ochiai. \\[ \\beta j= a/a+b+c \\] , onde a = n√∫mero de esp√©cies compartilhadas, b = n√∫mero de esp√©cies exclusivas da comunidade 1, c = n√∫mero de esp√©cies exclusivas da comunidade 2. A diferen√ßa entre Jaccard e S√∏rensen √© o S√∏rensen d√° peso dobrado para duplas presen√ßas. Por conta dessas caracter√≠sticas estes √≠ndices s√£o adequados para quantificar diversidade beta (Marti J. Anderson et al. 2010; Pierre Legendre and De C√°ceres 2013). Esses √≠ndices variam entre 0 (nenhuma esp√©cie √© compartilhada entre o par de locais) a 1 (todas as esp√©cies s√£o compartilhadas entre o par de locais). 9.1.2.2 Coeficientes bin√°rios para descritores (R mode) Se o objetivo for calcular a similaridade entre descritores bin√°rios (e.g., presen√ßa ou aus√™ncia de caracter√≠sticas ambientais) de pares de locais, geralmente o coeficiente recomendado √© o de Sokal &amp; Michener. Este √≠ndice est√° implementado em ade4::dist.binary. 9.1.2.3 Coeficientes quantitativos para objetos Estes s√£o os coeficientes utilizados para dados de contagem (e.g., abund√¢ncia), quantitativos (e.g., frequ√™ncia, biomassa, porcentagem cobertura). Diferentemente das dist√¢ncias, estes coeficientes s√£o assim√©tricos, ou seja, n√£o consideram duplas aus√™ncias, e portanto s√£o adequados para analisar dados de composi√ß√£o de esp√©cies. Al√©m disso, uma outra caracter√≠stica deles √© serem semi-m√©tricos. Os √≠ndices mais comuns deste tipo s√£o Bray-Curtis (conhecido como percentage difference em ingl√™s), Chord, log-Chord, Hellinger, chi-quadrado, e Morisita-Horn. Todos os √≠ndices discutidos at√© aqui est√£o implementados nas fun√ß√µes ade4::dist.ktab, adespatial::dist.ldc, e vegan::vegdist. 9.1.2.4 Coeficientes para descritores (R mode) que incluem mistura de tipos de dados √â comum em an√°lises de diversidade funcional que tenhamos um conjunto de atributos (traits) de esp√©cies que s√£o formados por v√°rios tipos de dados: quantitativos (e.g., tamanho de corpo), bin√°rios (presen√ßa aus√™ncia de uma dada caracter√≠stica), fuzzy (um atributo multiestado descrito codificado em v√°rias colunas com porcentagem), ordinais, e circulares (e.g., distribui√ß√£o de uma fenofase ao longo de um ano). O √≠ndice que lida com todos esses dados √© o Gower. A vers√£o extendida do √≠ndice de Gower pode ser encontrada na fun√ß√£o ade4::dist.ktab. O cap√≠tulo 7 de (P. Legendre and Legendre 2012a) fornece uma chave dicot√¥mica para escolha do √≠ndice mais adequado. 9.1.2.5 Padroniza√ß√µes e transforma√ß√µes √â comum coletarmos m√∫ltiplas vari√°veis ambientais cujas unidades sejam diferentes. Por exemplo, temperatura (¬∫C), dist√¢ncia da margem (m), √°rea (m2). Para diminuir a taxa de Erro Tipo I das an√°lises √© recomendado que padronizemos os dados utilizando distribui√ß√£o Z, assim todas as vari√°veis passam a ter m√©dia 0 e desvio padr√£o 1. Essa padroniza√ß√£o pode ser implementada na fun√ß√£o vegan::decostand. Um outro problema comum de matrizes de dados de composi√ß√£o de esp√©cies √© o alto n√∫mero de zeros, enquanto outras esp√©cies podem ter altas abund√¢ncias. Isso gera problemas em ordena√ß√µes. Para diminuir esta discrep√¢ncia podemos transformar os dados, por exemplo, utilizando a dist√¢ncia de Hellinger ou Chord. Isso pode ser feito na fun√ß√£o vegan::decostand. 9.2 An√°lise de agrupamento hier√°rquico O objetivo da an√°lise de agrupamento √© agrupar objetos admitindo que haja um grau de similaridade entre eles. Esta an√°lise pode ser utilizada ainda para classificar uma popula√ß√£o em grupos homog√™neos de acordo com uma caracter√≠stica de interesse. A grosso modo, uma an√°lise de agrupamento tenta resumir uma grande quantidade de dados e apresent√°-la de maneira f√°cil de visualizar e entender (em geral, na forma de um dendrograma). No entanto, os resultados da an√°lise podem n√£o refletir necessariamente toda a informa√ß√£o originalmente contida na matriz de dados. Para avaliar o qu√£o bem uma an√°lise de agrupamento representa os dados originais existe uma m√©trica ‚Äî o coeficiente de correla√ß√£o cofen√©tico ‚Äî o qual discutiremos em detalhes mais adiante. Antes de considerar algum m√©todo de agrupamento, pense porque voc√™ esperaria que houvesse uma descontinuidade nos dados; ou ainda, considere se existe algum ganho pr√°tico em dividir uma nuvem de objetos cont√≠nuos em grupos. O padr√£o apresentado pelo dendograma depende do protocolo utilizado (m√©todo de agrupamento e √≠ndice de dissimilaridade); os grupos formados dependem do n√≠vel de corte escolhido. A matriz deve conter os objetos a serem agrupados (e.g., esp√©cies) nas linhas e as vari√°veis (e.g., locais de coleta ou medidas morfol√≥gicas) nas colunas. A escolha do m√©todo de agrupamento √© cr√≠tico para a escolha de um coeficiente de associa√ß√£o. √â importante compreender as propriedades dos m√©todos de agrupamento para interpretar corretamente a estrutura ecol√≥gica que eles evidenciam (P. Legendre and Legendre 2012a). De acordo com a classifica√ß√£o de Sneath &amp; Sokal (1973) existem cinco tipos de m√©todos: 1) sequÃàenciais ou simult√¢neos; 2) aglomerativo ou divisivo; 3) monot√©ticos ou polit√©ticos; 4) hier√°rquico ou n√£o hier√°rquicos e 5) probabil√≠stico. Sugerimos a leitura do artigo citado para aprofundar seus conhecimentos sobre os diferentes m√©todos. M√©todos hier√°rquicos podem ser divididos naqueles que consideram o centr√≥ide ou a m√©dia aritm√©tica entre os grupos. O principal m√©todo hier√°rquico que utiliza a m√©dia aritm√©tica √© o UPGMA (Agrupamento pelas m√©dias aritm√©ticas n√£o ponderadas), e o principal m√©todo que utiliza centr√≥ides √© a Dist√¢ncia m√≠nima de Ward. O UPGMA funciona da seguinte forma: a maior similaridade (ou menor dist√¢ncia) identifica os pr√≥ximos agrupamentos a serem formados. Ap√≥s esse evento, o m√©todo calcula a m√©dia aritm√©tica das similaridades ou dist√¢ncias entre um objeto e cada um dos membros do grupo ou, no caso de um grupo previamente formado, entre todos os membros dos dois grupos. Todos os objetos recebem pesos iguais no c√°lculo. O m√©todo de Ward √© baseado no crit√©rio de quadrados m√≠nimos (OLS), o mesmo utilizado para ajustar um modelo linear. O objetivo √© definir os grupos de maneira que a soma de quadrados (i.e.¬†similar ao erro quadrado da ANOVA) dentro dos grupos seja minimizada (Borcard, Gillet, and Legendre 2018). No entanto, para interpretar os resultados precisamos antes definir um n√≠vel de corte, que vai nos dizer quantos grupos existem. H√° v√°rios m√©todos para definir grupos, desde os heur√≠sticos aos que utilizam bootstrap. Se quisermos interpretar este dendrograma, podemos por exemplo estabelecer um n√≠vel de corte de 50% de dist√¢ncia (ou seja, grupos cujos objetos tenham ao menos 50% de similaridade entre si). Checklist Verifique se n√£o h√° espa√ßo nos nomes das colunas e linhas Se os dados forem de abund√¢ncia, recomenda-se realizar a transforma√ß√£o de Hellinger [@legendre2001]. Esta transforma√ß√£o √© necess√°ria porque a matriz de comunidades (em especial, com a presen√ßa de muitas esp√©cies raras) pode causar distor√ß√µes nos m√©todos de ordena√ß√£o baseados em dist√¢ncia Euclidiana [@legendre2001]. Se a matriz original contiver muitos valores discrepantes (e.g., uma esp√©cie muito mais ou muito menos abundante que outras) √© necess√°rio transformar os dados usando log1p. Se as vari√°veis forem medidas tomadas em diferentes escalas (metros, graus celcius etc), √© necess√°rio padronizar cada vari√°vel para ter a m√©dia 0 e desvio padr√£o 1. Isso pode ser feito utulizando a fun√ß√£o decostand do pacote vegan. 9.2.0.1 Exemplo 1 Neste exemplo vamos utilizar um conjunto de dados que cont√©m larvas de esp√©cies de anf√≠bios anuros coletados em 14 po√ßas com diferentes coberturas de dossel. Pergunta Existem grupos de esp√©cies de anf√≠bios anuros com padr√µes de ocorr√™ncia similar ao longo das po√ßas? Predi√ß√µes Iremos encontrar ao menos dois grupos de esp√©cies: aquelas que ocorrem em po√ßas dentro de floresta (i.e., maior cobertura de dossel) vs.¬†aquelas que ocorrem em po√ßas de √°reas abertas (menor cobertura de dossel). Vari√°veis Vari√°veis preditoras: a matriz de dados cont√©m a abund√¢ncia das esp√©cies nas linhas e locais (po√ßas) nas colunas. 9.2.1 An√°lise no R Para come√ßar, vamos primeiro importar os dados e depois calcular a matriz de dist√¢ncia que seja adequada para o tipo de dado que temos (abund√¢ncia de esp√©cies - dados de contagem) ## Composi√ß√£o de esp√©cies (seis primeiras localidades) head(sp_compos) #&gt; BP4 PP4 PP3 AP1 AP2 PP1 PP2 BP9 PT1 PT2 PT3 BP2 PT5 #&gt; Aper 0 3 0 0 2 0 0 0 0 0 0 181 0 #&gt; Bahe 859 14 14 0 87 312 624 641 0 0 0 14 0 #&gt; Rict 1772 1517 207 573 796 0 0 0 0 0 0 0 0 #&gt; Cleuco 0 0 0 0 0 0 0 0 0 29 369 0 84 #&gt; Dmic 0 0 6 60 4 0 0 0 2758 319 25 0 329 #&gt; Dmin 0 84 344 1045 90 0 0 0 8 0 0 0 0 ## Matriz de similaridade com o coeficiente de Morisita-Horn distBocaina &lt;- vegdist(sp_compos, method=&quot;horn&quot;) # Agrupamento com a fun√ß√£o hclust e o m√©todo UPGMA dendro &lt;- hclust(distBocaina, method=&quot;average&quot;) # Visualizar os resultados plot(dendro) 9.2.2 Assessando a qualidade do dendrograma Precisamos verificar que o agrupamento reduziu a dimensionalidade da matiz de forma eficiente, de maneira a n√£o distorcer a informa√ß√£o. Fazemos isso calculando o Coeficiente de correla√ß√£o cofen√©tica (CCC) cofresult &lt;- cophenetic(dendro) cor(cofresult, distBocaina) #&gt; [1] 0.9455221 Um CCC &gt; .7 indica uma boa representa√ß√£o. Portanto, o nosso resultado de 0.9455221 √© alto, garantindo que o dendrograma √© adequado. plot(dendro) k &lt;- 4 n &lt;- ncol(sp_compos) MidPoint &lt;- (dendro$height[n-k] + dendro$height[n-k+1]) / 2 abline(h = MidPoint, lty=2) Nesse caso teremos a forma√ß√£o de cinco grupos, representados pelos n√≥s que est√£o abaixo da linha de corte. Portanto, o resultado n√£o suporta a nossa hip√≥tese a priori que predizia a forma√ß√£o de apenas dois grupos de esp√©cies. 9.2.2.1 Exemplo 2 No exemplo anterior vimos que √© dif√≠cil interpretar os grupos baseado num n√≠vel de corte. A seguir, vamos utilizar o pacote pvclust que calcula automaticamente o n√≠vel de corte de similaridade baseado no Bootstrap de cada n√≥. Uma desvantagem deste m√©todo √© que ele somente aceita √≠ndices de similaridade da fun√ß√£o dist que possui apenas a dist√¢ncia Euclidiana, Manhattan e Canberra. Uma maneira de contornarmos essa limita√ß√£o √© utilizar transforma√ß√µes dos dados dispon√≠veis na fun√ß√£o disttransform no pacote BiodiversityR ou o decostand do pacote vegan. Tamb√©m √© poss√≠vel utilizar a transforma√ß√£o de Box-Cox para dados multivariados, dispon√≠vel no material suplementar de (Pierre Legendre and Borcard 2018). aqui. Esta transforma√ß√£o √© geralmente utilizada para tornar a distribui√ß√£o dos dados mais sim√©trica (menos enviesada para valores extremos: reduzir o skewness dos dados). 9.2.3 An√°lise no R Vamos utilizar o mesmo conjunto de dados acima pra responder √† mesma pergunta. Aqui vamos utilizar a dist√¢ncia de Chord (que √© indicada para dados de composi√ß√£o de esp√©cies) para calcular a matriz de dist√¢ncia. Se transformarmos uma matriz usando a transforma√ß√£o Chord e depois calcularmos a dist√¢ncia Euclidiana, isso equivale √† calcular diretamente a dist√¢ncia de Chord: # Dados head(sp_compos) #&gt; BP4 PP4 PP3 AP1 AP2 PP1 PP2 BP9 PT1 PT2 PT3 BP2 PT5 #&gt; Aper 0 3 0 0 2 0 0 0 0 0 0 181 0 #&gt; Bahe 859 14 14 0 87 312 624 641 0 0 0 14 0 #&gt; Rict 1772 1517 207 573 796 0 0 0 0 0 0 0 0 #&gt; Cleuco 0 0 0 0 0 0 0 0 0 29 369 0 84 #&gt; Dmic 0 0 6 60 4 0 0 0 2758 319 25 0 329 #&gt; Dmin 0 84 344 1045 90 0 0 0 8 0 0 0 0 # Passo 1: transformar para dist√¢ncia de Chord bocaina_transf &lt;- disttransform(sp_compos, &quot;chord&quot;) # Passo 2: realizar pvclust com m√©todo average e dist√¢ncia euclidiana analise &lt;- pvclust(bocaina_transf, method.hclust=&quot;average&quot;, method.dist=&quot;euclidean&quot;) #&gt; Bootstrap (r = 0.5)... Done. #&gt; Bootstrap (r = 0.56)... Done. #&gt; Bootstrap (r = 0.69)... Done. #&gt; Bootstrap (r = 0.75)... Done. #&gt; Bootstrap (r = 0.88)... Done. #&gt; Bootstrap (r = 1.0)... Done. #&gt; Bootstrap (r = 1.06)... Done. #&gt; Bootstrap (r = 1.19)... Done. #&gt; Bootstrap (r = 1.25)... Done. #&gt; Bootstrap (r = 1.38)... Done. # Passo 3: dendrograma plot(analise, hang=-1) pvrect(analise) √â poss√≠vel notar que existe um √∫nico grupo com BS &gt; 95%. Agora vamos tentar usar a dist√¢ncia de Hellinger, que √© recomendada (junto com a dist√¢ncia de Chord) para transformar dados de composi√ß√£o de esp√©cies e, desse modo, reduzem distor√ß√µes nas ordena√ß√µes como PCA e CA (Pierre Legendre and Gallagher 2001). # Passo 1: transformar dados com Hellinger bocaina_transf2 &lt;- disttransform(bocaina, &quot;hellinger&quot;) # Passo 2: realizar pvclust com m√©todo average e dist√¢ncia euclidiana analise2 &lt;- pvclust(bocaina_transf2, method.hclust=&quot;average&quot;, method.dist=&quot;euclidean&quot;) #&gt; Bootstrap (r = 0.5)... Done. #&gt; Bootstrap (r = 0.56)... Done. #&gt; Bootstrap (r = 0.69)... Done. #&gt; Bootstrap (r = 0.75)... Done. #&gt; Bootstrap (r = 0.88)... Done. #&gt; Bootstrap (r = 1.0)... Done. #&gt; Bootstrap (r = 1.06)... Done. #&gt; Bootstrap (r = 1.19)... Done. #&gt; Bootstrap (r = 1.25)... Done. #&gt; Bootstrap (r = 1.38)... Done. # Passo 3: dendrograma plot(analise2, hang=-1) pvrect(analise2) 9.2.3.1 Interpreta√ß√£o dos resultados Notem que se mudarmos o coeficiente de associa√ß√£o, o resultado tamb√©m muda. Agora temos 1 grupo a mais, composto por Dendropsophus minutus e Scinax duartei que n√£o apareciam antes. Isso se deve ao fato de que a dist√¢ncia de Hellinger d√° menos peso para esp√©cies raras do que a Chord. Neste sentido, os dados n√£o suportam a nossa hip√≥tese inicial da forma√ß√£o de dois grupos, independentemente do coeficiente de associa√ß√£o utilizado. 9.3 K-means e agrupamentos n√£o-hier√°rquicos Ao contr√°rio do dendrograma, o K-means √© um agrupamento n√£o-hier√°rquico e, desse modo, n√£o √© otimizado para busca grupos menores aninhados em grupos grupos maiores. Resumidamente, podemos calcular o K-means apartir de uma matriz quadrada ou de dist√¢ncia. Essa t√©cnica procura particionar os objetos em k grupos de maneira a minimizar a soma de quadrados entre grupos e maximiz√°-la dentro dos grupos. Um crit√©rio similar ao de uma ANOVA (cap7?). Um diferencial do K-means em rela√ß√£o aos agrupamentos hier√°rquicos √© que o usu√°rio pode escolher antecipadamente o n√∫mero de grupos que deseja formar. 9.3.0.1 Exemplo 1 Para este exemplo iremos utilizar um conjunto de dados dispon√≠vel no pacote ade4 que cont√©m dados de 27 esp√©cies de peixes coletados em 30 pontos ao longo do Rio Doubs, na fronteira entre a Fran√ßa e Sui√ßa. Pergunta Qual √© o n√∫mero de grupos que melhor sumariza o padr√£o de ocorr√™ncia de esp√©cies de peixes ao longo de um riacho? (neste caso, estamos realizando uma an√°lise explorat√≥ria e n√£o temos uma predi√ß√£o) Vari√°veis Vari√°veis resposta: composi√ß√£o de esp√©cies de peixes Checklist Vamos normalizar os dados de abund√¢ncia antes de entrar na an√°lise propriamente, j√° que existem muitos zeros na matriz. 9.3.1 An√°lise # mostrar somente seis primeiras esp√©cies de seis localidades head(doubs$fish)[,1:6] #&gt; Cogo Satr Phph Neba Thth Teso #&gt; 1 0 3 0 0 0 0 #&gt; 2 0 5 4 3 0 0 #&gt; 3 0 5 5 5 0 0 #&gt; 4 0 4 5 5 0 0 #&gt; 5 0 2 3 2 0 0 #&gt; 6 0 3 4 5 0 0 # retirar a linha 8 (rio sem nenhuma ocorr√™ncia de peixe) spe &lt;- doubs$fish[-8,] # Fun√ß√£o do pacote vegan para normalizar os dados spe.norm &lt;- decostand(spe, &quot;normalize&quot;) O argumento centers na fun√ß√£o abaixo indica o n√∫mero de grupos que se quer formar. Neste exemplo estamos utilizando centers = 4. spe.kmeans &lt;- kmeans(spe.norm, centers = 4, nstart = 100) spe.kmeans #&gt; K-means clustering with 4 clusters of sizes 3, 12, 6, 8 #&gt; #&gt; Cluster means: #&gt; Cogo Satr Phph Neba Thth Teso Chna Chto #&gt; 1 0.00000000 0.000000000 0.00000000 0.00000000 0.000000000 0.000000000 0.05205792 0.00000000 #&gt; 2 0.10380209 0.542300691 0.50086515 0.43325916 0.114024105 0.075651573 0.00000000 0.00000000 #&gt; 3 0.06167791 0.122088022 0.26993915 0.35942538 0.032664966 0.135403325 0.06212775 0.21568957 #&gt; 4 0.00000000 0.006691097 0.02506109 0.06987391 0.006691097 0.006691097 0.10687104 0.09377516 #&gt; Lele Lece Baba Spbi Gogo Eslu Pefl Rham #&gt; 1 0.07647191 0.3166705 0.00000000 0.0000000 0.20500174 0.07647191 0.00000000 0.0000000 #&gt; 2 0.06983991 0.1237394 0.02385019 0.0000000 0.05670453 0.04722294 0.02949244 0.0000000 #&gt; 3 0.25887226 0.2722562 0.15647062 0.1574388 0.16822286 0.12276089 0.17261621 0.0793181 #&gt; 4 0.14194394 0.2011411 0.24327992 0.1326062 0.28386032 0.20630360 0.16920496 0.2214275 #&gt; Legi Scer Cyca Titi Abbr Icme Acce Ruru #&gt; 1 0.05205792 0.07647191 0.00000000 0.00000000 0.00000000 0.0000000 0.18058775 0.31667052 #&gt; 2 0.00000000 0.00000000 0.00000000 0.03833408 0.00000000 0.0000000 0.00000000 0.01049901 #&gt; 3 0.06190283 0.04516042 0.06190283 0.14539027 0.01473139 0.0000000 0.03192175 0.32201597 #&gt; 4 0.19066542 0.13171275 0.16019126 0.26230024 0.19561641 0.1331835 0.26713081 0.32103755 #&gt; Blbj Alal Anan #&gt; 1 0.05205792 0.7618709 0.00000000 #&gt; 2 0.00000000 0.0000000 0.00000000 #&gt; 3 0.01473139 0.1095241 0.04739636 #&gt; 4 0.22883055 0.3326939 0.18873077 #&gt; #&gt; Clustering vector: #&gt; 1 2 3 4 5 6 7 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #&gt; 2 2 2 2 3 2 2 3 2 2 2 2 2 2 3 3 3 3 4 4 4 1 1 1 4 4 4 4 4 #&gt; #&gt; Within cluster sum of squares by cluster: #&gt; [1] 0.3560423 2.5101386 1.7361453 0.4696535 #&gt; (between_SS / total_SS = 66.7 %) #&gt; #&gt; Available components: #&gt; #&gt; [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; &quot;betweenss&quot; #&gt; [7] &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; O objeto que fornece o resultado cont√©m: 1) o tamanho (n√∫mero de objetos) em cada um dos 4 grupos; 2) o centroide de cada grupo e o pertencimento de cada esp√©cie a cada grupo; e 3) o quanto da Soma de Quadrados dos dados √© explicada por esta conforma√ß√£o de grupos. No entanto, n√£o √© poss√≠vel saber a priori qual o n√∫mero ideal de grupos. Para descobrir isso repetimos o k-means com uma s√©rie de valores de K. Isso pode ser feito na fun√ß√£o cascadeKM. spe.KM.cascade &lt;- cascadeKM(spe.norm, inf.gr=2, sup.gr=10, iter=100, criterion=&quot;ssi&quot;) Tanto calinski quando ssi s√£o bons crit√©rios para encontrar o n√∫mero ideal de grupos. Quanto maior o valor de ssi, melhor (veja ?cascadeKM mais detalhes). # Resumo dos resultados spe.KM.cascade$results #&gt; 2 groups 3 groups 4 groups 5 groups 6 groups 7 groups 8 groups 9 groups #&gt; SSE 8.2149405 6.4768108 5.0719796 4.3015573 3.58561200 2.9523667 2.4840549 2.05218880 #&gt; ssi 0.1312111 0.1675852 0.1398159 0.1138008 0.08295513 0.1410657 0.1461625 0.07877382 #&gt; 10 groups #&gt; SSE 1.75992916 #&gt; ssi 0.06817212 SSE: crit√©rio utilizado pelo algor√≠timo para achar o agrupamento √≥timo dos objetos. plot(spe.KM.cascade, sortg=TRUE) 9.3.2 Interpreta√ß√£o dos resultados Diferentemente da nossa predi√ß√£o inicial, o resultado da an√°lise mostra que o n√∫mero ideal de grupos para explicar a vari√¢ncia no padr√£o de ocorr√™ncia de esp√©cies √© 3. Notem que o SSI m√°ximo √© alcan√ßado neste n√∫mero de grupos 0.1675852 (tamb√©m indicado pela bola vermelha no plot). 9.4 Esp√©cies indicadoras Uma pergunta normalmente feita por ec√≥logos √©: qual esp√©cie pode ser indicadora de uma determinada condi√ß√£o ambiental (e.g., polui√ß√£o)? O √≠ndice IndVal mede dois aspectos das esp√©cies: Especificidade e fidelidade. Uma alta fidelidade significa que esp√©cies ocorrem em todos os locais do grupo e uma alta especificidade significa que as esp√©cies ocorrem somente naquele grupo. Uma boa esp√©cie indicadora √© aquela na qual todos os indiv√≠duos ocorrem em todas a amostras referentes a um grupo espec√≠fico. A Especificidade √© dada pela divis√£o da abundancia m√©dia da esp√©cie no grupo pela somat√≥ria das abundancias m√©dias dos grupos. Fidelidade √© igual ao n√∫mero de lugares no grupo onde a esp√©cie est√° presente dividido pelo n√∫mero total de lugares do grupo (DufreÃÇne and Legendre 1997). Esp√©cies raras podem receber o mesmo valor de IndVal das esp√©cies indicadoras, por√©m s√£o chamadas de indicadoras assim√©tricas, uma vez que contribuem com a especificidade do habitat mas n√£o servem para predizer grupos. Ao contr√°rio, as esp√©cies indicadoras s√£o verdadeiros indicadores sim√©tricos e podem ser usadas para predizer grupos. A an√°lise procede da seguinte forma: Uma matriz de dist√¢ncia √© constru√≠da e as unidades amostrais s√£o classificadas com alguma an√°lise de agrupamento, hier√°rquico ou n√£o; A vari√°vel ambiental para a qual se deseja classificar os grupos √© inserida; As esp√©cies indicadoreas de cada grupo s√£o formadas atrav√©s do c√°lculo da especificidade e fidelidade, obtendo-se o valor de IndVal para cada esp√©cie; Por fim, o conjunto de dados originais √© comparado para ver se an√°lise faz sentido. O c√°lculo da signific√¢ncia do √≠ndice de IndVal √© feito por aleatoriza√ß√£o de Monte Carlo. Os m√©todos de Monte Carlo utilizam n√∫meros aleat√≥rios de dados reais para simular certos padr√µes esperados na aus√™ncia de um processo ecol√≥gico espec√≠fico [numerica2012]. Assim, o valor do √≠ndice √© aleatorizado 999 vezes (ou o n√∫mero de vezes que voc√™ optar) dentro dos tratamentos e o valor de P √© dado pelo n√∫mero de vezes em que o √≠ndice observado foi igual ou maior que os valores aleatorizados. 9.4.0.1 Exemplo 1 Pergunta Podemos utilizar as esp√©cies de girinos como indicadoras da fitofisionomia? Predi√ß√µes Esp√©cies terrestres ser√£o indicadoras de √°rea aberta, enquanto esp√©cies arbor√≠colas ser√£o indicadoras de √°reas florestais. Vari√°veis Vari√°veis resposta: mesma matriz j√° utilizada contendo a abund√¢ncia de girinos ao longo de po√ßas na Serra da Bocaina. 9.4.1 An√°lise no R Para este exemplo vamos utilizado o mesmo conjunto de dados utilizado acima com abund√¢ncia de 16 esp√©cies de girinos coletados em 14 po√ßas com diferentes graus de cobertura de dossel na Serra da Bocaina. O IndVal est√° dispon√≠vel tanto no pacote indicspecies quando no labdsv. Para este exemplo iremos usar o labdsv. Primeiro vamos agrupar as unidades amostrais (po√ßas) que informa os grupos de fitofisionomias onde as po√ßas se localizam e para os quais deseja-se encontrar esp√©cies indicadoras: ## Dados head(bocaina) #&gt; BP4 PP4 PP3 AP1 AP2 PP1 PP2 BP9 PT1 PT2 PT3 BP2 PT5 #&gt; Aper 0 3 0 0 2 0 0 0 0 0 0 181 0 #&gt; Bahe 859 14 14 0 87 312 624 641 0 0 0 14 0 #&gt; Rict 1772 1517 207 573 796 0 0 0 0 0 0 0 0 #&gt; Cleuco 0 0 0 0 0 0 0 0 0 29 369 0 84 #&gt; Dmic 0 0 6 60 4 0 0 0 2758 319 25 0 329 #&gt; Dmin 0 84 344 1045 90 0 0 0 8 0 0 0 0 fitofis &lt;- c(rep(1,4), rep(2,4), rep(3,4), rep(4,4), rep(5,4)) ## An√°lise de esp√©cies indicadoras res_indval &lt;- indval(bocaina, fitofis) # A fun√ß√£o summary s√≥ exibe o resultado para as esp√©cies indicadoras summary(res_indval) #&gt; [1] cluster indicator_value probability #&gt; &lt;0 rows&gt; (or 0-length row.names) #&gt; #&gt; Sum of probabilities = 9.324 #&gt; #&gt; Sum of Indicator Values = 3.97 #&gt; #&gt; Sum of Significant Indicator Values = 0 #&gt; #&gt; Number of Significant Indicators = 0 #&gt; #&gt; Significant Indicator Distribution #&gt; &lt; table of extent 0 &gt; Para apresentar uma tabela dos resultados para todas as esp√©cies temos de processar os dados: res_indval$maxcls # classe de maior valor indicador / esp√©cie #&gt; BP4 PP4 PP3 AP1 AP2 PP1 PP2 BP9 PT1 PT2 PT3 BP2 PT5 #&gt; 1 1 2 2 2 2 1 1 4 2 1 2 2 res_indval$indcls # valor indicador (indval) #&gt; BP4 PP4 PP3 AP1 AP2 PP1 PP2 BP9 PT1 #&gt; 0.4268332 0.3554217 0.3990627 0.4887564 0.5812265 0.1283151 0.2194093 0.2260226 0.3535255 #&gt; PT2 PT3 BP2 PT5 #&gt; 0.1945122 0.2341371 0.1648885 0.1991525 res_indval$pval # signific√¢ncia do indval #&gt; BP4 PP4 PP3 AP1 AP2 PP1 PP2 BP9 PT1 PT2 PT3 BP2 PT5 #&gt; 0.281 0.613 0.282 0.146 0.316 1.000 1.000 1.000 0.742 1.000 1.000 0.944 1.000 tab_indval &lt;- cbind.data.frame(maxcls = res_indval$maxcls, ind.value = res_indval$indcls, P = res_indval$pval) tab_indval #&gt; maxcls ind.value P #&gt; BP4 1 0.4268332 0.281 #&gt; PP4 1 0.3554217 0.613 #&gt; PP3 2 0.3990627 0.282 #&gt; AP1 2 0.4887564 0.146 #&gt; AP2 2 0.5812265 0.316 #&gt; PP1 2 0.1283151 1.000 #&gt; PP2 1 0.2194093 1.000 #&gt; BP9 1 0.2260226 1.000 #&gt; PT1 4 0.3535255 0.742 #&gt; PT2 2 0.1945122 1.000 #&gt; PT3 1 0.2341371 1.000 #&gt; BP2 2 0.1648885 0.944 #&gt; PT5 2 0.1991525 1.000 9.4.2 Interpreta√ß√£o dos resultados No resultado podemos ver que temos duas esp√©cies indicadoras da fitofisionimia 1: Rhinella icterica (Rict) e Scinax duartei (Sduar). Nenhuma esp√©cie foi indicadora dos outros grupos neste exemplo. 9.5 An√°lises de Ordena√ß√£o Os an√°lises de ordena√ß√£o representam um conjunto de m√©todos e t√©cnicas multivariadas que buscam organizar objetos (e.g., localidades, indiv√≠duos, esp√©cies) em alguma ordem. Por exemplo, tais m√©todos permitem identificar se existem grupo de esp√©cies que ocorrem exclusivamente em um determinado h√°bitat. Ao buscar esta ordem as t√©cnicas de ordena√ß√£o possuem tr√™s principais utilidades: (1) reduzir a dimensionalidade e revelar padr√µes, (2) separar vari√°veis mais e menos importantes em combina√ß√µes complexas, e (3) separar rela√ß√µes mais e menos fortes ao comparar vari√°veis preditoras e dependentes. Em geral, os m√©todos s√£o divid√≠dos em ordena√ß√µes irrestritas (ou an√°lise de gradiente indireto) e restritas (ou an√°lise de gradiente direto). As ordena√ß√µes irrestritas organizam os objetos (e.g., esp√©cies) de acordo com sua estrutura de covari√¢ncia (ou correla√ß√£o), o que demonstra que a proximidade (ou dist√¢ncia) dentro do espa√ßo multidimensional representa semelhan√ßa (ou diferen√ßa) dos objetos. Por outro lado, as ordena√ß√µes restritras posiciona os objetos (e.g., esp√©cies) de acordo com sua rela√ß√£o linear com outras vari√°veis coletadas nas mesmas unidades amostraits (e.g., temperatura e precipita√ß√£o). Ao passo que as ordena√ß√µes irrestritas dependem somente de uma matriz (e.g., esp√©cies por localidades), as ordena√ß√µes restritas utilizam no m√≠nimo duas matrizes (e.g., esp√©cies por localidades e vari√°veis clim√°ticas por localidade). Desse modo, fica claro por esta diferen√ßa entre os dados utilizados que as an√°lises irrestritas s√£o mais explorat√≥rias, enquanto an√°lises restritas s√£o ideias para testar hip√≥teses com dados multidimensionais. A tabela a seguir apresenta as principais an√°lises utilizadas em ecologia. M√©todo Tipo de vari√°vel Fun√ß√£o R Ordena√ß√£o irrestrita PCA Vari√°veis cont√≠nuas (dist√¢ncia euclidiana) PCA, rda, dudi.pca PCoA Aceita qualquer tipo de vari√°vel, mas depende da escolha apropriada de uma medida de dist√¢ncia pcoa, dudi.pco nMDS Aceita qualquer tipo de vari√°vel, mas depende da escolha apropriada de uma medida de dist√¢ncia metaMDS, nmds CA dudi.coa Hill-Smith Aceita qualquer tipo de vari√°vel dudi.hillsmith Ordena√ß√£o restrita RDA Vari√°veis preditoras de qualquer tipo e vari√°veis dependentes cont√≠nuas (ou presen√ßa e aus√™ncia) rda RDA parcial Vari√°veis preditoras de qualquer tipo e vari√°veis dependentes cont√≠nuas (ou presen√ßa e aus√™ncia) rda dbRDA Vari√°veis preditoras de qualquer tipo e matriz de dist√¢ncia obtida a partir das vari√°veis dependentes capscale, dbrda CCA Vari√°veis preditoras de qualquer tipo e vari√°veis dependentes cont√≠nuas (ou presen√ßa e aus√™ncia) rda PERMANOVA Vari√°veis preditoras de qualquer tipo e matriz de dist√¢ncia obtida a partir das vari√°veis dependentes adonis, adonis2 PCR Vari√°vel dependente necessariamente representada por escores da PCA ou PCoA e vari√°veis preditoras de qualquer tipo pca, pcoa, lm, glm 9.5.1 Ordena√ß√µes irrestritas 9.5.1.1 An√°lise de Componentes Principais - PCA A PCA √© uma das ordena√ß√µes mais utilizadas em diversas √°reas do conhecimento. Em ecologia, ela se popularizou por facilitar a visualiza√ß√£o de dados complexos como de distribui√ß√£o de esp√©cies em diferentes localidades e de potenciais vari√°veis explicativas. Ao mesmo tempo que ganhou tamanha popularidade, a PCA tem sido empregada de maneira incorreta, uma vez que muitos estudos utilizam a visualiza√ß√£o gr√°fica da ordena√ß√£o (o biplot) para intepretar ‚Äúrela√ß√µes‚Äù entre vari√°veis preditoras (ambientais) e dependentes (esp√©cies). Por√©m, como informado anteriormente, as ordena√ß√µes irrestritas utilizam a estrutura de covari√¢ncia dos objetos para organizar suas rela√ß√µes de similaridade. Antes de explicar a an√°lise, imagine que vamos usar uma matriz com cinco esp√©cies de aranhas que foram encontradas em oito cidades diferentes. A quantidade de indiv√≠duos de cada esp√©cie coletada em cada cidade ser√° o valor de preenchimento desta matriz. Sendo assim, a matriz possui oito objetos (cidades, representando unidades amostrais) e cinco descritores (esp√©cies), como na tabela abaixo: Cidade sp1 sp2 sp3 sp4 sp5 Cidade 1 5 0 0 0 0 Cidade 2 7 6 0 0 0 Cidade 3 2 3 0 0 0 Cidade 4 0 4 9 0 0 Cidade 5 0 0 12 4 0 Cidade 6 0 0 3 10 6 Cidade 7 0 0 0 8 9 Cidade 8 0 0 0 0 12 O primeiro passo da PCA √© obter uma matriz centralizada onde cada valor √© subtra√≠do da m√©dia da coluna que aquele valor pertence. Esta centraliza√ß√£o pode ser calculada com a fun√ß√£o scale. aranhas &lt;- data.frame(sp1 = c(5, 7, 2, 0, 0, 0, 0, 0), sp2 = c(0, 6, 3, 4, 0, 0, 0, 0), sp3 = c(0, 0, 0, 9, 12, 3, 0, 0), sp4 = c(0, 0, 0, 0, 4, 10, 8, 0), sp5 = c(0, 0, 0, 0, 0, 6, 9, 12), row.names = paste(&quot;cidade&quot;, 1:8, sep=&quot;&quot;)) aranha.cent &lt;- as.data.frame(base::scale(aranhas, center = TRUE, scale=FALSE)) O segundo passo √© calcular uma matriz de covari√¢ncia (ou matriz de dispers√£o) e, a partir desta matriz, obter os autovalores e autovetores. Os autovalores representam a porcentagem de explica√ß√£o de cada eixo e podem ser calculados dividindo a soma do autovalor de cada eixo pela soma de todos os autovalores. No exemplo que apresentamos, os dois primeiros eixos representam 47,20% e 35,01%, respectivamente, de toda varia√ß√£o. Os autovetores, por sua vez, representam os valores que multiplicam as vari√°veis originais e, desse modo, indicam a dire√ß√£o desses valores. Por fim, os componentes principais (Matriz F) s√£o obtidos multiplicando os autovetores com os valores da matriz centralizada. ## Matriz de covai√¢ncia matriz_cov &lt;- cov(aranha.cent) ## Autovalores e autovetores eigen_aranhas &lt;- eigen(matriz_cov) autovalores&lt;- eigen_aranhas$values autovetores &lt;- as.data.frame(eigen_aranhas$vectors) autovalores # eigenvalue #&gt; [1] 36.733031 27.243824 9.443805 2.962749 1.438020 colnames(autovetores) &lt;- paste(&quot;PC&quot;, 1:5, sep=&quot;&quot;) rownames(autovetores) &lt;- colnames(aranhas) autovetores #&gt; PC1 PC2 PC3 PC4 PC5 #&gt; sp1 -0.2144766 0.38855265 0.29239380 -0.02330706 0.8467522 #&gt; sp2 -0.2442026 0.17463316 0.01756743 0.94587037 -0.1220204 #&gt; sp3 -0.3558368 -0.80222917 -0.27591770 0.10991178 0.3762942 #&gt; sp4 0.4159852 -0.41786654 0.78820962 0.17374202 0.0297183 #&gt; sp5 0.7711688 0.01860152 -0.46560957 0.25003826 0.3544591 matriz_F &lt;- as.data.frame(as.matrix(aranha.cent)%*%as.matrix(autovetores)) matriz_F #&gt; PC1 PC2 PC3 PC4 PC5 #&gt; cidade1 -2.979363 4.4720575 1.1533417 -3.2641923 0.5433206 #&gt; cidade2 -4.873532 6.2969618 1.8435339 2.3644158 1.5047024 #&gt; cidade3 -3.068541 3.8302991 0.3288626 -0.3566600 -2.3629973 #&gt; cidade4 -6.086322 -3.9922356 -2.7216169 1.6250305 -0.7918743 #&gt; cidade5 -4.513082 -8.7689219 -0.4668012 -1.1337476 0.9439633 #&gt; cidade6 5.812374 -3.9444494 3.9520584 0.4197281 -0.1376205 #&gt; cidade7 8.361421 -0.6462243 1.8065636 0.4926235 -0.2625625 #&gt; cidade8 7.347046 2.7525126 -5.8959421 -0.1471979 0.5630683 ## Porcentagem de explica√ß√£o de cada eixo 100* (autovalores / sum(autovalores)) #&gt; [1] 47.201691 35.008126 12.135225 3.807112 1.847846 Agora, √© poss√≠vel visualizar a rela√ß√£o entre as cidades e similaridade na esp√©cies de aranhas que vivem em cada uma delas. matriz_F %&gt;% ggplot(aes(x = PC1, y = PC2, label = rownames(matriz_F))) + theme_bw() + geom_label() + geom_hline(yintercept = 0, linetype=2) + geom_vline(xintercept = 0, linetype=2) + theme(axis.title.x = element_text(size=14), axis.text.x = element_text(vjust=0.5, size=12), axis.title.y = element_text(size=14), axis.text.y = element_text(vjust=0.5, size=12)) Checklist Verifique se todas as vari√°veis utilizadas s√£o cont√≠nuas. Caso contr√°rio, considere utilizar PCoA. Apesar do exemplo acima ter apresentado a ocorr√™ncia de esp√©cies de aranhas em diferentes cidades, √© fundamental saber que utilizar PCA com esses dados pode ser problem√°tico. Assim, tenha cuidado em usar de composi√ß√£o de esp√©cies (especialmente abund√¢ncia) com PCA, uma vez que ‚Äòduplos zeros‚Äô podem gerar distor√ß√µes na ordena√ß√£o (P. Legendre and Legendre 2012a). Como alternativa, √© poss√≠vel utilizar PCA com dados padronizados com o m√©todo de Hellinger (Pierre Legendre and Gallagher 2001). 9.5.1.2 Exemplo 1 Neste exemplo vamos utilizar um conjunto de dados morfol√≥gicos de pinguins do arquip√©lago Palmer (Pen√≠nsula Ant√°rtica) dispon√≠veis no pacote ‚Äòpalmerpenguins.‚Äô Os dados representam medidas do comprimento e largura do bico (mm), comprimento da nadadeira (mm) e massa corporal (gramas) de tr√™s esp√©cies: Ad√©lie, Chinstrap e Gentoo. Como descrito acima, a PCA deve ser utilizada para explora√ß√£o de dados ou para testes a posteriori (p.¬†ex., PCR). Neste exemplo, iremos usar a estrutura de perguntas e predi√ß√µes para manter a proposta do livro. Pergunta Existe diferen√ßas nas caracter√≠sticas morfol√≥gicas das esp√©cies de pinguins do arquip√©lago Palmer? Predi√ß√µes Pinguins com dieta diferente possuem differentes caracter√≠sticas morfol√≥gicas. Vari√°veis Preditora: esp√©cie (categ√≥rica com tr√™s n√≠veis) Dependentes: vari√°veis morfol√≥gicas (cont√≠nua) 9.5.1.3 An√°lise no R Antes de come√ßar, √© necess√°rio remover dados ausentes (se houver) e editar nomes das vari√°veis (ponto importante para determinar como devem aparecer no gr√°fico). ## Verificar se existem NAs nos dados. sum(is.na(penguins)) #&gt; [1] 19 ## Remover dados ausentes (NA), quando houver. penguins &lt;- na.omit(penguins) ## Editar nomes para aparecer nos gr√°ficos. names(penguins) &lt;- c(&quot;species&quot;, &quot;island&quot;, &quot;Bill length&quot;, &quot;Bill depth&quot;, &quot;Flipper length&quot;, &quot;Body mass&quot;, &quot;Sex&quot;, &quot;Year&quot;) ## Manter somentes dados cont√≠nuos que pretende aplicar a PCA. penguins_trait &lt;- penguins[,3:6] Agora sim os dados est√£o prontos para fazer a PCA. Um argumento √© essencial na an√°lise, o ‚Äúscale.unit.‚Äù Se voc√™ utiliar dentro deste argumento o sele√ß√£o ‚ÄòTRUE,‚Äô a fun√ß√£o padroniza automaticamente as vari√°veis para terem a m√©dia 0 e vari√¢ncia 1. Esta padroniza√ß√£o √© essencial quando as vari√°veis est√£o em escalas muito diferentes. No exemplo selecionado, temos vari√°veis como comprimento do bico (em mil√≠metros) e massa corporal (em gramas). # Compare com este c√≥digo a vari√¢ncia das vari√°veis penguins_trait %&gt;% dplyr::summarise(across(where(is.numeric), ~var(.x, na.rm=TRUE))) #&gt; # A tibble: 1 √ó 4 #&gt; `Bill length` `Bill depth` `Flipper length` `Body mass` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 29.9 3.88 196. 648372. # Agora, veja o mesmo c√°lculo se fizer a padroniza√ß√£o (scale.unit da fun√ß√£o PCA) penguins_pad &lt;- decostand(penguins_trait, &quot;standardize&quot;) penguins_pad %&gt;% dplyr::summarise(across(where(is.numeric), ~var(.x, na.rm=TRUE))) #&gt; Bill length Bill depth Flipper length Body mass #&gt; 1 1 1 1 1 # PCA pca.p &lt;- PCA(penguins_trait, scale.unit = TRUE, graph = FALSE) Apesar da simplicidade do comando para executar a PCA, o objeto resultante da an√°lise possui diversas informa√ß√µes que s√£o essenciais para sua plena interpreta√ß√£o. Dentre elas, se destacam os autovalores, escores e loadings. Os autovalores representam a porcentagem de explica√ß√£o de cada eixo. O escores representam as coordenadas (posi√ß√µes no espa√ßo multidimensional) representando os objetos (geralmente localidades ou indiv√≠duos) e descritores (geralmente esp√©cies ou vari√°veis ambientais e espaciais). Os loadings, por sua vez, representam a combina√ß√£o linear entre os escores (nova posi√ß√£o do valor do descritor no espa√ßo ordenado) e os valores originais dos descritores. ## Autovalores: porcentagem de explica√ß√£o para usar no gr√°fico pca.p$eig #&gt; eigenvalue percentage of variance cumulative percentage of variance #&gt; comp 1 2.7453557 68.633893 68.63389 #&gt; comp 2 0.7781172 19.452929 88.08682 #&gt; comp 3 0.3686425 9.216063 97.30289 #&gt; comp 4 0.1078846 2.697115 100.00000 ## Visualiza√ß√£o da porcentagem de explica√ß√£o de cada eixo # nota: √© necess√°rio ficar atento ao valor m√°ximo do eixo 1 da an√°lise para determinar o valor do ylim (neste caso, colocamos que o eixo varia de 0 a 70) fviz_screeplot(pca.p, addlabels = TRUE, ylim = c(0, 70)) ## Outros valores importantes var_env &lt;- get_pca_var(pca.p) # Escores (posi√ß√£o) das vari√°veis em cada eixo var_env$coord #&gt; Dim.1 Dim.2 Dim.3 Dim.4 #&gt; Bill length 0.7518288 0.52943763 -0.3900969 -0.04768208 #&gt; Bill depth -0.6611860 0.70230869 0.2585287 0.05252186 #&gt; Flipper length 0.9557480 0.00510580 0.1433474 0.25684871 #&gt; Body mass 0.9107624 0.06744932 0.3592789 -0.19204478 # Contribui√ß√£o (%) das vari√°veis para cada eixo var_env$contrib #&gt; Dim.1 Dim.2 Dim.3 Dim.4 #&gt; Bill length 20.58919 36.023392267 41.279994 2.107420 #&gt; Bill depth 15.92387 63.388588337 18.130600 2.556942 #&gt; Flipper length 33.27271 0.003350291 5.574092 61.149849 #&gt; Body mass 30.21423 0.584669105 35.015313 34.185789 # loadings - correla√ß√£o das vari√°veis com os eixos var_env$cor #&gt; Dim.1 Dim.2 Dim.3 Dim.4 #&gt; Bill length 0.7518288 0.52943763 -0.3900969 -0.04768208 #&gt; Bill depth -0.6611860 0.70230869 0.2585287 0.05252186 #&gt; Flipper length 0.9557480 0.00510580 0.1433474 0.25684871 #&gt; Body mass 0.9107624 0.06744932 0.3592789 -0.19204478 # Qualidade da representa√ß√£o da vari√°vel. Esse valor √© obtido multiplicado var_env$coord por var_env$coord var_env$cos2 #&gt; Dim.1 Dim.2 Dim.3 Dim.4 #&gt; Bill length 0.5652466 2.803042e-01 0.15217561 0.002273581 #&gt; Bill depth 0.4371669 4.932375e-01 0.06683710 0.002758546 #&gt; Flipper length 0.9134542 2.606919e-05 0.02054847 0.065971260 #&gt; Body mass 0.8294881 4.549411e-03 0.12908133 0.036881196 # Escores (posi√ß√£o) das localidades (&quot;site scores&quot;) em cada eixo ind_env &lt;- get_pca_ind(pca.p) O pacote FactoMineR criou uma fun√ß√£o (dimdesc) que seleciona as melhores vari√°veis (aquelas mais explicativas) para cada eixo atrav√©s de uma an√°lise fatorial. No exemplo com pinguins, o primeiro eixo (objeto pca.p$eig) explica ~69% da varia√ß√£o morfol√≥gica. A fun√ß√£o dimdesc mostra que as quatro vari√°veis morfol√≥gicas est√£o fortemente associadas com o eixo 1. Por√©m, enquanto comprimento da nadadeira, massa corporal e comprimento do bico est√£o positivamente associados com o eixo 1 (correla√ß√£o positiva), a largura do bico tem rela√ß√£o negativa. O eixo 2, por sua vez, explica ~20% da varia√ß√£o, sendo relacionado somente com largura e comprimento do bico. # Vari√°veis mais importantes para o Eixo 1 dimdesc(pca.p)$Dim.1 #&gt; $quanti #&gt; correlation p.value #&gt; Flipper length 0.9557480 5.962756e-178 #&gt; Body mass 0.9107624 3.447018e-129 #&gt; Bill length 0.7518288 7.830597e-62 #&gt; Bill depth -0.6611860 3.217695e-43 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;condes&quot; &quot;list&quot; # Vari√°veis mais importantes para o Eixo 2 dimdesc(pca.p)$Dim.2 #&gt; $quanti #&gt; correlation p.value #&gt; Bill depth 0.7023087 8.689230e-51 #&gt; Bill length 0.5294376 1.873918e-25 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;condes&quot; &quot;list&quot; Agora podemos utilizar o famoso ‚Äúbiplot‚Äù para representar a compara√ß√£o morfol√≥gica dos pinguins dentro e entre esp√©cies fviz_pca_biplot(pca.p, geom.ind = &quot;point&quot;, fill.ind = penguins$species, col.ind = &quot;black&quot;, alpha.ind=0.7, pointshape = 21, pointsize = 4, palette = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;), addEllipses = FALSE, alpha.var = 1, col.var = &quot;black&quot;, gradient.cols = &quot;RdBu&quot;, invisible = &quot;quali&quot;, title = NULL) + theme_bw() + xlab(&quot;PC 1 (68.63%)&quot;) + ylab(&quot;PC 2 (19.45%)&quot;) + theme(axis.title.x = element_text(size=14), axis.text.x = element_text(vjust=0.5, size=12), axis.title.y = element_text(size=14), axis.text.y = element_text(vjust=0.5, size=12), legend.position = &quot;top&quot;, legend.title = element_blank())+ tema_livro() 9.5.2 An√°lise de Coordenadas Principais - PCoA Diferentemente da PCA, a PCoA √© uma an√°lise de ordena√ß√£o irrestrita que aceita dados de diferentes tipos, como cont√≠nuos, categ√≥ricos, ordinais, bin√°rios, entre outros. Assim, a PCoA √© aplicada para casos em que a dist√¢ncia euclidiana n√£o √© aplicada (como na PCA). Desse modo, o primeiro passo da an√°lise √© calcular uma matriz de similaridade ou de dist√¢ncia (discutido acima). Depois, os passos para obter autovalores e autovetores s√£o bastante parecidos com a PCA. Da mesma forma, os eixos da PCoA e os valores ou posi√ß√µes dos objetos nesses eixos representam a rela√ß√£o de semelhan√ßa (ou diferen√ßa) baseada nos descritores desses objetos. A diferen√ßa, neste caso, √© que a PCoA representa um espa√ßo n√£o-euclidiano, que ir√° ser afetado pela escolha do m√©todo de similaridade. As utiliza√ß√µes mais comuns da PCoA s√£o a ordena√ß√£o (1) da matriz de composi√ß√£o de esp√©cies usando a dist√¢ncia apropriada (Jaccard, Sorensen, Bray Curits), (2) da matriz de vari√°veis ambientais com mistos (cont√≠nuos, categ√≥ricos, circulares, etc‚Ä¶), e (3) da matriz filogen√©tica (m√©todo PVR Jose Alexandre Felizola Diniz-Filho, Sant‚ÄôAna, and Bini 1998). Abaixo, exemplificamos a ordena√ß√£o da matriz de composi√ß√£o de esp√©cies. Checklist Compare as dimens√µes das matrizes utilizadas para a PCoA. Com bastante frequ√™ncia, a tentativa de combinar dados categ√≥ricos (algum descritor dos objetos) com os valores obtidos com a PCoA gera erros para plotar a figura ou para executar a an√°lise. Verifique, ent√£o, se as linhas s√£o as mesmas (nome das localidades ou indiv√≠duos e quantidade). √â fundamental conhecer o tipo de dados que est√° usando para selecionar a medida de dist√¢ncia apropriada. Essa escolha vai afetar a qualidade da ordena√ß√£o e sua habilidade para interpretar a rela√ß√£o de semelhan√ßa entre os objetos comparados. Diferente da PCA, a PCoA aceita dados ausentes se a medida de dist√¢ncia escolhida tamb√©m n√£o tiver esta limita√ß√£o. Por exemplo, a dist√¢ncia de Gower produz matrizes de similaridade mesmo com dados ausentes em determinados objetos. Em alguns casos, a autovalores negativos s√£o produzidos na ordena√ß√£o com PCoA (cap9?). Apesar deste problema, os autovalores mais importantes (eixos iniciais) n√£o s√£o afetados e, deste modo, a qualidade da representa√ß√£o dos objetos no espa√ßo multidimensional n√£o √© afetada. Alguns autores sugerem utilizar corre√ß√µes m√©todos de corre√ß√£o, como Lingoes ou Cailliez (P. Legendre and Legendre 2012a). 9.5.2.1 Exemplo 1 Neste exemplo vamos utilizar a composi√ß√£o de √°caros Oribatidae em 70 manchas de musgo coletados por Borcard et al. (1992). Pergunta A composi√ß√£o de esp√©cies de √°caros muda entre diferentes topografias? Predi√ß√µes Iremos encontrar ao menos dois grupos de esp√©cies: aquelas que ocorrem em po√ßas dentro de floresta vs.¬†aquelas que ocorrem em po√ßas de √°reas abertas. Vari√°veis Preditora: topografia (categ√≥rica com dois n√≠veis) Dependentes: composi√ß√£o de esp√©cies de √°caro 9.5.2.2 An√°lise no R # Padroniza√ß√£o dos dados com Hellinger mite.hel &lt;- decostand(mite, &quot;hellinger&quot;) # C√°lculo da matriz de dist√¢ncia com m√©todo Bray Curtos sps.dis &lt;- vegdist(mite.hel, &quot;bray&quot;) # PCoA pcoa.sps &lt;- pcoa(sps.dis, correction=&quot;cailliez&quot;) Assim como na PCA, a porcentagem de explica√ß√£o dos eixos √© uma das informa√ß√µes mais importantes pois descrevem a efetividade da redu√ß√£o da dimensionalidade dos dados. ## Porcentagem de explica√ß√£o do Eixo 1 100*(pcoa.sps$values[,1] / pcoa.sps$trace)[1] #&gt; [1] 49.10564 ## Porcentagem de explica√ß√£o dos Eixo 2 100*(pcoa.sps$values[,1] / pcoa.sps$trace)[2] #&gt; [1] 14.30308 ## Porcentagem de explica√ß√£o acumulada dos dois primeiros eixos sum(100*(pcoa.sps$values[,1] / pcoa.sps$trace)[1:2]) #&gt; [1] 63.40872 # Selecionar os dois primeiros eixos eixos &lt;- pcoa.sps$vectors[,1:2] ## Juntar com algum dado categ√≥rico de interesse para fazer a figura pcoa.dat &lt;- data.frame(topografia=mite.env$Topo, eixos) Para visualizar os resultados da PCoA, vamos exportar os escores dos eixos para usar no ggplot2. ## Escores dos dois primeiros eixos eixos &lt;- pcoa.sps$vectors[,1:2] ## Combinar dados dos escores com um dado categ√≥rico de interesse para nossa pergunta pcoa.dat &lt;- data.frame(topografia=mite.env$Topo, eixos) ### Gr√°fico biplot da PCoA pcoa.dat %&gt;% ggplot(aes(x = Axis.1, y = Axis.2, fill = topografia, color = topografia, shape = topografia)) + theme_bw() + geom_point(size=4, alpha = 0.7) + scale_shape_manual(values=c(21, 22)) + scale_color_manual(values=c(&quot;black&quot;, &quot;black&quot;)) + scale_fill_manual(values=c(&quot;darkorange&quot;, &quot;cyan4&quot;)) + xlab(&quot;PCO 1 (49.11%)&quot;) + ylab(&quot;PCO 2 (14.30%)&quot;) + theme(legend.position = &quot;top&quot;, legend.title=element_blank()) + geom_hline(yintercept = 0, linetype=2) + geom_vline(xintercept = 0, linetype=2)+ tema_livro() 9.5.2.3 Limita√ß√µes importantes das ordena√ß√µes irrestritas Com frequ√™ncia, pesquisadores utilizam an√°lises como PCA e PCoA para ‚Äútestar‚Äù diferen√ßas na composi√ß√£o de esp√©cies entre determinados fatores relevantes (altitude, clima, etc‚Ä¶). Por√©m, como falado acima, as an√°lises de ordena√ß√£o irrestritas n√£o s√£o utilizadas para testar qualquer hip√≥tese. Ao inv√©s disso, essas an√°lises representam uma poderosa ferramente para explorar padr√µes em vari√°veis dependentes ou independentes para ajudar na interpreta√ß√£o ou mesmo para testar hip√≥teses em an√°lises combinadas com as ordena√ß√µes irrestritas. 9.6 PCR - Regress√£o de Componentes Principais Uma maneira de testar hip√≥teses utilizando ordena√ß√µes irrestritas √© utilizando os resultados da ordena√ß√£o (escores) como vari√°veis preditoras ou dependentes como, por exemplo, em modelos lineares (e.g., regress√£o m√∫ltipla). O primeiro passo √© utilizar uma ordena√ß√£o, como a PCA, para gerar os ‚Äúnovos‚Äù dados que ser√£o usados na an√°lise. A utiliza√ß√£o desses novos dados (que representam as coordenadas principais ou escores da PCA) vai depender da pergunta em quest√£o. Por exemplo, pode ser que esses valores representem gradientes clim√°ticos e, por este motivo, ser√£o utilizados como vari√°veis preditoras em um modelo linear (e.g., regress√£o m√∫ltipla). Por outro lado, esses valores podem representar o espa√ßo morfol√≥gicos de esp√©cies de peixe e, como consequ√™ncia, ser√£o utilizados como vari√°veis dependentes para entender o efeito da presen√ßa de predador sobre a morfologia. Checklist Compare as dimens√µes das matrizes utilizadas para a PCR. Com bastante frequ√™ncia, a tentativa de combinar dados categ√≥ricos (algum descritor dos objetos) com os valores obtidos com a PCoA gera erros para plotar a figura ou para executar a an√°lise. Verifique, ent√£o, se as linhas s√£o as mesmas (nome das localidades ou indiv√≠duos e quantidade). Estudos recentes t√™m criticado a utiliza√ß√£o de PCR para testar hip√≥teses ecol√≥gicas pelo fato dos escores n√£o representarem, necessariamente, a varia√ß√£o total das vari√°veis originais, bem como a rela√ß√£o entre a vari√°vel preditora e a dependente. 9.6.0.1 Exemplo 1 Neste exemplo vamos utilizar a composi√ß√£o de esp√©cies de aves em 23 regi√µes dos alpes franceses. Os dados ambientais (env) representam vari√°veis clim√°ticas (temperatura e chuva) e altitude. Pergunta Gradientes clim√°ticos afetam a riqueza de aves? Predi√ß√µes O aumento da umidade e redu√ß√£o da temperatura aumentam o n√∫mero de esp√©cies de aves. Vari√°veis Preditora: temperatura e chuva (cont√≠nuas) e altitude (categ√≥rica com tr√™s n√≠veis) Dependentes: riqueza de esp√©cies de aves # Dados env_cont &lt;- env[,-8] env.pca &lt;- PCA(env_cont, scale.unit = TRUE, graph = FALSE) var_env &lt;- get_pca_var(env.pca) # Contribui√ß√£o (%) das vari√°veis para cada eixo var_env$contrib #&gt; Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 #&gt; mini.jan 10.93489 22.2975487 16.1607726 7.6025527 0.01782438 #&gt; maxi.jan 20.18065 3.2890767 2.1814486 4.2756350 41.05646526 #&gt; mini.jul 11.87396 21.1379132 0.3428843 0.7750666 44.70209396 #&gt; maxi.jul 18.47244 0.9159957 56.5369988 9.4368661 2.59283074 #&gt; rain.jan 9.95206 21.5387403 6.5737927 53.7375738 4.44283706 #&gt; rain.jul 16.14997 11.2368132 7.2608047 19.6972097 0.71454880 #&gt; rain.tot 12.43603 19.5839121 10.9432983 4.4750959 6.47339980 # Loadings - correla√ß√£o das vari√°veis com os eixos var_env$cor #&gt; Dim.1 Dim.2 Dim.3 Dim.4 Dim.5 #&gt; mini.jan 0.6830371 0.6766524 -0.21924927 0.12298817 -0.004517369 #&gt; maxi.jan 0.9279073 0.2598807 -0.08055260 0.09223249 0.216804944 #&gt; mini.jul 0.7117620 0.6588220 0.03193603 -0.03926930 -0.226225907 #&gt; maxi.jul 0.8877675 0.1371462 0.41008461 -0.13702428 0.054483561 #&gt; rain.jan -0.6516187 0.6650391 -0.13983474 -0.32698110 0.071319550 #&gt; rain.jul -0.8300858 0.4803509 0.14696011 0.19796389 -0.028601865 #&gt; rain.tot -0.7284135 0.6341424 0.18041856 0.09435932 0.086088397 ind_env &lt;- get_pca_ind(env.pca) env.pca$eig #&gt; eigenvalue percentage of variance cumulative percentage of variance #&gt; comp 1 4.26652359 60.9503370 60.95034 #&gt; comp 2 2.05340251 29.3343216 90.28466 #&gt; comp 3 0.29745014 4.2492878 94.53395 #&gt; comp 4 0.19896067 2.8422953 97.37624 #&gt; comp 5 0.11448717 1.6355310 99.01177 #&gt; comp 6 0.04312874 0.6161248 99.62790 #&gt; comp 7 0.02604718 0.3721025 100.00000 O objeto env.pca$eig demonstra que os tr√™s primeiros eixos explicam 94.54% da varia√ß√£o total dos dados clim√°ticos. Como o intuito da PCR √© reduzir a dimensionalidade (ou seja, o n√∫mero de vari√°veis preditoras ou depedentes) para facilitar a interpreta√ß√£o e garantir que as vari√°veis n√£o sejam correlacionadas. O pr√≥ximo passo ent√£o √© obter os valores dos escores que representam os valores convertidos para serem usados em uma determinada an√°lise, como a regress√£o m√∫ltipla. # Passo 1: obter os primeiros eixos pred.env &lt;- ind_env$coord[,1:3] # Passo 2: calcular a riqueza de esp√©cies riqueza &lt;- specnumber(species) # Passo 3: combinar os dois valores em um √∫nico data.frame dat &lt;- data.frame(pred.env, riqueza) Agora que os dados foram combinados em uma √∫nica matriz, podemos utilizar os comandos aprendidos no (cap7?) para testar nossa hip√≥tese. # Regress√£o m√∫ltipla mod1 &lt;- lm(riqueza~Dim.1+Dim.2+Dim.3, data = dat) par(mfrow=c(2,2)) plot(mod1) # verificar pressupostos dos modelos lineares summary(mod1) # resultados do teste #&gt; #&gt; Call: #&gt; lm(formula = riqueza ~ Dim.1 + Dim.2 + Dim.3, data = dat) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -3.4008 -1.1729 0.4356 1.2072 2.4571 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 13.30435 0.37639 35.347 &lt; 2e-16 *** #&gt; Dim.1 0.68591 0.18222 3.764 0.00131 ** #&gt; Dim.2 -0.09961 0.26267 -0.379 0.70874 #&gt; Dim.3 -0.21708 0.69014 -0.315 0.75654 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 1.805 on 19 degrees of freedom #&gt; Multiple R-squared: 0.4313, Adjusted R-squared: 0.3415 #&gt; F-statistic: 4.804 on 3 and 19 DF, p-value: 0.01179 dimdesc(env.pca)$Dim.1 #&gt; $quanti #&gt; correlation p.value #&gt; maxi.jan 0.9279073 1.846790e-10 #&gt; maxi.jul 0.8877675 1.607390e-08 #&gt; mini.jul 0.7117620 1.396338e-04 #&gt; mini.jan 0.6830371 3.282701e-04 #&gt; rain.jan -0.6516187 7.559358e-04 #&gt; rain.tot -0.7284135 8.112903e-05 #&gt; rain.jul -0.8300858 9.588034e-07 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;condes&quot; &quot;list&quot; Como percebemos, a Dim.1 foi o √∫nico gradiente ambiental que afetou a riqueza de esp√©cies. Para interpretar esta dimens√£o (e outras importantes), podemos usar a fun√ß√£o dimdesc para verificar as vari√°veis mais importantes. Neste caso, os valores mais extremos de correla√ß√£o (maior que 0.8) indicam que a temperatura do m√™s de janeiro e julho bem como a chuva do m√™s de julho foram as vari√°veis mais importantes para determinar o gradiente ambiental expresso na dimens√£o 1. Assim, podemos fazer um gr√°fico para representar a rela√ß√£o entre Eixo 1 (gradiente chuva-temperatura) e a riqueza de esp√©cies de aves. Valores negativos do eixo 1 (Gradiente ambiental - PC1) representam localidades com mais chuva, ao passo que valores positivos indicam localidades com temperaturas maiores. dat %&gt;% ggplot(aes(x = Dim.1, y = riqueza)) + theme_bw() + geom_smooth(method = lm, fill = &quot;#525252&quot;, color = &quot;black&quot;) + geom_point(size=4, shape=21, alpha = 0.7, color=&quot;#1a1a1a&quot;, fill=&quot;cyan4&quot;) + xlab(&quot;Gradiente ambiental (PC1)&quot;) + ylab(&quot;Riqueza de aves&quot;) + theme(axis.title.x = element_text(size=14), axis.text.x = element_text(vjust=0.5, size=12), axis.title.y = element_text(size=14), axis.text.y = element_text(vjust=0.5, size=12))+ tema_livro() 9.6.0.2 Exemplo 2 √â poss√≠vel que os dados utilizados em seu estudo sejam mistos, ou seja, incluem tanto vari√°veis categ√≥ricas quanto cont√≠nuas. Como falado acima, nesses casos a an√°lise indicada √© a PCoA. Assim como na PCA, podemos extrair os escores da PCoA para utilizar a posteriori em an√°lises univariadas e multivariadas. Pergunta: Vari√°veis clim√°ticas, vegetacionais e topogr√°ficas afetam a riqueza de √°caros? Predi√ß√µes A densidade da vegeta√ß√£o e disponibilidade de √°gua aumentam a riqueza de esp√©cies de √°caros. Vari√°veis Preditoras: densidade de substrado e disponibilidade de √°gua (cont√≠nuas), tipo de substrado (categ√≥rica com 7 n√≠veis), densidade arbusto (ordinal com 3 n√≠veis), e topografia (categ√≥rica com 2 n√≠veis) Dependentes: riqueza de esp√©cies de √°caros O primeiro passo ent√£o √© utilizar um m√©todo de dist√¢ncia apropriado para o seu conjunto de dados. Em nosso exemplo, utilizaremos a dist√¢ncia de Gower, que √© usada para dados mistos ((cap14?)). ## Matriz de dist√¢ncia env.dist &lt;- gowdis(mite.env) ## PCoA env.mite.pco &lt;- pcoa(env.dist, correction=&quot;cailliez&quot;) ## Porcentagem de explica√ß√£o do Eixo 1 100*(env.mite.pco$values[,1] / env.mite.pco$trace)[1] #&gt; [1] 61.49635 ## Porcentagem de explica√ß√£o dos Eixo 2 100*(env.mite.pco$values[,1] / env.mite.pco$trace)[2] #&gt; [1] 32.15486 O pr√≥ximo passo √© exportar os escores para as an√°lises a posteriori. ## Selecionar os dois primeiros eixos pred.scores.mite &lt;- env.mite.pco$vectors[,1:2] ## Juntar com os dados da √°rea para fazer a figura mite.riqueza &lt;- specnumber(mite) pred.vars &lt;- data.frame(riqueza=mite.riqueza, pred.scores.mite) ### Regress√£o m√∫ltipla mod.mite &lt;- lm(riqueza~Axis.1+Axis.2, data=pred.vars) par(mfrow=c(2,2)) plot(mod.mite) summary(mod.mite) #&gt; #&gt; Call: #&gt; lm(formula = riqueza ~ Axis.1 + Axis.2, data = pred.vars) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -10.6874 -2.3960 -0.1378 2.5032 8.6873 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 15.1143 0.4523 33.415 &lt; 2e-16 *** #&gt; Axis.1 -11.4303 2.0013 -5.711 2.8e-07 *** #&gt; Axis.2 5.6832 2.7677 2.053 0.0439 * #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 3.784 on 67 degrees of freedom #&gt; Multiple R-squared: 0.3548, Adjusted R-squared: 0.3355 #&gt; F-statistic: 18.42 on 2 and 67 DF, p-value: 4.225e-07 Finalmente, ap√≥s interpretar os resultados do modelo, podemos fazer a figura com as vari√°veis (eixos) importantes g_acari_axi1 &lt;- pred.vars %&gt;% ggplot(aes(x = Axis.1, y = riqueza)) + theme_bw() + geom_smooth(method = lm, fill = &quot;#525252&quot;, color = &quot;black&quot;) + geom_point(size=4, shape=21, alpha = 0.7, color=&quot;#1a1a1a&quot;, fill=&quot;cyan4&quot;) + xlab(&quot;Gradiente ambiental (PC1)&quot;) + ylab(&quot;Riqueza de √°caros&quot;) + theme(axis.title.x = element_text(size=14), axis.text.x = element_text(vjust=0.5, size=12), axis.title.y = element_text(size=14), axis.text.y = element_text(vjust=0.5, size=12))+ tema_livro() g_acari_axi2 &lt;-pred.vars %&gt;% ggplot(aes(x = Axis.2, y = riqueza)) + theme_bw() + geom_smooth(method = lm, fill = &quot;#525252&quot;, color = &quot;black&quot;) + geom_point(size=4, shape=21, alpha = 0.7, color=&quot;#1a1a1a&quot;, fill=&quot;darkorange&quot;) + xlab(&quot;Gradiente ambiental (PC2)&quot;) + ylab(&quot;Riqueza de √°caros&quot;) + theme(axis.title.x = element_text(size=14), axis.text.x = element_text(vjust=0.5, size=12), axis.title.y = element_text(size=14), axis.text.y = element_text(vjust=0.5, size=12))+ tema_livro() ## Fun√ß√£o para combinar os dois plots em uma √∫nica janela grid.arrange(g_acari_axi1, g_acari_axi2, nrow=1) 9.7 Ordena√ß√£o restrita A ordena√ß√£o restrita, ou an√°lise de gradiente direto organiza os objetos de acordo com suas rela√ß√µes com outras vari√°veis (preditoras) coletadas nas mesmas unidades amostrais. O exemplo mais comum na ecologia √© de investigar a rela√ß√£o entre diversas vari√°veis ambientais (matriz X) coletadas em n localidades e a abund√¢ncia (ou presen√ßa aus√™ncia) de y esp√©cies coletadas nas mesmas localidades (matrix Y). Com frequ√™ncia, outras dados s√£o utilizados como as coordenadas geogr√°ficas das unidades amostrais (matriz W), os atributos funcionais das esp√©cies coletadas (matriz T) e a rela√ß√£o filogen√©tica dessas esp√©cies (matriz P). Diversos m√©todos s√£o utilizados para combinar duas ou mais matrizes, mas neste cap√≠tulo iremos apresentar a RDA, RDAp e m√©todos espaciais para incluir a matriz W nas an√°lises de gradiente direto. 9.7.1 RDA: An√°lise de Redund√¢ncia A RDA √© uma an√°lise semelhante a regress√£o m√∫ltipla (cap7?) mas que usa dados multivariados como vari√°vel dependente. As duas matrizes comuns, matriz X (n unidades amostraits e m vari√°veis) e matriz Y (n unidades amostrais e p descritores - geralmente, esp√©cies). O primeiro passo da RDA √© centralizar (assim como na PCA, exemplo acima) as matrizes X e Y. Ap√≥s a centraliza√ß√£o, realiza-se regress√µes lineares entre X e Y para obter os valores preditos de Y (ou seja, os valores de Y que representa√ß√£o uma combina√ß√£o linear com X). O passo seguinte √© realizar uma PCA dos valores preditos de Y. Este √∫ltimo procedimento gera os autovalores, autovetores e os eixos can√¥nicos que correspondem √†s coordenadas dos objetos (unidades amostrais), vari√°veis preditoras e das vari√°veis resposta. A diferen√ßa da ordena√ß√£o do valor de Y predito e da ordena√ß√£o somente de Y (como na PCA implementada acima) √© que a segunda mostra a posi√ß√£o prevista pela rela√ß√£o linear entre X e Y. Logo, essa √© exatamente o motivo da ordena√ß√£o ser conhecida como restrita, pois a varia√ß√£o em Y √© restrita (linearmente) pela varia√ß√£o de X. Assim como na regress√£o m√∫ltipla, a estat√≠stica da RDA √© representada pelo valor de R2 e F. O valor de R2 indica a for√ßa da rela√ß√£o linear entre X e Y e o valor do F representa o teste global de signific√¢ncia. Al√©m disso, √© poss√≠vel testar a signific√¢ncia de cada um dos eixos da ordena√ß√£o (e a presen√ßa de pelo menos um eixo significativo √© pr√©-requisito para que exista a rela√ß√£o linear entre X e Y) e de cada uma das vari√°veis preditoras da matriz X. Checklist Vari√°veis preditoras: importante verificar (1) a estrutura de correla√ß√£o das vari√°veis ambientais, e a (2) presen√ßa de autocorrela√ß√£o espacial. Composi√ß√£o de esp√©cies como matriz Y: fundamental observar se os valores utilizados representam abund√¢ncia ou presen√ßa-aus√™ncia e qual a necessidade de padroniza√ß√£o (e.g., Hellinger). Assim como em modelos de regress√£o linear e m√∫ltipla, os valores de R2 ajustado devem ser selecionados ao inv√©s do valor de R2. 9.7.1.1 Exemplo 1 Esp√©cies de aves que ocorrem em localidades com diferentes altitudes. Pergunta: O clima e a altitude modificam a composi√ß√£o de esp√©cies de aves? Predi√ß√µes Diferen√ßas clim√°ticas (temperatura e chuva) e altitudinais alteram a composi√ß√£o de esp√©cies de aves. Vari√°veis (mesmo conjunto de dados usados na PERMANOVA) Preditoras: Temperatura e chuva (cont√≠nuas) e altitude (categ√≥rica com tr√™s n√≠veis) Dependente: composi√ß√£o de esp√©cies de aves ## Passo 1: transforma√ß√£o de hellinger da matriz de esp√©cies # caso tenha dados de abund√¢ncia. species.hel &lt;- decostand(species, &quot;hellinger&quot;) ## Passo 2: selecionar vari√°veis importantes. # Para isso, √© necess√°rio remover a vari√°vel categ√≥rica. env.contin &lt;- env[,-8] ## Evite usar vari√°veis muito correlacionadas sel.vars &lt;- forward.sel(species.hel, env.contin) #&gt; Testing variable 1 #&gt; Testing variable 2 #&gt; Testing variable 3 #&gt; Procedure stopped (alpha criteria): pvalue for variable 3 is 0.219000 (&gt; 0.050000) sel.vars$variables #&gt; [1] &quot;rain.jul&quot; &quot;maxi.jul&quot; env.sel &lt;- env[,sel.vars$variables] ## Passo 3: padronizar matriz ambiental (somente vari√°veis cont√≠nuas) env.pad &lt;- decostand(env.sel, &quot;standardize&quot;) ## Matriz final com vari√°veis preditoras env.pad.cat &lt;- data.frame(env.pad, altitude = env$altitude) Depois de selecionar um subconjunto dos dados com o m√©todo Forward Selection e padroniz√°-los (m√©dia 0 e desvio padr√£o 1), o modelo da RDA √© constru√≠do como modelos lineares e PERMANOVA. ## RDA com dados selecionados e padronizados rda.bird &lt;- rda(species.hel~rain.jul+maxi.jul+altitude, data=env.pad.cat) # Para interpretar, √© necess√°rio saber a signific√¢ncia dos eixos para representar a rela√ß√£o entre as vari√°veis preditoras e a composi√ß√£o de esp√©cies res.axis &lt;- anova.cca(rda.bird, by=&quot;axis&quot;) res.axis #&gt; Permutation test for rda under reduced model #&gt; Forward tests for axes #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; Model: rda(formula = species.hel ~ rain.jul + maxi.jul + altitude, data = env.pad.cat) #&gt; Df Variance F Pr(&gt;F) #&gt; RDA1 1 0.045759 12.0225 0.001 *** #&gt; RDA2 1 0.009992 2.6252 0.062 . #&gt; RDA3 1 0.007518 1.9752 0.133 #&gt; RDA4 1 0.003582 0.9410 0.471 #&gt; Residual 18 0.068510 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Em seguida, √© poss√≠vel identificar quais s√£o as vari√°veis que contribuem ou que mais contribuem para a varia√ß√£o na composi√ß√£o de esp√©cies res.var &lt;- anova.cca(rda.bird, by=&quot;term&quot;) ## Qual vari√°vel? res.var #&gt; Permutation test for rda under reduced model #&gt; Terms added sequentially (first to last) #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; Model: rda(formula = species.hel ~ rain.jul + maxi.jul + altitude, data = env.pad.cat) #&gt; Df Variance F Pr(&gt;F) #&gt; rain.jul 1 0.036514 9.5936 0.001 *** #&gt; maxi.jul 1 0.011264 2.9596 0.016 * #&gt; altitude 2 0.019071 2.5053 0.010 ** #&gt; Residual 18 0.068510 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Al√©m disso, √© poss√≠vel obter o valor do R2 do modelo r_quadr &lt;- RsquareAdj(rda.bird) r_quadr #&gt; $r.squared #&gt; [1] 0.4938685 #&gt; #&gt; $adj.r.squared #&gt; [1] 0.3813949 # Ordena√ß√£o multi-escala (MSO) para entender os resultados da ordena√ß√£o em rela√ß√£o √† dist√¢ncia geogr√°fica bird.rda &lt;- mso(rda.bird, xy, grain = 1, permutations = 99) msoplot(bird.rda) #&gt; Error variance of regression model underestimated by -2 percent ## Triplot da RDA ggord(rda.bird, ptslab = TRUE, size = 1, addsize = 3, parse = TRUE) + theme_bw() + geom_hline(yintercept = 0, linetype=2) + geom_vline(xintercept = 0, linetype=2) + theme(axis.title.x = element_text(size=14), axis.text.x = element_text(vjust=0.5, size=12), axis.title.y = element_text(size=14), axis.text.y = element_text(vjust=0.5, size=12))+ tema_livro() 9.7.1.2 Interpreta√ß√£o dos resultados Os objetos res.axis, res.var e r_quadr mostram, respectivamente, (i) as dimens√µes (RDA1, RDA2, etc.) que possuem varia√ß√£o na composi√ß√£o de esp√©cies, (ii) as vari√°veis preditoras que explicam esta varia√ß√£o, e (iii) o valor do R2 ajustado. Neste exemplo, podemos observar que somente a dimens√£o 1 (RDA1) representa uma varia√ß√£o significativa da composi√ß√£o de esp√©cies (P = 0,001). As vari√°veis rain.jul, maxi.jul e altitude foram todas preditoras importantes da composi√ß√£o de esp√©cies, mas rain.jul se destacada com maior valor de F. Al√©m disso, o valor do R2 ajustado de 0.381 indica forte contribui√ß√£o dessas vari√°veis preditoras. Por√©m, uma das limita√ß√µes desta an√°lise √© n√£o considerar que tanto esp√©cies quanto vari√°veis preditoras podem estar estruturadas espacialmente. Como resultado, os res√≠duos da an√°lises podem apresentar autocorrela√ß√£o espacial que, por sua vez, aumenta o erro do tipo I (P. Legendre and Legendre 2012a). A figura obtida com o comando msoplot(bird.rda) demonstra que existe autocorrela√ß√£o espacial em algumas dist√¢ncias da an√°lise. Veja abaixo algumas alternativas para res√≠duos com autocorrela√ß√£o espacial. 9.7.2 RDAp: An√°lise de Redund√¢ncia parcial Um dos problemas da abordagem anterior √© que tanto a composi√ß√£o de esp√©cies como as vari√°veis ambientais est√£o estruturadas espacialmente. Talvez mais importantes, para que os valores de probabilidade da RDA sejam interpretados corretamente (e para evitar erro do tipo I), os res√≠duos do modelo n√£o devem estar correlacionados espacialmente, como demonstrado com a an√°lise MSO. Uma alternativa √© de incluir a matriz de dados espaciais (matrix W) como valor condicional dentro da RDA. Esta an√°lise √© conhecida como RDA parcial. Por√©m, a obten√ß√£o dos dados espaciais da matriz W √© mais complexo do que simplesmente incluir dados de localiza√ß√£o geogr√°fica (latitude e longitude), como feito em alguns modelos lineares (gls, (cap7?)). Existem diversas ferramentas que descrevem e incorporam o componente espacial em m√©todos mulitidimensionais, mas os Mapas de autovetores de Moran (MEM) s√£o certamente os mais utilizados (Dray et al. 2012). A an√°lise MEM consiste na ordena√ß√£o (PCoA) de uma matriz truncada obtida atrav√©s da localiza√ß√£o geogr√°fica das localidades utilizando dist√¢ncia euclidiana, matriz de conectividade e matriz espacial ponderada. Os autovalores obtidos no MEM s√£o id√™nticos aos coeficientes de correla√ß√£o espacial de Moran I. Um procedimento chave desta an√°lise √© a defini√ß√£o de um limiar de trucamento (do ingl√™s truncate threshold). Este limiar √© calculado a partir de uma ‚Äú√°rvore de espa√ßo m√≠nimo‚Äù (MST, do ingl√™s minimum spanning tree) que conecta todos os pontos de coleta. Na pr√°tica, os valores menores do que o limiar definido pela MST indicam que os pontos com aqueles valores est√£o conectados e, assim possuem correla√ß√£o positiva. Outro ponto importante desta an√°lise √© a obten√ß√£o da matriz espacial ponderada (SWM, do ingl√™s spatial weighthing matrix). A sele√ß√£o da matriz SWM √© parte essencial do c√°lculo dos MEM e n√£o deve ser feita arbitratiamente (Bauman, Drouet, Fortin, et al. 2018). Por este motivo a an√°lise recebe este nome (P. Legendre and Legendre 2012a). Finalmente, o m√©todo produz autovetores que representam preditores espaciais que podem ser utilizados na RDA parcial (e outras an√°lises). √â importante ressaltar que o crit√©rio de sele√ß√£o do n√∫mero de autovetores √© bastante debatido na literatura e, para isso, sugerimos a leitura dos seguintes artigos Bauman, Drouet, Dray, et al. (2018). Ent√£o, o primeiro passo para realizar uma RDA parcial √© de gerar os autovetores espaciais (MEMs). ## Dados # matriz padronizada de composi√ß√£o de esp√©cies. head(species.hel)[,1:6] #&gt; Fauvette_orphee Fauvette_des_jardins Fauvette_a_tete_noire Fauvette_babillarde #&gt; S01 0 0.3651484 0.3651484 0.2581989 #&gt; S02 0 0.3333333 0.3333333 0.2357023 #&gt; S03 0 0.3162278 0.3162278 0.3162278 #&gt; S04 0 0.4200840 0.3429972 0.2425356 #&gt; S05 0 0.3872983 0.3162278 0.2236068 #&gt; S06 0 0.3779645 0.3779645 0.2672612 #&gt; Fauvette_grisette Fauvette_pitchou #&gt; S01 0.2581989 0 #&gt; S02 0.2357023 0 #&gt; S03 0.2236068 0 #&gt; S04 0.0000000 0 #&gt; S05 0.3162278 0 #&gt; S06 0.0000000 0 # latitude e longitude. head(xy) #&gt; x y #&gt; S01 156 252 #&gt; S02 141 217 #&gt; S03 171 233 #&gt; S04 178 215 #&gt; S05 123 189 #&gt; S06 154 195 # dados ambientais padronizados e altitude head(env.pad.cat) #&gt; rain.jul maxi.jul altitude #&gt; S01 1.333646 0.1462557 Montanhoso #&gt; S02 1.468827 -0.6848206 Intermedi√°rio #&gt; S03 1.505694 -0.2099199 Montanhoso #&gt; S04 1.296778 -2.0699476 Montanhoso #&gt; S05 1.075572 -0.3682201 Plano #&gt; S06 1.100151 -0.6056705 Intermedi√°rio # Passo 1: Gerar um arquivo LIST W: list bin√°ria de vizinhan√ßa mat_knn &lt;- knearneigh(as.matrix(xy), k=2, longlat = FALSE) mat_nb &lt;- knn2nb(mat_knn, sym=TRUE) mat_listw &lt;- nb2listw(mat_nb, style = &quot;W&quot;) mat_listw #&gt; Characteristics of weights list object: #&gt; Neighbour list object: #&gt; Number of regions: 23 #&gt; Number of nonzero links: 58 #&gt; Percentage nonzero weights: 10.96408 #&gt; Average number of links: 2.521739 #&gt; #&gt; Weights style: W #&gt; Weights constants summary: #&gt; n nn S0 S1 S2 #&gt; W 23 529 23 18.84444 96.01111 # Passo 2: Listar os m√©todos &quot;candidatos&quot; para obter a matriz SWM MEM_mat &lt;- scores.listw(mat_listw, MEM.autocor = &quot;positive&quot;) candidates &lt;- listw.candidates(xy, nb = c(&quot;gab&quot;, &quot;mst&quot;, &quot;dnear&quot;), weights = c(&quot;binary&quot;, &quot;flin&quot;)) # Passo 3: Selecionar a melhor matriz SWM e executar o MEM W_sel_mat &lt;- listw.select(species.hel, candidates, MEM.autocor = &quot;positive&quot;, p.adjust = TRUE, method = &quot;FWD&quot;) #&gt; Procedure stopped (alpha criteria): pvalue for variable 5 is 0.088000 (&gt; 0.050000) #&gt; Procedure stopped (alpha criteria): pvalue for variable 3 is 0.064000 (&gt; 0.050000) #&gt; Procedure stopped (alpha criteria): pvalue for variable 3 is 0.061000 (&gt; 0.050000) #&gt; Procedure stopped (alpha criteria): pvalue for variable 4 is 0.159000 (&gt; 0.050000) # Passo 4: Matriz dos preditores espaciais escolhidos (MEMs) spatial.pred &lt;- as.data.frame(W_sel_mat$best$MEM.select) # necess√°rio atribuir os nomes das linhas rownames(spatial.pred) &lt;- rownames(xy) Depois de gerar os valores dos autovetores espaciais (MEM), √© poss√≠vel executar a a RDA parcial utilizando esses valores no argumento ‚ÄòConditional.‚Äô ## Combinar vari√°veis ambientais e espaciais em um √∫nico data.frame pred.vars &lt;- data.frame(env.pad.cat, spatial.pred) ## RDA parcial rda.p &lt;- rda(species.hel ~ rain.jul + maxi.jul + altitude + # Preditores ambientais Condition(MEM1+MEM2+MEM4+MEM5), # Preditores espaciais data = pred.vars) # Para interpretar, √© necess√°rio saber a signific√¢ncia dos eixos para representar a rela√ß√£o entre as vari√°veis preditoras e a composi√ß√£o de esp√©cies res.p.axis &lt;- anova.cca(rda.p, by=&quot;axis&quot;) res.p.axis #&gt; Permutation test for rda under reduced model #&gt; Forward tests for axes #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; Model: rda(formula = species.hel ~ rain.jul + maxi.jul + altitude + Condition(MEM1 + MEM2 + MEM4 + MEM5), data = pred.vars) #&gt; Df Variance F Pr(&gt;F) #&gt; RDA1 1 0.008471 2.1376 0.312 #&gt; RDA2 1 0.004830 1.2189 0.782 #&gt; RDA3 1 0.003240 0.8176 0.892 #&gt; RDA4 1 0.001891 0.4773 0.902 #&gt; Residual 14 0.055477 # Em seguida, √© poss√≠vel identificar quais s√£o as vari√°veis que contribuem ou que mais contribuem para a varia√ß√£o na composi√ß√£o de esp√©cies res.p.var &lt;- anova.cca(rda.p, by=&quot;term&quot;) ## Qual vari√°vel? res.p.var #&gt; Permutation test for rda under reduced model #&gt; Terms added sequentially (first to last) #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; Model: rda(formula = species.hel ~ rain.jul + maxi.jul + altitude + Condition(MEM1 + MEM2 + MEM4 + MEM5), data = pred.vars) #&gt; Df Variance F Pr(&gt;F) #&gt; rain.jul 1 0.004406 1.1119 0.340 #&gt; maxi.jul 1 0.004446 1.1220 0.337 #&gt; altitude 2 0.009579 1.2087 0.238 #&gt; Residual 14 0.055477 RsquareAdj(rda.p) #&gt; $r.squared #&gt; [1] 0.1361661 #&gt; #&gt; $adj.r.squared #&gt; [1] 0.02330319 Se voc√™ comparar os resultados do objeto res.p.var (RDA parcial) com res.var (RDA simples) √© poss√≠vel perceber como a estrutura espacial nos res√≠duos aumenta a probabilidade de cometer erro do tipo 1. O modelo da RDA parcial mostra que n√£o existem qualquer efeito direto das vari√°veis ambientais sobre a composi√ß√£o de esp√©cies (conclus√£o com a RDA simples). Na verdade, tanto a composi√ß√£o de esp√©cies quanto as vari√°veis clim√°ticas est√£o fortemente estruturadas no espa√ßo, como demonstramos a seguir: ## Padr√£o espacial na composi√ß√£o de esp√©cies pca.comp &lt;- dudi.pca(species.hel, scale = FALSE, scannf = FALSE) moran.comp &lt;- moran.mc(pca.comp$li[, 1], mat_listw, 999) ## Padr√£o espacial das vari√°veis ambientais env$altitude &lt;- as.factor(env$altitude) ca.env &lt;- dudi.hillsmith(env, scannf = FALSE) moran.env &lt;- moran.mc(ca.env$li[, 1], mat_listw, 999) ## Estrutura espacial na composi√ß√£o de esp√©cies? moran.comp #&gt; #&gt; Monte-Carlo simulation of Moran I #&gt; #&gt; data: pca.comp$li[, 1] #&gt; weights: mat_listw #&gt; number of simulations + 1: 1000 #&gt; #&gt; statistic = 0.62815, observed rank = 1000, p-value = 0.001 #&gt; alternative hypothesis: greater ## Estrutura espacial na varia√ß√£o ambiental? moran.env #&gt; #&gt; Monte-Carlo simulation of Moran I #&gt; #&gt; data: ca.env$li[, 1] #&gt; weights: mat_listw #&gt; number of simulations + 1: 1000 #&gt; #&gt; statistic = 0.72714, observed rank = 1000, p-value = 0.001 #&gt; alternative hypothesis: greater Como resultado, √© poss√≠vel que a varia√ß√£o ambiental espacialmente estruturada √© o principal efeito sobre a composi√ß√£o de esp√©cies. Uma maneira de visualizar a contribui√ß√£o relativa de diferentes matrizes (ambiental e espacial, por exemplo) √© utilizar o m√©todo de parti√ß√£o de vari√¢ncia. O resultado deste modelo indica que, de fato, n√£o existe efeito direto das vari√°veis ambientais e sim do componente representado pela autocorrela√ß√£o espacial dessas vari√°veis. ### Parti√ß√£o de vari√¢ncia pv.birds &lt;- varpart(species.hel, env.pad.cat, spatial.pred) plot(pv.birds) 9.8 PERMANOVA A PERMANOVA √© um acr√¥nimo, em ingl√™s, de permutational multivariate analysis of variance, an√°lise proposta por Anderson (Marti J. Anderson 2001). A PERMANOVA √© usada para testar hip√≥teses multivariadas que comparam a abund√¢ncia de diferentes esp√©cies em resposta a diferentes tratamentos ou gradientes ambientais. Esta an√°lise foi desenvolvida como forma de solucionar algumas limita√ß√µes da tradicional ANOVA multivariada (MANOVA). Em especial, o pressuposto da MANOVA de distribui√ß√£o normal multivariada √© raramente encontrado em dados ecol√≥gicos. O primeiro passo da PERMANOVA √© selecionar uma medida de dist√¢ncia apropriada aos dados e, al√©m disso, verificar a necessidade de padroniza√ß√£o ou transforma√ß√£o dos dados. Em seguida, as dist√¢ncias s√£o comparadas entre os grupos de interesse (por exemplo, tratamento vs.¬†controle) usando a estat√≠stica F de maneira muito parecida com uma ANOVA (cap7?), chamada de pseudo-F: \\[ F = (SSa / SSr)*[(N-g) / (g-1)] \\] onde SSa representa a soma dos quadrados entre grupos, SSr a soma de quadrados dentro do grupo (residual), N o n√∫mero de unidades amostrais e g os grupos (ou n√≠veis da vari√°vel categ√≥rica). Esta f√≥rmula do pseudo-F √© espec√≠fica para desenho experimental com um fator. Outros desenhos mais complexos s√£o apresetandos em Anderson [(2001); (2017). O c√°lculo do valor de probilidade √© realizado por m√©todos de permuta√ß√£o que s√£o discutidos em Anderson &amp; Ter Braak (2003). 9.8.0.1 Exemplo 1 Esp√©cies de aves que ocorrem em localidades com diferentes altitudes. Pergunta O clima e a altitude modificam a composi√ß√£o de esp√©cies de aves? Predi√ß√µes Diferen√ßas clim√°ticas (temperatura e chuva) e altitudinais alteram a composi√ß√£o de esp√©cies de aves. Vari√°veis Preditoras: Temperatura e chuva (cont√≠nuas) e altitude (categ√≥rica com tr√™s n√≠veis) Dependente: composi√ß√£o de esp√©cies de aves # Composi√ß√£o de esp√©cies padronizar com m√©todo de Hellinger species.hel &lt;- decostand(species, &quot;hellinger&quot;) # Matriz de dist√¢ncia com m√©todo Bray Curtis sps.dis &lt;- vegdist(species.hel, &quot;bray&quot;) Para reduzir o n√∫mero de vari√°veis no modelo, voc√™ pode considerar duas abordangens. A primeira, e mais importante delas, √© manter somente vari√°veis preditoras que voc√™ tenha raz√£o biol√≥gica para mant√™-la e, al√©m disso, que esteja relacionada com suas hip√≥teses. Assim, uma vez que voc√™ j√° removeu vari√°veis que n√£o tem relev√¢ncia biol√≥gica, voc√™ deve usar diferentes m√©todos para remover as vari√°veis muito correlacionadas (forward selection, Variance Inflation Factor (VIF), entre outros). Neste exemplo, vamos simplesmente fazer uma correla√ß√£o m√∫ltipla e remover as vari√°veis com correla√ß√£o maior do que 0.9 ou -0.9. A fun√ß√£o ggpairs mostra um gr√°fico bem did√°tico para representa a rela√ß√£o entre todas as vari√°veis e o valor (r) desta correla√ß√£o. ## Verifica correla√ß√£o entre as vari√°veis ggpairs(env) # Ap√≥s verificar a estrutura de correla√ß√£o, vamos manter somente tr√™s #vari√°veis env2 &lt;- env[,c(&quot;mini.jan&quot;, &quot;rain.tot&quot;, &quot;altitude&quot;)] Ap√≥s selecionar as vari√°veis do modelo, vamos executar a PERMANOVA e entender as principais etapas para interpretar corretamente o teste. A fun√ß√£o adonis do pacote vegan √© a melhor op√ß√£o no vegan. Por√©m, √© importante referir o programa PRIMER e PERMANOVA+ como √≥tima op√ß√£o para implementar a PERMANOVA e ter maior controle em desenhos complexos (M. J. Anderson, Gorley, and Clarke 2008). Assim como nos modelos lineares apresentados no (cap7?), os argumento seguem o mesmo formato, com vari√°vel dependente separada por um ‚Äú~‚Äù das vari√°veis preditoras. Por√©m, alguns autores demonstraram que a PERMANOVA (assim como Mantel e ANOSIM) n√£o pode identificar se diferen√ßas significativas do teste (usando a estat√≠stica pseudo-F) se devem a diferen√ßas no posi√ß√£o, na dispers√£o ou ambos. Ou seja, ao comparar grupos n√£o √© poss√≠vel identificar se existe mudan√ßas de composi√ß√£o (posi√ß√£o) ou a varia√ß√£o da composi√ß√£o de esp√©cies dentro de um grupo (dispers√£o) √© maior do que a varia√ß√£o dentro do outro grupo (Marti J. Anderson and Walsh 2013). Para solucionar este problema, √© poss√≠vel combinar a PERMANOVA com a an√°lise PERMDISP (ou BETADISPER, como chamado no pacote vegan). Esta an√°lise permite comparar se existe heterogeneidade nas vari√¢ncias entre grupos. Deste modo, a presen√ßa de heterogeneidade de vari√¢ncias (valor do BETADISPER significativo), √© poss√≠vel saber que as diferen√ßas entre os grupos ocorre principalmente por diferen√ßas na dispers√£o e n√£o, necessariamente, de posi√ß√£o. Mais detalhes sobre a relev√¢ncia de combinar essas duas an√°lises est√£o dispon√≠veis em Anderson &amp; Walsh (2013). perm.aves &lt;- adonis2(sps.dis ~ mini.jan + rain.tot + altitude, data = env2) perm.aves ### Diferen√ßas entre os tratamentos? #&gt; Permutation test for adonis under reduced model #&gt; Terms added sequentially (first to last) #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; adonis2(formula = sps.dis ~ mini.jan + rain.tot + altitude, data = env2) #&gt; Df SumOfSqs R2 F Pr(&gt;F) #&gt; mini.jan 1 0.09069 0.15997 6.3307 0.001 *** #&gt; rain.tot 1 0.12910 0.22771 9.0118 0.001 *** #&gt; altitude 2 0.08929 0.15749 3.1163 0.021 * #&gt; Residual 18 0.25787 0.45483 #&gt; Total 22 0.56695 1.00000 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 betad.aves &lt;-betadisper(sps.dis, env2$altitude) permutest(betad.aves) #&gt; #&gt; Permutation test for homogeneity of multivariate dispersions #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; Response: Distances #&gt; Df Sum Sq Mean Sq F N.Perm Pr(&gt;F) #&gt; Groups 2 0.0042643 0.0021322 1.4672 999 0.247 #&gt; Residuals 20 0.0290636 0.0014532 Em nosso exemplo, temperatura, chuva e altitude afetaram a varia√ß√£o na composi√ß√£o de esp√©cies. Por√©m, para identificar se as diferen√ßas de composi√ß√£o entre os n√≠veis da vari√°vel altitude, √© necess√°rio interpretar os resultados da an√°lise BETADISPER. O comando permutest(betad.aves) mostra que o valor de probabilidade da an√°lise foi de 0.253, ou seja, a hip√≥tese nula de que a vari√¢ncia entre grupos √© homog√™nea √© aceita. Assim, n√£o existe diferen√ßas na dispers√£o entre grupo, sugerindo que a diferen√ßa encontrada na PERMANOVA (objeto perm.aves) se deve, em parte, a mudan√ßa na composi√ß√£o de esp√©cies de aves entre diferentes altitudes (R2 = 0.135). Al√©m disso, a chuva (R2 = 0.183) e temperatura (R2 = 0.127) foram fatores importantes na varia√ß√£o da composi√ß√£o de esp√©cies. Como falado anteriormente, as an√°lises de ordena√ß√£o irrestritas (PCA, PCoA, nMDS) s√£o utilizadas para explorar dados. Uma maneira poderosa de us√°-las √© combinando com an√°lises que testam hip√≥teses, como PERMANOVA e RDA (abaixo). A literatura ecol√≥gica tem usado a an√°lise de escalonamento n√£o m√©trico (nMDS) combinado com an√°lises multidimensionais de vari√¢ncia (como a PERMANOVA) para visualiza√ß√£o da similaridade na composi√ß√£o de esp√©cies dentro e entre grupos. A seguir, implementamos o nMDS na matriz de composi√ß√£o de esp√©cies de √°caros. # Matriz de dist√¢ncia representando a varia√ß√£o na composi√ß√£o de esp√©cies (m√©todo Bray-Curtis) as.matrix(sps.dis)[1:6, 1:6] #&gt; S01 S02 S03 S04 S05 S06 #&gt; S01 0.0000000 0.15133734 0.16720405 0.2559122 0.2559882 0.2588892 #&gt; S02 0.1513373 0.00000000 0.04114702 0.1190172 0.1289682 0.1391056 #&gt; S03 0.1672040 0.04114702 0.00000000 0.1420233 0.1358127 0.1410867 #&gt; S04 0.2559122 0.11901720 0.14202325 0.0000000 0.1140283 0.1199803 #&gt; S05 0.2559882 0.12896823 0.13581271 0.1140283 0.0000000 0.2129054 #&gt; S06 0.2588892 0.13910558 0.14108668 0.1199803 0.2129054 0.0000000 # √â preciso calcular uma primeira &quot;melhor&quot; solu√ß√£o do nMDS sol1 &lt;- metaMDS(sps.dis) #&gt; Run 0 stress 0.1344042 #&gt; Run 1 stress 0.1272417 #&gt; ... New best solution #&gt; ... Procrustes: rmse 0.0789082 max resid 0.3526074 #&gt; Run 2 stress 0.1344042 #&gt; Run 3 stress 0.1336481 #&gt; Run 4 stress 0.1344042 #&gt; Run 5 stress 0.1336481 #&gt; Run 6 stress 0.1336481 #&gt; Run 7 stress 0.1338432 #&gt; Run 8 stress 0.1338432 #&gt; Run 9 stress 0.1378506 #&gt; Run 10 stress 0.1336481 #&gt; Run 11 stress 0.1338433 #&gt; Run 12 stress 0.1338432 #&gt; Run 13 stress 0.1338432 #&gt; Run 14 stress 0.1336481 #&gt; Run 15 stress 0.1344042 #&gt; Run 16 stress 0.1600808 #&gt; Run 17 stress 0.1272418 #&gt; ... Procrustes: rmse 8.48708e-05 max resid 0.0003246819 #&gt; ... Similar to previous best #&gt; Run 18 stress 0.1344042 #&gt; Run 19 stress 0.1611279 #&gt; Run 20 stress 0.1336481 #&gt; *** Solution reached # Depois, executar a mesma fun√ß√£o, mas utilizando uma &quot;melhor solu√ß√£o inicial&quot; para evitar resultdos sub√≥timos no nMDS nmds.beta &lt;- metaMDS(sps.dis, previous.best = sol1) #&gt; Starting from 2-dimensional configuration #&gt; Run 0 stress 0.1272417 #&gt; Run 1 stress 0.1272418 #&gt; ... Procrustes: rmse 2.997893e-05 max resid 0.000115054 #&gt; ... Similar to previous best #&gt; Run 2 stress 0.1378506 #&gt; Run 3 stress 0.1336481 #&gt; Run 4 stress 0.1344042 #&gt; Run 5 stress 0.1344042 #&gt; Run 6 stress 0.1272417 #&gt; ... New best solution #&gt; ... Procrustes: rmse 3.864488e-06 max resid 1.312654e-05 #&gt; ... Similar to previous best #&gt; Run 7 stress 0.1600803 #&gt; Run 8 stress 0.1336481 #&gt; Run 9 stress 0.1272417 #&gt; ... Procrustes: rmse 2.636369e-06 max resid 7.540622e-06 #&gt; ... Similar to previous best #&gt; Run 10 stress 0.1272417 #&gt; ... Procrustes: rmse 2.44969e-05 max resid 9.417254e-05 #&gt; ... Similar to previous best #&gt; Run 11 stress 0.1336481 #&gt; Run 12 stress 0.1272417 #&gt; ... New best solution #&gt; ... Procrustes: rmse 4.828567e-06 max resid 1.820829e-05 #&gt; ... Similar to previous best #&gt; Run 13 stress 0.1344042 #&gt; Run 14 stress 0.1272417 #&gt; ... Procrustes: rmse 7.317335e-06 max resid 2.766948e-05 #&gt; ... Similar to previous best #&gt; Run 15 stress 0.3652494 #&gt; Run 16 stress 0.1659926 #&gt; Run 17 stress 0.1338432 #&gt; Run 18 stress 0.1336481 #&gt; Run 19 stress 0.1344042 #&gt; Run 20 stress 0.1272418 #&gt; ... Procrustes: rmse 2.223437e-05 max resid 8.504391e-05 #&gt; ... Similar to previous best #&gt; *** Solution reached # O stress √© o valor mais importante para interpretar a qualidade da ordena√ß√£o () nmds.beta$stress # valor ideal entre 0 e 0.2 #&gt; [1] 0.1272417 # Exportar os valores para fazer gr√°fico dat.graf &lt;- data.frame(vegan::scores(nmds.beta), altitude = env2$altitude) # Definir os grupos (&quot;HULL&quot;) para serem categorizados no gr√°fico grp.mon &lt;- dat.graf[dat.graf$altitude == &quot;Montanhoso&quot;, ][chull(dat.graf[dat.graf$altitude == &quot;Montanhoso&quot;, c(&quot;NMDS1&quot;, &quot;NMDS2&quot;)]), ] grp.int &lt;- dat.graf[dat.graf$altitude == &quot;Intermedi√°rio&quot;, ][chull(dat.graf[dat.graf$altitude == &quot;Intermedi√°rio&quot;, c(&quot;NMDS1&quot;, &quot;NMDS2&quot;)]), ] grp.pla &lt;- dat.graf[dat.graf$altitude == &quot;Plano&quot;, ][chull(dat.graf[dat.graf$altitude == &quot;Plano&quot;, c(&quot;NMDS1&quot;, &quot;NMDS2&quot;)]), ] ## Combinar dados dos grupos para cada Convex Hull hull.data &lt;- rbind(grp.mon, grp.int, grp.pla) head(hull.data) #&gt; NMDS1 NMDS2 altitude #&gt; S04 -0.10578360 -0.10682795 Montanhoso #&gt; S01 -0.25332377 0.04198598 Montanhoso #&gt; S11 -0.12504868 0.14477145 Montanhoso #&gt; S15 0.09166003 0.09857211 Montanhoso #&gt; S18 0.01968282 -0.12417413 Intermedi√°rio #&gt; S06 -0.16053934 -0.08924307 Intermedi√°rio # Gr√°fico combinado os escores do nMDS com pol√≠gonos dos valores por cada cota altitudinal dat.graf %&gt;% ggplot(aes(x = NMDS1, y = NMDS2, color = altitude, shape = altitude)) + theme_bw() + geom_point(size=4, alpha=0.7) + geom_polygon(data = hull.data, aes(fill = altitude, group = altitude), alpha=0.3) + scale_color_manual(values=c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values=c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + xlab(&quot;NMDS1&quot;) + ylab(&quot;NMDS2&quot;) + theme(axis.title.x = element_text(size=14), axis.text.x = element_text(vjust=0.5, size=12), axis.title.y = element_text(size=14), axis.text.y = element_text(vjust=0.5, size=12), legend.position = &quot;top&quot;, legend.title = element_blank())+ tema_livro() 9.8.1 Para se aprofundar Agrupamento de esp√©cies e locais baseado em modelos Numerical Ecology with R James &amp; McCulloch (1990) Legendre &amp; Legendre (2012) Refer√™ncias "],["cap10.html", "Cap√≠tulo 10 Rarefa√ß√£o 10.1 Aspectos te√≥ricos 10.2 Curva de rarefa√ß√£o baseada no indiv√≠duo (individual-based) 10.3 Curva de rarefa√ß√£o baseada em amostras (sample-based) 10.4 Curva de rarefa√ß√£o coverage-based", " Cap√≠tulo 10 Rarefa√ß√£o Pr√©-requisitos do cap√≠tulo # Pacotes library(iNEXT) library(devtools) library(ecodados) library(ggplot2) library(vegan) library(nlme) library(dplyr) library(piecewiseSEM) ## Dados necess√°rios data(&quot;mite&quot;) data(&quot;mite.xy&quot;) coord &lt;- mite.xy colnames(coord) &lt;- c(&quot;long&quot;, &quot;lat&quot;) data(&quot;mite.env&quot;) agua &lt;- mite.env[,2] dados_rarefacao &lt;- ecodados::rarefacao_morcegos rarefacao_repteis &lt;- ecodados::rarefacao_repteis rarefacao_anuros &lt;- ecodados::rarefacao_anuros dados_amostras &lt;- ecodados::morcegos_rarefacao_amostras 10.1 Aspectos te√≥ricos Uma das grandes dificuldades na compara√ß√£o da riqueza de esp√©cies entre comunidades √© decorrente da diferen√ßa no esfor√ßo amostral (e.g.¬†diferen√ßa no n√∫mero de indiv√≠duos, discrep√¢ncia na quantidade de unidades amostrais ou √°rea amostrada) que inevitavelmente influenciar√° no n√∫mero de esp√©cies observadas (N. J. Gotelli and Chao 2013; Roswell, Dushoff, and Winfree 2021). O m√©todo de rarefa√ß√£o nos permite comparar o n√∫mero de esp√©cies entre comunidades quando o tamanho da amostra (e.g.¬†n√∫mero de unidades amostrais), o esfor√ßo amostral (e.g.¬†tempo de amostragem) ou a abund√¢ncia de indiv√≠duos n√£o s√£o iguais. A rarefa√ß√£o calcula o n√∫mero esperado de esp√©cies em cada comunidade tendo como base comparativa um valor em que todas as amostras atinjam um tamanho padr√£o. Gotelli &amp; Colwell (2001) descrevem dois tipos de curvas de rarefa√ß√£o: i) baseada em indiv√≠duos (individual-based) - as compara√ß√µes s√£o feitas considerando a abund√¢ncia da comunidade padronizada pelo menor n√∫mero de indiv√≠duos; e ii) baseada na amostra (sampled-based) - as compara√ß√µes s√£o padronizadas pela comunidade com menor n√∫mero de amostragens. O m√©todo foi formulado considerando a seguinte pergunta: Se considerarmos n indiv√≠duos ou amostras (n &lt; N) para cada comunidade, quantas esp√©cies registrar√≠amos nas comunidades considerando o mesmo n√∫mero de indiv√≠duos ou amostras? Gotelli &amp; Colwell (2001) descrevem este m√©todo e discutem em detalhes as restri√ß√µes sobre seu uso na ecologia: As amostras a serem comparadas devem ser consistentes do ponto de vista taxon√¥mico, ou seja, todos os indiv√≠duos devem pertencer ao mesmo grupo taxon√¥mico; As compara√ß√µes devem ser realizadas somente entre amostras com as mesmas t√©cnicas de coleta. Por exemplo, n√£o √© recomendado comparar amostras onde a riqueza de esp√©cies de anuros de uma amostra foi estimada utilizando armadilhas de intercepta√ß√£o e queda e a outra foi estimada por vocaliza√ß√µes em s√≠tios de reprodu√ß√£o; Os tipos de h√°bitat onde as amostras s√£o obtidas devem ser semelhantes; √â um m√©todo para estimar a riqueza de esp√©cies em uma amostra menor ‚Äì n√£o pode ser usado para extrapolar a riqueza para amostras maiores. üìù Importante: Esta √∫ltima restri√ß√£o foi superada por Colwell et al. (2012) e Chao &amp; Jost (2012) que desenvolveram uma nova abordagem onde os dados podem ser interpolados (rarefeito) para amostras menores e extrapolados para amostras maiores. Al√©m disso, Chao &amp; Jost (2012) prop√µem a curva de rarefa√ß√£o coverage-based que padroniza as amostras pela cobertura ou totalidade (completeness) da amostra ao inv√©s do tamanho. As rarefa√ß√µes tradicionais apresentam limita√ß√µes matem√°ticas que s√£o superadas por essa nova abordagem (Anne Chao and Jost 2012). 10.2 Curva de rarefa√ß√£o baseada no indiv√≠duo (individual-based) 10.2.0.1 Exemplo pr√°tico 1 - Morcegos Explica√ß√£o dos dados Usaremos os dados de esp√©cies de morcegos amostradas em tr√™s fragmentos florestais (Breviglieri 2008): i) Mata Ciliar do C√≥rrego Talhadinho com 12 hectares; ii) Mata Ciliar do C√≥rrego dos Tenentes com 10 hectares; e iii) Fazenda Experimental de Pindorama com 128 hectares. Pergunta: A riqueza de esp√©cies de morcegos √© maior na Fazenda Experimental do que nos fragmentos florestais menores? Predi√ß√µes O n√∫mero de esp√©cies ser√° maior em fragmentos florestais maiores. Vari√°veis Vari√°veis resposta e preditoras Matriz ou dataframe com as abund√¢ncias das esp√©cies de morcegos (vari√°vel resposta) registradas nos tr√™s fragmentos florestais (vari√°vel preditora). Checklist Verificar se a sua matriz ou dataframe est√£o com as esp√©cies nas linhas e os fragmentos florestais nas colunas An√°lise Vamos olhar os dados usando a fun√ß√£o head head(dados_rarefacao) #&gt; MC_Tenentes MC_Talhadinho FF_Experimental #&gt; Chrotopterus_auritus 0 1 1 #&gt; Phyllostomus_hastatus 0 1 0 #&gt; Phyllostomus_discolor 0 2 2 #&gt; Artibeus_lituratus 17 26 26 #&gt; Artibeus_obscurus 1 4 6 #&gt; Artibeus_planirostris 34 72 52 Usaremos as fun√ß√µes do pacote iNEXT (iNterpolation e EXTrapolation) para o c√°lculo da rarefa√ß√£o. Esta fun√ß√£o permite estimar a riqueza de esp√©cies utilizando a fam√≠lia Hill-numbers (Hill 1973; explica√ß√£o dos conceitos da fam√≠lia Hill-numbers est√° detalhada no @[cap12]). O argumento q refere-se a fam√≠lia Hill-numbers onde: 0 = riqueza de esp√©cies; 1 = diversidade de Shannon; e 2 = diversidade de Simpson. # Datatype refere-se ao tipo de dados que voc√™ vai analisar (e.g. abund√¢ncia, # incid√™ncia). # Endpoint refere-se ao valor m√°ximo que voc√™ determina para a extrapola√ß√£o. resultados_morcegos &lt;- iNEXT(dados_rarefacao, q = 0, datatype = &quot;abundance&quot;, endpoint = 800) Vamos visualizar os resultados. # type define o tipo de curva de rarefa√ß√£o: # 1 = curva de rarefa√ß√£o baseada no indiv√≠duo ou amostra; # 2 = curva de representatividade da amostra; e # 3 = curva de rarefa√ß√£o baseada na representatividade (coverage-based). ggiNEXT(resultados_morcegos, type = 1) + labs(x = &quot;N√∫mero de indiv√≠duos&quot;, y = &quot; Riqueza de esp√©cies&quot;) + scale_linetype_discrete(labels = c(&quot;Interpolado&quot;, &quot;Extrapolado&quot;)) + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) Interpreta√ß√£o dos resultados Foram registrados 166 indiv√≠duos na MC_Tenentes, 413 na MC_Talhadinho e 223 na FF_Experimental. Lembrando, voc√™ n√£o pode comparar a riqueza de esp√©cies observada diretamente: 15 esp√©cies na MC_Tenentes, 19 esp√©cies na MC_Talhadinho, e 17 esp√©cies no FF_Experimental. A compara√ß√£o da riqueza de esp√©cies entre as comunidades deve ser feita com base na riqueza de esp√©cies rarefeita, que √© calculada com base no n√∫mero de indiv√≠duos da comunidade com menor abund√¢ncia (166 indiv√≠duos). Olhando o gr√°fico √© poss√≠vel perceber que a riqueza de esp√©cies de morcegos rarefeita n√£o √© diferente entre os tr√™s fragmentos florestais quando corrigimos o problema da diferen√ßa na abund√¢ncia pela rarefa√ß√£o. A interpreta√ß√£o √© feita com base no intervalo de confian√ßa de 95%. As curvas ser√£o diferentes quando os intervalos de confian√ßa n√£o se sobreporem (A. Chao et al. 2014). Percebam que esta abordagem, al√©m da interpola√ß√£o (rarefa√ß√£o), tamb√©m realiza extrapola√ß√µes que podem ser usadas para estimar o n√∫mero de esp√©cies caso o esfor√ßo de coleta fosse maior. Este √© o assunto do nosso pr√≥ximo cap√≠tulo. ¬† 10.2.0.2 Exemplo pr√°tico 2 - Anuros e R√©pteis Explica√ß√£o dos dados Neste exemplo, iremos comparar o n√∫mero de esp√©cies de anuros e r√©pteis (serpentes e lagartos) usando informa√ß√µes dos indiv√≠duos depositados em cole√ß√µes cient√≠ficas e coletas de campo (da Silva et al. 2017). Pergunta: A riqueza de esp√©cies estimada para uma mesma regi√£o √© maior usando informa√ß√µes de cole√ß√µes cient√≠ficas do que informa√ß√µes de coletas de campo? Predi√ß√µes O n√∫mero de esp√©cies ser√° maior em cole√ß√µes cient√≠ficas devido ao maior esfor√ßo amostral (i.e.¬†maior varia√ß√£o temporal para depositar os indiv√≠duos e maior n√∫mero de pessoas contribuindo com coletas espor√°dicas). Vari√°veis Vari√°veis resposta e preditoras Matriz ou dataframe com as abund√¢ncias das esp√©cies de anuros e r√©pteis (vari√°vel resposta) registradas em cole√ß√µes cient√≠ficas e coletas de campo (vari√°vel preditora). Checklist Verificar se a sua matriz ou dataframe est√£o com as esp√©cies nas linhas e a fonte dos dados nas colunas. An√°lise Olhando os dados dos r√©pteis. head(rarefacao_repteis) #&gt; Coleta.Campo Colecoes.Cientificas #&gt; Ameiva_ameiva 1 0 #&gt; Amphisbaena_mertensii 1 0 #&gt; Apostolepis_dimidiata 0 1 #&gt; Bothrops__itapetiningae 0 2 #&gt; Bothrops__pauloensis 0 1 #&gt; Bothrops_alternatus 0 1 An√°lise usando o pacote iNEXT. # An√°lise resultados_repteis &lt;- iNEXT(rarefacao_repteis, q = 0, datatype = &quot;abundance&quot;, endpoint = 200) # Visualizar os resultados. ggiNEXT(resultados_repteis, type = 1) + labs(x = &quot;N√∫mero de indiv√≠duos&quot;, y = &quot; Riqueza de esp√©cies&quot;) + scale_linetype_discrete(labels = c(&quot;Interpolado&quot;, &quot;Extrapolado&quot;)) + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;)) Interpreta√ß√£o dos resultados - r√©pteis Foram registradas oito esp√©cies de r√©pteis nas coletas de campo (40 indiv√≠duos) e 28 esp√©cies nas cole√ß√µes cient√≠ficas (77 indiv√≠duos). Com base na rarefa√ß√£o, conclu√≠mos que a riqueza de esp√©cies de r√©pteis obtida nas cole√ß√µes cient√≠ficas (20,5) √© 2,9 vezes maior do que a obtida em coletas de campo (7,05). Olhando os dados dos anuros head(rarefacao_anuros) #&gt; Coleta.Campo Colecoes.Cientificas #&gt; Chiasmocleis_albopunctata 15 0 #&gt; Dendropsophus_elianae 11 1 #&gt; Dendropsophus_jimi 15 2 #&gt; Dendropsophus_nanus 0 1 #&gt; Dendropsophus_minutus 24 0 #&gt; Dendropsophus_sanborni 0 1 An√°lise e visualiza√ß√£o do gr√°fico. # An√°lise resultados_anuros &lt;- iNEXT(rarefacao_anuros, q = 0, datatype = &quot;abundance&quot;, endpoint = 800) # Visualizar os resultados. ggiNEXT(resultados_anuros, type = 1) + labs(x = &quot;N√∫mero de indiv√≠duos&quot;, y = &quot; Riqueza de esp√©cies&quot;) + scale_linetype_discrete(labels = c(&quot;Interpolado&quot;, &quot;Extrapolado&quot;)) + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;cyan4&quot;)) Interpreta√ß√£o dos resultados - anuros Foram registradas 21 esp√©cies de anuros nas coletas de campo (709 indiv√≠duos) e 12 esp√©cies nas cole√ß√µes cient√≠ficas (37 indiv√≠duos). Com base na rarefa√ß√£o, conclu√≠mos que n√£o h√° diferen√ßa entre a riqueza de esp√©cies de anuros obtida em coletas de campo e cole√ß√µes cient√≠ficas. 10.3 Curva de rarefa√ß√£o baseada em amostras (sample-based) 10.3.0.1 Exemplo pr√°tico 3 - Morcegos Explica√ß√£o dos dados Usaremos os mesmos dados de esp√©cies de morcegos amostradas em tr√™s fragmentos florestais (Breviglieri 2008). Contudo, ao inv√©s de padronizarmos a riqueza de esp√©cies pela abund√¢ncia, iremos padronizar pelo n√∫mero de amostras. Vari√°veis Vari√°veis resposta e preditoras Lista de vetores. Cada vetor deve conter como primeira informa√ß√£o, o n√∫mero total de amostras (vari√°vel preditora), seguido da frequ√™ncia de ocorr√™ncia das esp√©cies (i.e.¬†n√∫mero de amostras em que cada esp√©cie foi registrada - vari√°vel resposta). Checklist Verificar se a sua lista est√° com o n√∫mero total de amostras e a frequ√™ncia de ocorr√™ncia das esp√©cies. An√°lise Vamos olhar os dados. head(dados_amostras) #&gt; MC_Tenentes MC_Talhadinho FF_Experimental #&gt; amostras 12 20 12 #&gt; sp1 12 20 12 #&gt; sp2 12 19 10 #&gt; sp3 10 15 8 #&gt; sp4 8 10 8 #&gt; sp5 6 7 7 Vamos criar uma lista com as amostragens de cada comunidade e os comandos da an√°lise. # Usamos [,] para excluir os NAs. Lembrando que valores antes da # v√≠rgula representam as linhas e os posteriores representam as colunas. lista_rarefacao &lt;- list(Tenentes = dados_amostras[1:18,1], Talhadinho = dados_amostras[,2], Experimental = dados_amostras[1:16,3]) # An√°lise. res_rarefacao_amostras &lt;- iNEXT(lista_rarefacao, q = 0, datatype=&quot;incidence_freq&quot;) Visualizar os resultados. # Gr√°fico ggiNEXT(res_rarefacao_amostras , type = 1, color.var = &quot;site&quot;) + theme_bw(base_size = 18) + theme(legend.position = &quot;right&quot;) + labs(x = &quot;N√∫mero de amostras&quot;, y = &quot; Riqueza de esp√©cies&quot;) + scale_linetype_discrete(name = &quot;M√©todo&quot;, labels = c(&quot;Interpolado&quot;, &quot;Extrapolado&quot;)) + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) Interpreta√ß√£o dos resultados Olhando o gr√°fico √© poss√≠vel perceber que a riqueza de esp√©cies de morcegos rarefeita n√£o √© diferente entre os tr√™s fragmentos florestais quando corrigimos o problema da diferen√ßa no n√∫mero de amostras. 10.4 Curva de rarefa√ß√£o coverage-based 10.4.0.1 Exemplo pr√°tico 4 - Morcegos Explica√ß√£o dos dados Neste exemplo, usaremos os mesmos dados de esp√©cies de morcegos amostradas em tr√™s fragmentos florestais (Breviglieri 2008). An√°lise Os comandos para a rarefa√ß√£o coverage-based s√£o id√™nticos aos utilizados para o c√°lculo das curvas de rarefa√ß√µes baseadas nas abund√¢ncias e amostras. Portanto, n√£o repetiremos as linhas de comando aqui e utilizaremos os resultados j√° calculados para a visualiza√ß√£o dos gr√°ficos. Para isso, digitamos type = 3 que representa a curva de rarefa√ß√£o coverage-based. # Visualizar os resultados da rarefa√ß√£o *coverage-based*. ggiNEXT(res_rarefacao_amostras, type = 3, color.var = &quot;site&quot;) + theme_bw(base_size = 18) + theme(legend.position = &quot;right&quot;) + labs(x = &quot;Representatividade nas amostras&quot;, y = &quot;Riqueza de esp√©cies&quot;) + scale_linetype_discrete(labels = c(&quot;Interpolado&quot;, &quot;Extrapolado&quot;)) + scale_colour_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) + scale_fill_manual(values = c(&quot;darkorange&quot;, &quot;darkorchid&quot;, &quot;cyan4&quot;)) Interpreta√ß√£o dos resultados Coverage √© uma medida que determina a propor√ß√£o de amostras (sampled-based) ou do n√∫mero de indiv√≠duos (abundance-based) da comunidade que representa as esp√©cies presentes na amostra. Um valor de coverage = 0,85 representa a riqueza estimada com base em 85% das amostragens ou da abund√¢ncia da comunidade. No nosso exemplo, os valores de coverage foram acima de 0,93 indicando que precisamos de praticamente todas as amostras para estimar a riqueza observada em cada comunidade. Comparando as comunidades considerando o mesmo valor de coverage, 0,937 na comunidade Tenentes, identificamos que a riqueza de esp√©cies de morcegos estimada na comunidade Experimental √© menor do que a estimada para a comunidade de Talhadinho (n√£o h√° sobreposi√ß√£o do intervalo de confian√ßa). Percebam que usando a curva de rarefa√ß√£o coverage-based, a interpreta√ß√£o dos resultados foi diferente das observadas usando as curvas baseadas nos indiv√≠duos ou amostras. Veja Chao &amp; Jost (2012) e Roswell et al. (2021) para explica√ß√µes mais detalhadas sobre esta metodologia. ¬† 10.4.0.2 Exemplo pr√°tico 5 - Generalized Least Squares (GLS) Explica√ß√£o dos dados Neste exemplo, iremos refazer o exerc√≠cio do @{cap8} onde usamos Generalized Least Squares (GLS) para testar a rela√ß√£o da riqueza de √°caros com a quantidade de √°gua no substrato. Contudo, ao inv√©s de considerar a riqueza de esp√©cies de √°caros observada como vari√°vel resposta, iremos utilizar a riqueza rarefeita para controlar o efeito da amostragem (i.e.¬†diferentes abund√¢ncias entre as comunidades). Os dados que usaremos est√£o dispon√≠veis no pacote vegan e representam a composi√ß√£o de esp√©cies de √°caros amostradas em 70 amostras. Pergunta: A riqueza rarefeita de esp√©cies de √°caros √© maior em comunidades localizadas em √°reas com substratos secos? Predi√ß√µes O n√∫mero de esp√©cies rarefeita ser√° maior em substratos secos, uma vez que as limita√ß√µes fisiol√≥gicas impostas pela umidade limitam a ocorr√™ncia de v√°rias esp√©cies de √°caros. Vari√°veis Vari√°veis resposta e preditoras Matriz ou dataframe com as abund√¢ncias das esp√©cies de √°caros (vari√°vel resposta) registradas em 70 comunidades (vari√°vel preditora). Checklist Verificar se a sua matriz ou dataframe est√£o com as esp√©cies nas linhas e as comunidades nas colunas. An√°lise Vamos calcular a riqueza rarefeita com base na comunidade com menor abund√¢ncia. # Os dados est√£o com as comunidades nas colunas e as esp√©cies nas linhas. # Para as an√°lises teremos que transpor a planilha. composicao_acaros &lt;- t(mite) # Verificar qual √© a menor abund√¢ncia registrada nas comunidades. min(colSums(composicao_acaros)) #&gt; [1] 8 Vamos calcular a riqueza rarefeita de esp√©cies para todas as comunidades considerando a menor abund√¢ncia. Para padronizar e facilitar a extra√ß√£o dos resultados, definimos os argumentos knots (i.e.¬†representa o intervalo igualmente espa√ßado que a fun√ß√£o ir√° utilizar para determinar a riqueza estimada) e endpoint (i.e.¬†o valor final de amostras ou abund√¢ncia extrapolados) com o valor de abund√¢ncia = 8. resultados_rarefacao &lt;- iNEXT(composicao_acaros, q = 0, datatype = &quot;abundance&quot;, knots = 8, endpoint = 8) Vamos criar um loop para facilitar a extra√ß√£o da riqueza rarefeita para as 70 comunidades. resultados_comunidades &lt;- data.frame() riqueza_rarefeita &lt;- c() for (i in 1:70){ resultados_comunidades &lt;- data.frame(resultados_rarefacao$iNextEst[i]) riqueza_rarefeita[i] &lt;- resultados_comunidades[8,4] } Vamos juntar esses resultados com os dados geogr√°ficos e ambientais. # Agrupando os dados em um dataframe final. dados_combinado &lt;- data.frame(riqueza_rarefeita, agua, coord) Agora, seguindo os passos descritos no @[cap8], vamos identificar o melhor modelo que representa a estrutura espacial dos dados da riqueza rarefeita. # Criando diferentes modelos usando a fun√ß√£o gls. # sem estrutura espacial no_spat_gls &lt;- gls(riqueza_rarefeita ~ agua, data = dados_combinado, method = &quot;REML&quot;) # Covari√¢ncia esf√©rica espher_model &lt;- gls(riqueza_rarefeita ~ agua, data = dados_combinado, corSpher(form = ~lat + long, nugget = TRUE)) # Covari√¢ncia exponencial expon_model &lt;- gls(riqueza_rarefeita ~ agua, data = dados_combinado, corExp(form = ~lat + long, nugget = TRUE)) # Covari√¢ncia Gaussiana gauss_model &lt;- gls(riqueza_rarefeita ~ agua, data = dados_combinado, corGaus(form = ~lat + long, nugget = TRUE)) # Covari√¢ncia raz√£o quadr√°tica ratio_model &lt;- gls(riqueza_rarefeita ~ agua, data = dados_combinado, corRatio(form = ~lat + long, nugget = TRUE)) Agora vamos usar o AIC para selecionar o modelo mais ‚Äúprov√°vel‚Äù explicando a distribui√ß√£o da riqueza rarefeita das esp√©cies de √°caros. # Sele√ß√£o dos modelos. aic_fit &lt;- AIC(no_spat_gls, espher_model, expon_model, gauss_model, ratio_model) aic_fit %&gt;% arrange(AIC) #&gt; df AIC #&gt; 1 5 164.5840 #&gt; 2 5 165.7649 #&gt; 3 5 165.8698 #&gt; 4 3 166.7530 #&gt; 5 5 169.0242 # Visualizando os res√≠duos do modelo selecionado. plot(gauss_model) Percebam que os pontos est√£o dispersos no gr√°fico e n√£o apresentam padr√µes que indiquem heterogeneidade de vari√¢ncia. # Visualizando os resultados. summary(gauss_model)$tTable #&gt; Value Std.Error t-value p-value #&gt; (Intercept) 6.086125990 0.2927633293 20.788553 3.550849e-31 #&gt; agua -0.003142615 0.0006670097 -4.711498 1.258304e-05 # Calculando o R-squared. rsquared(gauss_model) #&gt; Response family link method R.squared #&gt; 1 riqueza_rarefeita gaussian identity none 0.2991059 # Obtendo os valores preditos pelo modelo. predito &lt;- predict(gauss_model) # Plotando os resultados no gr√°fico. ggplot(data = dados_combinado, aes(x= agua, y= riqueza_rarefeita)) + labs(x = &quot;Concentra√ß√£o de √°gua no substrato&quot;, y = &quot;Riqueza rarefeita \\ndas esp√©cies de √°caros&quot;, size = 15) + geom_point(size = 4, shape = 21, fill = &quot;gray&quot;, alpha = 0.7) + tema_livro() + geom_line(aes(y = predito), size = 1) Interpreta√ß√£o dos resultados A concentra√ß√£o de √°gua no substrato explica 29,9% da varia√ß√£o na riqueza rarefeita das esp√©cies de √°caros. Como predito, a riqueza de esp√©cies de √°caros foi maior em comunidades localizadas em √°reas com substratos secos do que em √°reas com substratos √∫midos (t = -4.71, df = 68, P &lt; 0.01). 10.4.1 Para se aprofundar Recomendamos aos interessados que olhem a p√°gina do EstimateS software e baixem o manual do usu√°rio que cont√©m informa√ß√µes detalhadas sobre os √≠ndices de rarefa√ß√£o. Este site foi criado e √© mantido pelo Dr.¬†Robert K. Colwell, um dos maiores especialistas do mundo em estimativas da biodiversidade Recomendamos a p√°gina pessoal da pesquisadora Anne Chao que √© uma das respons√°veis pelo desenvolvimento da metodologia e do pacote iNEXT. Nesta p√°gina, voc√™s ir√£o encontrar exemplos e explica√ß√µes detalhadas sobre as an√°lises. Recomendamos tamb√©m o livro Biological Diversity Frontiers in Measurement and Assessment (Magurran and McGill 2011). Refer√™ncias "],["cap11.html", "Cap√≠tulo 11 Estimadores de riqueza 11.1 Aspectos te√≥ricos 11.2 Estimadores baseados na abund√¢ncia das esp√©cies 11.3 Estimadores baseados na incid√™ncia das esp√©cies", " Cap√≠tulo 11 Estimadores de riqueza Pr√©-requisitos do cap√≠tulo # Carregando todos os pacotes que ser√£o utilizados neste cap√≠tulo. library(iNEXT) library(devtools) # remotes::install_github(&quot;paternogbc/ecodados&quot;) library(ecodados) library(ggplot2) library(vegan) library(nlme) library(dplyr) library(piecewiseSEM) ## Dados necess√°rios dados_coleta &lt;- poca_anuros data(&quot;mite&quot;) data(&quot;mite.xy&quot;) coord &lt;- mite.xy colnames(coord) &lt;- c(&quot;long&quot;, &quot;lat&quot;) # altera o nome das colunas data(&quot;mite.env&quot;) agua &lt;- mite.env[,2] # seleciona a vari√°vel de interesse 11.1 Aspectos te√≥ricos Uma vez que determinar o n√∫mero total de esp√©cies numa √°rea √© praticamente imposs√≠vel, principalmente em regi√µes com alta riqueza de esp√©cies, os estimadores s√£o √∫teis para extrapolar a riqueza observada e tentar estimar a riqueza total atrav√©s de uma amostra incompleta de uma comunidade biol√≥gica (Walther and Moore 2005). Neste cap√≠tulo, ser√£o considerados os estimadores n√£o param√©tricos que usam informa√ß√µes da frequ√™ncia de esp√©cies raras na comunidade (N. J. Gotelli and Chao 2013). Isto porque tanto os testes param√©tricos que tentam determinar os par√¢metros de uma curva usando o formato da curva de acumula√ß√£o de esp√©cies (e.g.¬†equa√ß√£o log√≠stica, Michaelis-Menten), quanto os testes que usam a frequ√™ncia do n√∫mero de indiv√≠duos para enquadr√°-las em uma das distribui√ß√µes de abund√¢ncia das esp√©cies (e.g.¬†distribui√ß√µes log-s√©ries, log-normal) n√£o funcionam muito bem com dados emp√≠ricos (N. J. Gotelli and Chao 2013). Para mais detalhes sobre os testes param√©tricos veja (Magurran and McGill 2011) e Colwell &amp; Coddington (1994). Quatro caracter√≠sticas para um bom estimador de riqueza (Chazdon et al. 1998; Hortal, Borges, and Gaspar 2006): Independ√™ncia do tamanho da amostra (quantidade de esfor√ßo amostral realizado); Insensibilidade a diferentes padr√µes de distribui√ß√µes (e.g.¬†agrupado, disperso ou aleat√≥rio); Insensibilidade em rela√ß√£o √† ordem das amostragens; Insensibilidade √† heterogeneidade entre as amostras usadas entre os estudos. 11.2 Estimadores baseados na abund√¢ncia das esp√©cies 11.2.1 CHAO 1 - (A. Chao 1984, 1987): Estimador simples do n√∫mero absoluto de esp√©cies em uma comunidade. √â baseado no n√∫mero de esp√©cies raras dentro de uma amostra. \\[Chao_{1} = S_{obs} + \\left(\\frac{n-1}{n}\\right)\\frac{F_1(F_1-1)}{2(F_2+1)}\\] onde: Sobs = n√∫mero de esp√©cies observadas na comunidade, n = n√∫mero de amostras, F1 = n√∫mero de esp√©cies observadas com abund√¢ncia de um indiv√≠duo (esp√©cies singleton), F2 = n√∫mero de esp√©cies observadas com abund√¢ncia de dois indiv√≠duos (esp√©cies doubletons). O valor de Chao 1 √© m√°ximo quando todas as esp√©cies menos uma s√£o √∫nicas (singleton). Neste caso, a riqueza estimada √© aproximadamente o dobro da riqueza observada. 11.2.1.1 Exemplo pr√°tico - Chao 1 Explica√ß√£o dos dados Usaremos os dados de 17 esp√©cies de anuros amostradas em 14 dias de coletas de campo em um habitat reprodutivo localizado na regi√£o noroeste do estado de S√£o Paulo, Brasil. Pergunta: Quantas esp√©cies a mais poderiam ser amostradas caso aument√°ssemos at√© o infinito o esfor√ßo amostral? Predi√ß√µes O n√∫mero de esp√©cies estimadas √© similar ao n√∫mero de esp√©cies observada; O n√∫mero de esp√©cies estimadas √© maior do que o n√∫mero de esp√©cies observada. Vari√°veis Vari√°veis resposta e preditora data frame ou matriz com as abund√¢ncias das esp√©cies de anuros (vari√°vel resposta) registradas em 14 dias de amostragens (vari√°vel preditora) em um habitat reprodutivo. Checklist Verificar se a sua matriz est√° com as esp√©cies nas colunas e as amostragens nas linhas. Verificar se os dados s√£o de abund√¢ncia e n√£o de incid√™ncia (presen√ßa e aus√™ncia). An√°lise Vamos olhar os dados. head(poca_anuros) #&gt; Boana_albopunctata Boana_faber Boana_raniceps Dendropsophus_eliane #&gt; Dia_1 5 0 2 0 #&gt; Dia_2 0 0 0 0 #&gt; Dia_3 0 0 0 6 #&gt; Dia_4 0 0 0 15 #&gt; Dia_5 0 0 0 2 #&gt; Dia_6 1 0 0 2 #&gt; Dendropsophus_melanargyrius Dendropsophus_minutus Dendropsophus_nanus #&gt; Dia_1 0 0 4 #&gt; Dia_2 0 2 0 #&gt; Dia_3 0 1 3 #&gt; Dia_4 0 15 15 #&gt; Dia_5 1 8 2 #&gt; Dia_6 0 2 2 #&gt; Dermatonotus_muelleri Elachistocleis_bicolor Elachistocleis_sp Leptodactylus_chaquensis #&gt; Dia_1 0 0 0 0 #&gt; Dia_2 0 0 0 0 #&gt; Dia_3 0 0 0 0 #&gt; Dia_4 3 0 0 0 #&gt; Dia_5 12 0 0 11 #&gt; Dia_6 0 0 0 0 #&gt; Leptodactylus_fuscus Leptodactylus_labyrinthicus Physalameus_cuvieri #&gt; Dia_1 8 0 5 #&gt; Dia_2 3 0 3 #&gt; Dia_3 2 0 4 #&gt; Dia_4 5 0 2 #&gt; Dia_5 4 0 2 #&gt; Dia_6 2 0 2 #&gt; Physalaemus_nattereri Rhinella_schneideri Scinax_fuscovarius #&gt; Dia_1 0 2 0 #&gt; Dia_2 4 1 0 #&gt; Dia_3 1 2 0 #&gt; Dia_4 0 2 0 #&gt; Dia_5 17 1 0 #&gt; Dia_6 0 1 0 C√°lculo do estimador de riqueza - Chao 1. # An√°lise. est_chao1 &lt;- estaccumR(dados_coleta, permutations = 100) summary(est_chao1, display = &quot;chao&quot;) #&gt; $chao #&gt; N Chao 2.5% 97.5% Std.Dev #&gt; Dia_13 1 7.161667 3.000 12.33333 2.786019 #&gt; Dia_7 2 10.255429 6.000 18.81250 3.465467 #&gt; Dia_12 3 11.614500 7.475 19.52500 3.104127 #&gt; Dia_5 4 13.078167 9.000 20.00000 3.037566 #&gt; Dia_6 5 14.093333 9.000 22.00000 3.259457 #&gt; Dia_4 6 14.621667 10.000 22.00000 3.129084 #&gt; Dia_10 7 15.308333 10.475 22.00000 3.048741 #&gt; Dia_1 8 16.140000 12.000 22.00000 2.863106 #&gt; Dia_11 9 16.773333 12.000 22.00000 2.777931 #&gt; Dia_8 10 17.606667 13.000 22.00000 2.754093 #&gt; Dia_3 11 18.205000 13.000 22.00000 2.453708 #&gt; Dia_9 12 18.815000 14.975 22.00000 2.034618 #&gt; Dia_14 13 19.585000 15.500 22.00000 1.494189 #&gt; Dia_2 14 20.000000 20.000 20.00000 0.000000 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;summary.poolaccum&quot; Percebam que a fun√ß√£o retorna: N = n√∫mero de amostragens; Chao = valor m√©dio da estimativa do √≠ndice de Chao; 2.5% e 97.5% = intervalo de confian√ßa de 95%; e Std.Dev = desvio padr√£o. Essas dados s√£o obtidos usando permuta√ß√µes, sem reposi√ß√£o, que alteram a ordem das amostragens. Neste exemplo, usamos 100 permuta√ß√µes. Vamos visualizar os resultados com intervalo de confian√ßa de 95%. # Preparando os dados para fazer o gr√°fico. resultados &lt;- summary(est_chao1, display = c(&quot;S&quot;, &quot;chao&quot;)) res_chao &lt;- cbind(resultados$chao[,1:4], resultados$S[,2:4]) res_chao &lt;- as.data.frame(res_chao) colnames(res_chao) &lt;- c(&quot;Amostras&quot;, &quot;Chao&quot;, &quot;C_inferior&quot;, &quot;C_superior&quot;, &quot;Riqueza&quot;, &quot;R_inferior&quot;, &quot;R_superior&quot;) # Comando para o gr√°fico. ggplot(res_chao, aes(y = Riqueza, x = Amostras)) + geom_point(aes(y = Chao, x = Amostras + 0.1), size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(aes(y = Riqueza, x = Amostras), size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_line (aes(y = Chao, x = Amostras), color = &quot;darkorange&quot;) + geom_line (aes(y = Riqueza, x = Amostras), color = &quot;cyan4&quot;) + geom_linerange(aes(ymin = C_inferior, ymax = C_superior, x = Amostras + 0.1), color = &quot;darkorange&quot;) + geom_linerange(aes(ymin = R_inferior, ymax = R_superior, x = Amostras), color = &quot;cyan4&quot;) + ylab (&quot;Riqueza estimada - Chao 1&quot;) + xlab (&quot;N√∫mero de amostras&quot;) + scale_x_continuous(limits = c(1,15), breaks=seq(1,15,1)) + geom_point(y= 7.5, x = 9, size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(y= 5.9, x = 9, size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_label( y = 7.5, x = 12, label = &quot;Riqueza estimada - Chao 1&quot;) + geom_label( y = 5.9, x = 11.3, label = &quot;Riqueza observada&quot;) + tema_livro() Interpreta√ß√£o dos resultados Com base no n√∫mero de esp√©cies raras (singletons e doubletons), o estimador Chao 1 indica a possibilidade de encontrarmos mais tr√™s esp√©cies caso o esfor√ßo amostral fosse maior e n√£o estima tend√™ncia de estabiliza√ß√£o da curva em uma ass√≠ntota. 11.2.2 ACE - Abundance-based Coverage Estimador (A. Chao and Lee 1992; A. Chao et al. 2000): Este m√©todo trabalha com a abund√¢ncia das esp√©cies raras (i.e.¬†abund√¢ncia baixa). Entretanto, diferente do estimador anterior, esse m√©todo permite ao pesquisador determinar os limites para os quais uma esp√©cie seja considerada rara. Em geral, s√£o consideradas raras esp√©cies com abund√¢ncia entre 1 e 10 indiv√≠duos. A riqueza estimada pode variar conforme se aumente ou diminua o limiar de abund√¢ncia, e infelizmente n√£o existem crit√©rios biol√≥gicos definidos para a escolha do melhor intervalo. \\[ACE = S_{abund} + \\frac{S_{rare}}{C_{ace}} + \\frac{F_1}{C_{ace}}Y_{ace}^2\\] onde: \\[Y_{ace}^2 = max \\left[\\frac{S_{rare}}{C_{ace}}\\frac{\\sum_{i=i}^{10}i(i-1)F1}{(N_{rare})({N_{rare} - 1)}}-1,0\\right]\\] \\[C_{ace} = 1 - \\frac{F1}{N_{rare}}\\] \\[N_{rare} = \\sum_{i=1}^{10}iF_i\\] 11.2.2.1 Exemplo pr√°tico - ACE Explica√ß√£o dos dados Usaremos os mesmos dados de 17 esp√©cies de anuros amostradas em 14 dias de coletas de campo em um habitat reprodutivo localizado na regi√£o noroeste do estado de S√£o Paulo, Brasil. An√°lise C√°lculo do estimador de riqueza - ACE. # An√°lise. est_ace &lt;- estaccumR(dados_coleta, permutations = 100) summary(est_ace, display = &quot;ace&quot;) #&gt; $ace #&gt; N ACE 2.5% 97.5% Std.Dev #&gt; Dia_11 1 7.123899 3.545190 13.71429 2.768212 #&gt; Dia_3 2 9.832864 6.000000 18.42880 2.876526 #&gt; Dia_2 3 11.395043 7.619618 18.01220 2.668935 #&gt; Dia_14 4 12.442264 8.000000 17.13587 2.398428 #&gt; Dia_7 5 13.512461 9.328990 19.24111 2.482220 #&gt; Dia_8 6 14.249301 10.179603 19.70014 2.608287 #&gt; Dia_6 7 15.272604 10.712067 21.68808 2.950251 #&gt; Dia_5 8 16.269161 11.419992 22.61582 3.000033 #&gt; Dia_12 9 17.584889 12.635634 24.20307 3.149600 #&gt; Dia_1 10 19.491955 13.410767 25.28994 3.732346 #&gt; Dia_13 11 21.058884 13.923335 25.72368 3.607014 #&gt; Dia_9 12 22.452802 15.911357 25.72368 3.249493 #&gt; Dia_4 13 23.796512 17.676471 25.72368 2.243847 #&gt; Dia_10 14 24.703704 24.703704 24.70370 0.000000 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;summary.poolaccum&quot; Visualizar os resultados com intervalo de confian√ßa de 95%. # Preparando os dados para fazer o gr√°fico. resultados_ace &lt;- summary(est_ace, display = c(&quot;S&quot;, &quot;ace&quot;)) res_ace &lt;- cbind(resultados_ace$ace[,1:4], resultados_ace$S[,2:4]) res_ace &lt;- as.data.frame(res_ace) colnames(res_ace) &lt;- c(&quot;Amostras&quot;, &quot;ACE&quot;, &quot;ACE_inferior&quot;, &quot;ACE_superior&quot;, &quot;Riqueza&quot;, &quot;R_inferior&quot;, &quot;R_superior&quot;) # Gr√°fico. ggplot(res_ace, aes(y = Riqueza, x = Amostras)) + geom_point(aes(y = ACE, x = Amostras + 0.1), size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(aes(y = Riqueza, x = Amostras), size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_line (aes(y = ACE, x = Amostras), color = &quot;darkorange&quot;) + geom_line (aes(y = Riqueza, x = Amostras), color = &quot;cyan4&quot;) + geom_linerange(aes(ymin = ACE_inferior, ymax = ACE_superior, x = Amostras + 0.1), color = &quot;darkorange&quot;) + geom_linerange(aes(ymin = R_inferior, ymax = R_superior, x = Amostras), color = &quot;cyan4&quot;) + ylab (&quot;Riqueza estimada - ACE&quot;) + xlab (&quot;N√∫mero de amostras&quot;) + scale_x_continuous(limits = c(1,15), breaks=seq(1,15,1)) + geom_point(y= 7.5, x = 9, size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(y= 5.9, x = 9, size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_label( y = 7.5, x = 11.7, label = &quot;Riqueza estimada - ACE&quot;) + geom_label( y = 5.9, x = 11.3, label = &quot;Riqueza observada&quot;) + tema_livro() Interpreta√ß√£o dos resultados Com base no n√∫mero de esp√©cies raras (abund√¢ncia menor que 10 indiv√≠duos - default), o estimador ACE indica a possibilidade de encontrarmos mais sete esp√©cies caso o esfor√ßo amostral fosse maior e n√£o estimou tend√™ncia de estabiliza√ß√£o da curva em uma ass√≠ntota. 11.3 Estimadores baseados na incid√™ncia das esp√©cies 11.3.1 CHAO 2 - (A. Chao 1987): De acordo com Anne Chao, o estimador Chao 1 pode ser modificado para uso com dados de presen√ßa/aus√™ncia levando em conta a distribui√ß√£o das esp√©cies entre amostras. Neste caso √© necess√°rio somente conhecer o n√∫mero de esp√©cies encontradas em somente uma amostra e o n√∫mero de esp√©cies encontradas exatamente em duas amostras. Essa varia√ß√£o ficou denominada como Chao 2: \\[Chao_{2} = S_{obs} + \\left(\\frac{m-1}{m}\\right)\\left(\\frac{Q_1(Q_1-1)}{2(Q_2 + 1}\\right)\\] onde: Sobs = o n√∫mero de esp√©cies observada na comunidade, m = n√∫mero de amostras, Q1 = n√∫mero de esp√©cies observadas em uma amostra (esp√©cies uniques), Q2 = n√∫mero de esp√©cies observadas em duas amostras (esp√©cies duplicates). O valor de Chao2 √© m√°ximo quando as esp√©cies menos uma s√£o √∫nicas (uniques). Neste caso, a riqueza estimada √© aproximadamente o dobro da riqueza observada. Colwell &amp; Coddington (1994) encontraram que o valor de Chao 2 mostrou ser o estimador menos enviesado para amostras com tamanho pequeno. üìù Importante: Voc√™s ir√£o perceber que ao longo do cap√≠tulo as recomenda√ß√µes sobre qual √© o melhor √≠ndice varia entre estudos (e.g. Palmer 1990; Walther and Moore 2005). 11.3.1.1 Exemplo pr√°tico - Chao 2 Explica√ß√£o dos dados Usaremos os mesmos dados de 17 esp√©cies de anuros amostradas em 14 dias de coletas de campo em um habitat reprodutivo localizado na regi√£o noroeste do estado de S√£o Paulo, Brasil. An√°lise C√°lculo do estimador de riqueza - Chao 2. # An√°lise. est_chao2 &lt;- poolaccum(dados_coleta, permutations = 100) summary(est_chao2, display = &quot;chao&quot;) #&gt; $chao #&gt; N Chao 2.5% 97.5% Std.Dev #&gt; [1,] 3 14.31571 9.211111 24.35000 3.909186 #&gt; [2,] 4 15.12125 8.796875 26.50000 4.676977 #&gt; [3,] 5 17.18113 10.485000 34.12500 5.116710 #&gt; [4,] 6 18.40042 11.336806 34.50625 5.802968 #&gt; [5,] 7 20.06214 12.142857 34.00000 6.145670 #&gt; [6,] 8 21.28187 12.391927 38.11562 6.923969 #&gt; [7,] 9 22.60556 12.538889 36.82500 6.845149 #&gt; [8,] 10 25.94025 14.327500 42.20000 7.446691 #&gt; [9,] 11 27.58773 15.401136 39.27273 6.931535 #&gt; [10,] 12 29.55229 19.933333 39.45833 6.111500 #&gt; [11,] 13 31.51769 22.384615 39.61538 4.586452 #&gt; [12,] 14 33.71429 33.714286 33.71429 0.000000 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;summary.poolaccum&quot; Visualizar os resultados com intervalo de confian√ßa de 95%. # Preparando os dados para fazer o gr√°fico. resultados_chao2 &lt;- summary(est_chao2, display = c(&quot;S&quot;, &quot;chao&quot;)) res_chao2 &lt;- cbind(resultados_chao2$chao[,1:4], resultados_chao2$S[,2:4]) res_chao2 &lt;- as.data.frame(res_chao2) colnames(res_chao2) &lt;- c(&quot;Amostras&quot;, &quot;Chao2&quot;, &quot;C_inferior&quot;, &quot;C_superior&quot;, &quot;Riqueza&quot;, &quot;R_inferior&quot;, &quot;R_superior&quot;) # Gr√°fico ggplot(res_chao2, aes(y = Riqueza, x = Amostras)) + geom_point(aes(y = Chao2, x = Amostras + 0.1), size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(aes(y = Riqueza, x = Amostras), size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_line (aes(y = Chao2, x = Amostras), color = &quot;darkorange&quot;) + geom_line (aes(y = Riqueza, x = Amostras), color = &quot;cyan4&quot;) + geom_linerange(aes(ymin = C_inferior, ymax = C_superior, x = Amostras + 0.1), color = &quot;darkorange&quot;) + geom_linerange(aes(ymin = R_inferior, ymax = R_superior, x = Amostras), color = &quot;cyan4&quot;) + ylab (&quot;Riqueza estimada - Chao 2&quot;) + xlab (&quot;N√∫mero de amostras&quot;) + scale_x_continuous(limits = c(1,15), breaks=seq(1,15,1)) + geom_point(y= 9.8, x = 10, size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(y= 7.7, x = 10, size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_label( y = 9.8, x = 12.95, label = &quot;Riqueza estimada - Chao 2&quot;) + geom_label( y = 7.7, x = 12.3, label = &quot;Riqueza observada&quot;) + tema_livro() Interpreta√ß√£o dos resultados Com base no n√∫mero de esp√©cies raras (uniques e duplicates), Chao 2 estimou a possibilidade de encontrarmos mais dezesseis esp√©cies caso o esfor√ßo amostral fosse maior e n√£o estimou tend√™ncia de estabiliza√ß√£o da curva em uma ass√≠ntota. 11.3.2 JACKKNIFE 1 (Burnham and Overton 1978, 1979): Este estimador baseia-se no n√∫mero de esp√©cies que ocorrem em somente uma amostra (Q1). \\[S_{jack1} = S_{obs} + Q_1\\left(\\frac{m - 1}{m}\\right)\\] onde: Sobs = o n√∫mero de esp√©cies observadas na comunidade, Q1 = n√∫mero de esp√©cies observadas em uma amostra (esp√©cies uniques), m = n√∫mero de amostras. Jackknife √© um m√©todo de reamostragem (sem repeti√ß√£o) n√£o param√©trico usado para estimar a riqueza de esp√©cies e a vari√¢ncia associada com a estimativa. Para isso, o m√©todo: i) exclui uma amostra e contabiliza o valor da riqueza estimada usando a f√≥rmula acima; ii) repete este processo n vezes at√© que todas as amostras tenham sido exclu√≠das; e iii) estima a m√©dia e a vari√¢ncia da riqueza de esp√©cie (Smith and van Belle 1984). Palmer (1990) verificou que Jackknife 1 foi o estimador mais preciso e menos enviesado comparado a outros m√©todos de extrapola√ß√£o. 11.3.2.1 Exemplo pr√°tico - Jackknife 1 Explica√ß√£o dos dados Usaremos os mesmos dados de 17 esp√©cies de anuros amostradas em 14 dias de coletas de campo em um habitat reprodutivo localizado na regi√£o noroeste do estado de S√£o Paulo, Brasil. An√°lise C√°lculo do estimador de riqueza - Jackknife 1. # An√°lise. est_jack1 &lt;- poolaccum(dados_coleta, permutations = 100) summary(est_jack1, display = &quot;jack1&quot;) #&gt; $jack1 #&gt; N Jackknife 1 2.5% 97.5% Std.Dev #&gt; [1,] 3 13.64667 8.333333 19.17500 2.798035 #&gt; [2,] 4 14.75000 9.750000 20.01250 2.788188 #&gt; [3,] 5 15.32800 9.800000 20.42000 2.780091 #&gt; [4,] 6 16.01500 11.229167 21.96250 2.802425 #&gt; [5,] 7 17.07714 12.782143 22.93214 2.575868 #&gt; [6,] 8 18.11625 14.165625 23.12500 2.536306 #&gt; [7,] 9 18.77778 14.719444 23.22222 2.609373 #&gt; [8,] 10 19.56100 14.800000 23.77250 2.586909 #&gt; [9,] 11 20.42455 16.727273 23.36364 2.190412 #&gt; [10,] 12 21.16000 17.185417 23.41667 1.863867 #&gt; [11,] 13 21.92846 18.692308 23.46154 1.335047 #&gt; [12,] 14 22.57143 22.571429 22.57143 0.000000 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;summary.poolaccum&quot; Visualizar os resultados com 95% intervalo de confian√ßa. # Preparando os dados para fazer o gr√°fico. resultados_jack1 &lt;- summary(est_jack1, display = c(&quot;S&quot;, &quot;jack1&quot;)) res_jack1 &lt;- cbind(resultados_jack1$jack1[,1:4], resultados_jack1$S[,2:4]) res_jack1 &lt;- as.data.frame(res_jack1) colnames(res_jack1) &lt;- c(&quot;Amostras&quot;, &quot;JACK1&quot;, &quot;JACK1_inferior&quot;, &quot;JACK1_superior&quot;, &quot;Riqueza&quot;, &quot;R_inferior&quot;, &quot;R_superior&quot;) # Comando para o gr√°fico. ggplot(res_jack1, aes(y = Riqueza, x = Amostras)) + geom_point(aes(y = JACK1, x = Amostras + 0.1), size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(aes(y = Riqueza, x = Amostras), size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_line (aes(y = JACK1, x = Amostras), color = &quot;darkorange&quot;) + geom_line (aes(y = Riqueza, x = Amostras), color = &quot;cyan4&quot;) + geom_linerange(aes(ymin = JACK1_inferior, ymax = JACK1_superior, x = Amostras + 0.1), color = &quot;darkorange&quot;) + geom_linerange(aes(ymin = R_inferior, ymax = R_superior, x = Amostras), color = &quot;cyan4&quot;) + ylab (&quot;Riqueza estimada - Jackknife 1&quot;) + xlab (&quot;N√∫mero de amostras&quot;) + scale_x_continuous(limits = c(1,15), breaks=seq(1,15,1)) + geom_point(y= 9.9, x = 9, size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(y= 8.6, x = 9, size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_label( y = 9.9, x = 12.5, label = &quot;Riqueza estimada - Jackknife 1&quot;) + geom_label( y = 8.6, x = 11.5, label = &quot;Riqueza observada&quot;) + tema_livro() Interpreta√ß√£o dos resultados Com base no n√∫mero de esp√©cies raras, o estimador Jackknife 1 estimou possibilidade de encontrarmos mais seis esp√©cies caso o esfor√ßo amostral fosse maior e n√£o estimou tend√™ncia de estabiliza√ß√£o da curva em uma ass√≠ntota. 11.3.3 JACKKNIFE 2 (Burnham and Overton 1978, 1979; Palmer 1991): Este m√©todo baseia-se no n√∫mero de esp√©cies que ocorrem em apenas uma amostra e no n√∫mero de esp√©cies que ocorrem em exatamente duas amostras. \\[S_{jack2} = S_{obs} + \\left[\\frac{Q_1(2m - 3)}{m}-\\frac{Q_2(m - 2)^2}{m(m-1)}\\right]\\] onde: Sobs = o n√∫mero de esp√©cies observadas na comunidade, m = n√∫mero de amostras, Q1 = n√∫mero de esp√©cies observadas em uma amostra (esp√©cies uniques), Q2 = n√∫mero de esp√©cies observadas em duas amostras (esp√©cies duplicates). 11.3.3.1 Exemplo pr√°tico - Jackknife 2 Explica√ß√£o dos dados Usaremos os mesmos dados de 17 esp√©cies de anuros amostradas em 14 dias de coletas de campo em um habitat reprodutivo localizado na regi√£o noroeste do estado de S√£o Paulo, Brasil. An√°lise C√°lculo do estimador de riqueza - Jackknife 2. # An√°lise. est_jack2 &lt;- poolaccum(dados_coleta, permutations = 100) summary(est_jack2, display = &quot;jack2&quot;) #&gt; $jack2 #&gt; N Jackknife 2 2.5% 97.5% Std.Dev #&gt; [1,] 3 14.27667 7.904167 21.50000 3.750886 #&gt; [2,] 4 15.73500 8.566667 23.77292 4.127584 #&gt; [3,] 5 16.36650 9.150000 24.68625 4.262113 #&gt; [4,] 6 18.16900 10.631667 27.46667 4.274110 #&gt; [5,] 7 19.57786 12.339881 27.21250 3.875295 #&gt; [6,] 8 20.78679 14.133929 28.58527 3.778223 #&gt; [7,] 9 21.82028 13.972222 27.98611 3.960469 #&gt; [8,] 10 22.84444 14.977778 28.18889 3.770196 #&gt; [9,] 11 24.04227 17.445455 28.35455 3.123930 #&gt; [10,] 12 24.99455 20.242424 28.49242 2.618660 #&gt; [11,] 13 26.09481 21.301282 28.60897 1.953804 #&gt; [12,] 14 26.92308 26.923077 26.92308 0.000000 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;summary.poolaccum&quot; Visualizar os resultados com intervalo de confian√ßa de 95%. # Preparando os dados para fazer o gr√°fico. resultados_jack2 &lt;- summary(est_jack2, display = c(&quot;S&quot;, &quot;jack2&quot;)) res_jack2 &lt;- cbind(resultados_jack2$jack2[,1:4], resultados_jack2$S[,2:4]) res_jack2 &lt;- as.data.frame(res_jack2) colnames(res_jack2) &lt;- c(&quot;Amostras&quot;, &quot;JACK2&quot;, &quot;JACK2_inferior&quot;, &quot;JACK2_superior&quot;, &quot;Riqueza&quot;, &quot;R_inferior&quot;, &quot;R_superior&quot;) # Comando para o gr√°fico. ggplot(res_jack2, aes(y = Riqueza, x = Amostras)) + geom_point(aes(y = JACK2, x = Amostras + 0.1), size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(aes(y = Riqueza, x = Amostras), size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_line (aes(y = JACK2, x = Amostras), color = &quot;darkorange&quot;) + geom_line (aes(y = Riqueza, x = Amostras), color = &quot;cyan4&quot;) + geom_linerange(aes(ymin = JACK2_inferior, ymax = JACK2_superior, x = Amostras + 0.1), color = &quot;darkorange&quot;) + geom_linerange(aes(ymin = R_inferior, ymax = R_superior, x = Amostras), color = &quot;cyan4&quot;) + ylab (&quot;Riqueza estimada - Jackknife 2&quot;) + xlab (&quot;N√∫mero de amostras&quot;) + scale_x_continuous(limits = c(1,15), breaks=seq(1,15,1)) + geom_point(y= 9.9, x = 9, size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(y= 8.2, x = 9, size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_label( y = 9.9, x = 12.5, label = &quot;Riqueza estimada - Jackknife 2&quot;) + geom_label( y = 8.2, x = 11.5, label = &quot;Riqueza observada&quot;) + tema_livro() Interpreta√ß√£o dos resultados Com base no n√∫mero de esp√©cies raras, o estimador Jackknife 2 estimou a possibilidade de encontrarmos mais dez esp√©cies caso o esfor√ßo amostral fosse maior e n√£o estimou tend√™ncia estabiliza√ß√£o da curva em uma ass√≠ntota. 11.3.4 BOOTSTRAP (Smith and van Belle 1984): Este m√©todo difere dos demais por utilizar dados de todas as esp√©cies coletadas para estimar a riqueza total, n√£o se restringindo √†s esp√©cies raras. Ele requer somente dados de incid√™ncia. A estimativa pelo bootstrap √© calculada somando-se a riqueza observada √† soma do inverso da propor√ß√£o de amostras em que cada esp√©cie ocorre. \\[S_{boot} = S_{obs} + \\sum_{k=1}^{S_{obs}}(1-P_k)^m\\] onde: Sobs = o n√∫mero de esp√©cies observadas na comunidade, m = n√∫mero de amostragens, Pk = propor√ß√£o do n√∫mero de amostras em que cada esp√©cie foi registrada. Bootstrap √© um m√©todo n√£o param√©trico usado para estimar os par√¢metros de uma popula√ß√£o por reamostragem. A premissa √© que as reamostragens podem ser entendidas como pseudo-popula√ß√µes, com caracter√≠sticas similares as da popula√ß√£o original. Para isso, o m√©todo: i) seleciona ao acaso um conjunto de amostras (no nosso exemplo 14 amostras) com reposi√ß√£o; ii) repete este processo n vezes; e iii) estima a m√©dia e a vari√¢ncia da riqueza de esp√©cie (Smith and van Belle 1984). 11.3.4.1 Exemplo pr√°tico - Bootstrap Explica√ß√£o dos dados Usaremos os mesmos dados de 17 esp√©cies de anuros amostradas em 14 dias de coletas de campo em um habitat reprodutivo localizado na regi√£o noroeste do estado de S√£o Paulo, Brasil. An√°lise C√°lculo do estimador de riqueza - Bootstrap. # An√°lise. est_boot &lt;- poolaccum(dados_coleta, permutations = 100) summary(est_boot, display = &quot;boot&quot;) #&gt; $boot #&gt; N Bootstrap 2.5% 97.5% Std.Dev #&gt; [1,] 3 11.87407 8.425000 15.51852 2.011130 #&gt; [2,] 4 13.14934 9.771387 16.77627 2.001598 #&gt; [3,] 5 13.83898 10.822584 17.43899 1.964793 #&gt; [4,] 6 14.66163 10.705144 18.37757 1.977243 #&gt; [5,] 7 15.47596 11.981076 18.68644 1.879223 #&gt; [6,] 8 16.18653 12.599602 19.68927 1.830489 #&gt; [7,] 9 16.61378 13.042764 19.61772 1.779771 #&gt; [8,] 10 17.19346 13.077245 19.70960 1.788670 #&gt; [9,] 11 17.82230 14.315556 19.81162 1.558281 #&gt; [10,] 12 18.35152 15.374464 19.58721 1.270158 #&gt; [11,] 13 18.75381 16.570376 19.59107 1.027014 #&gt; [12,] 14 19.27832 19.278321 19.27832 0.000000 #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;summary.poolaccum&quot; Visualizar os resultados com intervalo de confian√ßa de 95%. # Preparando os dados para fazer o gr√°fico. resultados_boot &lt;- summary(est_boot, display = c(&quot;S&quot;, &quot;boot&quot;)) res_boot &lt;- cbind(resultados_boot$boot[,1:4], resultados_boot$S[,2:4]) res_boot &lt;- as.data.frame(res_boot) colnames(res_boot) &lt;- c(&quot;Amostras&quot;, &quot;BOOT&quot;, &quot;BOOT_inferior&quot;, &quot;BOOT_superior&quot;, &quot;Riqueza&quot;, &quot;R_inferior&quot;, &quot;R_superior&quot;) # Gr√°fico. ggplot(res_boot, aes(y = Riqueza, x = Amostras)) + geom_point(aes(y = BOOT, x = Amostras + 0.1), size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(aes(y = Riqueza, x = Amostras), size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_line (aes(y = BOOT, x = Amostras), color = &quot;darkorange&quot;) + geom_line (aes(y = Riqueza, x = Amostras), color = &quot;cyan4&quot;) + geom_linerange(aes(ymin = BOOT_inferior, ymax = BOOT_superior, x = Amostras + 0.1), color = &quot;darkorange&quot;) + geom_linerange(aes(ymin = R_inferior, ymax = R_superior, x = Amostras), color = &quot;cyan4&quot;) + ylab (&quot;Riqueza estimada - Bootstrap&quot;) + xlab (&quot;N√∫mero de amostras&quot;) + scale_x_continuous(limits = c(1,15), breaks=seq(1,15,1)) + geom_point(y= 10.4, x = 9, size = 4, color = &quot;darkorange&quot;, alpha = 0.7) + geom_point(y= 9.3, x = 9, size = 4, color = &quot;cyan4&quot;, alpha = 0.7) + geom_label( y = 10.4, x = 12.3, label = &quot;Riqueza estimada - Bootstrap&quot;) + geom_label( y = 9.3, x = 11.5, label = &quot;Riqueza observada&quot;) + tema_livro() Interpreta√ß√£o dos resultados Com base na frequ√™ncia de ocorr√™ncia das esp√©cies, o estimador bootstrap estimou a possibilidade de encontrarmos mais duas esp√©cies caso o esfor√ßo amostral fosse maior e n√£o estimou tend√™ncia de estabiliza√ß√£o da curva em uma ass√≠ntota. 11.3.5 Interpola√ß√£o e Extrapola√ß√£o baseadas em rarefa√ß√£o usando amostragens de incid√™ncia ou abund√¢ncia (Anne Chao and Jost 2012; Colwell et al. 2012): Este m√©todo utiliza teoria de amostragem (e.g.¬†modelos multinomial, Poisson e Bernoulli) para conectar rarefa√ß√£o (interpola√ß√£o) e predi√ß√£o (extrapola√ß√£o) com base no tamanho da amostra. Este m√©todo utiliza uma abordagem com bootstrap para calcular o intervalo de confian√ßa de 95%. üìù Importante: A extrapola√ß√£o torna-se altamente incerta quando estendida para o dobro ou mais do tamanho da amostragem. 11.3.5.1 Exemplo pr√°tico 1 Explica√ß√£o dos dados Usaremos os mesmos dados de 17 esp√©cies de anuros amostradas em 14 dias de coletas de campo em um habitat reprodutivo localizado na regi√£o noroeste do estado de S√£o Paulo, Brasil. An√°lise C√°lculo da extrapola√ß√£o da riqueza com base no n√∫mero de indiv√≠duos. # Preparando os dados para an√°lises considerando a abund√¢ncia. dados_inext_abu &lt;- colSums(dados_coleta) resultados_abundancia &lt;- iNEXT(dados_inext_abu, q = 0, datatype = &quot;abundance&quot;, endpoint = 600) # Visualizar os dados no gr√°fico. anuros_ab &lt;- ggiNEXT(resultados_abundancia, type = 1) anuros_ab + labs(x = &quot;N√∫mero de indiv√≠duos&quot;, y = &quot; Riqueza de esp√©cies&quot;) + scale_linetype_discrete(labels = c(&quot;Interpolado&quot;, &quot;Extrapolado&quot;)) + scale_colour_manual(values = &quot;darkorange&quot;) + scale_fill_manual(values = &quot;darkorange&quot;) + tema_livro() Interpreta√ß√£o dos resultados Veja que o ponto no final da linha cont√≠nua representa as 17 esp√©cies de anuros (eixo Y) observadas entre os 304 individuos (eixo X). A extrapola√ß√£o m√°xima (600 indiv√≠duos no nosso exemplo), estima um aumento de at√© oito esp√©cies (intervalo de confian√ßa) caso amostr√°ssemos mais 296 indiv√≠duos. C√°lculo da extrapola√ß√£o da riqueza com base no n√∫mero de amostras. # Preparando os dados para an√°lises considerando a incid√™ncia. # Precisa transpor o dataframe. dados_inext &lt;- as.incfreq(t(dados_coleta)) resultados_incidencia &lt;- iNEXT(dados_inext, q = 0, datatype = &quot;incidence_freq&quot;, endpoint = 28) # Visualizar os dados no gr√°fico. anuros_IC &lt;- ggiNEXT(resultados_incidencia, type = 1) anuros_IC + labs(x = &quot;N√∫mero de amostras&quot;, y = &quot; Riqueza de esp√©cies&quot;) + scale_linetype_discrete(labels = c(&quot;Interpolado&quot;, &quot;Extrapolado&quot;)) + scale_colour_manual(values = &quot;darkorange&quot;) + scale_fill_manual(values = &quot;darkorange&quot;) + tema_livro() Interpreta√ß√£o dos resultados Veja que o ponto no final da linha cont√≠nua representa as 17 esp√©cies de anuros (eixo Y) observadas nos 14 dias de coleta (eixo X - amostras). A extrapola√ß√£o m√°xima (28 dias de coleta no nosso exemplo), estima um aumento de at√© 12 esp√©cies (intervalo de confian√ßa) caso amostr√°ssemos mais 14 dias. 11.3.5.2 Exemplo pr√°tico 2 Explica√ß√£o dos dados Neste exemplo, iremos refazer o exemplo do @[Cap8] que usa Generalized Least Squares (GLS) para testar a rela√ß√£o da riqueza de √°caros com a quantidade de √°gua no substrato. Contudo, ao inv√©s de considerar a riqueza de esp√©cies de √°caros observada como vari√°vel resposta, iremos utilizar a riqueza extrapolada. Os dados que usaremos est√£o dispon√≠veis no pacote vegan e representa a composi√ß√£o de esp√©cies de √°caros amostradas em 70 comunidades/amostras. Pergunta: A riqueza extrapolada de esp√©cies de √°caros √© maior em comunidades localizadas em √°reas com substratos secos? Predi√ß√µes O n√∫mero de esp√©cies extrapolada ser√° maior em substratos secos uma vez que as limita√ß√µes fisiol√≥gicas impostas pela umidade limitam a ocorr√™ncia de v√°rias esp√©cies de √°caros. Vari√°veis Vari√°veis resposta e preditoras matriz ou dataframe com as abund√¢ncias das esp√©cies de √°caros (vari√°vel resposta) registradas em 70 comunidades/amostras (vari√°vel preditora). Checklist Verificar se a sua matriz ou dataframe est√£o com as esp√©cies nas linhas e as comunidades nas colunas. An√°lise Vamos iniciar calculando a riqueza extrapolada com base na comunidade com maior abund√¢ncia. # Os dados est√£o com as comunidades nas colunas e as esp√©cies nas linhas. # Para as an√°lises teremos que transpor a planilha. composicao_acaros &lt;- t(mite) # A comunidade com maior abund√¢ncia tem 781 indiv√≠duos. max(colSums(composicao_acaros)) #&gt; [1] 781 # Calcular a riqueza extrapolada de esp√©cies para todas as comunidades # considerando a maior abund√¢ncia. resultados_extrapolacao &lt;- iNEXT(composicao_acaros, q = 0, datatype = &quot;abundance&quot;, endpoint = 781) Vamos criar umloop para extrair a riqueza extrapolada para as 70 comunidades. # Criando um data.frame vazio para salvar os dados resultados_comunidades_ext &lt;- data.frame() # Criando um vetor vazio para salvar os resultados riqueza_extrapolada &lt;- c() # Loop repetindo as an√°lises para as 70 comunidades # O objetivo √© extrair a riqueza estimada extrapolada para 781 individuos for (i in 1:70){ resultados_comunidades_ext &lt;- data.frame(resultados_extrapolacao$iNextEst[i]) riqueza_extrapolada[i] &lt;- resultados_comunidades_ext[40,4] } Agora, seguindo os passos descritos no @[Cap8], vamos identificar o melhor modelo que representa a estrutura espacial dos dados extrapolados. # Criando data frame com todas as vari√°veis dados_combinado_ext &lt;- data.frame(riqueza_extrapolada, agua, coord) # Modelo gls sem estrutura espacial. no_spat_gls &lt;- gls(riqueza_extrapolada ~ agua, data = dados_combinado_ext, method = &quot;REML&quot;) # Covari√¢ncia esf√©rica. espher_model &lt;- gls(riqueza_extrapolada ~ agua, data = dados_combinado_ext, corSpher(form = ~lat + long, nugget = TRUE)) # Covari√¢ncia exponencial (corExp(form=~lat+long)). expon_model &lt;- gls(riqueza_extrapolada ~ agua, data = dados_combinado_ext, corExp(form = ~lat + long, nugget = TRUE)) # Covari√¢ncia Gaussiana (corGaus(form=~lat+long)). gauss_model &lt;- gls(riqueza_extrapolada ~ agua, data = dados_combinado_ext, corGaus(form = ~lat + long, nugget = TRUE)) # Covari√¢ncia linear (corLin(form=~lat+long). cor_linear_model &lt;- gls(riqueza_extrapolada ~ agua, data = dados_combinado_ext, corLin(form = ~lat + long, nugget = TRUE)) # Covari√¢ncia raz√£o quadr√°tica (corRatio(form=~lat+long)). ratio_model &lt;- gls(riqueza_extrapolada ~ agua, data = dados_combinado_ext, corRatio(form = ~lat + long, nugget = TRUE)) Vamos usar o AIC para selecionar o modelo mais ‚Äúprov√°vel‚Äù explicando a distribui√ß√£o da riqueza extrapolada das esp√©cies de √°caros. # Sele√ß√£o dos modelos. aic_fit_ext &lt;- AIC(no_spat_gls, espher_model, cor_linear_model, expon_model, gauss_model, ratio_model) aic_fit_ext %&gt;% arrange(AIC) #&gt; df AIC #&gt; 1 5 467.9349 #&gt; 2 3 469.3103 #&gt; 3 5 473.2373 #&gt; 4 5 473.2815 #&gt; 5 5 473.3086 #&gt; 6 5 473.3103 # Visualizando os res√≠duos do modelo com menor valor de AIC (veja Cap√≠tulo 8). plot(ratio_model) De forma geral, a distribui√ß√£o dos res√≠duos est√° adequada com apenas dois pontos fugindo da nuvem. Contudo, eles podem influenciar os resultados (veja abaixo). # Visualizando os resultados e calculando pseudo-R-squared. summary(ratio_model)$tTable #&gt; Value Std.Error t-value p-value #&gt; (Intercept) 24.09577588 4.816461582 5.002796 4.227862e-06 #&gt; agua -0.01181425 0.006977381 -1.693221 9.499017e-02 rsquared(ratio_model) #&gt; Response family link method R.squared #&gt; 1 riqueza_extrapolada gaussian identity none 0.05977552 # Gr√°fico. predito_ext &lt;- predict(ratio_model) ggplot(data = dados_combinado_ext, aes(x= agua, y= riqueza_extrapolada)) + labs(x = &quot;Concentra√ß√£o de √°gua no substrato&quot;, y = &quot;Riqueza extrapolada \\ndas esp√©cies de √°caros&quot;, size = 15) + geom_point(size = 4, shape = 21, fill = &quot;darkorange&quot;, alpha = 0.7) + geom_line(aes(y = predito_ext), size = 1) + tema_livro() Interpreta√ß√£o dos resultados A riqueza extrapolada das esp√©cies de √°caros foi maior em comunidades localizadas em √°reas com substratos secos do que em √°reas com substratos √∫midos. Contudo, apesar do modelo apresentar um rela√ß√£o significativa entre as vari√°veis, a concentra√ß√£o de √°gua explica apenas 5,9% da varia√ß√£o da riqueza extrapolada das esp√©cies de √°caros. O padr√£o observado, valor de P &lt; 0.05 e o baixo valor de R2, provavelmente est√° relacionado com as duas comunidades com altos valores de riqueza extapolada (e.g.¬†outilers). Refa√ßa as an√°lises sem os dois pontos e vejam o padr√£o dos novos resultados. 11.3.6 Para se aprofundar Recomendamos aos interessados que olhem a p√°gina do EstimateS software e baixem o manual do usu√°rio que cont√©m informa√ß√µes detalhadas sobre os √≠ndices de rarefa√ß√£o e estimadores de riqueza. Este site foi criado e √© mantido pelo Dr.¬†Robert K. Colwell, um dos maiores especialistas do mundo em estimativas da biodiversidade Recomendamos tamb√©m o livro Biological Diversity Frontiers in Measurement and Assessment (Magurran and McGill 2011). Refer√™ncias "],["cap12.html", "Cap√≠tulo 12 Diversidade Taxon√¥mica 12.1 Aspectos te√≥ricos 12.2 Diversidade alfa 12.3 Diversidade de esp√©cies 12.4 Diagramas de Whittaker ou Curva de Domin√¢ncia 12.5 Curvas de distribui√ß√£o de abund√¢ncias 12.6 N√∫meros de Hill ou S√©rie de Hill 12.7 Diversidade beta", " Cap√≠tulo 12 Diversidade Taxon√¥mica Pr√©-requisitos do cap√≠tulo ## Pacotes library(devtools) # install_github(&quot;paternogbc/ecodados&quot;) # para instalar o ecodados library(ecodados) library (vegan) library(ggplot2) library(BiodiversityR) library(hillR) library(betapart) ## Dados necess√°rios composicao_especies &lt;- ecodados::composicao_anuros_div_taxonomica precipitacao &lt;- ecodados::precipitacao_div_taxonomica 12.1 Aspectos te√≥ricos A diversidade biol√≥gica √© um conceito multifacetado que pode ser definido e analisado de diferentes maneiras (e.g.¬†diversidade gen√©tica, taxon√¥mica, funcional, filogen√©tica, ecossist√™mica, etc.)(Magurran and McGill 2011; N. J. Gotelli and Chao 2013). Whittaker (1960, 1972) particionou a diversidade em tr√™s componentes: i) diversidade alfa que √© caracterizada pela diversidade dentro do habitat ou unidade amostral; ii) diversidade beta que √© caracterizada pela varia√ß√£o na diversidade entre habitats ou unidades amostrais; e iii) diversidade gama que √© caracterizada pela combina√ß√£o da diversidade alfa e beta ou definida como a diversidade regional englobando todos os habitats ou unidades amostrais. Portanto, n√£o existe um m√©todo que quantifique todos os par√¢metros associados √† diversidade biol√≥gica. Consequentemente, a escolha da m√©trica de diversidade depender√° i) do objetivo do estudo; e ii) das informa√ß√µes dispon√≠veis para o pesquisador. Neste cap√≠tulo, iremos abordar a diversidade taxon√¥mica que ignora a rela√ß√£o de parentesco entre as esp√©cies (e.g.¬†diversidade filogen√©tica - @ref[cap13]) e as diferentes fun√ß√µes que as esp√©cies realizam no ecossistema (e.g.¬†diversidade funcional - @ref[cap14]). Na diversidade taxon√¥mica, pesquisadores est√£o interessados na riqueza de esp√©cies (e.g.¬†n√∫mero de esp√©cies), na distribui√ß√£o de abund√¢ncia das esp√©cies (e.g.¬†fato que algumas esp√©cies s√£o comuns e outras raras) e/ou diversidade de esp√©cies (e.g.¬†√≠ndices que descrevem a rela√ß√£o entre a riqueza e a distribui√ß√£o da abund√¢ncia relativa das esp√©cies) nas localidades. 12.2 Diversidade alfa 12.2.1 Riqueza de esp√©cies ou n√∫mero de esp√©cies Riqueza de esp√©cies √© uma m√©trica intuitiva e de f√°cil compreens√£o, uma vez que se refere ao n√∫mero de esp√©cies observadas em uma localidade. √â importante ter em mente que a riqueza de esp√©cies √© influenciada pelo esfor√ßo amostral e sua estimativa real √© um imenso desafio (Magurran and McGill 2011). Compara√ß√µes entre comunidades com diferen√ßas no n√∫mero de amostragens ou abund√¢ncia das esp√©cies devem ser realizadas por meio de rarefa√ß√µes (veja @ref[cap10]), enquanto que o n√∫mero de esp√©cies n√£o detectadas pode ser estimado pelos estimadores de riqueza (veja @ref[cap11]). Embora raramente usados como alternativa a rarefa√ß√£o, existem alguns √≠ndices que calculam a riqueza de esp√©cies ponderando a abund√¢ncia total (i.e.¬†tamanho da amostra) dentro de cada comunidade. Esses √≠ndices s√£o: √çndice de Margalef \\[D_{Mg} = \\frac{S-1}{ln (N)}\\] onde: S = o n√∫mero de esp√©cies na comunidade; ln = logaritmo natural; N = n√∫mero total de indiv√≠duos na comunidade; DMg n√£o tem um valor m√°ximo e sua interpreta√ß√£o √© comparativa, com valores maiores indicando maior riqueza de esp√©cies. e √çndice de Menhinick \\[D_{Mn} = \\frac{S}{\\sqrt{N}}\\] onde: S = o n√∫mero de esp√©cies na comunidade; N = n√∫mero total de indiv√≠duos na comunidade; DMn n√£o tem um valor m√°ximo e sua interpreta√ß√£o √© comparativa, com valores maiores indicando maior riqueza de esp√©cies. 12.2.1.1 Exemplo pr√°tico 1 - Riqueza de esp√©cies Explica√ß√£o dos dados Neste exemplo, avaliaremos a riqueza de esp√©cies de 10 comunidades. Os dados de ocorr√™ncia das esp√©cies nas comunidades foram simulados para demonstrar as propriedades das m√©tricas de diversidade taxon√¥micas. Utilizaremos este conjunto de dados para todos os exemplos deste cap√≠tulo. Pergunta: A varia√ß√£o espacial na riqueza de esp√©cies nas comunidades est√° associada com a varia√ß√£o na precipita√ß√£o? Predi√ß√µes Os valores de riqueza de esp√©cies ser√£o maiores nas comunidades localizadas em regi√µes que recebem grande volume de precipita√ß√£o do que em regi√µes mais secas. Vari√°veis Vari√°veis resposta e preditoras Dataframe com as comunidades (unidade amostral) nas linhas e as esp√©cies (vari√°vel resposta) nas colunas. Dataframe com as comunidades (unidade amostral) nas linhas e precipita√ß√£o anual (vari√°vel preditora) na coluna. Checklist Verificar se os dataframes de composi√ß√£o de esp√©cies e vari√°veis ambientais est√£o com as unidades amostrais nas linhas e vari√°veis preditores nas colunas. Verificar se as comunidades nos dataframes de composi√ß√£o de esp√©cies e vari√°veis ambientais est√£o distribu√≠dos na mesma sequ√™ncia/ordem nos dois arquivos. Abaixo demonstramos os c√≥digos no R para determinar a riqueza de esp√©cies para cada comunidade a partir da planilha de composi√ß√£o de esp√©cies. Os dados est√£o dispon√≠veis no pacote ecodados. # Ver os dados das comunidades head(composicao_especies) #&gt; sp1 sp2 sp3 sp4 sp5 sp6 sp7 sp8 sp9 sp10 #&gt; Com_1 10 10 10 10 10 10 10 10 10 10 #&gt; Com_2 91 1 1 1 1 1 1 1 1 1 #&gt; Com_3 1 3 6 25 1 0 0 0 0 0 #&gt; Com_4 0 0 0 0 0 15 15 18 17 16 #&gt; Com_5 0 9 0 6 0 11 0 2 12 0 #&gt; Com_6 3 0 5 0 12 1 0 13 12 0 Vamos ver a riqueza de esp√©cies para cada comunidade. # Calculando a riqueza observada de esp√©cies para cada comunidade. (riqueza_sp &lt;- specnumber(composicao_especies)) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 Com_10 #&gt; 10 10 5 5 5 6 2 4 6 4 Vamos ver a abund√¢ncia total de cada comunidade. # Calculamos a abund√¢ncia total para cada comunidade. (abundancia &lt;- apply(composicao_especies, 1, sum)) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 Com_10 #&gt; 100 100 36 81 40 46 4 20 15 11 Calculando o √çndice de Margalef. # A fun√ß√£o round √© para limitar o resultado para duas casas decimais. (Margalef &lt;- round((riqueza_sp-1)/log(abundancia), 2)) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 Com_10 #&gt; 1.95 1.95 1.12 0.91 1.08 1.31 0.72 1.00 1.85 1.25 Calculando o √çndice de Menhinick. (Menhinick &lt;- round(riqueza_sp/sqrt(abundancia), 2)) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 Com_10 #&gt; 1.00 1.00 0.83 0.56 0.79 0.88 1.00 0.89 1.55 1.21 Agora vamos analisar a rela√ß√£o entre a riqueza de esp√©cies e a precipita√ß√£o anual. # Juntando todos os dados em um √∫nico dataframe. dados &lt;- data.frame(precipitacao$prec, riqueza_sp, Margalef, Menhinick) # Renomenado as colunas colnames(dados) &lt;- c(&quot;Precipitacao&quot;, &quot;Riqueza&quot;, &quot;Margalef&quot;, &quot;Menhinick&quot;) # Riqueza de esp√©cies e precipita√ß√£o anova(lm(dados$Riqueza ~ dados$Precipitacao)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados$Riqueza #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados$Precipitacao 1 30.622 30.6224 8.9156 0.01744 * #&gt; Residuals 8 27.478 3.4347 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 H√° uma rela√ß√£o positiva entre a riqueza de esp√©cies e a precipita√ß√£o anual (F1,8 = 8,91, P = 0,01). Rela√ß√£o entre o √çndice de Margalef e a precipita√ß√£o anual. anova(lm(dados$Margalef ~ dados$Precipitacao)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados$Margalef #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados$Precipitacao 1 0.37865 0.37865 2.1201 0.1835 #&gt; Residuals 8 1.42879 0.17860 N√£o h√° uma rela√ß√£o positiva entre o √≠ndice de Margalef e a precipita√ß√£o anual (F1,8 = 2,12, P = 0,18). Agora vamos analisar a rela√ß√£o entre a riqueza de esp√©cies e a precipita√ß√£o anual. anova(lm(dados$Menhinick ~ dados$Precipitacao)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados$Menhinick #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados$Precipitacao 1 0.07626 0.076262 1.0992 0.3251 #&gt; Residuals 8 0.55503 0.069378 N√£o h√° uma rela√ß√£o positiva entre o √≠ndice de Menhinick e a precipita√ß√£o anual (F1,8 = 1,09, P = 0,32). Vamos plotar o gr√°fico com os resultados da riqueza de esp√©cies ao longo do gradiente de precipita√ß√£o anual. ggplot(data = dados, aes(x= Precipitacao, y= Riqueza)) + labs(x = &quot;Precipita√ß√£o anual (mm)&quot;, y = &quot;Riqueza de esp√©cies&quot;) + geom_point(size = 4, shape = 21, fill = &quot;darkorange&quot;, alpha = 0.7) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) Interpreta√ß√£o dos resultados Percebam que ponderar a riqueza de esp√©cies pela abund√¢ncia altera a interpreta√ß√£o dos resultados. O n√∫mero de esp√©cies √© maior em comunidades com maior precipita√ß√£o. Contudo, quando poderamos pela abund√¢ncia (√≠ndices de Margalef ou Menhinick), a rela√ß√£o com a precipita√ß√£o n√£o √© significativa. 12.3 Diversidade de esp√©cies Diferente dos √≠ndices de riqueza de esp√©cies que n√£o levam em considera√ß√£o a abund√¢ncia relativa das esp√©cies (i.e.¬†todas as esp√©cies tem o mesmo peso), os √≠ndices de diversidade avaliam al√©m da riqueza, a domin√¢ncia ou raridade das esp√©cies nas comunidades. Assim, quando comparamos duas comunidades com a mesma riqueza de esp√©cies, e uma das comunidades √© dominada por uma √∫nica esp√©cie e a outra comunidade apresenta esp√©cies com abund√¢ncias parecidas, consideramos a segunda comunidade mais diversa. Os √≠ndices de diversidade variam porque eles d√£o pesos diferentes para a riqueza e equitabilidade das esp√©cies. Assim, um determinado √≠ndice de diversidade pode indicar que uma comunidade X √© mais diversa que Y, enquanto outro √≠ndice indica o oposto (Melo 2008). Portanto, uma maneira de determinar qual √≠ndice de diversidade usar √© saber se voc√™ quer dar maior peso para riqueza ou equitabilidade das esp√©cies nas comunidades. üìù Importante: Ressaltamos que h√° v√°rias cr√≠ticas em rela√ß√£o ao uso dos √≠ndices de diversidade que s√£o abstratos e dif√≠ceis de se interpretar (Hurlbert 1971). Por exemplo, dizer que o valor X estimado por √≠ndices de diversidade √© alto ou baixo √© irrelevante se n√£o tivermos uma base comparativa (para mais detalhes veja Melo 2008). Os dois √≠ndices de diversidade mais usados na ecologia s√£o: √çndice de Shannon-Wiener - quantifica a incerteza associada em predizer a identidade de uma esp√©cie dado o n√∫mero de esp√©cies e a distribui√ß√£o de abund√¢ncia para cada esp√©cie. Este √≠ndice √© mais sens√≠vel a mudan√ßas nas esp√©cies raras da comunidade. \\[H&#39; = -\\sum_{i=1}^{S}p_i * ln p_i\\] onde: pi = abund√¢ncia relativa de cada esp√©cie, calculada pela propor√ß√£o dos indiv√≠duos de uma esp√©cie pelo n√∫mero total dos indiv√≠duos na comunidade; ln = logaritmo natural, mas outras bases logar√≠tmas podem ser utilizadas; H‚Äô n√£o tem um valor m√°ximo e sua interpreta√ß√£o √© comparativa, com valores maiores indicando maior diversidade. e √çndice de Simpson - quantifica a probabilidade de dois indiv√≠duos retirados ao acaso da comunidade pertencerem a mesma esp√©cie. Este √≠ndice √© na verdade uma medida de domin√¢ncia. Assim, como a probabilidade dos indiv√≠duos serem da mesma esp√©cie diminui com o aumento da riqueza de esp√©cies, o √≠ndice de Simpson tamb√©m diminui com a riqueza. \\[D = \\sum_{i=1}^{S}p_i^2\\] onde: Pi = abund√¢ncia relativa de cada esp√©cie, calculada pela propor√ß√£o dos indiv√≠duos de uma esp√©cie pelo n√∫mero total dos indiv√≠duos na comunidade. D varia de 0 a 1 com valores pr√≥ximos de 1 indicando menor diversidade enquanto valores pr√≥ximos de 0 indicam maior diversidade. Para evitar confus√£o nas interpreta√ß√µes, normalmente o √≠ndice de Simpson √© expressado como o valor inverso (1 - D) para que os maiores valores representem maior diversidade. Neste caso, o valor inverso √© conhecido na literatura como √≠ndice Gini-Simpson. Para o √≠ndice Gini-Simpson estamos avaliando a probabilidade de dois indiv√≠duos retirados ao acaso da comunidade sejam de esp√©cies diferentes. 12.3.0.1 Exemplo pr√°tico 2 - Diversidade de esp√©cies Explica√ß√£o dos dados Usaremos os mesmos dados simulados do exemplo pr√°tico 1. Pergunta: A varia√ß√£o espacial na diversidade de esp√©cies das comunidades est√° associado com o gradiente de precipita√ß√£o? Predi√ß√µes Os valores de diversidade de esp√©cies ser√£o maiores nas comunidades localizadas em regi√µes maior volume de precipita√ß√£o do que em regi√µes mais secas. Abaixo demonstramos os comandos no R para determinar a diversidade de esp√©cies para cada comunidade a partir da planilha de composi√ß√£o de esp√©cies. # MARGIN = 1 significa que a fun√ß√£o ir√° calcular o √≠ndice considerando # as linhas do data.frame (comunidades). shannon_res &lt;- diversity(composicao_especies, index = &quot;shannon&quot;, MARGIN = 1) shannon_res #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 #&gt; 2.3025851 0.5002880 0.9580109 1.6068659 1.4861894 1.5607038 0.6931472 1.1058899 1.7140875 #&gt; Com_10 #&gt; 1.2636544 O argumento index = \"simpson\", calcula o √≠ndice Gini-Simpson (1-D). simpson_res &lt;- diversity(composicao_especies, index = &quot;simpson&quot;, MARGIN = 1) simpson_res #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 #&gt; 0.9000000 0.1710000 0.4814815 0.7989636 0.7587500 0.7674858 0.5000000 0.5850000 0.8088889 #&gt; Com_10 #&gt; 0.6942149 Interpreta√ß√£o dos resultados A comunidade 1 foi a comunidade que apresentou a maior diversidade de esp√©cies, enquanto a comunidade 2 foi a comunidade que apresentou a menor diversidade. Gostar√≠amos de chamar a aten√ß√£o para a import√¢ncia da distribui√ß√£o da abund√¢ncia relativa das esp√©cies dentro das comunidades. Percebam que tanto a comunidade 1 quanto a comunidade 2 abrigam o mesmo n√∫mero de esp√©cies (10 esp√©cies) e abund√¢ncia total (100 indiv√≠duos), mas o padr√£o de distribui√ß√£o da abund√¢ncia relativa entre as esp√©cies dentro das comunidades s√£o bem discrepantes. Na comunidade 1 as esp√©cies apresentam abund√¢ncias semelhantes entre elas (i.e.¬†alta equitabilidade), enquanto que na comunidade 2 uma esp√©cie √© dominante e as outras raras (i.e.¬†baixa equitabilidade). Essa diferen√ßa na distribui√ß√£o da abund√¢ncia relativa entre as comunidades √© um fator muito importante para os √≠ndices de diversidade. Dentro desta perspectiva, alguns √≠ndices fornecem uma estimativa sobre a equitabilidade da distribui√ß√£o da abund√¢ncia nas comunidades. Entre eles, o mais conhecido foi proposto por Pielou (1966): √çndice de Equabilidade (ou Equitabilidade) de Pielou √© uma m√©trica derivada do √≠ndice de Shannon-Wiener que descreve o padr√£o de distribui√ß√£o da abund√¢ncia relativa das esp√©cies na comunidade. \\[J = \\frac{H&#39;}{Hmax} = \\frac{H&#39;}{ln (S)}\\] onde: H‚Äô = √≠ndice de Shannon-Wiener; Hmax = todas as esp√©cies teriam a mesma abund√¢ncia relativa. Hmax √© calculado aplicando o logaritmo natural (ln) para a riqueza de esp√©cies (S); Se todas as esp√©cies apresentam a mesma abund√¢ncia relativa, ent√£o J = 1. Se uma esp√©cie apresenta forte domin√¢ncia, J aproxima-se de zero. N√£o h√° uma fun√ß√£o no R que calcule o √≠ndice de Pielou, mas ele pode facilmente ser calculado usando os valores de diversidade de Shannon e o logaritmo da riqueza de esp√©cies de cada comunidade (Pielou &lt;- shannon_res/log(specnumber(composicao_especies))) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 #&gt; 1.0000000 0.2172723 0.5952456 0.9984019 0.9234214 0.8710454 1.0000000 0.7977309 0.9566505 #&gt; Com_10 #&gt; 0.9115340 Agora que temos uma ideia de como a riqueza de esp√©cies e a distribui√ß√£o da abund√¢ncia relativa s√£o importantes para quantificar os valores dos √≠ndices de diversidade, vamos testar se h√° rela√ß√£o entre os √≠ndices de diversidade e precipita√ß√£o anual nas comunidades. # Juntando todos os dados em um √∫nico dataframe. dados_div &lt;- data.frame(precipitacao$prec, shannon_res, simpson_res, Pielou) # Renomeando as colunas colnames(dados_div) &lt;- c(&quot;Precipitacao&quot;, &quot;Shannon&quot;, &quot;Simpson&quot;, &quot;Pielou&quot;) Regress√£o simples para verificar a rela√ß√£o entre o √≠ndice de Shannon-Wiener e a precipita√ß√£o anual nas comunidades. anova(lm(dados_div$Shannon ~ dados_div$Precipitacao)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_div$Shannon #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_div$Precipitacao 1 0.10989 0.10989 0.3627 0.5637 #&gt; Residuals 8 2.42366 0.30296 Regress√£o simples para verificar a rela√ß√£o entre o √≠ndice de Simpson e a precipita√ß√£o anual nas comunidades. anova(lm(dados_div$Simpson ~ dados_div$Precipitacao)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_div$Simpson #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_div$Precipitacao 1 0.00132 0.001325 0.0252 0.8778 #&gt; Residuals 8 0.42064 0.052580 Regress√£o simples para verificar a rela√ß√£o entre o √≠ndice de Pielou e a precipita√ß√£o anual nas comunidades. anova(lm(dados_div$Pielou ~ dados_div$Precipitacao)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_div$Pielou #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_div$Precipitacao 1 0.09080 0.090798 1.5792 0.2443 #&gt; Residuals 8 0.45997 0.057496 üìù Importante: As an√°lises acima s√£o apenas ilustrativas. N√£o estamos avaliando as premissas de normalidade e homogeneidade da vari√¢ncia dos res√≠duos (veja @ref[cap7]). Interpreta√ß√£o dos resultados A varia√ß√£o espacial na diversidade de esp√©cies, obtida atrav√©s dos √≠ndices de Shannon-Wiener e Simpson, e a equitabilidade de Pielou n√£o foram associados com a varia√ß√£o na precipita√ß√£o anual entre as √°reas (P &gt; 0,05). 12.4 Diagramas de Whittaker ou Curva de Domin√¢ncia Embora os √≠ndices de diversidade de esp√©cies englobem os componentes riqueza e abund√¢ncia relativa das esp√©cies nas suas estimativas, n√£o √© poss√≠vel conhecer o n√∫mero de esp√©cies ou quais s√£o as esp√©cies dominantes ou raras dentro das comunidades. Por exemplo, duas comunidades podem ter o mesmo valor de diversidade e ainda assim apresentar diferen√ßas na riqueza e equitabilidade (Melo 2008). O diagrama de Whittaker √© um m√©todo que lida com essas quest√µes utilizando informa√ß√µes visuais do n√∫mero de esp√©cies e abund√¢ncia relativa de cada esp√©cie nas comunidades. Este m√©todo plota as esp√©cies ranqueadas no eixo X da mais abundante para a menos abundante, enquanto que no eixo Y as abund√¢ncias relativas das esp√©cies s√£o plotadas em escala logaritma (log10). Este gr√°fico permite ao leitor reconhecer: i) a riqueza de esp√©cies observando o eixo X, ii) a equitabilidade da abund√¢ncia relativa das esp√©cies pela inclina√ß√£o da reta; e iii) quais s√£o as esp√©cies dominantes, intermedi√°rias e raras nas comunidades atrav√©s da observa√ß√£o em rela√ß√£o ao eixo Y. A partir destas curvas, v√°rios autores propuseram modelos matem√°ticos para explicar a distribui√ß√£o de abund√¢ncia das esp√©cies gerando diferentes modelos te√≥ricos (e.g.¬†s√©rie geom√©trica, broken-stick, log-series e log-normal). Cada modelo possui predi√ß√µes distintas: o modelo geom√©trico prediz distribui√ß√£o de abund√¢ncias desiguais, broken-stick prediz distribui√ß√£o de abund√¢ncias uniformes, enquanto log-normal e log-series s√£o intermedi√°rias com predi√ß√µes distintas sobre as propor√ß√µes de esp√©cies raras - alta em log-series, baixa em log-normal (veja McGill et al. (2007) para revis√£o). Para an√°lises explorat√≥rias onde voc√™ tem interesse em visualizar o padr√£o da distribui√ß√£o relativa das esp√©cies por comunidade, a fun√ß√£o rankabundance do pacote BiodiversityR √© uma op√ß√£o interessante. # c√°lculo da curva para as comunidades 2 e 3. rank_com2 &lt;- rankabundance(composicao_especies[2, composicao_especies[2,] &gt; 0]) rank_com3 &lt;- rankabundance(composicao_especies[3, composicao_especies[3,] &gt; 0]) # Gr√°fico # Veja a ajuda da fun√ß√£o rankabundplot para outros exemplos de gr√°ficos. rankabunplot(rank_com2, scale = &quot;logabun&quot;, specnames = c(1), pch = 19, col = &quot;darkorange&quot;) rankabunplot(rank_com3, scale = &quot;logabun&quot;, specnames = c(1), pch = 19, xlim = c(0,10), addit = T, col = &quot;cyan4&quot; , legend = T) legend(5, 40, legend = c(&quot;Comunidade 2&quot;, &quot;Comunidade 3&quot;), col = c(&quot;darkorange&quot;, &quot;cyan4&quot;), lty = 1, cex = 0.8, box.lty = 0) Interpreta√ß√£o dos resultados Percebam que olhando os eixos do gr√°fico conseguimos determinar que a comunidade 2 (c√≠rculo laranja) abriga 10 esp√©cies no total (i.e. comprimento do eixo X), com a esp√©cie sp1 apresentando alta domin√¢ncia e as outras esp√©cies apresentando abund√¢ncias muito baixas. A comunidade 3 (c√≠rculo ciano) abriga cinco esp√©cies no total, sendo que a esp√©cie sp4 apresenta alta domin√¢ncia, duas esp√©cies apresentam abund√¢ncias intermedi√°rias e outras duas abund√¢ncias baixas. 12.5 Curvas de distribui√ß√£o de abund√¢ncias Caso o interesse seja avaliar qual dos modelos te√≥ricos melhor explica a distribui√ß√£o das abund√¢ncias das esp√©cies, a fun√ß√£o radift do pacote vegan √© a melhor op√ß√£o. A fun√ß√£o radfit avalia cinco modelos te√≥ricos para determinar qual deles melhor se ajustam aos dados. Os modelos te√≥ricos avaliados na fun√ß√£o s√£o: Null = modelo broken-stick; preemption = s√©rie geom√©trica; log-normal; Zipf; Zipf-Mandelbrot. Voc√™ pode realizar as an√°lises separadamente para cada comunidade ou para todas as comunidades ao mesmo tempo. Vamos come√ßar avaliando separadamente a comunidade 2. curvas_dominancia_com2 &lt;- radfit(composicao_especies[2,]) curvas_dominancia_com2 #&gt; #&gt; RAD models, family poisson #&gt; No. of species 10, total abundance 100 #&gt; #&gt; par1 par2 par3 Deviance AIC BIC #&gt; Null 175.242 199.592 199.592 #&gt; Preemption 0.68962 79.560 105.910 106.213 #&gt; Lognormal -0.65366 3.2485 47.350 75.701 76.306 #&gt; Zipf 0.83829 -3.0254 26.612 54.963 55.568 #&gt; Mandelbrot 0.83829 -3.0254 1.6448e-07 26.612 56.963 57.871 Agora vamos fazer um gr√°fico com as predi√ß√µes dos modelos plot(curvas_dominancia_com2, ylab = &quot;Abund√¢ncia&quot;, xlab = &quot;Ranqueamento das esp√©cies&quot;) Interpreta√ß√£o dos resultados Os pontos brancos representam as esp√©cies ranqueadas de acordo com a abund√¢ncia e as linhas representam as predi√ß√µes dos modelos mat√©maticos. Com base nos valores de AIC (veja Cap√≠tulo 7), o Zipf √© o melhor modelo explicando a distribui√ß√£o da abund√¢ncia relativa das esp√©cies na comunidade 2. Agora vamos analisar os dados considerando todas as comunidades. curvas_dominancia_todas &lt;- radfit(composicao_especies) curvas_dominancia_todas #&gt; #&gt; Deviance for RAD models: #&gt; #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 #&gt; Null 8.2193e+01 1.7524e+02 8.9085e+00 4.2265e+01 4.9719e+00 4.7099e+00 #&gt; Preemption 2.2878e+01 7.9560e+01 1.5423e+00 1.4332e+01 3.0438e+00 4.5536e+00 #&gt; Lognormal 1.7764e-15 4.7350e+01 1.0161e+00 2.9441e-02 1.9303e+00 4.8898e+00 #&gt; Zipf -1.7764e-15 2.6612e+01 2.1659e-01 1.5846e-02 3.6094e+00 8.3245e+00 #&gt; Mandelbrot -1.7764e-15 2.6612e+01 2.0926e-01 1.1390e-02 1.8740e+00 4.1131e+00 #&gt; Com_7 Com_8 Com_9 Com_10 #&gt; Null 1.1507e+00 1.8998e+00 2.7703e+00 1.1146 #&gt; Preemption 7.7259e-01 1.7847e+00 9.2518e-01 0.7428 #&gt; Lognormal -2.2053e-25 1.4556e+00 2.0626e-01 0.5079 #&gt; Zipf -2.2073e-25 6.6938e-01 4.7931e-01 0.8730 #&gt; Mandelbrot 0.0000e+00 6.6938e-01 2.3634e-01 0.4456 # Vamos fazer um gr√°fico para cada comunidade plot(curvas_dominancia_todas, log = &quot;y&quot;) Interpreta√ß√£o dos resultados A comunidade 1 foi associada com o modelo log-normal, as comunidades 2 e 4 com o modelo Zipf, a comunidade 3 com o modelo s√©rie geom√©trica e as outras comunidades com o modelo nulo. Para explorar a explica√ß√£o biol√≥gica por tr√°s destes modelos veja os artigos (Wilson 1991; B. J. McGill et al. 2007; Magurran and McGill 2011). Contudo, esse link entre o modelo matem√°tico e a explica√ß√£o biol√≥gica precisa ser interpretado com cuidado porque diferentes modelos matem√°ticos podem levar ao mesmo padr√£o de distribui√ß√£o de abund√¢ncia. 12.6 N√∫meros de Hill ou S√©rie de Hill Embora os √≠ndices de Shannon-Wiener e Gini-Simpson sejam amplamente usados em estudos ecol√≥gicos e de conserva√ß√£o, eles sofrem de propriedades matem√°ticas e n√£o representam a diversidade propriamente dita (Jost 2006). Portanto, quando o objetivo √© avaliar a diversidade, os √≠ndices de Shannon-Wiener e Gini-Simpson n√£o deveriam ser utilizados na sua forma padr√£o, mas transformados em n√∫meros efetivos de esp√©cies ou diversidade verdadeira (Jost 2006). O n√∫mero efetivo de esp√©cies √© o n√∫mero de esp√©cies igualmente abundantes (i.e.¬†todas as esp√©cies com a mesma abund√¢ncia) necess√°rias para produzir o valor observado para um determinado √≠ndice. Por exemplo, uma comunidade com √≠ndice de Shannon-Wiener estimado de 4,5 teria um n√∫mero efetivo de 90 esp√©cies igualmente abundantes. Jost et al.¬†(2006) usam o seguinte exemplo para explicar o conceito do n√∫mero efetivo de esp√©cies - uma comunidade com 16 esp√©cies igualmente abundantes √© duas vezes mais diversa do que uma comunidade com 8 esp√©cies igualmente abundantes. Neste caso, a diversidade deveria ser proporcional ao n√∫mero de esp√©cies. Contudo, quando aplicamos os √≠ndices de diversidade para estas comunidades com 16 e 8 esp√©cies (cada esp√©cie com 5 indiv√≠duos), o √≠ndice de Shannon-Wiener √© 2,772 e 2,079 respectivamente, e o √≠ndice de Gini-Simpson √© 0,937 e 0,875 respectivamente. Claramente, os valores estimados pelos √≠ndices de diversidade n√£o representam a diferen√ßa entre as comunidades porque eles carecem de uma particularidade matem√°tica conhecida como propriedade de duplica√ß√£o. O pr√≥ximo exemplo (modificado do website de Lou Jost; http://www.loujost.com/) demostra a import√¢ncia da transforma√ß√£o dos √≠ndices de diversidade em n√∫meros efetivos de esp√©cies. Imagine que voc√™ foi contratado para avaliar a diversidade de peixes em um riacho antes e depois da instala√ß√£o de uma usina hidrel√©trica. Suponha que os valores estimados pelo √≠ndice de Gini-Simpson foi de 0,99 antes da instala√ß√£o e de 0,97 depois da instala√ß√£o. A princ√≠pio, voc√™ poderia concluir que a diversidade diminuiu somente 2% e que a instala√ß√£o da hidrel√©trica n√£o afetou a diversidade de peixes no riacho. Contudo, transformando os valores do √≠ndice de diversidade em n√∫meros efetivos, percebemos que antes da instala√ß√£o a diversidade do riacho equivale a 100 esp√©cies igualmente abundantes enquanto ap√≥s a instala√ß√£o, equivale a 33 esp√©cies igualmente abundantes. Portanto, a queda da diversidade √© 66% e n√£o 2%. Hill (1973) derivou uma equa√ß√£o geral para o c√°lculo do n√∫mero efetivo de esp√©cies ou diversidade verdadeira que depende apenas do valor de q e da abund√¢ncia relativa das esp√©cies: \\[^qD = (\\sum_{i=1}^{S}p_i^q)^{1/(1-q)}\\] Onde: q = √© um par√¢metro conhecido como ordem da diversidade e √© usado para dar peso as esp√©cies comuns ou raras. q = 0 n√£o considera a frequ√™ncia das esp√©cies e representa a riqueza observada de esp√©cies; q = 1 equivale a transforma√ß√£o do √≠ndice de Shannon-Wiener (i.e.¬†exp(H‚Äô)) e da peso as esp√©cies com base na propor√ß√£o das suas frequ√™ncias; q = 2 equivale a transforma√ß√£o do √≠ndice de Gini-Simpson (i.e.¬†1/(1-D)) e da peso as esp√©cies mais comuns. Valores de q &lt;1 favorecem esp√©cies raras enquanto valores de q &gt; 1 favorecem esp√©cies comuns. pi = abund√¢ncia relativa de cada esp√©cie, calculada pela propor√ß√£o dos indiv√≠duos de uma esp√©cie pelo n√∫mero total dos indiv√≠duos na comunidade. Vamos calcular o n√∫mero de Hill para as comunidades do nosso exemplo. Calculando o N√∫mero de Hill com q = 0. (hill_res_q_0 &lt;- hill_taxa(composicao_especies, q = 0)) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 Com_10 #&gt; 10 10 5 5 5 6 2 4 6 4 Calculando o N√∫mero de Hill com q = 1. (hill_res_q_1 &lt;- hill_taxa(composicao_especies, q = 1)) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 #&gt; 10.000000 1.649196 2.606507 4.987156 4.420220 4.762172 2.000000 3.021912 5.551608 #&gt; Com_10 #&gt; 3.538328 Calculando o N√∫mero de Hill com q = 2. (hill_res_q_2 &lt;- hill_taxa(composicao_especies, q = 2)) #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 #&gt; 10.000000 1.206273 1.928571 4.974223 4.145078 4.300813 2.000000 2.409639 5.232558 #&gt; Com_10 #&gt; 3.270270 Criando um data frame com os tr√™s resultados anteriores res_hill &lt;- data.frame(hill_res_q_0, hill_res_q_1, hill_res_q_2) colnames(res_hill) &lt;- c(&quot;q=0&quot;, &quot;q=1&quot;, &quot;q=2&quot;) head(res_hill) #&gt; q=0 q=1 q=2 #&gt; Com_1 10 10.000000 10.000000 #&gt; Com_2 10 1.649196 1.206273 #&gt; Com_3 5 2.606507 1.928571 #&gt; Com_4 5 4.987156 4.974223 #&gt; Com_5 5 4.420220 4.145078 #&gt; Com_6 6 4.762172 4.300813 Interpreta√ß√£o dos resultados Como na comunidade 1 todas as esp√©cies s√£o igualmente abundantes, alterar os valores de q n√£o altera o n√∫mero efetivo de esp√©cies que permanece sempre 10. Contudo, na comunidade 2 que apresenta alta domin√¢ncia de uma esp√©cie, alterar os valores de q diminui consideravelmente a estimativa de diversidade. A vantagem dos n√∫meros de Hill √© que eles s√£o de f√°cil interpreta√ß√£o e compara√ß√£o entre as comunidades. Fator ausente para os √≠ndices de diversidade. Neste ponto, esperamos que tenha ficado claro que mais do que a riqueza de esp√©cies, a abund√¢ncia relativa das esp√©cies (e.g.¬†comuns ou raras) tem um papel fundamental na estimativa da diversidade de esp√©cies. 12.7 Diversidade beta O termo diversidade beta foi proposto por Whittker (1960) e foi definido como a raz√£o entre a diversidade gama e diversidade alfa (i.e.¬†diversidade beta multiplicativa) quantificando n√£o s√≥ a rela√ß√£o entre a diversidade regional e local, mas tamb√©m o grau de diferencia√ß√£o entre as comunidades. Para demonstrar como a diversidade beta varia entre comunidades locais dentro de uma regi√£o usaremos a explica√ß√£o do Baselga (http://webspersoais.usc.es/persoais/andres.baselga/beta.html). Imagine tr√™s comunidades, cada comunidade abrigando as mesmas cinco esp√©cies. Neste caso, a m√©dia da diversidade alfa = 5, a diversidade gama = 5 e a raz√£o entre elas (gama/alfa) indica uma diversidade beta = 1. Isso significa que na regi√£o existe apenas uma unidade distinta de composi√ß√£o. Quando a composi√ß√£o de esp√©cies das tr√™s comunidades √© completamente diferente (i.e.¬†diferencia√ß√£o m√°xima), temos que a m√©dia da diversidade alfa = 5, a diversidade gama = 15 e a raz√£o entre elas indica uma diversidade beta = 3. Neste caso, existem tr√™s unidades distintas dentro da regi√£o. Assim, a diversidade beta multiplicativa varia de 1 at√© o n√∫mero de comunidades dentro da regi√£o. A maioria dos √≠ndices de (dis)similaridade utilizadas na ecologia (e.g.¬†√≠ndices de Jaccard e S√∏rensen) s√£o √≠ndices que padronizam a diversidade beta e geram valores independentes do n√∫mero de comunidades. Eles podem ser calculados para dados de incid√™ncia (presen√ßa e aus√™ncia) ou abund√¢ncia (P. Legendre and Legendre 2012b) e considerando compara√ß√µes par-a-par entre as comunidades ou compara√ß√£o entre m√∫ltiplas comunidades (i.e. multiple-site). Por muito tempo, os valores de (dis)similaridade foram interpretados como sin√¥nimo de substitui√ß√£o de esp√©cies (turnover) entre comunidades. Contudo, √≠ndices de (dis)similaridade como Jaccard e S√∏rensen geram valores de (dis)similaridade para comunidades que n√£o apresentam diferen√ßas na composi√ß√£o de esp√©cies, mas apresentam diferen√ßas na riqueza de esp√©cies (i.e.¬†comunidades aninhadas). Pensando nestes fatores, Baselga (2012) prop√¥s uma abordagem que particiona a diversidade beta total em dois componentes: o componente resultante da substitui√ß√£o de esp√©cies (turnover) e o componente resultante do aninhamento (i.e.¬†diferen√ßa na riqueza de esp√©cies). Baselga (2013) prop√¥s a a parti√ß√£o da diversidade beta para √≠ndices de dissimilaridade que lidam com dados de abund√¢ncia. Neste caso os componentes da diversidade beta s√£o chamados de varia√ß√£o balanceada na abund√¢ncia (similar ao componente substitui√ß√£o de esp√©cies) e gradiente de abund√¢ncia (similar ao componente aninhamento). Reconhecer estes componentes da diversidade beta √© importante porque eles apresentam padr√µes distintos (substitui√ß√£o de esp√©cies vs perda ordenada de esp√©cies) que provavelmente est√£o sendo gerados por processos ecol√≥gicos diferentes (Baselga 2010, 2012, 2013). Aqui, vamos demonstrar alguns exemplos de como calcular a parti√ß√£o da diversidade beta para os dados deste cap√≠tulo. Para isso, primeiro vamos transformar nossa planilha de abund√¢ncia em presen√ßa e aus√™ncia. # Transformando dados em presencia e aus√™ncia. composicao_PA &lt;- decostand(composicao_especies, method = &quot;pa&quot;) Calculando a diversidade beta par a par usando os dados de presen√ßa e aus√™ncia. resultado_PA &lt;- beta.pair(composicao_PA, index.family = &quot;sorensen&quot;) A fun√ß√£o beta.pairgera tr√™s listas com matrizes triangulares: Diversidade beta total = √≠ndice de Sorensen (beta.sor); Componente substitui√ß√£o de esp√©cies = √≠ndice de Simpson (beta.sim); Componente aninhado = beta.sor - beta.sim. Vamos olhar os resultados da diversidade beta total. resultado_PA$beta.sor #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 #&gt; Com_2 0.0000000 #&gt; Com_3 0.3333333 0.3333333 #&gt; Com_4 0.3333333 0.3333333 1.0000000 #&gt; Com_5 0.3333333 0.3333333 0.6000000 0.4000000 #&gt; Com_6 0.2500000 0.2500000 0.4545455 0.4545455 0.4545455 #&gt; Com_7 0.6666667 0.6666667 0.7142857 0.7142857 1.0000000 0.7500000 #&gt; Com_8 0.4285714 0.4285714 0.7777778 0.3333333 0.3333333 0.2000000 1.0000000 #&gt; Com_9 0.2500000 0.2500000 0.4545455 0.4545455 0.2727273 0.5000000 0.7500000 0.4000000 #&gt; Com_10 0.4285714 0.4285714 0.3333333 0.7777778 0.5555556 0.4000000 0.6666667 0.7500000 #&gt; Com_9 #&gt; Com_2 #&gt; Com_3 #&gt; Com_4 #&gt; Com_5 #&gt; Com_6 #&gt; Com_7 #&gt; Com_8 #&gt; Com_9 #&gt; Com_10 0.6000000 Vamos montar um data.frame com os resultados data.frame_PA &lt;- data.frame(round(as.numeric(resultado_PA$beta.sor), 2), round(as.numeric(resultado_PA$beta.sim), 2), round(as.numeric(resultado_PA$beta.sne), 2)) colnames(data.frame_PA) &lt;- c(&quot;Sorensen&quot;, &quot;Simpson&quot;, &quot;Aninhamento&quot;) head(data.frame_PA) #&gt; Sorensen Simpson Aninhamento #&gt; 1 0.00 0 0.00 #&gt; 2 0.33 0 0.33 #&gt; 3 0.33 0 0.33 #&gt; 4 0.33 0 0.33 #&gt; 5 0.25 0 0.25 #&gt; 6 0.67 0 0.67 üìù Importante: Percebam que a primeira linha e primeira coluna do data frame (i.e.¬†0.00) representa a dissimilaridade de Sorensen entre a Com1 e Com2 (compare com os valores da matriz triangular acima). As linhas subsequentes representam a dissimilaridade da Com1 com todas as outras comunidades, depois da Com2 com todas as comunidades e assim sucessivamente. Lembrem-se que os componentes, subsitui√ß√£o (Simpson) e aninhamento, s√£o um desdobramento da diversidade beta total (Sorensen). Assim, a soma da dissimilaridade de Simpson e aninhamento √© igual ao valor de dissimilaridade de Sorensen (Baselga 2009, 2012). Vamos calcular a dissimilaridade entre a precipita√ß√£o anual das comunidades usando o √≠ndice de dist√¢ncia euclidiana. Vejam a ajuda da fun√ß√£o vegdist que calcula 17 √≠ndices diferentes de dissimilaridade. prec_dis &lt;- vegdist(precipitacao, method = &quot;euclidian&quot;) dados_prec &lt;- as.numeric(prec_dis) Agora vamos juntar os resultados. üìù Importante: As comunidades devem estar dispostas na mesma ordem nas duas planilhas (composi√ß√£o de esp√©cies e precipita√ß√£o) para que os resultados representem as dissimilaridades par a par para as mesmas comunidades no data frame. Criando data.frame. dados_dis &lt;- data.frame(dados_prec, data.frame_PA) head(dados_dis) #&gt; dados_prec Sorensen Simpson Aninhamento #&gt; 1 88 0.00 0 0.00 #&gt; 2 400 0.33 0 0.33 #&gt; 3 1400 0.33 0 0.33 #&gt; 4 294 0.33 0 0.33 #&gt; 5 195 0.25 0 0.25 #&gt; 6 2270 0.67 0 0.67 Vamos testar a rela√ß√£o entre as diferen√ßa na composi√ß√£o de esp√©cies e precipita√ß√£o nas comunidades. # Avaliar a rela√ß√£o entre os valores de diversidade beta total (Sorensen) e precipita√ß√£o anova(lm(dados_dis$Sorensen ~ dados_dis$dados_prec)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_dis$Sorensen #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_dis$dados_prec 1 0.00188 0.001877 0.0358 0.8508 #&gt; Residuals 43 2.25264 0.052387 # Avaliar a rela√ß√£o entre os valores do componente substitui√ß√£o (Simpson) e precipita√ß√£o anova(lm(dados_dis$Simpson ~ dados_dis$dados_prec)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_dis$Simpson #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_dis$dados_prec 1 0.1403 0.140342 1.4905 0.2288 #&gt; Residuals 43 4.0488 0.094157 # Avaliar a rela√ß√£o entre os valores do componente aninhamento e precipita√ß√£o anova(lm(dados_dis$Aninhamento ~ dados_dis$dados_prec)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_dis$Aninhamento #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_dis$dados_prec 1 0.17467 0.17467 6.4006 0.01515 * #&gt; Residuals 43 1.17349 0.02729 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Interpreta√ß√£o dos resultados H√° uma rela√ß√£o positiva entre o componente aninhado da diversidade beta e a diferen√ßa na precipita√ß√£o entre as comunidades (F1,43 = 6,4, P = 0,01). Contudo, n√£o h√° rela√ß√£o entre a diversidade beta total (Sorensen) e o componente substitui√ß√£o de esp√©cies (Simpson) com a precipita√ß√£o (P &gt; 0,05). Agora vamos fazer um gr√°fico com o componente aninhamento da diversidade beta. ggplot(data = dados_dis, aes(x= dados_prec, y= Aninhamento)) + labs(x = &quot;Diferen√ßa precipita√ß√£o (mm)&quot;, y = &quot;Componente aninhamento da\\n diversidade beta&quot;) + geom_point(size = 4, shape = 21, fill = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) Interpreta√ß√£o dos resultados As comunidades com baixa precipita√ß√£o anual apresentam esp√©cies que s√£o um subgrupo das esp√©cies presentes nas comunidades com alta precipita√ß√£o anual. Agora vamos fazer um exemplo considerando os dados de abund√¢ncia das esp√©cies. A fun√ß√£o beta.pair.abundgera tr√™s listas com matrizes triangulares: Diversidade beta total = √≠ndice de Bray-Curtis (beta.bray); Componente varia√ß√£o balanceada (beta.bray.bal); Componente gradiente de abund√¢ncia (beta.bray.gra). An√°lise. resultado_AB &lt;- beta.pair.abund(composicao_especies, index.family = &quot;bray&quot;) Cria um data.frame com os resultados. # Vamos montar um data.frame com os resultados data.frame_AB &lt;- data.frame(round(as.numeric(resultado_AB$beta.bray), 2), round(as.numeric(resultado_AB$beta.bray.bal), 2), round(as.numeric(resultado_AB$beta.bray.gra), 2)) colnames(data.frame_AB) &lt;- c(&quot;Bray&quot;, &quot;Balanceada&quot;, &quot;Gradiente&quot;) head(data.frame_AB) #&gt; Bray Balanceada Gradiente #&gt; 1 0.81 0.81 0.00 #&gt; 2 0.69 0.42 0.27 #&gt; 3 0.45 0.38 0.06 #&gt; 4 0.47 0.07 0.40 #&gt; 5 0.47 0.15 0.31 #&gt; 6 0.92 0.00 0.92 ## Agora vamos juntar os resultados com a precipita√ß√£o dados_dis_AB &lt;- data.frame(dados_prec, data.frame_AB) Testar a rela√ß√£o da dissimilaridade considerando a abund√¢ncia com a diferen√ßa na precipita√ß√£o entre as comunidades. ## Avaliar a rela√ß√£o entre os valores de diversidade beta total e precipita√ß√£o anova(lm(dados_dis_AB$Bray ~ dados_dis$dados_prec)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_dis_AB$Bray #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_dis$dados_prec 1 0.01782 0.017815 0.8441 0.3634 #&gt; Residuals 43 0.90755 0.021106 ## Avaliar a rela√ß√£o entre os valores do componente balanceada e precipita√ß√£o anova(lm(dados_dis_AB$Balanceada ~ dados_dis$dados_prec)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_dis_AB$Balanceada #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_dis$dados_prec 1 0.48761 0.48761 7.0742 0.01094 * #&gt; Residuals 43 2.96391 0.06893 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Avaliar a rela√ß√£o entre os valores do componente gradiente e precipita√ß√£o anova(lm(dados_dis_AB$Gradiente ~ dados_dis$dados_prec)) #&gt; Analysis of Variance Table #&gt; #&gt; Response: dados_dis_AB$Gradiente #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; dados_dis$dados_prec 1 0.68981 0.68981 18.705 8.903e-05 *** #&gt; Residuals 43 1.58575 0.03688 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Interpreta√ß√£o dos resultados H√° uma rela√ß√£o positiva entre os componentes varia√ß√£o balanceada (F1,43 = 7,07, P = 0,01) e gradiente (F1,43 = 18,7, P &lt; 0,001) de abund√¢ncia da diversidade beta com a diferen√ßa na precipita√ß√£o entre as comunidades. Contudo, n√£o h√° rela√ß√£o entre a diversidade beta total (Bray) com a precipita√ß√£o (F1,43 = 0,84, P = 0,36). Vamos fazer um gr√°fico para cada um dos componentes da diversidade beta. ggplot(data = dados_dis_AB, aes(x= dados_prec, y= Balanceada)) + labs(x = &quot;Diferen√ßa precipita√ß√£o (mm)&quot;, y = &quot;Componente varia√ß√£o balanceada\\n da diversidade beta&quot;) + geom_point(size = 4, shape = 21, fill = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) Interpreta√ß√£o dos resultados Olhando o √≠nicio do eixo X onde as comunidades apresentam precipita√ß√£o anual similares (i.e.¬†baixa diferen√ßa na precipita√ß√£o), o componente varia√ß√£o balanceada indica que h√° uma tend√™ncia das esp√©cies com maiores abund√¢ncias n√£o serem as mesmas quando comparamos duas comunidades (i.e. maiores valores de dissimilaridade). Por outro lado, quando a diferen√ßa na precipita√ß√£o entre duas comunidades √© alta, o componente varia√ß√£o balanceada √© baixo, indicando que as mesmas esp√©cies est√£o dominando a abund√¢ncia nas comunidades comparadas. ggplot(data = dados_dis_AB, aes(x= dados_prec, y= Gradiente)) + labs(x = &quot;Diferen√ßa precipita√ß√£o anual (mm)&quot;, y = &quot;Componente gradiente de abund√¢ncia\\n da diversidade beta&quot;) + geom_point(size = 4, shape = 21, fill = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) Interpreta√ß√£o dos resultados Olhando o √≠nicio do eixo X onde as comunidades apresentam precipita√ß√£o anual similares (i.e.¬†baixa diferen√ßa na precipita√ß√£o), o componente gradiente indica que h√° uma tend√™ncia das esp√©cies apresentarem abund√¢ncias parecidas (i.e.¬†menor valor de dissimilaridade). Por outro lado, quando a diferen√ßa na precipita√ß√£o entre duas comunidades √© alta, o componente gradiente √© alto, indicando que as mesmas esp√©cies tem valores discrepantes de abund√¢ncias entre as comunidades. 12.7.1 Para se aprofundar Recomendamos aos interessados a leitura dos artigos citados no cap√≠tulo e os livros Magurran &amp; McGill (2011) - Biological Diversity Frontiers in Measurement and Assessment and Legendre &amp; Legendre (2012b) - Numerical Ecology. Refer√™ncias "],["cap13.html", "Cap√≠tulo 13 Diversidade Filogen√©tica 13.1 Aspectos te√≥ricos 13.2 Manipula√ß√£o de filogenias 13.3 M√©tricas de diversidade alfa filogen√©tica 13.4 An√°lise da dimens√£o riqueza da diversidade alfa filogen√©tica 13.5 Phylogenetic Species Richness (PSR, Helmus et al.¬†2007) 13.6 Phylogenetic Endemism (PE, Rosauer et al.¬†2009) 13.7 Species Evolutionary Distinctiveness (ED, Redding &amp; Mooers 2006) 13.8 An√°lise da dimens√£o diverg√™ncia da diversidade alfa filogen√©tica 13.9 Mean Pairwise Distance (MPD, Webb et al.¬†2002) 13.10 Mean Nearest Taxon Distance (MNTD, Webb et al.¬†2002) 13.11 Phylogenetic Species Variability (PSV, Helmus et al.¬†2007) 13.12 An√°lise da dimens√£o regularidade da diversidade alfa filogen√©tica 13.13 Variance of Pairwise Distance (VPD, Clarke &amp; Warwick 2001) 13.14 Correla√ß√£o entre as m√©tricas de diversidade alfa filogen√©tica 13.15 Associa√ß√£o entre as m√©tricas de diversidade alfa filogen√©tica e o gradiente de precipita√ß√£o 13.16 M√©tricas de diversidade beta filogen√©tica 13.17 An√°lise da dimens√£o diverg√™ncia da diversidade beta filogen√©tica 13.18 Community Mean Pairwise Distance (COMDIST, Webb et al.¬†2008) 13.19 Community Mean Nearest Taxon Distance (COMDISTNT, Webb et al.¬†2008) 13.20 Correla√ß√£o entre as m√©tricas de diversidade beta filogen√©tica 13.21 Associa√ß√£o entre as m√©tricas de diversidade beta filogen√©tica e o gradiente de precipita√ß√£o 13.22 An√°lise da dimens√£o riqueza da diversidade beta filogen√©tica 13.23 Phylogenetic index of beta diversity (Phylosor, Bryant et al.¬†2008) 13.24 Unique Fraction metric (UniFrac, Lozupone &amp; Knight 2005) 13.25 Vamos avaliar a correla√ß√£o entre Phylosor e Unifrac 13.26 Parti√ß√£o da diversidade beta filogen√©tica 13.27 Modelos Nulos 13.28 Nearest Relative Index (NRI) ou Standardized Effect Size of MPD (Webb et al.¬†2008) 13.29 Nearest Taxon Index (NTI) ou Standardized Effect Size of MNTD (Webb et al.¬†2008) 13.30 Standardized Effect Size of PD (Webb et al.¬†2008) 13.31 Standardized Effect Size", " Cap√≠tulo 13 Diversidade Filogen√©tica Pr√©-requisitos do cap√≠tulo ## Pacotes library(devtools) # install_github(&quot;paternogbc/ecodados&quot;) library(ecodados) # install_github(&quot;jinyizju/V.PhyloMaker&quot;) library(V.PhyloMaker) library(vegan) library(ggplot2) library(GGally) library(ggpubr) library(picante) library(phytools) library(ape) library(geiger) library(phyloregion) library(pez) library(reshape2) library(betapart) ## Dados necess√°rios minha_arvore &lt;- ecodados::filogenia_aves especies_plantas &lt;- ecodados::sp_list comunidade &lt;- ecodados::comm composicao_especies &lt;- ecodados::composicao_aves_filogenetica filogenia_aves &lt;- ecodados::filogenia_aves precipitacao &lt;- precipitacao_filogenetica 13.1 Aspectos te√≥ricos A diversidade filogen√©tica captura a ancestralidade compartilhada entre as esp√©cies em termos de quantidade da hist√≥ria evolutiva e o grau de parentesco entre as esp√©cies. Pesquisadores t√™m utilizado diferentes m√©tricas de diversidade filogen√©tica em duas linhas de investiga√ß√µes principais: i) incorporar a hist√≥ria evolutiva das esp√©cies na sele√ß√£o das √°reas priorit√°rias para conserva√ß√£o visando minimizar a perda da diversidade evolutiva (Vane-Wright, Humphries, and Williams 1991; Faith 1992; V√©ron et al. 2019), e ii) produzir explica√ß√µes sobre os processos atuando na montagem das comunidades (Webb et al. 2002; Helmus et al. 2007). A quantidade de artigos abordando ecologia, macroecologia e conserva√ß√£o com diversidade filogen√©tica cresceram exponencialmente nas √∫ltimas d√©cadas (V√©ron et al. 2019). Seguindo esta tend√™ncia, o n√∫mero de m√©tricas de diversidade filogen√©tica propostas n√£o param de aumentar. Tucker et al. (2016) revisaram 70 m√©tricas de diversidade filogen√©tica e classificaram estas m√©tricas em tr√™s dimens√µes: i) riqueza - representa a soma da diferen√ßa filogen√©tica acumulada entre t√°xons; ii) diverg√™ncia - representa o padr√£o de diferen√ßa filogen√©tica entre t√°xons de uma assembleia; e iii) regularidade - representa o grau de varia√ß√£o das diferen√ßas filogen√©ticas entre t√°xons em uma assembleia. Outros autores utilizaram diferentes classifica√ß√µes (S. Pavoine and Bonsall 2010; M. Vellend et al. 2011; Garamszegi 2014). Neste cap√≠tulo, iremos seguir a classifica√ß√£o de Tucker et al. (2016) e mostrar algumas das principais m√©tricas dentro de cada uma dessas dimens√µes. Alguns autores recomendam que os pesquisadores n√£o foquem em apenas uma dimens√£o, mas comparem m√©tricas de diferentes dimens√µes (Tucker et al. 2016). 13.2 Manipula√ß√£o de filogenias Nesta se√ß√£o, iremos descrever os c√≥digos no R para carregar uma filogenia, plotar a filogenia, acessar os dados da filogenia e excluir e adicionar esp√©cies na filogenia. Estes s√£o c√≥digos introdut√≥rios e necess√°rios para realizarmos as an√°lises de diversidade filogen√©tica. N√£o iremos descrever os comandos necess√°rios para construir uma filogenia. Estamos assumindo que j√° existe uma filogenia dispon√≠vel para os organismos de interesse. Mas antes vamos entender as terminologias de uma filogenia (Figura 1). √Årvore filogen√©tica: s√£o hip√≥teses que representam o rela√ß√£o de parentesco entre as esp√©cies (pode ser tamb√©m individ√≠duos, genes, etc.) com informa√ß√µes sobre quais esp√©cies compartilham um ancestral comum e a dist√¢ncia (tempo, gen√©tica, ou diferen√ßas nos caracteres) que as separam; N√≥: o ponto onde uma linhagem da origem a duas ou mais linhagens descendentes; Politomia: Tr√™s ou mais linhagens descendendo de um √∫nico n√≥; Ramo: uma linha orientada ao longo de um eixo terminais-raiz que conecta os n√≥s na filogenia; Terminal (do ingl√™s tip): o final do ramo representando uma esp√©cie atual ou extinta (pode tamb√©m reprentar g√™neros, indiv√≠duos, genes, etc.); Raiz: representa o ancestral comum de todas as esp√©cies na filogenia; Clado: um grupo de esp√©cies aparentadas descendendo de um √∫nico n√≥ na filogenia; Ultram√©trica: a dist√¢ncia de todos os terminais at√© a raiz s√£o identicas. Caracter√≠stica requerida pela maioria dos √≠ndices de diversidade filogen√©tica. Ilustra√ß√µes de diferentes √°rvores filogen√©ticas. A) √Årvore enraizada e ultram√©trica indicando a raiz da √°rvore, n√≥s, ramos, comprimento do ramo, politomias e terminais. B) √Årvore n√£o enraizada que mostra as rela√ß√µes entre as esp√©cies, mas n√£o define a hist√≥ria evolutiva. C) √Årvore n√£o ultram√©trica onde as esp√©cies apresentam diferentes dist√¢ncias at√© a raiz. ¬† Agora vamos plotar a filogenia para visualizar as rela√ß√µes entre as 37 esp√©cies de aves end√™micas da Mata Atl√¢ntica. filogenia foi extra√≠da de Jetz et al. (2012). Os dados est√£o dispon√≠veis no pacote ecodados. plot.phylo (minha_arvore, type = &quot;phylogram&quot;, show.tip.label = TRUE, show.node.label = TRUE, edge.color = &quot;black&quot;, edge.width = 1.5, tip.color = &quot;black&quot;, cex = 0.45, label.offset = 2) Podemos alterar o formato de apresenta√ß√£o da filogenia usando o argumento type e a cor dos ramos usando o argumento edge.color. plot.phylo (minha_arvore, type = &quot;fan&quot;, show.tip.label = TRUE, show.node.label = TRUE, edge.color = &quot;blue&quot;, edge.width = 1.5, tip.color = &quot;black&quot;, cex = 0.45, label.offset = 2) Percebam que existem v√°rios argumentos para modificar a largura e cor dos ramos, tamanho da fonte, dist√¢ncia entre a filogenia e o nomes da esp√©cies e muito mais. Uma sugest√£o √© visitar o blog do professor Liam Revell (http://blog.phytools.org/) que √© o criador e mantenedor do pacote phytools no R. Um das caracter√≠sticas mais interessantes do R √© que podemos acessar as informa√ß√µes do objeto. Neste caso, o nosso objeto √© a filogenia e, muitas vezes, temos interesse nas informa√ß√µes que est√£o inseridas dentro da filogenia. Para sabermos quais s√£o as informa√ß√µes que podemos acessar na filogenia, vamos usar a fun√ß√£o names(). names(minha_arvore) #&gt; [1] &quot;edge&quot; &quot;edge.length&quot; &quot;Nnode&quot; &quot;tip.label&quot; Temos acesso a quatro componentes da filogenia: i) ramo (edge), ii) comprimento do ramo (edge.length), iii) n√∫mero de n√≥s (Nnode), e iv) nome das esp√©cies (tip.label). Podemos usar o operador $ para acessar estes componentes. Veja abaixo como acessar o nome das 37 esp√©cies de aves na filogenia. minha_arvore$tip.label #&gt; [1] &quot;Cranioleuca_pallida&quot; &quot;Synallaxis_ruficapilla&quot; #&gt; [3] &quot;Phacellodomus_ferrugineigula&quot; &quot;Cinclodes_pabsti&quot; #&gt; [5] &quot;Conopophaga_melanops&quot; &quot;Herpsilochmus_pileatus&quot; #&gt; [7] &quot;Pyriglena_leucoptera&quot; &quot;Formicivora_serrana&quot; #&gt; [9] &quot;Chiroxiphia_caudata&quot; &quot;Neopelma_aurifrons&quot; #&gt; [11] &quot;Carpornis_cucullata&quot; &quot;Mionectes_rufiventris&quot; #&gt; [13] &quot;Phylloscartes_kronei&quot; &quot;Dacnis_nigripes&quot; #&gt; [15] &quot;Ramphocelus_bresilius&quot; &quot;Sporophila_frontalis&quot; #&gt; [17] &quot;Tangara_seledon&quot; &quot;Euphonia_pectoralis&quot; #&gt; [19] &quot;Cyanocorax_caeruleus&quot; &quot;Brotogeris_tirica&quot; #&gt; [21] &quot;Pionopsitta_pileata&quot; &quot;Pyrrhura_frontalis&quot; #&gt; [23] &quot;Ramphastos_dicolorus&quot; &quot;Pteroglossus_bailloni&quot; #&gt; [25] &quot;Veniliornis_maculifrons&quot; &quot;Melanerpes_flavifrons&quot; #&gt; [27] &quot;Malacoptila_striata&quot; &quot;Strix_hylophila&quot; #&gt; [29] &quot;Pulsatrix_koeniswaldiana&quot; &quot;Megascops_sanctaecatarinae&quot; #&gt; [31] &quot;Leucopternis_polionotus&quot; &quot;Buteogallus_lacernulatus&quot; #&gt; [33] &quot;Thalurania_glaucopis&quot; &quot;Stephanoxis_lalandi&quot; #&gt; [35] &quot;Aramides_saracura&quot; &quot;Ortalis_guttata&quot; #&gt; [37] &quot;Tinamus_solitarius&quot; ou o comprimento de cada um dos ramos da filogenia. minha_arvore$edge.length #&gt; [1] 8.3802647 18.8669712 1.7333865 3.6642170 10.6732942 15.2239228 11.0917270 #&gt; [8] 1.7755983 28.3607791 2.9678911 1.7546545 8.0910030 8.0910030 9.8456576 #&gt; [15] 12.8135486 41.1743278 25.4606915 0.5546030 16.9346316 16.9346316 17.4892346 #&gt; [22] 18.4363079 4.6581580 13.5498048 17.3960309 17.3960309 30.9471871 12.4567724 #&gt; [29] 23.1472214 23.1472214 17.4065182 24.1723764 12.4712971 2.4600303 12.6082491 #&gt; [36] 12.5529673 12.6146793 15.2153841 27.6866812 51.8590576 50.4721698 1.0975337 #&gt; [43] 28.3691666 28.3691666 29.4667004 0.4805624 1.9967144 2.7687118 17.0272986 #&gt; [50] 23.4955884 20.5338341 17.3003772 17.3003772 22.2636579 15.5705534 15.5705534 #&gt; [57] 61.3297997 50.6621138 5.3479249 22.3470597 22.3470597 27.6949846 66.5513507 #&gt; [64] 14.5744595 14.5744595 67.7448719 15.3776527 15.3776527 85.3364736 104.2034448 #&gt; [71] 112.5837095 Nas an√°lises de diversidade filogen√©tica, as esp√©cies que estar√£o presentes na filogenia normalmente s√£o aquelas que foram amostradas no seu estudo. Contudo, muitas vezes utilizamos filogenias contendo esp√©cies que n√£o est√£o presentes no nosso estudo. Neste caso, precisamos excluir essas esp√©cies da filogenia. A fun√ß√£o drop.tip() faz essa tarefa. # Vamos criar um novo nome para o objeto e excluir as esp√©cies Leucopternis polionotus # e Aramides saracura da filogenia filogenia_cortada &lt;- drop.tip(minha_arvore, c(&quot;Leucopternis_polionotus&quot;, &quot;Aramides_saracura&quot;)) filogenia_cortada #&gt; #&gt; Phylogenetic tree with 35 tips and 33 internal nodes. #&gt; #&gt; Tip labels: #&gt; Cranioleuca_pallida, Synallaxis_ruficapilla, Phacellodomus_ferrugineigula, Cinclodes_pabsti, Conopophaga_melanops, Herpsilochmus_pileatus, ... #&gt; #&gt; Rooted; includes branch lengths. Vejam que agora a filogenia tem 35 esp√©cies de aves. As duas esp√©cies que selecionamos foram exclu√≠das da filogenia. Outra situa√ß√£o bem comum √© quando precisamos inserir esp√©cies que foram amostradas no nosso estudo, mas n√£o est√£o presente na filogenia. Para isso, vamos usar a fun√ß√£o add.species.to.genus. A fun√ß√£o force.ultrametric √© usada para que a filogenia continue sendo ultram√©trica (sem essa fun√ß√£o a √°rvore perde os comprimentos dos ramos) üìù Importante: O comprimento do ramo que a esp√©cie ir√° receber depender√° de onde voc√™ indicar a inser√ß√£o da esp√©cie. As op√ß√µes s√£o: root que insere a esp√©cie no ancestral comum mais recente (MRCA) de todas as esp√©cies do g√™nero (default); random que insere a esp√©cie aleatoriamente dentro do clado do MRCA contendo todos as esp√©cies do g√™nero. # Vamos inserir as esp√©cies Megascops_sp1, Carponis_sp, Strix_sp1, Strix_sp2 e # Strix_sp3 na filogenia Megascops &lt;- c(&quot;Megascops_sp1&quot;) Carpornis &lt;- c(&quot;Carpornis_sp1&quot;) Strix &lt;- c(&quot;Strix_sp1&quot;, &quot;Strix_sp2&quot;, &quot;Strix_sp3&quot;) # Inserindo esp√©cies como politomias filogenia_nova &lt;- add.species.to.genus(force.ultrametric(minha_arvore), Megascops) filogenia_nova &lt;- add.species.to.genus(force.ultrametric(filogenia_nova), Carpornis) Agora vamos inserir v√°rias esp√©cies dentro do mesmo g√™nero. # Para inserir mais de uma esp√©cie dentro do g√™nero, vamos utilizar um loop. for(i in 1:length(Strix)) filogenia_nova &lt;- add.species.to.genus(force.ultrametric(filogenia_nova), Strix[i], where=&quot;root&quot;) plot(filogenia_nova, cex = 0.5, no.margin = TRUE) Vamos fazer outro exemplo usando a fun√ß√£o phylo.maker() do pacote V.PhyloMaker que adiciona as esp√©cies nos g√™neros ou os g√™neros nas fam√≠lias usando uma filog√™nia backbone. Essa fun√ß√£o permite a adi√ß√£o dos g√™neros ou esp√©cies considerando tr√™s cen√°rios diferentes: Cen√°rio 1 - adiciona g√™neros ou esp√©cies como politomias basais dentro das fam√≠lias ou g√™neros da filogenia respectivamente. Cen√°rio 2 - adiciona g√™neros e esp√©cies aleatoriamente nas fam√≠lias ou g√™neros da filogenia respectivamente. Cen√°rio 3 - adiciona g√™neros e esp√©cies nas fam√≠lias ou g√™neros da filogenia respectivamente usando as abordagens implementadas no Phylomatic e BLADJ. # A fun√ß√£o phylo.maker usa uma filogenia default de plantas (i.e. GBOTB.extended). # Caso voc√™ queira utilizar outra filogenia, √© s√≥ alterar o argumento tree novas_filogenias &lt;- phylo.maker(especies_plantas, tree = GBOTB.extended, scenarios=c(&quot;S1&quot;,&quot;S2&quot;,&quot;S3&quot;)) #&gt; [1] &quot;Note: 2 taxa fail to be binded to the tree,&quot; #&gt; [1] &quot;Genus7_sp1&quot; &quot;Genus8_sp1&quot; # Gr√°fico mostrando o resultado para os cen√°rios 1 e 3 par(mfrow = c(1, 2)) plot.phylo(novas_filogenias$scenario.1, cex = 0.5, main = &quot;Cen√°rio 1&quot;) plot.phylo(novas_filogenias$scenario.3, cex = 0.5, main = &quot;Cen√°rio 3&quot;) dev.off() #&gt; null device #&gt; 1 13.3 M√©tricas de diversidade alfa filogen√©tica M√©tricas de diversidade alfa utilizam os dados de incid√™ncia (presen√ßa e aus√™ncia) ou abund√¢ncia das esp√©cies para determinar um valor de diversidade para cada comunidade ou s√≠tio de interesse. 13.3.0.1 Exemplo pr√°tico 1 - Medidas de diversidade filogen√©tica Explica√ß√£o dos dados Avaliaremos a diversidade filogen√©tica de 10 comunidades de aves amostradas ao longo de um gradiente de precipita√ß√£o. Utilizaremos este conjunto de dados para todos os exemplos deste cap√≠tulo. Pergunta: A varia√ß√£o na distribui√ß√£o espacial dos valores de diversidade filogen√©tica das comunidades est√° associada com o gradiente de precipita√ß√£o? Predi√ß√µes Os valores de diversidade filogen√©tica ser√£o maiores nas comunidades localizadas em regi√µes com altas precipita√ß√µes do que em regi√µes mais secas. Vari√°veis Vari√°veis resposta e preditoras Dataframe com as comunidades (unidade amostral) nas linhas e as esp√©cies de aves nas colunas (vari√°vel resposta). Dataframe com as comunidades (unidade amostral) nas linhas e a vari√°vel precipita√ß√£o anual na coluna (vari√°vel preditora). Arquivo com a filogenia das 37 esp√©cies de aves (vari√°vel resposta). Checklist Verificar se os dataframes de composi√ß√£o de esp√©cies e vari√°veis ambientais est√£o com as unidades amostrais nas linhas e vari√°veis preditoras nas colunas Verificar se as comunidades nos dataframes de composi√ß√£o de esp√©cies e vari√°veis ambientais est√£o distribu√≠dos na mesma sequ√™ncia/ordem nos dois arquivos. Verificar se o nome das esp√©cies de aves no dataframe de composi√ß√£o de esp√©cies √© id√™ntico ao nome das esp√©cies na filogenia. 13.4 An√°lise da dimens√£o riqueza da diversidade alfa filogen√©tica As m√©tricas de riqueza somam a quantidade da diferen√ßa filogen√©tica presente em uma comunidade (Tucker et al.¬†2016). 13.4.1 Phylogenetic diversity (PD, Faith 1992) Esta m√©trica √© definida pela soma do comprimento dos ramos conectando todas as esp√©cies na comunidade. √â a m√©trica mais conhecida e usada nos estudos de conserva√ß√£o e comunidade. Vamos conferir se os nomes das esp√©cies de aves no dataframe de composi√ß√£o s√£o os mesmos da filogenia - OK indica que os nomes est√£o corretos. Caso contr√°rio, verificar e arrumar. name.check(filogenia_aves, t(composicao_especies)) #&gt; [1] &quot;OK&quot; Os nomes das esp√©cies que est√£o na planilha s√£o iguais aos nomes das esp√©cies que est√£o na filogenia. Podemos continuar as an√°lises. Abaixo, demonstramos os c√≥digos no R para o c√°lculo de PD para as comunidades de aves. # Calculando a m√©trica de diversidade filogen√©tica proposta por Faith (1992). resultados_PD &lt;- pd(composicao_especies, filogenia_aves) # Mostra o valor de PD e riqueza de esp√©cies para cada comunidade. resultados_PD #&gt; PD SR #&gt; Com_1 1259.3151 27 #&gt; Com_2 1293.1521 26 #&gt; Com_3 1222.3102 25 #&gt; Com_4 1254.5410 25 #&gt; Com_5 1021.9670 22 #&gt; Com_6 856.7810 18 #&gt; Com_7 930.6452 15 #&gt; Com_8 678.9394 12 #&gt; Com_9 673.6288 13 #&gt; Com_10 599.6924 9 A comunidade 2 abriga a maior diversidade filogen√©tica com a composica√ß√£o de esp√©cies contemplando 1293,15 milh√µes de anos (i.e.¬†soma do comprimento dos ramos ligando todas as esp√©cies da comunidade). Por outro lado, a comunidade 10 abriga a menor diversidade filogen√©tica contemplando 599,69 milh√µes de anos. Importante, este √≠ndice √© correlacionado com a riqueza de esp√©cies. Discutiremos essa quest√£o na se√ß√£o de modelos nulos. 13.5 Phylogenetic Species Richness (PSR, Helmus et al.¬†2007) Esta m√©trica √© calculada multiplicando a riqueza de esp√©cies registrada na comunidade pela Phylogenetic Species Variability (PSV) da comunidade. PSR √© diretamente compar√°vel ao n√∫mero de esp√©cies na comunidade, mas inclui o parentesco filogen√©tico entre as esp√©cies. Abaixo, demonstramos os c√≥digos no R para o c√°lculo do PSR utilizando os dados das comunidades de aves. # An√°lise com dados de composi√ß√£o das esp√©cies nas comunidades. resultados_PSR &lt;- psr(composicao_especies,filogenia_aves) # Mostra os valores de PSR para cada comunidade. resultados_PSR #&gt; PSR SR vars #&gt; Com_1 18.084236 27 0.04537904 #&gt; Com_2 18.167183 26 0.04881734 #&gt; Com_3 16.230938 25 0.05205832 #&gt; Com_4 17.153972 25 0.05205832 #&gt; Com_5 13.981597 22 0.06060866 #&gt; Com_6 11.287030 18 0.06933707 #&gt; Com_7 10.279983 15 0.07398666 #&gt; Com_8 7.538134 12 0.07721118 #&gt; Com_9 8.060933 13 0.07627517 #&gt; Com_10 5.720063 9 0.07948474 13.6 Phylogenetic Endemism (PE, Rosauer et al.¬†2009) Esta m√©trica calcula a fra√ß√£o dos ramos restritas a regi√µes espec√≠ficas. PE identifica √°reas ou comunidades que abrigam componentes restritos da diversidade filogen√©tica. PE √© uma m√©trica proposta para auxiliar estudos de conserva√ß√£o estabelecendo crit√©rios para priorizar regi√µes a serem conservadas com base na import√¢ncia evolutiva (i.e.¬†partes da filog√™nia com distribui√ß√£o espacial limitada) das esp√©cies que ocorrem nestes locais (Rosauer et al. 2009). Abaixo, demonstramos os c√≥digos no R para o c√°lculo do PE utilizando os dados das comunidades de aves. # Transformando data.frame em matriz. dados_matriz &lt;- as.matrix(composicao_especies) # An√°lise. resultados_PE &lt;- phylo_endemism(dados_matriz, filogenia_aves, weighted = TRUE) # Mostra os valores de PE para cada comunidade. resultados_PE #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 Com_9 #&gt; 232.09145 272.60106 210.22647 218.89037 146.99281 135.06423 148.65234 79.22402 77.95458 #&gt; Com_10 #&gt; 68.50266 O √≠ndice PE considera as 10 comunidades como o range espacial m√°ximo. Se todas as esp√©cies ocorressem nas 10 comunidades, o valor de PE seria 1 indicando baixo endemismo filogen√©tico. A comunidade 2 abriga um conjunto de esp√©cies cujo os ramos com distribui√ß√£o espacial restrita contemplam 272,6 milh√µes de anos. Por outro lado, a comunidade 10 abriga um conjunto de esp√©cies cujo os ramos com distribui√ß√£o espacial restrita contemplam 68,5 milh√µes de anos . Assim, as comunidades 2, 1 e 4 s√£o as √°reas que abrigam os maiores endemismo filogen√©ticos. 13.7 Species Evolutionary Distinctiveness (ED, Redding &amp; Mooers 2006) Esta m√©trica calcula qual √© a fra√ß√£o da √°rvore filogen√©tica que √© atribu√≠da para uma esp√©cie. ED reflete qu√£o evolutivamente isolada uma esp√©cie √© comparada com as outras esp√©cies na filogenia (Redding and Mooers 2006). ED √© uma m√©trica proposta para auxiliar estudos de conserva√ß√£o estabelecendo crit√©rios para priorizar as esp√©cies a serem conservadas com base na sua import√¢ncia evolutiva (exclusividade do comprimento do ramo) que n√£o √© comportilhada com outras esp√©cies. Portanto, apenas as informa√ß√µes da filogenia s√£o utilizadas para o c√°lculo de ED. Abaixo, demonstramos os c√≥digos no R para o c√°lculo do ED utilizando os dados das comunidades de aves. # An√°lise. resultados_ED &lt;- evol.distinct(filogenia_aves) # Mostra os valores de ED para cada esp√©cie. head(resultados_ED) #&gt; Species w #&gt; 1 Cranioleuca_pallida 14.07447 #&gt; 2 Synallaxis_ruficapilla 14.07447 #&gt; 3 Phacellodomus_ferrugineigula 20.05793 #&gt; 4 Cinclodes_pabsti 30.27020 #&gt; 5 Conopophaga_melanops 47.72685 #&gt; 6 Herpsilochmus_pileatus 26.40947 13.8 An√°lise da dimens√£o diverg√™ncia da diversidade alfa filogen√©tica As m√©tricas de diverg√™ncia utilizam a m√©dia da distribui√ß√£o das unidades extra√≠das da √°rvore filogen√©tica (Tucker et al. 2016). 13.9 Mean Pairwise Distance (MPD, Webb et al.¬†2002) Esta m√©trica utiliza a matriz de dist√¢ncia filogen√©tica para quantificar a dist√¢ncia m√©dia do parentesco entre pares de esp√©cies em uma comunidade. Este √≠ndice pode ser calculado considerando dados de incid√™ncia ou considerando dados de abund√¢ncia das esp√©cies. Importante, o MPD √© uma m√©trica que pesa a estrutura interna da filogenia (e.g.¬†rela√ß√µes entre esp√©cies de fam√≠lias diferentes). Abaixo, demonstramos os c√≥digos no R para o c√°lculo do MPD utilizando os dados das comunidades de aves. Vamos iniciar com dados de incid√™ncia (presen√ßa e aus√™ncia) das esp√©cies nas comunidades. A fun√ß√£o cophenetic gera uma matriz com as dist√¢ncias par a par entre as esp√©cies. Essas dist√¢ncias s√£o utilizadas para computar a dist√¢ncia m√©dia do parentesco das esp√©cies dentro das comunidades. resultados_MPD_PA &lt;- mpd(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = FALSE) # Mostra os valores de MPD para cada comunidade. resultados_MPD_PA #&gt; [1] 150.7914 157.3158 146.1622 154.5005 143.0727 141.1926 154.3145 141.4292 139.6198 143.0862 A comunidade 9 abriga a composi√ß√£o de esp√©cies mais aparentada (i.e.¬†menor diversidade filogen√©tica) com dist√¢ncia m√©dia entre as esp√©cies de 139,62 milh√µes de anos. Por outro lado, a comunidade 2 abriga a composi√ß√£o de esp√©cies menos aparentada (i.e.¬†maior diversidade filogen√©tica) com dist√¢ncia m√©dia de 157,31 milh√µes anos. Vamos refazer a an√°lise do MPD, mas desta vez, considerando a abund√¢ncia das esp√©cies de aves nas comunidades. Para isso, alteramos o argumento abundance.weighted = TRUE. # An√°lise com dados de abund√¢ncia das esp√©cies nas comunidades. resultados_MPD_AB &lt;- mpd(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = TRUE) # Mostra os valores de MPD para cada comunidade. resultados_MPD_AB #&gt; [1] 135.0704 143.3156 129.1940 142.8127 131.4027 128.7733 134.0380 132.6389 133.4041 117.8787 Percebam que pesando o comprimento do ramo pela abund√¢ncia das esp√©cies altera-se os valores do √≠ndice de diversidade filogen√©tica. Neste caso, a comunidade 10 passa a ser a comunidade que abriga a composi√ß√£o de esp√©cies mais aparentada (i.e.¬†menor diversidade filogen√©tica) com dist√¢ncia m√©dia entre as esp√©cies de 117,88 milh√µes de anos. 13.10 Mean Nearest Taxon Distance (MNTD, Webb et al.¬†2002) Esta m√©trica utiliza a matriz de dist√¢ncia filogen√©tica para quantificar a m√©dia dos valores m√≠nimos de parentesco entre pares de esp√©cies em uma comunidade. Ou seja, qual o valor m√©dio da dist√¢ncia para o vizinho mais pr√≥ximo. Este √≠ndice pode ser calculado considerando dados de incid√™ncia (presen√ßa e aus√™ncia) ou considerando dados de abund√¢ncia das esp√©cies. Diferente do MPD, o MNTD √© uma m√©trica terminal que pesa as rela√ß√µes nas pontas da filogenia (e.g.¬†esp√©cies dentro do mesmo g√™nero). Abaixo, demonstramos os c√≥digos no R para o c√°lculo do MNTD utilizando os dados das comunidades de aves. # An√°lise com dados de presen√ßa e aus√™ncia das esp√©cies nas comunidades. resultados_MNTD_PA &lt;- mntd(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = FALSE) # Mostra os valores de MPD para cada comunidade. resultados_MNTD_PA #&gt; [1] 63.89727 66.15828 72.96912 67.67170 64.93477 63.72337 93.54980 78.24876 62.34565 #&gt; [10] 112.23127 A comunidade 9 abriga a composi√ß√£o de esp√©cies com dist√¢ncia m√©dia do vizinho mais pr√≥ximo de 62,34 milh√µes de anos. Esse resultado indica que as esp√©cies terminais s√£o mais aparentada (e.g.¬†esp√©cies do mesmo g√™nero) do que a composi√ß√£o de esp√©cies da comunidade 10 onde a dist√¢ncia m√©dia do vizinho mais pr√≥ximo √© 112,23 milh√µes de anos (e.g.¬†esp√©cies de g√™neros diferentes). Vamos refazer a an√°lise do MNTD, mas desta vez, considerando a abund√¢ncia das esp√©cies de aves nas comunidades. # An√°lise com dados de abund√¢ncia das esp√©cies nas comunidades. resultados_MNTD_AB &lt;- mntd(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = TRUE) # Mostra os valores de MPD para cada comunidade. resultados_MNTD_AB #&gt; [1] 57.11745 53.02212 70.47864 59.12049 61.23225 60.26180 110.13043 97.35404 82.12099 #&gt; [10] 127.70084 13.11 Phylogenetic Species Variability (PSV, Helmus et al.¬†2007) Esta m√©trica estima a quantidade relativa dos comprimentos dos ramos n√£o compartilhados entre as comunidades. Quando todas as esp√©cies em uma amostra n√£o s√£o aparentadas (i.e.¬†filogenia em estrela), o valor do PSV √© 1 (um), indicando m√°xima variabilidade. Quando as esp√©cies tornando-se mais aparentadas, o valor de PSV aproxima-se de 0 (zero), indicando reduzida variabilidade. Os valores esperados de PSV s√£o estatisticamente independentes da riqueza de esp√©cies. üìù Importante: Os valores de PSV s√£o id√™nticos ao MPD quando a filogenia √© ultram√©trica. Abaixo, demonstramos os c√≥digos no R para o c√°lculo do PSV utilizando os dados das comunidades de aves. # An√°lise com dados de presen√ßa e aus√™ncia das esp√©cies nas comunidades. resultados_PSV &lt;- psv(composicao_especies,filogenia_aves) # Mostra os valores de PSV para cada comunidade. resultados_PSV #&gt; PSVs SR vars #&gt; Com_1 0.6697865 27 6.224834e-05 #&gt; Com_2 0.6987378 26 7.221499e-05 #&gt; Com_3 0.6492375 25 8.329332e-05 #&gt; Com_4 0.6861589 25 8.329332e-05 #&gt; Com_5 0.6355271 22 1.252245e-04 #&gt; Com_6 0.6270572 18 2.140033e-04 #&gt; Com_7 0.6853322 15 3.288296e-04 #&gt; Com_8 0.6281778 12 5.361887e-04 #&gt; Com_9 0.6200717 13 4.513324e-04 #&gt; Com_10 0.6355626 9 9.812931e-04 13.12 An√°lise da dimens√£o regularidade da diversidade alfa filogen√©tica As m√©tricas de regularidade caracterizam a varia√ß√£o das dist√¢ncias entre as esp√©cies em uma comunidade (Tucker et al. 2016). 13.13 Variance of Pairwise Distance (VPD, Clarke &amp; Warwick 2001) Esta m√©trica utiliza a matriz de dist√¢ncia filogen√©tica para quantificar a vari√¢ncia do parentesco entre pares de esp√©cies em uma comunidade (Clarke and Warwick 2001). Abaixo, demonstramos os c√≥digos no R para o c√°lculo do VPD utilizando os dados das comunidades de aves. # Transformando data.frame em matriz. dados_matriz &lt;- as.matrix(composicao_especies) # Transformar os dados para o formato requerido pelo pacote pez. dados &lt;- comparative.comm (filogenia_aves, dados_matriz) # An√°lise. resultados_VPD &lt;- .vpd(dados, cophenetic(filogenia_aves)) # Mostra os valores de VPD para cada comunidade. resultados_VPD #&gt; Com_1 Com_10 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 #&gt; 1619.4697 1031.8887 1828.1930 1630.4026 1317.9919 1465.1728 1519.6115 825.5349 1278.0076 #&gt; Com_9 #&gt; 1508.0495 13.14 Correla√ß√£o entre as m√©tricas de diversidade alfa filogen√©tica Vamos avaliar a correla√ß√£o entre os valores das m√©tricas de diversidade alfa filogen√©tica. Vamos criar um data.frame com os resultados das m√©tricas separados para as dimens√µes de riqueza e diverg√™ncia. N√£o iremos fazer para regularidade pois s√≥ apresentamos uma m√©trica de diversidade filogen√©tica nesta dimens√£o. # Vamos criar um data.frame com os resultados das m√©tricas da dimens√£o riqueza. metricas_riqueza &lt;- data.frame(riqueza = resultados_PD$SR, PD = resultados_PD$PD, PSR = resultados_PSR$PSR, PE = resultados_PE) # Gr√°fico mostrando na parte: # i) inferior a distribui√ß√£o dos pontos considerando as m√©tricas pareadas; # ii) superior o valor da correla√ß√£o de pearson; e # iii) diagonal a curva de densidade. ggpairs(metricas_riqueza, upper = list(continuous = wrap(&quot;cor&quot;, size = 4))) Percebam que as tr√™s m√©tricas apresentam correla√ß√µes pareadas acima de 96%. Isso indica que as m√©tricas s√£o redundantes. Portanto, n√£o h√° necessidade de calcular mais de uma m√©trica dentro da dimens√£o da riqueza filogen√©tica. Al√©m disso, as tr√™s m√©tricas de diversidade alfa filogen√©tica tamb√©m apresentam alta correla√ß√£o com a riqueza de esp√©cies. Veja abaixo na se√ß√£o de modelos nulos como controlar o efeito da riqueza de esp√©cies nas m√©tricas de diversidade filogen√©tica. Vamos avaliar a correla√ß√£o entre os valores das m√©tricas de diversidade alfa filog√©netica para a dimens√£o diverg√™ncia. # Vamos criar um data.frame com os resultados das m√©tricas da dimens√£o diverg√™ncia. metricas_divergencia &lt;- data.frame(riqueza = resultados_PD$SR, MPD = resultados_MPD_PA, MPD_AB = resultados_MPD_AB, MNTD = resultados_MNTD_PA, MNTD_AB = resultados_MNTD_AB, PSV = resultados_PSV$PSVs) # Gr√°fico. ggpairs(metricas_divergencia, upper = list(continuous = wrap(&quot;cor&quot;, size = 4))) Como mencionado, as m√©tricas MPD e PSV s√£o id√™nticas quando usamos uma filogenia ultram√©trica. Contudo, as m√©tricas de diverg√™ncia n√£o apresentam correla√ß√µes t√£o altas como as m√©tricas da dimens√£o riqueza, com exce√ß√£o do MNTD usando dados de incid√™ncia e abund√¢ncia que foram fortemente correlacionados (r = 0,9). Al√©m disso, estas m√©tricas n√£o s√£o t√£o afetadas pela riqueza de esp√©cies das comunidades como as m√©tricas da dimens√£o riqueza. 13.15 Associa√ß√£o entre as m√©tricas de diversidade alfa filogen√©tica e o gradiente de precipita√ß√£o Vamos avaliar e plotar a rela√ß√£o entre os valores de algumas m√©trica de diversidade alfa filogen√©tica (vari√°vel resposta) e os valores de precipita√ß√£o (vari√°vel preditora). # Vamos inserir os dados de precipita√ß√£o na planilha metrica_divergencia. metricas_divergencia$precipitacao &lt;- precipitacao_filogenetica$prec # Gr√°ficos. MPD_PA_plot &lt;- ggplot(metricas_divergencia, aes(precipitacao, MPD)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Mean Pairwise Distance\\n (MPD - Aus√™ncia e Presen√ßa)&quot;) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() MPD_AB_plot &lt;- ggplot(metricas_divergencia, aes(precipitacao, MPD_AB)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Mean Pairwise Distance\\n (MPD - Abund√¢ncia)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() MNTD_AP_plot &lt;- ggplot(metricas_divergencia, aes(precipitacao, MNTD)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Mean Nearest Taxon Distance\\n (MNTD - Aus√™ncia e Presen√ßa)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() MNTD_AB_plot &lt;- ggplot(metricas_divergencia, aes(precipitacao, MNTD_AB)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Mean Nearest Taxon Distance\\n (MNTD - Abund√¢ncia)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) ggarrange(MPD_PA_plot, MPD_AB_plot, MNTD_AP_plot, MNTD_AB_plot, ncol = 2, nrow = 2) O MPD, que avalia as rela√ß√µes de parentesco mais internas da filogenia (i.e.¬†rela√ß√µes entre esp√©cies de fam√≠lias diferentes) n√£o apresentou associa√ß√£o com o gradiente de precipita√ß√£o. Por outro lado, o MNTD que avalia as rela√ß√µes mais terminais da filogenia (i.e.¬†esp√©cies dentro do mesmo g√™nero) apresentou uma rela√ß√£o negativa com o gradiente de precipita√ß√£o. Interessante que a associa√ß√£o s√≥ foi significativa quando pesamos a an√°lise pela abund√¢ncia das esp√©cies nas comunidades. Esses resultados demonstram a import√¢ncia da sele√ß√£o das m√©tricas de diversidade filogen√©tica e tipos de dados (e.g.¬†incid√™ncia ou abund√¢ncia) utilizados na interpreta√ß√£o dos padr√µes observados na natureza. Vamos ver os gr√°ficos das m√©tricas da dimens√£o riqueza da diversidade alfa filogen√©tica # Vamos inserir os dados de precipita√ß√£o na planilha metrica_riqueza. metricas_riqueza$precipitacao &lt;- precipitacao$prec # Gr√°ficos. Riqueza_plot &lt;- ggplot(metricas_riqueza, aes(precipitacao, riqueza)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Riqueza de esp√©cies&quot;) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) PD_plot &lt;- ggplot(metricas_riqueza, aes(precipitacao, PD)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Diversidade Filogen√©tica\\n (Faith)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) PSR_plot &lt;- ggplot(metricas_riqueza, aes(precipitacao, PSR)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Phylogenetic Species Richness\\n (PSR)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) PE_plot &lt;- ggplot(metricas_riqueza, aes(precipitacao, PE)) + labs(x = &quot;Precipita√ß√£o (mm)&quot;, y = &quot;Phylogenetic Endemism\\n (PE)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) ggarrange(Riqueza_plot, PD_plot, PSR_plot, PE_plot, ncol = 2, nrow = 2) As tr√™s m√©tricas de diversidade filogen√©tica foram relacionadas com o gradiente de precipita√ß√£o. Esse resultado indica que comunidades localizadas em √°reas com maior precipita√ß√£o anual abrigaram maior diversidade filogen√©tica do que comunidades localizadas em √°reas mais secas. Contudo, estas m√©tricas s√£o dependentes da riqueza de esp√©cies nas comunidades. Veja abaixo a se√ß√£o de modelos nulos para entender como lidar com essa depend√™ncia. 13.16 M√©tricas de diversidade beta filogen√©tica M√©tricas de diversidade beta filogen√©tica utilizam dados de presen√ßa e aus√™ncia ou abund√¢ncia das esp√©cies para determinar um valor que representa a diferen√ßa entre comunidades em rela√ß√£o a hist√≥ria evolutiva das linhagens. 13.17 An√°lise da dimens√£o diverg√™ncia da diversidade beta filogen√©tica 13.18 Community Mean Pairwise Distance (COMDIST, Webb et al.¬†2008) Esta m√©trica √© uma extens√£o do MPD. COMDIST calcula a m√©dia da dist√¢ncia filogen√©tica entre as esp√©cies de duas comunidades (Webb, Ackerly, and Kembel 2008). COMDIST pode ser calculada usando dados de incid√™ncia (presen√ßa e aus√™ncia) ou abund√¢ncia das esp√©cies. Esta extens√£o do MPD tamb√©m √© conhecida na literatura como Dpw (Swenson 2011, 2014). Abaixo, demonstramos os c√≥digos no R para o c√°lculo do COMDIST utilizando os dados das comunidades de aves. # An√°lise com dados de presen√ßa e aus√™ncia das esp√©cies nas comunidades. resultados_Comdist_PA &lt;- comdist(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = FALSE) Vamos refazer a an√°lise do COMDIST, mas desta vez, considerando a abund√¢ncia das esp√©cies de aves nas comunidades. # An√°lise com dados de abund√¢ncia das esp√©cies nas comunidades. resultados_Comdist_AB &lt;- comdist(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = TRUE) 13.19 Community Mean Nearest Taxon Distance (COMDISTNT, Webb et al.¬†2008) Esta m√©trica √© uma extens√£o do MNTD. COMDISTNT calcula a m√©dia da dist√¢ncia filogen√©tica entre o t√°xon mais pr√≥ximo das esp√©cies de duas comunidades. COMDISTNT pode ser calculada usando dados de incid√™ncia ou abund√¢ncia das esp√©cies. Esta extens√£o do MNTD tamb√©m √© conhecida na literatura como Dnn (Swenson 2011). Abaixo, demonstramos os c√≥digos no R para o c√°lculo do COMDISTNT utilizando os dados das comunidades de aves. # An√°lise com dados de presen√ßa e aus√™ncia das esp√©cies nas comunidades. resultados_Comdistnt_PA &lt;- comdistnt(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = FALSE) Vamos refazer a an√°lise do COMDISTNT, mas desta vez, considerando a abund√¢ncia das esp√©cies de aves nas comunidades. # An√°lise com dados de abund√¢ncia das esp√©cies nas comunidades. resultados_Comdistnt_AB &lt;- comdistnt(composicao_especies, cophenetic(filogenia_aves), abundance.weighted = TRUE) 13.20 Correla√ß√£o entre as m√©tricas de diversidade beta filogen√©tica Vamos avaliar a correla√ß√£o entre os valores das m√©tricas da diversidade beta filogen√©tica para a dimens√£o diverg√™ncia. # Vamos criar um data.frame com os resultados das m√©tricas da dimens√£o # diverg√™ncia. metricas_divergencia_beta &lt;- data.frame( COMDIST_PA = as.numeric(resultados_Comdist_PA), COMDIST_AB = as.numeric(resultados_Comdist_AB), COMDISTNT_PA = as.numeric(resultados_Comdistnt_PA), COMDISTNT_AB = as.numeric(resultados_Comdistnt_AB)) # Gr√°fico. ggpairs(metricas_divergencia_beta, upper=list(continuous = wrap(&quot;cor&quot;, size = 4))) Os valores das m√©tricas de diverg√™ncia filogen√©tica beta apresentam correla√ß√µes mais baixas do que as m√©tricas da dimens√£o riqueza . Lembrem-se que COMDIST e COMDISTNT d√£o pesos diferentes para as rela√ß√µes de parentesco. COMDIST pesa as rela√ß√µes mais basais e internas da filogenia, enquanto COMDISTNT pesa as rela√ß√µes nas partes terminais da filogenia. Portanto, elas podem trazer informa√ß√µes complementares. 13.21 Associa√ß√£o entre as m√©tricas de diversidade beta filogen√©tica e o gradiente de precipita√ß√£o Vamos avaliar e plotar a rela√ß√£o entre os valores de algumas m√©trica de diversidade beta filogen√©tica (vari√°vel resposta) e os valores de precipita√ß√£o (vari√°vel preditora). # Precisamos calcular a dissimilaridade par a par da precipita√ß√£o entre # as comunidades. dis_prec &lt;- vegdist(precipitacao, &quot;euclidian&quot;) # Vamos inserir estes dados na planilha metrica_divergencia_beta. metricas_divergencia_beta$dis_prec &lt;- as.numeric(dis_prec) # Gr√°ficos. COMDIST_PA_plot &lt;- ggplot(metricas_divergencia_beta, aes(dis_prec, COMDIST_PA)) + labs(x = &quot;Diferen√ßa na precipita√ß√£o (mm)&quot;, y = &quot;COMDIST\\n (Presen√ßa e Aus√™ncia)&quot;) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() COMDIST_AB_plot &lt;- ggplot(metricas_divergencia_beta, aes(dis_prec, COMDIST_AB)) + labs(x = &quot;Diferen√ßa na precipita√ß√£o (mm)&quot;, y = &quot;COMDIST\\n (Abund√¢ncia)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) COMDISTNT_PA_plot &lt;- ggplot(metricas_divergencia_beta, aes(dis_prec, COMDISTNT_PA)) + labs(x = &quot;Diferen√ßa na precipita√ß√£o (mm)&quot;, y = &quot;COMDISTNT\\n (Aus√™ncia e Presen√ßa)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) COMDISTNT_AB_plot &lt;- ggplot(metricas_divergencia_beta, aes(dis_prec, COMDISTNT_AB)) + labs(x = &quot;Diferen√ßa na precipita√ß√£o (mm)&quot;, y = &quot; COMDISTNT\\n (Abund√¢ncia)&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() ggarrange(COMDIST_PA_plot, COMDIST_AB_plot, COMDISTNT_PA_plot, COMDISTNT_AB_plot, ncol = 2, nrow = 2) dev.off() #&gt; null device #&gt; 1 O COMDIST que avalia as rela√ß√µes de parentesco mais internas da filogenia (i.e.¬†rela√ß√µes entre esp√©cies de fam√≠lias diferentes) apresentou associa√ß√£o com o gradiente de precipita√ß√£o quando avaliado pesado pela abund√¢ncia das esp√©cies. Por outro lado, o COMDISTNT que avalia as rela√ß√µes mais terminais da filogenia (i.e.¬†esp√©cies dentro do mesmo g√™nero) apresentou uma rela√ß√£o negativa com o gradiente de precipita√ß√£o quando avaliado usando a incid√™ncia das esp√©cies. 13.22 An√°lise da dimens√£o riqueza da diversidade beta filogen√©tica 13.23 Phylogenetic index of beta diversity (Phylosor, Bryant et al.¬†2008) Phylosor √© uma m√©trica de similaridade e determina o comprimento total dos ramos da filogenia que √© compartilhado entre pares de comunidades (Bryant et al. 2008). Abaixo, demonstramos os c√≥digos no R para o c√°lculo do Phylosor utilizando os dados das comunidades de aves. # An√°lise com dados de presen√ßa e aus√™ncia das esp√©cies nas comunidades. resultados_Phylosor &lt;- phylosor(composicao_especies,filogenia_aves) # Mostra uma matriz triangular com a similaridade entre a fra√ß√£o dos ramos # compartilahdos entre duas comunidades resultados_Phylosor #&gt; Com_1 Com_2 Com_3 Com_4 Com_5 Com_6 Com_7 Com_8 #&gt; Com_2 0.7856828 #&gt; Com_3 0.8052839 0.7794964 #&gt; Com_4 0.7831520 0.8066793 0.8595462 #&gt; Com_5 0.8586780 0.6919478 0.8083230 0.7930266 #&gt; Com_6 0.6717414 0.5827551 0.6977734 0.7494945 0.7383098 #&gt; Com_7 0.7414284 0.7325727 0.6836231 0.7289449 0.7384561 0.6425717 #&gt; Com_8 0.6826177 0.6283918 0.6443193 0.6404373 0.7123197 0.5928097 0.6146854 #&gt; Com_9 0.6789983 0.6074676 0.6405220 0.6727656 0.7082867 0.6169977 0.6506880 0.9016007 #&gt; Com_10 0.6264594 0.5709671 0.6422800 0.5823317 0.6493935 0.5362575 0.6015983 0.9106658 #&gt; Com_9 #&gt; Com_2 #&gt; Com_3 #&gt; Com_4 #&gt; Com_5 #&gt; Com_6 #&gt; Com_7 #&gt; Com_8 #&gt; Com_9 #&gt; Com_10 0.8607104 13.24 Unique Fraction metric (UniFrac, Lozupone &amp; Knight 2005) UniFrac √© uma m√©trica de dissimilaridade e determina a fra√ß√£o √∫nica da filogenia contida em cada uma das duas comunidades (Lozupone and Knight 2005). Abaixo, demonstramos os c√≥digos no R para o c√°lculo da UniFrac utilizando os dados das comunidades de aves. # An√°lise com dados de presen√ßa e aus√™ncia das esp√©cies nas comunidades. resultados_UniFrac &lt;- unifrac(composicao_especies,filogenia_aves) 13.25 Vamos avaliar a correla√ß√£o entre Phylosor e Unifrac # Vamos criar um data.frame com os resultados das m√©tricas separados # para as dimens√µes de riqueza e diverg√™ncia. metricas_riqueza_beta &lt;- data.frame(Phylosor = as.numeric(resultados_Phylosor), UniFrac = as.numeric(resultados_UniFrac)) # Gr√°fico. ggpairs(metricas_riqueza_beta, upper=list(continuous = wrap(&quot;cor&quot;, size = 4))) Os valores de Phylosor e UniFrac apresenta 99% de correla√ß√£o entre eles. Portanto, essas duas m√©tricas identificam padr√µes id√™nticos e n√£o devem ser utilizadas simultaneamente. Gr√°ficos das m√©tricas da dimens√£o riqueza da diversidade beta filogen√©tica # Vamos inserir os dados de precipita√ß√£o na planilha metrica_riqueza_beta. metricas_riqueza_beta$dis_prec &lt;- as.numeric(dis_prec) # Gr√°ficos. # Phylosor. plot_phylosor &lt;- ggplot(metricas_riqueza_beta, aes(dis_prec, Phylosor)) + labs(x = &quot;Diferen√ßa na precipita√ß√£o (mm)&quot;, y = &quot;Phylosor&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + scale_y_continuous(limits = c(0, 1.0)) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) # Unifrag. plot_unifrac &lt;- ggplot(metricas_riqueza_beta, aes(dis_prec, UniFrac)) + labs(x = &quot;Diferen√ßa na precipita√ß√£o (mm)&quot;, y = &quot;UniFrac&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + scale_y_continuous(limits = c(0, 1.0)) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) ggarrange(plot_phylosor, plot_unifrac, ncol = 2) Phylosor (similaridade) e UniFrac (dissimilaridade) foram relacionadas com o gradiente de precipita√ß√£o. Comunidades com quantidade de precipita√ß√£o parecidas abrigaram linhagens similares enquanto comunidades que recebem quantidade de precipita√ß√£o diferentes abrigam linhagens mais distintas. 13.26 Parti√ß√£o da diversidade beta filogen√©tica As m√©tricas, Phylosor e UniFrac, podem ser particionadas em dois componentes (Baselga 2009; Leprieur et al. 2012): i) substitui√ß√£o (do ingl√™s turnover) de esp√©cies entre as comunidades; e ii) componente de aninhamento que representa a perda ou ganho de esp√©cies entre comunidades atribu√≠dos a diferen√ßa na riqueza de esp√©cies. A parti√ß√£o da diversidade beta nestes componentes permite avaliar diferentes hip√≥teses sobre os processos e mecanismos atuando na montagem de comunidades. Abaixo, demonstramos os c√≥digos no R para o c√°lculo da parti√ß√£o da diversidade beta filogen√©tica utilizando os dados das comunidades de aves. # Temos que transformar os dados para presen√ßa e aus√™ncia das esp√©cies # nas comunidades. dados_PA &lt;- decostand(composicao_especies, &quot;pa&quot;) # Parti√ß√£o dos componentes do Phylosor. resultados_Phylosor_particao &lt;- phylo.beta.pair(dados_PA, filogenia_aves, index.family = &quot;sorensen&quot;) Vamos refazer a an√°lise para UniFrac. # Parti√ß√£o dos componentes do UniFrac. resultados_UniFrac_particao &lt;- phylo.beta.pair(dados_PA, filogenia_aves, index.family = &quot;jaccard&quot;) # Resultado tem tr√™s matrizes: # i) dissimilaridade total (phylo.beta.jac); # ii) componente substitui√ß√£o de esp√©cies (phylo.beta.jtu); e # iii) componente aninhamento (phylo.beta.jne). # resultados_UniFrac_particao (para ver os resultados corra este comando) Gr√°fico com os resultados dos componentes substitui√ß√£o e aninhamento da diversidade beta filogen√©tica - Phylosor. # Vamos preparar os dados para o gr√°fico. particao_phylosor &lt;- data.frame( substituicao = as.numeric(resultados_Phylosor_particao$phylo.beta.sim), aninhamento = as.numeric(resultados_Phylosor_particao$phylo.beta.sne), sorensen = as.numeric(resultados_Phylosor_particao$phylo.beta.sor), dis_prec = as.numeric(dis_prec)) # Gr√°ficos. sorensen_plot &lt;- ggplot(particao_phylosor, aes(dis_prec, sorensen)) + labs(x = &quot;&quot;, y = &quot;Sorensen&quot;) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) subst_plot &lt;- ggplot(particao_phylosor, aes(dis_prec, substituicao)) + labs(x = &quot;Diferen√ßa na precipita√ß√£o\\n (mm)&quot;, y = &quot;Componente Substitui√ß√£o&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) aninha_plot &lt;- ggplot(particao_phylosor, aes(dis_prec, aninhamento)) + labs(x = &quot;&quot;, y = &quot;Componente aninhamento&quot;, size = 8) + geom_point(size = 4, shape = 19, col = &quot;darkorange&quot;) + tema_livro() + geom_smooth(method = lm, se = FALSE, color = &quot;black&quot;) ggarrange(sorensen_plot, subst_plot, aninha_plot, ncol = 3, nrow = 1) dev.off() #&gt; null device #&gt; 1 Percebam que o componente substitui√ß√£o √© maior entre comunidades que apresentam diferen√ßas altas na quantidade de precipita√ß√£o, enquanto o componente aninhamento √© maior entre as comunidades que apresentam quantidade similar de precipita√ß√£o. 13.27 Modelos Nulos Em muitos casos, os valores de diversidade filogen√©tica s√£o correlacionados com a riqueza de esp√©cies nas comunidades. Por exemplo, se um pesquisador relata que duas comunidades apresentam diferentes valores de PD, √© imposs√≠vel saber se esta diferen√ßa √© simplesmente porque elas t√™m diferentes valores de riqueza de esp√©cies ou se h√° algum fator fundamental sobre a informa√ß√£o filogen√©tica que √© importante. Outra quest√£o abordada nos estudos de montagem das comunidades √© saber se os valores observados para as m√©tricas (e.g.¬†MPD ou MNTD) relacionadas com a estrutura filogen√©tica das comunidades seriam diferentes se a coloniza√ß√£o das esp√©cies do pool regional fosse aleat√≥ria? Os modelos nulos respondem estas perguntas. Contudo, a defini√ß√£o do pool regional n√£o √© uma tarefa trivial (Lessard et al. 2012; Carstensen et al. 2013). Os modelos nulos s√£o constru√≠dos considerando processos ecol√≥gicos ou evolutivos de interesse. Eles geram padr√µes que s√£o baseados na aleatoriza√ß√£o dos dados ecol√≥gicos ou amostragens aleat√≥rias de uma distribui√ß√£o conhecida ou hip√≥tetica (N. J. Gotelli and Graves 1996). Neste caso, alguns elementos dos dados (como colunas ou linhas) s√£o mantidos constantes, e outros s√£o permitidos variar aleatoriamente para criar novos padr√µes. O principal motivo para a constru√ß√£o de modelos nulos √© produzir um padr√£o que seria esperado na aus√™ncia de um mecanismo ecol√≥gico espec√≠fico (N. J. Gotelli and Graves 1996). Contudo, ressaltamos que os modelos nulos podem revelar padr√µes n√£o comuns, mas eles n√£o podem determinar os mecanismos respons√°veis por gerar estes padr√µes (N. J. Gotelli and Graves 1996). Os modelos nulos empregados para contrapor os padr√µes observados pelas m√©tricas de diversidade filogen√©tica utilizam a aleatoriza√ß√£o dos dados de duas formas principais: i) aleatorizando o nome das esp√©cies na √°rvore filogen√©tica mantendo a estrutura e composi√ß√£o da matriz de co-ocorr√™ncia das esp√©cies e o comprimento dos ramos da √°rvore inalterados; e ii) aleatorizando as linhas e/ou colunas da matriz de co-ocorr√™ncia das esp√©cies (N. J. Gotelli 2000; Ulrich and Gotelli 2010). De forma geral, nas an√°lises de diversidade filogen√©tica as aleatoriza√ß√µes s√£o repetidas 999 vezes (pode ser mais ou menos a crit√©rio do pesquisador) e calcula-se a m√©dia e o desvio padr√£o dos valores gerados pelo modelos. Com estes dados, calcula-se o tamanho do efeito padronizado (do ingl√™s Standardized Effect Size - SES) utilizando a seguinte f√≥rmula: SES = (valor observado - m√©dia dos valores gerados na aleatoriza√ß√£o)/ desvio padr√£o dos valores gerados na aleatoriza√ß√£o Os valores de SES s√£o utilizados para rejeitar ou n√£o a hip√≥tese nula de que o padr√£o observado difere do esperado pelo acaso. Contudo, tenha em mente que a defini√ß√£o do esquema de aleatoriza√ß√£o dos modelos nulos n√£o √© meramente uma quest√£o t√©cnica (G√∂tzenberger et al. 2011). A defini√ß√£o do esquema de aleatoriza√ß√£o ir√° determinar quais os mecanismos ecol√≥gicos s√£o permitidos ou exclu√≠dos no modelo nulo (G√∂tzenberger et al. 2011). Consequentemente, ele estar√° avaliando diferentes hip√≥teses nulas. Abaixo, demonstramos os c√≥digos no R para calcular os modelos nulos para as m√©tricas de diversidade filogen√©tica. 13.28 Nearest Relative Index (NRI) ou Standardized Effect Size of MPD (Webb et al.¬†2008) Esta m√©trica calcula o tamanho do efeito padronizado para a m√©trica MPD. Contudo, NRI √© calculado multiplicando os resultados do SES por -1. Valores positivos de NRI indicam agrupamento filogen√©tico e valores negativos de NRI indicam dispers√£o filogen√©tica. # NRI ou SES_MPD. resultados_SES_MPD &lt;- ses.mpd(composicao_especies, cophenetic(filogenia_aves), null.model = &quot;taxa.labels&quot;, abundance.weighted = FALSE, runs = 999) # Mostra a riqueza de esp√©ices,MPD observado, m√©dia e desvio padr√£o dos # valores de MPD das aleatoriza√ß√µes, SES e o valor de p. head(resultados_SES_MPD) #&gt; ntaxa mpd.obs mpd.rand.mean mpd.rand.sd mpd.obs.rank mpd.obs.z mpd.obs.p runs #&gt; Com_1 27 150.7914 153.9953 3.891718 215 -0.8232597 0.215 999 #&gt; Com_2 26 157.3158 153.5833 4.367399 770 0.8546215 0.770 999 #&gt; Com_3 25 146.1622 153.9931 4.476428 52 -1.7493791 0.052 999 #&gt; Com_4 25 154.5005 153.5113 4.720348 551 0.2095591 0.551 999 #&gt; Com_5 22 143.0727 153.7490 5.294432 24 -2.0165115 0.024 999 #&gt; Com_6 18 141.1926 153.9709 6.951990 34 -1.8380846 0.034 999 Veja a ajuda destea fun√ß√£o usando?ses.mpd para ver todas as possibilidades de modelos nulos dispon√≠veis. 13.29 Nearest Taxon Index (NTI) ou Standardized Effect Size of MNTD (Webb et al.¬†2008) Esta m√©trica calcula o tamanho do efeito padronizado para a m√©trica MNTD. Contudo, NTI √© calculado multiplicando os resultados do SES por -1. Valores positivos de NTI indicam agrupamento filogen√©tico e valores negativos de NTI indicam dispers√£o filogen√©tica. # NTI ou SES_MNTD. resultados_SES_MNTD &lt;- ses.mntd(composicao_especies, cophenetic(filogenia_aves), null.model = &quot;taxa.labels&quot;, abundance.weighted = FALSE, runs = 999) # Mostra a riqueza de esp√©ices,MNTD observado, m√©dia e desvio padr√£o dos # valores de MNTD das aleatoriza√ß√µes, SES e o valor de p. head(resultados_SES_MNTD) #&gt; ntaxa mntd.obs mntd.rand.mean mntd.rand.sd mntd.obs.rank mntd.obs.z mntd.obs.p runs #&gt; Com_1 27 63.89727 63.30504 6.864478 518 0.08627467 0.518 999 #&gt; Com_2 26 66.15828 64.81499 7.217753 575 0.18610860 0.575 999 #&gt; Com_3 25 72.96912 65.76333 7.754651 811 0.92922217 0.811 999 #&gt; Com_4 25 67.67170 65.70886 7.752673 600 0.25318258 0.600 999 #&gt; Com_5 22 64.93477 69.46545 9.133114 305 -0.49607138 0.305 999 #&gt; Com_6 18 63.72337 76.12099 11.819687 162 -1.04889562 0.162 999 13.30 Standardized Effect Size of PD (Webb et al.¬†2008) Esta m√©trica calcula o tamanho do efeito padronizado para a m√©trica PD. # SES_PD. resultados_SES_PD &lt;- ses.pd(composicao_especies, filogenia_aves, null.model = &quot;independentswap&quot;, runs = 999) # Mostra a riqueza de esp√©ices,MNTD observado, m√©dia e desvio padr√£o dos # valores de PD das aleatoriza√ß√µes, SES e o valor de p. head(resultados_SES_PD) #&gt; ntaxa pd.obs pd.rand.mean pd.rand.sd pd.obs.rank pd.obs.z pd.obs.p runs #&gt; Com_1 27 1259.315 1271.5674 67.73874 444 -0.1808764 0.444 999 #&gt; Com_2 26 1293.152 1240.2776 69.17211 783 0.7643905 0.783 999 #&gt; Com_3 25 1222.310 1204.9035 67.51583 590 0.2578167 0.590 999 #&gt; Com_4 25 1254.541 1202.2728 65.90821 772 0.7930463 0.772 999 #&gt; Com_5 22 1021.967 1094.2347 65.59779 129 -1.1016782 0.129 999 #&gt; Com_6 18 856.781 951.3769 65.57431 72 -1.4425755 0.072 999 13.31 Standardized Effect Size N√£o h√° pacotes que calculam o SES para a m√©trica Phylosor. Assim, iremos usar a fun√ß√£o phylosor.rnd()para criar modelos nulos para o Physolor, e em seguida, iremos usar uma fun√ß√£o para calcular os valores de SES e os valores de P. # Modelo nulo que rearranja o nome das esp√©cies na filogenia. modelos_nulo &lt;- phylosor.rnd(composicao_especies, filogenia_aves, null.model = &quot;taxa.labels&quot;, runs = 9) # Fun√ß√£o para calcular o SES eo valor de P. ses.physo &lt;- function(obs, nulo_phylosor){ nulo_phylosor &lt;- t(as.data.frame(lapply (nulo_phylosor, as.vector))) physo.obs &lt;- as.numeric(obs) physo.mean &lt;- apply(nulo_phylosor, MARGIN = 2, FUN = mean, na.rm = TRUE) physo.sd &lt;- apply(nulo_phylosor, MARGIN = 2, FUN = sd, na.rm = TRUE) physo.ses &lt;- (physo.obs - physo.mean)/physo.sd physo.obs.rank &lt;- apply(X = rbind(physo.obs, nulo_phylosor), MARGIN = 2, FUN = rank)[1, ] physo.obs.rank &lt;- ifelse(is.na(physo.mean), NA, physo.obs.rank) data.frame(physo.obs, physo.mean, physo.sd, physo.obs.rank, physo.ses, physo.obs.p = physo.obs.rank/ (dim(nulo_phylosor)[1] + 1)) } resultados &lt;- ses.physo (resultados_Phylosor, modelos_nulo) head(resultados) #&gt; physo.obs physo.mean physo.sd physo.obs.rank physo.ses physo.obs.p #&gt; 1 0.7856828 0.8161982 0.04667325 4 -0.6538076 0.4 #&gt; 2 0.8052839 0.8767804 0.03480329 1 -2.0543045 0.1 #&gt; 3 0.7831520 0.8051510 0.03618897 4 -0.6078898 0.4 #&gt; 4 0.8586780 0.8682653 0.03871925 4 -0.2476110 0.4 #&gt; 5 0.6717414 0.7472615 0.04222288 1 -1.7886082 0.1 #&gt; 6 0.7414284 0.6764137 0.03653558 10 1.7794910 1.0 13.31.1 Para se aprofundar Recomendamos aos interessados os livros: i) Swenson (2014) Functional and Phylogenetic Ecology in R; ii) Paradis (2012) Analysis of Phylogenetics and Evolution in R; iii) Cadotte &amp; Davies (2016) Phylogenies in Ecology, iv) Gotelli &amp; Graves (1996) Null Models in Ecology; e v) Magurran &amp; McGill (2011) Biological Diversity Frontiers in Measurement and Assessment. Refer√™ncias "],["cap14.html", "Cap√≠tulo 14 Diversidade Funcional 14.1 Aspectos te√≥ricos 14.2 Definindo a dis(similaridade) entre esp√©cies 14.3 M√©tricas de diversidade funcional (alpha) 14.4 M√©tricas de diversidade funcional (beta) 14.5 Varia√ß√£o Intraspec√≠fica", " Cap√≠tulo 14 Diversidade Funcional Pr√©-requisitos do cap√≠tulo ## Pacotes library(FD) library(ade4) library(ecodados) library(gridExtra) library(ggplot2) library(ggrepel) library(tidyverse) library(picante) library(vegan) library(SYNCSA) library(GGally) library(FD) library(betapart) library(nlme) library(ape) library(TPD) library(cati) library(kableExtra) ## Dados e fun√ß√µes necess√°rias comun_fren_dat &lt;- ecodados::fundiv_frenette2012a_comu ambie_fren_dat &lt;- ecodados::fundiv_frenette2012a_amb trait_fren_dat &lt;- ecodados::fundiv_frenette2012a_trait trait_dat &lt;- ecodados::fundiv_barbaro2009a_trait comun_dat &lt;- ecodados::fundiv_barbaro2009a_comu ambie_dat &lt;- ecodados::fundiv_barbaro2009a_amb trait_baselga &lt;- ecodados::trait_baselga comm_baselga &lt;- ecodados::comm_baselga anuros_comm &lt;- ecodados::anuros_comm traits &lt;- ecodados::traits env &lt;- ecodados::env # ecodados::wITV # funtion: wITV 14.1 Aspectos te√≥ricos At√© a d√©cada de 1990, a teoria ecol√≥gica investigava basicamente quais processos determinavam a abund√¢ncia e riqueza de esp√©cies no espa√ßo e tempo. As d√©cadas de 1980 e 1990 foram marcadas por intensos debates sobre as regras de montagem de comunidades e como intera√ß√µes e filtros ambientais determinavam a coexist√™ncia de esp√©cies (Strong et al. 1984). Por√©m, a d√©cada 2000 foi marcada pelo uso mais expl√≠cito da caracter√≠sticas das esp√©cies como uma vari√°vel fundamental tanto para explicar como a distribui√ß√£o dos organismos seria afetada pelo ambiente, quanto para entender como tais esp√©cies afetariam o ecossistema (Dƒ±ÃÅaz and Cabido 2001; Brian J. McGill et al. 2006). O primeiro estudo que utilizou o termo Diversidade Funcional foi publicado por Williams (1967), que comparou esp√©cies de na√∫plios filogen√©ticamente relacionadas e demonstrou que elas possuem alta plasticidade funcional que favorecem ampla varia√ß√£o de comportamentos e, desse modo, permitem que sejam esp√©cies generalistas em ambientes em contante mudan√ßa. A unidade b√°sica desses estudos, o atributo funcional (do ingl√™s ‚Äúfunctional trait‚Äù), √© definido como uma propriedade mensur√°vel dos organismos (geralmente em n√≠vel individual) que represente caracter√≠sticas morfol√≥gicas, fisiol√≥gicas ou fenol√≥gicas que afetam a aptid√£o alterando aspectos do crescimento, reprodu√ß√£o e sobreviv√™ncia (Violle et al. 2007). Mais especificamente, o atributo funcional pode ser divido em atributo efeito (i.e., atributos do organismo que afetam condi√ß√µes ambientais ou propriedades do ecossistema) e resposta (i.e., atributos do organismo que variam em resposta a condi√ß√µes ambientais) (Violle et al. 2007). Dessa forma, as medidas de diversidade passam a ser representadas n√£o somente por diferen√ßas no n√∫mero e na quantidade de esp√©cies, mas pelas diferen√ßas e/ou semelhan√ßas dos atributos funcionais das esp√©cies dentro e entre localidades. Assim, a varia√ß√£o no grau de express√£o de diferentes atributos funcionais entre diferentes popula√ß√µes, comunidades ou ecossistemas √© definida como Diversidade Funcional (sensu Garnier, Navas, and Grigulis 2015). Por√©m, a diversidade funcional n√£o deve ser usada como medida √∫nica, uma vez que tais diferen√ßas entre os atributos funcionais pode ser medida a partir da abund√¢ncia relativa, riqueza e varia√ß√£o dos atributos funcionais. Desse modo, podemos dividir a diversidade funcional em tr√™s diferentes medidas: (1) riqueza funcional, (2) diverg√™ncia funcional, e (3) regularidade funcional (Vill√©ger, Mason, and Mouillot 2008). Existem dezenas de m√©tricas que calculam cada uma dessas dimens√µes da diversidadade funcional, mas se destacam aquelas baseadas em dendrograma (e.g., FD: Petchey and Gaston 2002) ou em medidas de dist√¢ncia (e.g., Vill√©ger, Mason, and Mouillot 2008). Assim como a diversidade taxon√¥mica 12, a diversidade funcional pode ser medida em componentes alfa e beta. A seguir, apresentamos diferentes maneiras de calcular a dist√¢ncia entre localidades tendo como base os atributos funcionais das esp√©cies e, al√©m disso, demonstramos como calcular algumas das m√©tricas de diversidade (alfa e beta) funcional mais usadas em ecologia. A parte final deste cap√≠tulo apresenta dois exemplos de como podemos testar hip√≥teses ecol√≥gicas comparando a diversidade funcional alfa e beta. 14.2 Definindo a dis(similaridade) entre esp√©cies Definir o qu√£o diferente ou semelhante s√£o duas esp√©cies que ocorrem em uma determinada localidade √© a base para calcular a diversidade alfa e beta funcional. Para isso, √© fundamental ter em mente que os atributos funcionais podem ser de v√°rios tipos como, por exemplo, cont√≠nuo (e.g., tamanho corporal em cent√≠metro), categ√≥rico (e.g., guilda: frug√≠voro, detrit√≠voro, etc.), ordinal (e.g., 1 para organismo at√© 5 cm, 2 para organismos entre 5 e 30 cm, e 3 para organismos maiores do que 30 cm), bin√°rios (e.g., presen√ßa ou aus√™ncia de espinho), entre outros (veja Tabela 1 em Gon√ßalves-Souza, Provete, et al. 2019). Por este motivo, a decis√£o do m√©todo de dist√¢ncia s√≥ ser√° poss√≠vel ap√≥s o reconhecimento dos tipos de atributos funcionais escolhidos. Em linhas gerais, para vari√°veis cont√≠nuas a dist√¢ncia euclideana √© a melhor op√ß√£o, enquanto para os outros tipos de vari√°veis ou para conjuntos de atributos com mais de um tipo de vari√°vel, a dist√¢ncia de Gower geralmente deve ser a melhor op√ß√£o (Sandrine Pavoine et al. 2009). 14.2.0.1 Exemplo pr√°tico Exemplo1: vari√°veis cont√≠nuas Vamos utilizar um conjunto de dados com atributos cont√≠nuos (e.g., √°rea foliar espec√≠fica, massa foliar seca) de 34 esp√©cies de plantas em um gradiente de aridez (Frenette-Dussault et al. 2012). Diversas an√°lises funcionais podem ser afetadas por valores extremos ou pela diferen√ßa de unidade/escala entre as vari√°veis utilizadas. Por este motivo, √© importante padronizar a matriz de atributos com m√©dia 0 e desvio padr√£o 1. Esta padroniza√ß√£o √© necess√°ria tanto para fazer uma PCA como para PCoA 9. Pergunta Quais s√£o as esp√©cies de plantas mais semelhantes? (Neste caso, sem predi√ß√£o, pois representa uma avalia√ß√£o explorat√≥ria com as caracter√≠sticas funcionais das esp√©cies) Vari√°veis Dependentes: atributos funcionais (matriz de atributos cont√≠nuos por esp√©cie: trait_fren_dat) ## 1. Padroniza√ß√£o dos dados trait_pad &lt;- decostand(trait_fren_dat, &quot;standardize&quot;) euclid_dis &lt;- vegdist(trait_pad, &quot;euclidean&quot;) ## 2. PCoA # Resultados s√£o id√™nticos aos resultados de uma PCA. pcoa_traits_cont &lt;- pcoa(euclid_dis, correction=&quot;cailliez&quot;) ## 3. Exportandos dados para gr√°fico # Ao usar &#39;[,1:2]&#39; voc√™ ir√° selecionar os dois primeiros eixos. eixos_cont &lt;- as.data.frame(pcoa_traits_cont$vectors[,1:2]) ## 4. Gr√°fico de ordena√ß√£o eixos_cont %&gt;% ggplot(aes(x=Axis.1, y=Axis.2)) + geom_point(pch=21, size=4, color = &quot;black&quot;, alpha = 0.7, fill=&quot;#525252&quot;) + geom_text_repel(aes(Axis.1, Axis.2, label = rownames(eixos_cont))) + xlab(&quot;PCO 1&quot;) + ylab(&quot;PCO 2&quot;) + theme(axis.title.x = element_text(face=&quot;bold&quot;, size=14), axis.text.x = element_text(vjust=0.5, size=12)) + theme(axis.title.y = element_text(face=&quot;bold&quot;, size=14), axis.text.y = element_text(vjust=0.5, size=12)) + geom_hline(yintercept = 0, linetype=2) + geom_vline(xintercept = 0, linetype=2)+ theme(legend.position = &quot;top&quot;, legend.title=element_blank()) + tema_livro()-&gt; plot_trait_cont plot_trait_cont Exemplo 2: vari√°veis categ√≥ricas Ao contr√°rio dos dados cont√≠nuos, para dados categ√≥ricos n√£o √© poss√≠vel utilizar PCA. No pr√≥ximo exemplo, utilizamos atributos funcionais de besouros distribu√≠dos na Europa (Barbaro and Van Halder 2009). Esses dados s√£o categ√≥ricos e incluem atributos como per√≠odo de atividade (noturno, diurno, dioturno), tend√™ncia da popula√ß√£o na europa (est√°vel, aumentando, diminu√≠ndo), entre outros. Pergunta: Quais s√£o as esp√©cies de besouros mais semelhantes? (Neste caso, sem predi√ß√£o, pois representa uma avalia√ß√£o explorat√≥ria com as caracter√≠sticas funcionais das esp√©cies) Vari√°veis Dependentes: atributos funcionais (matriz de atributos categ√≥ricos por esp√©cie: trait_dat) # 1. Selecionar somente os atributos categ√≥ricos trait_dat %&gt;% dplyr::select_if(is.character) -&gt; trait_cat # 2. Calcular a dist√¢ncia de Gower dist_categ &lt;- gowdis(trait_cat) # 3. PCoA da matriz de dist√¢ncia funcional (Gower) pcoa_traits_cat &lt;- pcoa(dist_categ, correction=&quot;cailliez&quot;) # 4. Exportar dados (escores) para ggiplot eixos_cat &lt;- as.data.frame(pcoa_traits_cat$vectors[,1:2]) # Selecionar os dois primeiros eixos # 5. Gr√°fico de ordena√ß√£o eixos_cat %&gt;% ggplot(aes(x=Axis.1, y=Axis.2)) + geom_point(pch=21, size=4, alpha = 0.7, color = &quot;black&quot;, fill=&quot;cyan4&quot;) + geom_text_repel(aes(Axis.1, Axis.2, label = rownames(eixos_cat))) + xlab(&quot;PCO 1&quot;) + ylab(&quot;PCO 2&quot;) + theme(axis.title.x = element_text(face=&quot;bold&quot;, size=14), axis.text.x = element_text(vjust=0.5, size=12)) + theme(axis.title.y = element_text(face=&quot;bold&quot;, size=14), axis.text.y = element_text(vjust=0.5, size=12)) + geom_hline(yintercept = 0, linetype=2) + geom_vline(xintercept = 0, linetype=2)+ theme(legend.position = &quot;top&quot;, legend.title=element_blank()) + tema_livro() + ggtitle(&quot;Dados categ√≥ricos&quot;)-&gt; plot_trait_cat plot_trait_cat Exemplo 3: vari√°veis mistas Em casos mais complexos, a pesquisa inclui diversos atributos funcionais com natureza diferente, como atributos cont√≠nuos, categ√≥ricos, ordinais, circulares, entre outros. Desse modo, √© poss√≠vel utilizar medidas como Gower (FD::gowdis). Por√©m, existe uma alternativa mais apropriada que generalizou coeficiente de Gower para tratar cada conjunto de vari√°veis de acordo com sua natureza (Sandrine Pavoine et al. 2009). Vamos usar o mesmo conjunto de dados que foram considerados no exemplo anterior. Por√©m, ao inv√©s de utilizar somente as vari√°veis categ√≥ricas, usaremos todas elas. O primeiro passo √© identificar para o programa as classes apropriadas para cada tipo de vari√°vel e, al√©m disso, preparar os dados para a fun√ß√£o ade4::dist.ktab. Pergunta Quais s√£o as esp√©cies de besouros mais semelhantes? (Neste caso, sem predi√ß√£o, pois representa uma avalia√ß√£o explorat√≥ria com as caracter√≠sticas funcionais das esp√©cies) Vari√°veis Dependentes: atributos funcionais (matriz de atributos cont√≠nuos e categ√≥ricos por esp√©cie: trait_dat) ## 1. Verifique a classe de todos os traits e veja se est√£o de acordo com sua expectativa trait_dat %&gt;% dplyr::summarise_all(class) %&gt;% tidyr::gather(variable, class) #&gt; variable class #&gt; 1 trend character #&gt; 2 redlist character #&gt; 3 regio integer #&gt; 4 biog character #&gt; 5 activ character #&gt; 6 diet character #&gt; 7 winter character #&gt; 8 color character #&gt; 9 breed character #&gt; 10 body integer #&gt; 11 wing character #&gt; 12 period character ## 2. Neste exemplo, algumas vari√°veis que s√£o ordinais (regio e body) # foram reconhecidas como num√©ricas ou categ√≥ricas. trait_dat$regio &lt;- as.ordered(trait_dat$regio) trait_dat$body &lt;- as.ordered(trait_dat$body) ## 3. Combinar cada conjunto de atributos de acordo com sua natureza em um # data.frame separado. # 3.1. Categ√≥ricos. trait_categ &lt;- cbind.data.frame(trend=trait_dat$trend, redlist=trait_dat$redlist, biog=trait_dat$biog, activ=trait_dat$activ, diet=trait_dat$diet, winter=trait_dat$winter,color=trait_dat$color, breed=trait_dat$breed,wing=trait_dat$wing, period=trait_dat$period) # 3.2 Ordinais. trait_ord &lt;- cbind.data.frame(regio=trait_dat$regio, body=trait_dat$body) rownames(trait_categ) &lt;- rownames(trait_dat) rownames(trait_ord) &lt;- rownames(trait_dat) # Agora, combinar os dois data.frames em uma lista chamada &quot;ktab&quot;. ktab_list &lt;- ktab.list.df(list(trait_categ, trait_ord)) # Por fim, calcular a dist√¢ncia funcional entre as esp√©cies. # Em &quot;type&quot;, a letra &quot;N&quot; indica vari√°vel categ√≥rica (ou nominal), # enquanto a letra &quot;O&quot; indica vari√°vel ordinal. dist_mist &lt;- dist.ktab(ktab_list, type= c(&quot;N&quot;, &quot;O&quot;)) ## Visualize os dados com uma PCoA (\\@ref(cap9)) pcoa_traits_mist &lt;- pcoa(dist_mist, correction=&quot;cailliez&quot;) eixos_mist &lt;- as.data.frame(pcoa_traits_mist$vectors[,1:2]) eixos_mist %&gt;% ggplot(aes(x=Axis.1, y=Axis.2)) + geom_point(pch=21, size=4, alpha = 0.7, color = &quot;black&quot;, fill=&quot;darkorange&quot;) + geom_text_repel(aes(Axis.1, Axis.2, label = rownames(eixos_mist)))+ xlab(&quot;PCO 1&quot;) + ylab(&quot;PCO 2&quot;) + theme(axis.title.x = element_text(face=&quot;bold&quot;, size=14), axis.text.x = element_text(vjust=0.5, size=12)) + theme(axis.title.y = element_text(face=&quot;bold&quot;, size=14), axis.text.y = element_text(vjust=0.5, size=12)) + geom_hline(yintercept = 0, linetype=2) + geom_vline(xintercept = 0, linetype=2)+ theme(legend.position = &quot;top&quot;, legend.title=element_blank()) + tema_livro() + ggtitle(&quot;Dados mistos&quot;) -&gt; plot_trait_mist plot_trait_mist Podemos combinar os dois gr√°ficos (baseado em vari√°veis categ√≥ricas e em vari√°veis mistas) para comparar as duas medidas de dist√¢ncia, uma somente com dados categ√≥ricos (FD::gower) e uma com dados categ√≥ricos e ordinais (ade4::dist.ktab). grid.arrange(plot_trait_cat, plot_trait_mist, ncol=2) 14.3 M√©tricas de diversidade funcional (alpha) 14.3.1 Riqueza funcional A riqueza funcional mede a quantidade de espa√ßo funcional preenchido pela esp√©cies de uma comunidade (Mason and Mouillot 2013). A estimativa desse espa√ßo pode ser calculada usando dengrogramas (Petchey and Gaston 2002) ou atrav√©s do m√©todo Convex Hull (Cornwell, Schwilk, and Ackerly 2006) que d√£o origem, respectivamente, as duas m√©tricas mais usadas: (1) Diversidade Funcional (FD) e (2) Riqueza Funcional (FRic). Os √≠ndices de riqueza funcional geralmente s√£o usados como indicadores do espa√ßo de nicho que √© potencialmente usado ou n√£o (Schleuter et al. 2010). 14.3.1.1 Exemplo pr√°tico Explica√ß√£o dos dados Os dados utilizados neste exemplo s√£o os mesmos do exemplo com dados mistos, i.e., categ√≥ricos e cont√≠nuos (objeto dist_mist). Pergunta Qual a rela√ß√£o entre riqueza de esp√©cies e diversidade funcional? Todos os √≠ndices s√£o correlacionados com a riqueza? Vari√°veis Dependentes: atributos funcionais e composi√ß√£o de esp√©cies para c√°lculo da diversidade funcional e riqueza em cada parcela. ## Estrutura dos dados # matriz de dist√¢ncia: dist√¢ncia entre as seis primeiras esp√©cies as.matrix(dist_mist)[1:6, 1:6] #&gt; sp1 sp2 sp3 sp4 sp5 sp6 #&gt; sp1 0.0000000 0.5000000 0.7107801 0.7771900 0.6107116 0.5041691 #&gt; sp2 0.5000000 0.0000000 0.6808389 0.8538292 0.7345988 0.6487320 #&gt; sp3 0.7107801 0.6808389 0.0000000 0.7179711 0.7381353 0.6527339 #&gt; sp4 0.7771900 0.8538292 0.7179711 0.0000000 0.5106682 0.6522593 #&gt; sp5 0.6107116 0.7345988 0.7381353 0.5106682 0.0000000 0.5177440 #&gt; sp6 0.5041691 0.6487320 0.6527339 0.6522593 0.5177440 0.0000000 # composi√ß√£o de esp√©cies: seis primeiras esp√©cies nas seis primeiras localidades head(comun_dat)[1:6, 1:6] #&gt; sp1 sp2 sp3 sp4 sp5 sp6 #&gt; 3 0 19 2 0 0 0 #&gt; 4 0 4 0 0 0 0 #&gt; 6 1 58 2 0 0 0 #&gt; 7 1 0 0 0 0 0 #&gt; 9 3 0 0 0 0 0 #&gt; 10 3 15 0 0 0 0 ## Antes de calcular as m√©tricas de diversidade funcional, vamos calcular # a riqueza de esp√©cies com intuito de compara√ß√£o entre m√©tricas. richness &lt;- dbFD(dist_mist, comun_dat)$nbsp #&gt; FRic: Dimensionality reduction was required. The last 17 PCoA axes (out of 19 in total) were removed. #&gt; FRic: Quality of the reduced-space representation = 0.3243851 #&gt; CWM: When &#39;x&#39; is a distance matrix, CWM cannot be calculated. head(richness) #&gt; 3 4 6 7 9 10 #&gt; 12 3 7 7 4 7 ## √â preciso definir uma dist√¢ncia apropriada (veja descri√ß√£o anterior) para os c√°lculos # abaixo # O √≠ndice &quot;Functional Richness&quot; s√≥ funciona para comunidades com 3 ou mais esp√©cies. # Caso voc√™ tenha comunidades com 1 ou 2 esp√©cies, o valor ser√° NA. fric &lt;- dbFD(dist_mist, comun_dat)$FRic #&gt; FRic: Dimensionality reduction was required. The last 17 PCoA axes (out of 19 in total) were removed. #&gt; FRic: Quality of the reduced-space representation = 0.3243851 #&gt; CWM: When &#39;x&#39; is a distance matrix, CWM cannot be calculated. head(fric) #&gt; 3 4 6 7 9 10 #&gt; 0.226236923 0.009033539 0.158760885 0.158529234 0.014290140 0.200075112 ## Functional Diversity # Passo 1: an√°lise de agrupamento para criar o dendrograma. dend &lt;- hclust(dist_mist, &quot;average&quot;) # Passo 2: transformar o dengrograma em um arquivo da classe phylo. tree_dend &lt;-as.phylo(dend) # Passo 3: calcular o valor da diversidade funcional. FD &lt;- pd(comun_dat, tree_dend)$PD head(FD) #&gt; [1] 3.590053 1.115574 2.255337 2.356478 1.472314 2.430329 14.3.2 Diverg√™ncia funcional A diverg√™ncia funcional √© uma medida que descreve a irregularidade na distribui√ß√£o dos valores dos atributos no volume do espa√ßo funcional ocupado por todas as esp√©cies de uma certa comunidade (Garnier, Navas, and Grigulis 2015). Para obter os valores de diverg√™ncia, o espa√ßo funcional √© calculado atrav√©s do m√©todo Convex Hull (Functional Divergence) ou do espa√ßo multidimensional calculado com um PCoA (Functional Dispersion). Nos dois casos, o valor da m√©trica representa a dist√¢ncia m√©dia das esp√©cies para o centro de gravidade ou centroide do espa√ßo funcional, ponderado pela abund√¢ncia relativa das esp√©cies (Vill√©ger, Mason, and Mouillot 2008; Lalibert√© and Legendre 2010). Desse modo, a diverg√™ncia funcional √© uma medida que calcula o grau de diferencia√ß√£o em que a distribui√ß√£o da abund√¢ncia maximiza a diverg√™ncia entre entre os atributos funcionais (Mason and Mouillot 2013). Em geral, estudos que usam esses √≠ndices buscam entender o grau de diferencia√ß√£o de recursos de esp√©cies que coexistem em uma comunidade (Garnier, Navas, and Grigulis 2015). ## Aqui, iremos utilizar a matriz de dist√¢ncia obtida dos dados # trait_dat (vari√°veis categ√≥ricas e ordinais) e nomeada como dist_mist. ## O √≠ndice &quot;Functional Divergence&quot; s√≥ √© calculado para comunidades com 3 ou mais esp√©cies # Caso voc√™ tenha comunidades com 1 ou 2 esp√©cies, a an√°lise ir√° retornar o valor &quot;NA&quot; fdiv &lt;- dbFD(dist_mist, comun_dat)$FDiv #&gt; FRic: Dimensionality reduction was required. The last 17 PCoA axes (out of 19 in total) were removed. #&gt; FRic: Quality of the reduced-space representation = 0.3243851 #&gt; CWM: When &#39;x&#39; is a distance matrix, CWM cannot be calculated. head(fdiv) #&gt; 3 4 6 7 9 10 #&gt; 0.9692023 0.8838557 0.4082808 0.9147644 0.9010790 0.6982640 # O √≠ndice &quot;Functional Dispersion&quot; atribui valor 0 para comunidades com 1 ou 2 esp√©cies fdis &lt;- dbFD(dist_mist, comun_dat)$FDis #&gt; FRic: Dimensionality reduction was required. The last 17 PCoA axes (out of 19 in total) were removed. #&gt; FRic: Quality of the reduced-space representation = 0.3243851 #&gt; CWM: When &#39;x&#39; is a distance matrix, CWM cannot be calculated. head(fdis) #&gt; 3 4 6 7 9 10 #&gt; 0.2977975 0.3203602 0.2218237 0.3261248 0.3683898 0.3910530 14.3.3 Regularidade funcional A regularidade funcional (do ingl√™s Functional Evenness) mede o qu√£o regular √© a distribui√ß√£o da abund√¢ncia dos valores dos atributos funcionais no espa√ßo funcional. Diferente dos outros m√©todos, a vers√£o multidimensional deste √≠ndice utiliza um m√©todo chamado Minimum Spanning Tree (MST) para conectar todas esp√©cies no espa√ßo funcional. A dist√¢ncia par-a-par das esp√©cies na MST √© ponderada pela abund√¢ncia relativa das esp√©cies e, desse modo, o valor final da regularidade funcional (FEve) vai variar de 0 (m√°xima irregularidade da distribui√ß√£o da abund√¢ncia ou dist√¢ncia funcional das esp√©cies) a 1 (m√°xima regularidade). ## Aqui, iremos utilizar a matriz de dist√¢ncia obtida dos dados trait_dat (vari√°veis categ√≥ricas e ordinais) e nomeada como dist_mist ## O √≠ndice &quot;Functional evenness&quot; s√≥ funciona para comunidades com 3 ou mais esp√©cies # Caso voc√™ tenha comunidades com 1 ou 2 esp√©cies, a an√°lise ir√° retornar o valor NA feve &lt;- dbFD(dist_mist, comun_dat)$FEve #&gt; FRic: Dimensionality reduction was required. The last 17 PCoA axes (out of 19 in total) were removed. #&gt; FRic: Quality of the reduced-space representation = 0.3243851 #&gt; CWM: When &#39;x&#39; is a distance matrix, CWM cannot be calculated. head(feve) #&gt; 3 4 6 7 9 10 #&gt; 0.4054808 0.5587917 0.5406140 0.6974712 0.9575697 0.6297941 ## Voc√™ pode criar uma tabela com os resultados de todas as m√©tricas metricas &lt;- data.frame(richness=richness, FD_gp = FD, fric = fric, fdiv = fdiv, fdis = fdis, feve = feve) head(metricas) #&gt; richness FD_gp fric fdiv fdis feve #&gt; 3 12 3.590053 0.226236923 0.9692023 0.2977975 0.4054808 #&gt; 4 3 1.115574 0.009033539 0.8838557 0.3203602 0.5587917 #&gt; 6 7 2.255337 0.158760885 0.4082808 0.2218237 0.5406140 #&gt; 7 7 2.356478 0.158529234 0.9147644 0.3261248 0.6974712 #&gt; 9 4 1.472314 0.014290140 0.9010790 0.3683898 0.9575697 #&gt; 10 7 2.430329 0.200075112 0.6982640 0.3910530 0.6297941 ### Gr√°fico para comparar o comportamento das m√©tricas ggpairs(metricas) Os resultados indicam que a Diversidade Funcional de Petchey &amp; Gaston (r = 0.985) e a riqueza funcional (r = 0.813) s√£o altamente correlacionadas com a riqueza de esp√©cies. Por√©m, a diverg√™ncia funcional, regularidade funcional e dispers√£o funcional n√£o est√£o correlacionadas com a riqueza de esp√©cies. A figura obtida com o comando ggpairs(metricas) representa uma matriz de correla√ß√£o comparando cada par de vari√°veis (neste caso, os √≠ndices de diversidade). No lado esquerdo da figura (abaixo da diagonal) s√£o representados scatterplots 6, a no lado direito (acima da diagonal) pode-se encontrar os valores das correla√ß√µes (r) entre os pares comparados. No caso das correla√ß√µes, quanto mais pr√≥ximo de +1 ou -1, mais forte √© a rela√ß√£o entre essas vari√°veis do par comparado. O gr√°fico de linhas na diagonal demonstra a densidade de cada vari√°veis individualmente 6. 14.4 M√©tricas de diversidade funcional (beta) Assim como na diversidade beta taxon√¥mica 12, a diversidade beta funcional √© uma medida que compara a composi√ß√£o (e a varia√ß√£o na composi√ß√£o) de atributos funcionais das esp√©cies entre duas ou mais localidades. Por√©m, assim como na medida tradicional taxon√¥mica (como Jaccard ou Sorensen), diferen√ßas na diversidade beta podem ser geradas pela mudan√ßa na identidade das esp√©cies (ou do atributo) ou na riqueza de esp√©cies (ou de atributos) entre duas localidades (Figura 1). Desse modo, √© poss√≠vel particionar a diversidade beta funcional em aninhamento e substitui√ß√£o (do ingl√™s turnover) 12. Al√©m disso, os c√°lculos da diversidade beta funcional podem ser realizados par-a-par (functional.beta.pair) ou para a compara√ß√µes de m√∫ltiplas localidades (funcional.beta.multi). Figura 1. Parti√ß√£o da diversidade beta taxon√¥mica (A) e funcional (B). Os tr√™s cen√°rios apresentados tanto para a diversidade beta taxon√¥mica como funcional representam, respectivamente, diversidade beta explicada somente por substitui√ß√£o, aninhamento e uma combina√ß√£o dos dois. Exemplo 4 Os dados no exemplo a seguir utilizam somente a informa√ß√£o de presen√ßa (1) ou aus√™ncia (0) das esp√©cies nas localidades. Neste exemplo hipot√©tico criado por Baselga et al.¬†(2021), foram amostradas 11 esp√©cies (sp1-sp11) em quatro localidades (A-D). Para cada esp√©cie, criamos dois atributos cont√≠nuos hipot√©ticos (trait1 e trait2). Pergunta Qual a contribui√ß√£o relativa do aninhamento e substitui√ß√£o para a diversidade beta? Vari√°veis Dependentes: atributos funcionais e composi√ß√£o de esp√©cies. ## Parti√ß√£o da Diversidade beta (M√©todo Baselga) fun_beta_multi &lt;- functional.beta.multi(x = comm_baselga, trait=trait_baselga, index=&quot;jaccard&quot;) fun_beta_multi #&gt; $funct.beta.JTU #&gt; [1] 0.7101449 #&gt; #&gt; $funct.beta.JNE #&gt; [1] 0.1509662 #&gt; #&gt; $funct.beta.JAC #&gt; [1] 0.8611111 ## Parti√ß√£o da Diversidade beta (M√©todo Baselga) fun_beta &lt;- functional.beta.pair(x = comm_baselga, trait=trait_baselga, index=&quot;jaccard&quot;) # Os comandos abaixo permitem extrair a matriz de dist√¢ncia (par-a-par) com a parti√ß√£o em substitui√ß√£o e nestedness fun_turnover &lt;- fun_beta$funct.beta.jne fun_nestedness &lt;- fun_beta$funct.beta.jtu fun_jaccard &lt;- fun_beta$funct.beta.jac # Gr√°fico de compara√ß√£o do substitui√ß√£o e aninhamento dat_betapart &lt;- data.frame(turnover=as.numeric(fun_turnover), nested = as.numeric(fun_nestedness)) dat_betapart %&gt;% ggplot(aes(x=turnover, y=nested)) + geom_point(pch=21, size=4, alpha = 0.7, color = &quot;black&quot;, fill=&quot;#525252&quot;) + xlab(&quot;Beta Diveristy (Substitui√ß√£o)&quot;) + ylab(&quot;Beta Diveristy (Aninhamento)&quot;) + theme(axis.title.x = element_text(face=&quot;bold&quot;, size=14), axis.text.x = element_text(vjust=0.5, size=12)) + theme(axis.title.y = element_text(face=&quot;bold&quot;, size=14), axis.text.y = element_text(vjust=0.5, size=12)) + theme(legend.position = &quot;top&quot;, legend.title=element_blank()) + tema_livro() -&gt; plot_betapart plot_betapart Os resultados da an√°lise de parti√ß√£o (fun_beta_multi) indicam que 82,5% (0,710 / 0,861) da varia√ß√£o na diversidade beta √© explicada pelo componente substitui√ß√£o, enquanto 17,5% (0,151 / 0,861) pelo componente aninhamento. As matrizes de dist√¢ncia obtidas na an√°lise par a par pode ser utilizadas para testar, a posteriori, a rela√ß√£o entre gradientes ambientais e diversidade beta funcional (mais detalhes abaixo). 14.4.1 Composi√ß√£o Funcional As medidas de diversidade beta funcional apresentadas acima fornecem matrizes de dist√¢ncia com compara√ß√µes par-a-par de localidades em termos da composi√ß√£o de atributos funcionais. Por√©m, muitas vezes o pesquisador quer medir o ‚Äúatributo m√©dio‚Äù da comunidade para investigar, por exemplo, se um determinado gradiente ambiental afeta a express√£o (em termos de abund√¢ncia ou densidade) de dado atributo funcional. Em geral, a medida utilizada √© o CWM (do ingl√™s Community Wegihed Means). O CWM √© basicamente uma m√©dia ponderada de um determinado atributo (coluna m na matriz T) em rela√ß√£o a abund√¢ncia de todas as esp√©cies que ocorrem na localidade n (matrix X). Para calcular no R a fun√ß√£o FD::functcomp usa somente as duas matrizes (T e X). Os leitores que pretendem usar essas m√©tricas devem ler cr√≠ticas em Peres-Neto et al. (2017). ## Matriz T head(trait_baselga) #&gt; Trait.1 Trait.2 #&gt; sp1 1 1 #&gt; sp2 1 2 #&gt; sp3 1 4 #&gt; sp4 2 1 #&gt; sp5 2 2 #&gt; sp6 3 3 ## Matriz X head(comm_baselga) #&gt; sp1 sp2 sp3 sp4 sp5 sp6 sp7 sp8 sp9 sp10 sp11 #&gt; A 1 1 0 1 1 0 0 0 0 0 0 #&gt; B 1 0 1 0 0 0 0 1 1 0 0 #&gt; C 0 0 0 0 0 1 1 0 0 1 1 #&gt; D 0 1 0 1 0 0 1 0 1 0 0 ## Fun√ß√£o functcomp calcula o cwm para combinar as matrizes T e X cwm_ex &lt;- functcomp(trait_baselga, as.matrix(comm_baselga)) cwm_ex #&gt; Trait.1 Trait.2 #&gt; A 1.5 1.5 #&gt; B 2.5 2.5 #&gt; C 4.0 4.0 #&gt; D 2.5 3.0 A matriz resultante cwm_es √© formada pelas localidades (linhas) e os atributos ‚Äúm√©dios‚Äù (colunas) nestas localidades. Essa matriz pode ser utilizada em diversas an√°lises como dbRDA, RDA ou RDA parcial 9. Na sequ√™ncia, vamos utilizar testes de hip√≥teses para entender como podemos calcular as diversidades funcional alfa e beta com outros testes estat√≠sticos apresentados neste livro. Exemplo 5 Neste exemplo, usaremos novamente os dados de 34 esp√©cies de plantas (Frenette-Dussault et al. 2012), mas agora vamos¬†testar o efeito de um gradiente de aridez sobre a diversidade alfa funcional. Pergunta O gradiente de aridez influencia a diverg√™ncia e regularidade funcional de plantas? Predi√ß√µes Predi√ß√£o 1: locais mais √°ridos possuem menor diverg√™ncia funcional de plantas (m√©trica escolhida: FDis) Predi√ß√£o 2: locais mais √∫midos possuem menor regularidade funcional de plantas (m√©trica escolhida: FEve) Vari√°veis Preditora: gradiente de aridez (matriz de vari√°veis ambientais por localidade: ambie_fren_dat) Dependentes: composi√ß√£o de esp√©cies (matriz de esp√©cies por localidade: comun_fren_dat) e atributos funcionais (matriz de atributos cont√≠nuos por esp√©cie: trait_fren_dat) ## Passo 1: calcular a dist√¢ncia funcional trait_pad &lt;- decostand(trait_fren_dat, &quot;standardize&quot;) euclid_dis &lt;- vegdist(trait_pad, &quot;euclidean&quot;) ## Passo 2: calcular a Diverg√™ncia funcional (FDis) e Regularidade Funcional (FEve) fdis &lt;- dbFD(euclid_dis, comun_fren_dat)$FDis# Fdis=0 em locais com somente uma esp√©cie #&gt; FRic: No dimensionality reduction was required. All 5 PCoA axes were kept as &#39;traits&#39;. #&gt; CWM: When &#39;x&#39; is a distance matrix, CWM cannot be calculated. feve &lt;- dbFD(euclid_dis, comun_fren_dat)$FEve #&gt; FRic: No dimensionality reduction was required. All 5 PCoA axes were kept as &#39;traits&#39;. #&gt; CWM: When &#39;x&#39; is a distance matrix, CWM cannot be calculated. ## Passo 3: Utilizar um modelo linear para comparar o efeito da aridez sobre FDis (predi√ß√£o 1) e FEve (predi√ß√£o 2) # Combinar dados em um data.frame. lm_dat &lt;- data.frame(aridez = ambie_fren_dat$Aridity, fdis = fdis, feve = feve) # Modelo 1 mod1 &lt;- lm(fdis ~ aridez, data = lm_dat) # conferir os pressupostos da an√°lise par(mfrow=c(2,2)) plot(mod1) # Conclus√£o: a aridez n√£o tem efeito sobre a diverg√™ncia funcional anova(mod1) #&gt; Analysis of Variance Table #&gt; #&gt; Response: fdis #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; aridez 1 0.2083 0.20834 0.9945 0.3241 #&gt; Residuals 44 9.2179 0.20950 # Modelo 2 mod2 &lt;- lm(feve ~ aridez, data = lm_dat) # conferir os pressupostos da an√°lise par(mfrow=c(2,2)) plot(mod2) # Conclus√£o: a aridez n√£o tem efeito sobre a regularidade funcional anova(mod2) #&gt; Analysis of Variance Table #&gt; #&gt; Response: feve #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; aridez 1 0.02098 0.020979 1.0447 0.3123 #&gt; Residuals 44 0.88353 0.020080 ## Passo 4: gr√°fico para visualizar os dois resultados # Gr√°fico modelo 1. lm_dat %&gt;% ggplot(aes(x=aridez, y=fdis)) + geom_point(pch=21, size=4, alpha = 0.7, color = &quot;black&quot;, fill=&quot;darkorange&quot;) + xlab(&quot;Aridez&quot;) + ylab(&quot;Diverg√™ncia Funcional (FDis)&quot;) + theme(axis.title.x = element_text(face=&quot;bold&quot;, size=14), axis.text.x = element_text(vjust=0.5, size=12)) + theme(axis.title.y = element_text(face=&quot;bold&quot;, size=14), axis.text.y = element_text(vjust=0.5, size=12)) + theme(legend.position = &quot;top&quot;, legend.title=element_blank())+ tema_livro() -&gt; plot_pred1 # Gr√°fico modelo 2. lm_dat %&gt;% ggplot(aes(x=aridez, y=feve)) + geom_point(pch=21, size=4, alpha = 0.7, color = &quot;black&quot;, fill=&quot;cyan4&quot;) + xlab(&quot;Aridez&quot;) + ylab(&quot;Regularidade Funcional (FEve)&quot;) + theme(axis.title.x = element_text(face=&quot;bold&quot;, size=14), axis.text.x = element_text(vjust=0.5, size=12)) + theme(axis.title.y = element_text(face=&quot;bold&quot;, size=14), axis.text.y = element_text(vjust=0.5, size=12)) + theme(legend.position = &quot;top&quot;, legend.title=element_blank()) + tema_livro() -&gt; plot_pred2 ## Visualiza√ß√£o dos dois gr√°ficos em um √∫nica janela grid.arrange(plot_pred1, plot_pred2, ncol=2) Os resultados dos modelos anova(mod1) e anova(mod2)indicam que o gradiente de aridez n√£o afeta a dispers√£o e regularidade funcional. Os detalhes para conferir os pressupostos das an√°lise foram descritos no 7. Exemplo 6 Agora, vamos utilizar novamente os dados de 34 esp√©cies de plantas (Frenette-Dussault et al.¬†2012), mas agora para testar o efeito do pastejo sobre a diversidade beta funcional. Pergunta: O pastejo determina a ocorr√™ncia de esp√©cies de plantas com diferentes atributos funcionais ? Predi√ß√£o * A composi√ß√£o funcional de plantas √© diferente entre √°reas com e sem pastejo? Vari√°veis * Preditora: √°reas com e sem pastejo de gado (vari√°vel categ√≥rica com dois n√≠veis: grazed e ungrazed: ambie_fren_dat) Dependentes: composi√ß√£o de esp√©cies (matriz de esp√©cies por localidade: comun_fren_dat) e atributos funcionais (matriz de atributos cont√≠nuos por esp√©cie: trait_fren_dat) ## Passo 1: CWM cwm_fren &lt;- functcomp(trait_pad, as.matrix(comun_fren_dat)) head(cwm_fren) #&gt; LA SLA LDMC LN15 LCC #&gt; 1 -0.2411700 -0.3485515 0.19745200 0.1874003 -0.5367368 #&gt; 2 -0.3977371 0.2326622 -0.09093270 -0.2859777 0.1643190 #&gt; 3 -0.1857134 0.2010756 -0.39877265 -0.1250643 -0.4304617 #&gt; 4 -0.2284064 0.1604101 0.80496307 -0.3704253 0.7193853 #&gt; 5 -0.1664790 0.3486956 0.02232213 -0.2041931 0.2051391 #&gt; 6 -0.3258821 0.3664583 0.04996829 -0.3352572 0.4713089 ## Passo 2: calcular a dist√¢ncia funcional cwm_dis &lt;- vegdist(cwm_fren, &quot;euclidean&quot;) ## Passo 3: testar se a composi√ß√£o funcional varia entre as √°reas com uma PERMANOVA perman_fren &lt;- adonis(cwm_fren ~ Grazing, data = ambie_fren_dat) perman_fren #&gt; #&gt; Call: #&gt; adonis(formula = cwm_fren ~ Grazing, data = ambie_fren_dat) #&gt; #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; Terms added sequentially (first to last) #&gt; #&gt; Df SumsOfSqs MeanSqs F.Model R2 Pr(&gt;F) #&gt; Grazing 1 -174.5 -174.46 -0.61591 -0.0142 0.547 #&gt; Residuals 44 12463.0 283.25 1.0142 #&gt; Total 45 12288.5 1.0000 ## Passo 4: comparar a varia√ß√£o dentro de cada grupo com Betadisper betad_fren &lt;- betadisper(cwm_dis, ambie_fren_dat$Grazing) permutest(betad_fren) #&gt; #&gt; Permutation test for homogeneity of multivariate dispersions #&gt; Permutation: free #&gt; Number of permutations: 999 #&gt; #&gt; Response: Distances #&gt; Df Sum Sq Mean Sq F N.Perm Pr(&gt;F) #&gt; Groups 1 0.0539 0.053858 0.1946 999 0.669 #&gt; Residuals 44 12.1763 0.276735 ## Passo 5: visualiza√ß√£o com PCoA plot(betad_fren) Neste exemplo, os resultados perman_fren demonstram que a composi√ß√£o funcional de plantas n√£o √© afetada pelo pastejo (P &gt; 0,05) e que a dispers√£o da composi√ß√£o (uma medida potencial de diversidade beta: Marti J. Anderson, Ellingsen, and McArdle 2006) de esp√©cies tamb√©m n√£o muda entre √°reas com ou sem pastejo (permutest(betad_fren)). A fun√ß√£o betadisper deve ser sempre utilizada em conjunto com a PERMANOVA (adonis) para poder interpretar quais as fontes de varia√ß√£o na composi√ß√£o de esp√©cies. Sendo assim, esta an√°lise representa um m√©todo fundamental para comparar se o potencial efeito (quando houver) √© fruto de diferen√ßa na composi√ß√£o de esp√©cies (i.e., diferen√ßa na posi√ß√£o dos centr√≥ides entre dois ou mais grupos) ou na varia√ß√£o da composi√ß√£o de esp√©cies entre os grupos (i.e., diferen√ßa na dispers√£o dos dados em rela√ß√£o aos centr√≥ides)9. Esta √∫ltima informa√ß√£o, dispers√£o, √© geralmente interpretada como uma analogia a homogeneidade de vari√¢ncias de uma ANOVA (i.e., teste de Levene). A hip√≥tese nula do betadisper √© que a dispers√£o dos grupos √© homog√™nea (ou seja, o valor de probabilidade nos casos que existem dispers√µes homog√™neas ser√° maior do que 0,05). Por√©m, se esse valor for menor do que 0,05, voc√™ deve rejeitar a hip√≥tese nula e concluir que as dispers√µes s√£o heterog√™neas. Os gr√°ficos de PCoA s√£o uma ferramenta poderosa para interpretar os resultados da PERMANOVA + Betadisper. Quanto mais diferente a composi√ß√£o de esp√©cies entre dois ou mais grupos, mais distante devem ser os centroides desse grupo. Al√©m disso, se as √°reas dos pol√≠gonos que conectam todas as r√©plicas de cada grupo forem diferentes em tamanho (hip√≥tese que ser√° testada com o Betadisper), √© poss√≠vel tamb√©m visualizar esta diferen√ßa. Em conclus√£o, para testar se diferen√ßas de composi√ß√£o funcional existem entre dois ou mais grupos, ser√° fundamental (1) comparar a varia√ß√£o da posi√ß√£o dos centr√≥ides (fun√ß√£o adonis) e (2) a varia√ß√£o da dispers√£o da composi√ß√£o funcional entre os grupos (fun√ß√£o betadisper). 14.5 Varia√ß√£o Intraspec√≠fica Os m√©todos discutidos anteriormente utilizam valores m√©dios dos atributos das esp√©cies para descrever a estrutura funcional da comunidade e interpretar as rela√ß√µes entre determinadas vari√°veis preditoras (como clima, por exemplo) com a diverisdade funcional. Por√©m, ao utilizar atributos m√©dios estamos desconsiderando que a varia√ß√£o deste atributo dentro da esp√©cie seja determinante para a resposta da esp√©cie ao ambiente ou seu efeito sobre o ecossistema (Bolnick et al. 2011 ; Violle et al. 2012). Os estudos que usam dados m√©dios para testar hip√≥teses em ecologia funcional argumentam que a varia√ß√£o dentro da esp√©cie √© menor do que a varia√ß√£o entre esp√©cies e, desse modo, o ru√≠do causado ao desconsiderar a vari√¢ncia do atributo dentro da esp√©cies √© desprez√≠vel. Por√©m, diversos estudos t√™m mostrado que esse argumento √© fr√°gil e que a inclus√£o da varia√ß√£o intraespec√≠fica melhora nossa capacidade preditiva em ecologia funcional (Violle et al. 2012; Siefert et al. 2015). Um abordagem geralmente utilizada √© a decomposi√ß√£o da vari√¢ncia do atributo em diferentes n√≠veis de organiza√ß√£o: (1) varia√ß√£o dentro da popula√ß√£o da mesma esp√©cie em uma mesma unidade amostral, (2) varia√ß√£o dentro das popula√ß√µes (independente da esp√©cie) de uma comunidade em uma mesma unidade amostral, e (3) varia√ß√£o entre popula√ß√µes. Conhecida como estat√≠stica T, esta abordagem permite entender as fontes (intra ou interespec√≠fica) de varia√ß√£o no atributos em diferentes escalas (Violle et al. 2012). Outro m√©todo que quantifica a vari√¢ncia explicada pela variabilidade intraespec√≠fica, interespec√≠fica e a covari√¢ncia entre elas foi proposto por Leps et al. (2011). Este m√©todo permite calcular a contribui√ß√£o da varia√ß√£o intraespec√≠fica dentro e entre comunidades. Agora, vamos entender a contribui√ß√£o da varia√ß√£o de um atributo dentro da esp√©cie comparada √† varia√ß√£o entre esp√©cies. Exemplo 7 Vamos utilizar os dados de 11 esp√©cies de anuros associados com 26 po√ßas no Parque Nacional Lagoa do Peixe (Dalmolin, Tozetti, and Pereira 2020). Atributos morfol√≥gicos foram coletados em todos os indiv√≠duos coletados em cada po√ßa. Desse modo, √© poss√≠vel comparar a varia√ß√£o morfol√≥gica entre indiv√≠duos da mesma esp√©cie e entre esp√©cies diferentes. Al√©m disso, √© poss√≠vel quantificar a contribui√ß√£o da varia√ß√£o dentro e entre diferentes po√ßas. No exemplo abaixo, criamos cinco atributos com nomes diferentes daqueles usados no artigo de Dalmolin et al. (2020). Em cada po√ßa, os autores coletaram os seguintes dados das po√ßas: (1) profundidade, (2) area, (3) dist√¢ncia entre po√ßas, e (4) dist√¢ncia da po√ßa para a floresta mais pr√≥xima. Pergunta 1 Qual a contribui√ß√£o da varia√ß√£o intraespec√≠fica para a varia√ß√£o total dos atributos morfol√≥gicos de anuros? Predi√ß√£o A alta plasticidade fenot√≠pica de anuros indica alta contribui√ß√£o da varia√ß√£o intraespec√≠fica comparada a interespec√≠fica. Vari√°veis Preditora: esp√©cies (categ√≥rica). Dependente: varia√ß√£o dos atributos morfol√≥gicos. ## Dados necess√°rios # Matriz de traits. head(traits) #&gt; pond Species body_size biomass eye_size leg_size flatness #&gt; 1 DN1 Sp2 2.405 2.291 3.104 0.450 0.794 #&gt; 2 DN1 Sp3 1.882 2.039 2.926 0.345 1.063 #&gt; 3 DN1 Sp4 0.699 0.342 0.782 0.104 3.055 #&gt; 4 DN1 Sp4 0.725 0.598 1.120 0.136 2.759 #&gt; 5 DN1 Sp4 0.448 0.385 0.844 0.107 3.557 #&gt; 6 DN1 Sp4 0.640 0.470 0.861 0.093 3.420 ## Parti√ß√£o da varia√ß√£o intra e interespec√≠fica ## Passo 1: Tamanho corporal mod_body_size &lt;- aov(body_size~Species, data = traits) summary(mod_body_size) #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Species 10 95.91 9.591 25.5 &lt;2e-16 *** #&gt; Residuals 195 73.35 0.376 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Contribui√ß√£o da varia√ß√£o intra-espec√≠fica para o tamanho corporal. itv_BS &lt;- 100*(73.35 / (95.92+73.35)) itv_BS #&gt; [1] 43.33314 ## Passo 2: Biomassa mod_biomass &lt;- aov(biomass~Species, data = traits) summary(mod_biomass) #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Species 10 118.17 11.817 23.95 &lt;2e-16 *** #&gt; Residuals 195 96.22 0.493 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Contribui√ß√£o da varia√ß√£o intra-espec√≠fica para a biomassa. itv_biomass &lt;- 100*(96.22 / (118.17+96.22)) itv_biomass #&gt; [1] 44.88082 ## Passo 3: Tamanho do olho mod_eye_size &lt;- aov(eye_size~Species, data = traits) summary(mod_eye_size) #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Species 10 203.1 20.309 50.51 &lt;2e-16 *** #&gt; Residuals 195 78.4 0.402 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Contribui√ß√£o da varia√ß√£o intra-espec√≠fica para o tamanho do olho. itv_eye_size &lt;- 100*(78.39 / (203.09+78.39)) itv_eye_size #&gt; [1] 27.84923 ## Passo 4: Achatamento dorso-ventral mod_flatness &lt;- aov(flatness~Species, data = traits) summary(mod_flatness) #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; Species 10 104.47 10.447 92.07 &lt;2e-16 *** #&gt; Residuals 195 22.13 0.113 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Contribui√ß√£o da varia√ß√£o intra-espec√≠fica para o achatamento dorso-ventral. itv_flatness &lt;- 100*(22.13 / (104.48+22.13)) itv_flatness #&gt; [1] 17.47887 ## Passo 5: Combinar os valores de cada trait em um vetor valores &lt;- c(itv_BS, itv_biomass, itv_eye_size, itv_flatness) # Passo 6: Combinar valores e traits em um data.frame. itv_results &lt;- data.frame(trait = c(&quot;body_size&quot;, &quot;biomass&quot;, &quot;eye_size&quot;, &quot;flatness&quot;), itv_explic = valores) ## Tabela com resultados da explica√ß√£o atribuida para a varia√ß√£o intraespec√≠fica itv_results %&gt;% mutate(&quot;explained intraspecific variance&quot; = round(itv_explic, 2)) %&gt;% dplyr::select(trait, &quot;explained intraspecific variance&quot;) #&gt; trait explained intraspecific variance #&gt; 1 body_size 43.33 #&gt; 2 biomass 44.88 #&gt; 3 eye_size 27.85 #&gt; 4 flatness 17.48 Pergunta 2 Qual a contribui√ß√£o da varia√ß√£o entre po√ßas para a varia√ß√£o total dos atributos morfol√≥gicos de anuros? Predi√ß√£o A varia√ß√£o morfol√≥gica de anuros √© afetada por mudan√ßas dentro das esp√©cies e entre diferentes esp√©cies de po√ßas distintas. Vari√°veis Preditoras: po√ßas e esp√©cies (ambas categ√≥ricas). Dependente: varia√ß√£o dos atributos morfol√≥gicos. ## Dados necess√°rios # Matriz de traits sem nomes de esp√©cies ou localidades trait_m &lt;- traits[,c(&quot;body_size&quot;, &quot;biomass&quot;, &quot;eye_size&quot;, &quot;leg_size&quot;, &quot;flatness&quot;)] head(trait_m) #&gt; body_size biomass eye_size leg_size flatness #&gt; 1 2.405 2.291 3.104 0.450 0.794 #&gt; 2 1.882 2.039 2.926 0.345 1.063 #&gt; 3 0.699 0.342 0.782 0.104 3.055 #&gt; 4 0.725 0.598 1.120 0.136 2.759 #&gt; 5 0.448 0.385 0.844 0.107 3.557 #&gt; 6 0.640 0.470 0.861 0.093 3.420 trait_decomp &lt;- decompCTRE(traits = trait_m, sp = traits$Species, ind.plot = traits$pond, print = FALSE) barplot.decompCTRE(trait_decomp) Pergunta 3 Caracter√≠sticas ambientais das po√ßas afetam a varia√ß√£o intraespec√≠fica? Predi√ß√£o A profunidade e √°rea da po√ßa aumentam a contribui√ß√£o da varia√ß√£o intraespec√≠fica em rela√ß√£o a varia√ß√£o interespec√≠fica. Vari√°veis Preditora: caracter√≠sticas das po√ßas. Dependentes: varia√ß√£o dos atributos morfol√≥gicos e contribui√ß√£o da varia√ß√£o intraespec√≠fica. Para calcular a contribui√ß√£o relativa da varia√ß√£o intraespec√≠fica em rela√ß√£o a varia√ß√£o interespec√≠fica dentro de uma comunidade, por exemplo, Siefert et al. (2015) sugeriram uma m√©trica chamada de wITV (‚Äúwithin-community Intraspecific Trait Variation‚Äù). A wITV representa a raz√£o da varia√ß√£o intraespec√≠fica em rela√ß√£o a varia√ß√£o total dentro de uma comunidade (e.g., parcela, po√ßa) que inclui: (i) a abund√¢ncia relativa de cada esp√©cie j ocorrendo na comunidade i, (ii) o valor m√©dio do atributo da esp√©cie j na comunidade i, e (iii) o valor do atributo k de cada indiv√≠duo da esp√©cie j que ocorre na comunidade i. Como esta medida √© feita por unidade amostral (ou seja, sua comunidade de interesse), √© poss√≠vel testar hip√≥teses ecol√≥gicas que tentem explicar processos que aumentem ou diminuam a varia√ß√£o de um determinado atributo dentro ou entre esp√©cies diferentes. A fun√ß√£o wITV foi adaptada para a linguagem R por de Bello et al. (2021). Para facilitar o c√°lculo do wITV para cada comunidade, de Bello et al. (2021) executaram os comandos com a fun√ß√£o for que repete iterativamente a an√°lise para gerar os valores de todas as comunidades em uma forma din√¢mica. Ap√≥s executar as an√°lises com o for, a fun√ß√£o salva os resultados dentro do objeto `wITVResults`. Ap√≥s obter esses resultados, √© poss√≠vel utilizar modelos lineares para testar quais vari√°veis preditoras (em nosso exemplo, caracter√≠sticas das po√ßas) afetam o aumento ou diminui√ß√£o da contribui√ß√£o relativa da varia√ß√£o intraespec√≠fica. ## Dados necess√°rios # Matriz de traits. head(traits) #&gt; pond Species body_size biomass eye_size leg_size flatness #&gt; 1 DN1 Sp2 2.405 2.291 3.104 0.450 0.794 #&gt; 2 DN1 Sp3 1.882 2.039 2.926 0.345 1.063 #&gt; 3 DN1 Sp4 0.699 0.342 0.782 0.104 3.055 #&gt; 4 DN1 Sp4 0.725 0.598 1.120 0.136 2.759 #&gt; 5 DN1 Sp4 0.448 0.385 0.844 0.107 3.557 #&gt; 6 DN1 Sp4 0.640 0.470 0.861 0.093 3.420 # Matriz de comunidades e padroniza√ß√£o para abund√¢ncia relativa head(anuros_comm) #&gt; Sp10 Sp11 Sp2 Sp3 Sp4 Sp6 Sp7 Sp8 Sp1 Sp9 Sp5 #&gt; DN1 1 8 1 1 6 8 4 0 0 0 0 #&gt; DN2 0 0 0 0 1 1 4 2 0 0 0 #&gt; DN3 1 0 0 0 0 0 0 0 0 0 0 #&gt; DN4 0 0 2 2 1 0 0 0 6 0 0 #&gt; DN5 0 0 3 0 1 0 4 1 0 0 0 #&gt; FIG1 0 0 1 0 0 0 1 0 0 0 0 anuros_comm_rel &lt;- decostand(anuros_comm, &quot;total&quot;) # Vari√°veis ambientais. head(env) #&gt; depth area dits_bt_pond dist_for #&gt; DN1 0.50 3800 115 2650 #&gt; DN2 0.60 54600 250 2500 #&gt; DN3 0.80 29110 150 1800 #&gt; DN4 1.00 1386 410 195 #&gt; DN5 1.00 590 770 100 #&gt; FIG1 0.15 30 25 135 ## Preara√ß√£o da matriz para receber os resultados do `for` wITVResults &lt;- data.frame(ITV = matrix(ncol=1, nrow=length(unique(traits$pond)))) rownames(wITVResults) &lt;- unique(traits$pond) for(i in 1:length(unique(traits$pond))){ commAux&lt;-subset(traits, traits$pond==unique(traits$pond)[i]) commAux$Species&lt;-droplevels(factor(commAux$Species)) spNames &lt;- unique(commAux$Species) relAbund&lt;- anuros_comm_rel[i ,as.character(spNames)] traitsVector &lt;- commAux$body_size spVector &lt;- commAux$Species wITVResults[i,1] &lt;- wITV(spIDs = spVector, traitVals = traitsVector, relAbund = relAbund) } wITVResults$ITV #&gt; [1] 0.82517670 0.23326457 NaN 0.15341806 0.10298952 0.00000000 0.02338235 0.68170997 #&gt; [9] 0.79275763 0.66446945 0.81726278 1.00000000 0.00000000 1.00000000 1.00000000 0.99220999 #&gt; [17] 1.00000000 0.55519098 0.58945126 0.55148974 0.80178255 1.00000000 1.00000000 NaN #&gt; [25] 0.19621528 0.14467854 env$wITV &lt;- wITVResults$ITV # NaN = locais com uma √∫nica esp√©cie ## Remover NAs para executar o modelo linear env2 &lt;- na.omit(env) head(env2) #&gt; depth area dits_bt_pond dist_for wITV #&gt; DN1 0.50 3800 115 2650 0.82517670 #&gt; DN2 0.60 54600 250 2500 0.23326457 #&gt; DN4 1.00 1386 410 195 0.15341806 #&gt; DN5 1.00 590 770 100 0.10298952 #&gt; FIG1 0.15 30 25 135 0.00000000 #&gt; FIG2 0.15 30 25 135 0.02338235 ## Modelo linear mod_itv &lt;- lm(wITV~depth+area+dits_bt_pond+dist_for, data = env) ## Testar pressuposto da an√°lise par(mfrow=c(2,2)) plot(mod_itv) ## Resultado summary(mod_itv) #&gt; #&gt; Call: #&gt; lm(formula = wITV ~ depth + area + dits_bt_pond + dist_for, data = env) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.6298 -0.3937 0.0448 0.3387 0.5266 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 4.555e-01 2.113e-01 2.156 0.0449 * #&gt; depth 2.767e-01 3.789e-01 0.730 0.4746 #&gt; area -3.116e-06 9.276e-06 -0.336 0.7409 #&gt; dits_bt_pond -3.653e-04 6.193e-04 -0.590 0.5626 #&gt; dist_for 5.698e-05 1.419e-04 0.401 0.6928 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 0.4103 on 18 degrees of freedom #&gt; (3 observations deleted due to missingness) #&gt; Multiple R-squared: 0.03155, Adjusted R-squared: -0.1837 #&gt; F-statistic: 0.1466 on 4 and 18 DF, p-value: 0.9621 Combinando os resultados das tr√™s an√°lises √© poss√≠vel compreender que existem diferen√ßas morfol√≥gicas entre as esp√©cies de po√ßas diferentes (componente substitui√ß√£o). Por√©m, √© evidente que a varia√ß√£o dentro da esp√©cie √© bastante relevante para compreender a diversidade funcional de anuros. Na primeira an√°lise, os resultados dessas quatro an√°lises indicam que a varia√ß√£o intraspecifica explica de 17% a 45% da varia√ß√£o morfol√≥gica nas metacomunidades de anuros. A segunda, por sua vez, demonstra que a varia√ß√£o morfol√≥gica entre esp√©cies de po√ßas diferentes representa o principal componente de varia√ß√£o, mas que a varia√ß√£o intraespec√≠fica n√£o pode ser ignorada. Por fim, ao combinar a m√©trica wITV com modelos lineares, percebe-se que as caracter√≠sticas das po√ßas n√£o determinam a contribui√ß√£o da varia√ß√£o intraespec√≠fica. Al√©m disso, existe uma varia√ß√£o muito grande entre po√ßas. Ao passo que em algumas po√ßas a varia√ß√£o intraespec√≠fica n√£o contribui para a varia√ß√£o total (wITV = 0), em outras, este componente representou 100% da varia√ß√£o (wITV = 1). Os resultados obtidos nas an√°lises das perguntas 1 a 3 indicam que utilizar somente a m√©dia dos atributos morfol√≥gicos pode refletir em interpreta√ß√µes incorretas em estudos que compararam a diversidade funcional no espa√ßo/tempo (veja discuss√£o em Dalmolin, Tozetti, and Pereira 2020). Refer√™ncias "],["refer√™ncias-1.html", "Refer√™ncias", " Refer√™ncias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
