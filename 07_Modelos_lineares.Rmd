# Modelos lineares {#cap7}

### Pr√©-requisitos do cap√≠tulo {-}

```{r}
## Pacotes
library(ecodados)
library(car)
library(ggplot2)
library(ggpubr)
library(ggforce)
library(lsmeans)
library(lmtest)
library(sjPlot)

## Dados necess√°rios
CRC_PN_macho <- ecodados::teste_t_var_igual
CRC_LP_femea <- ecodados::teste_t_var_diferente
Pareado <- ecodados::teste_t_pareado
correlacao_arbustos <- ecodados::correlacao
dados_regressao <- ecodados::regressoes
dados_regressao_mul <- ecodados::regressoes
dados_anova_simples <- ecodados::anova_simples
dados_dois_fatores <- ecodados::anova_dois_fatores
dados_dois_fatores_interacao <- ecodados::anova_dois_fatores
dados_dois_fatores_interacao2 <- ecodados::anova_dois_fatores_interacao2
dados_bloco <- ecodados::anova_bloco
dados_ancova <- ecodados::ancova


```

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Estat√≠sticas frequentistas como as que ser√£o abordadas neste cap√≠tulo s√£o baseadas em testes estat√≠sticos (e.g. F, t, ùõò^2^, etc...), que s√£o resultados n√∫mericos do teste, e um valor de probabilidade (valor de P) que √© associado com o teste estat√≠stico [@gotelli_primer_2012]. **O valor de P** mede a probabilidade que os valores observados ou mais extremos seriam encontrados caso a hip√≥tese nula seja verdadeira (veja \@{cap3}). Ao longo do livro usaremos o crit√©rio convencional de rejeitar a hip√≥tese nula quando P \< 0.05. Contudo, sugerimos a leitura destes artigos [@white2013; @barber2014; @burnham2014; @murtaugh2014; @halsey2019a] que discutemas limita√ß√µes e problemas associados ao valor de P .
:::

## Teste T (de Student) para duas amostras independentes

Uma das perguntas mais comuns em estat√≠stica √© saber se h√° diferen√ßa entre as m√©dias de dois grupos ou tratamentos. Para responder a esta pergunta, William Sealy Gosset, qu√≠mico da cervejaria Guinness em 1908, desenvolveu o Teste T que √© uma est√°tistica que segue uma distribui√ß√£o t de Student para rejeitar ou n√£o uma hip√≥tese nula de m√©dias iguais entre os grupos.

> $$ t = \frac{(\bar{X}_1 - \bar{X}_2)}{\sqrt{\frac{2S^2_p}{n}}}$$

Onde:

-   $\bar{X}$<sub>1</sub> - $\bar{X}$<sub>2</sub> = diferen√ßa entre as m√©dias de duas amostras,

-   S<sup>2</sup><sub>p</sub> = desvio padr√£o das amostras,

-   *n* = tamanho das amostras.

> #### Premissas do Teste t :
>
> -   As amostras devem ser independentes;
> -   As unidades amostrais s√£o selecionadas aleatoriamente;
> -   Distribui√ß√£o normal (gaussiana) dos res√≠duos. **Observa√ß√£o:** Zar [-@zar_biostatistical_2010] indica que o Test T √© robusto mesmo com moderada viola√ß√£o da normalidade, principalmente se o tamanho amostral for alto.
> -   Homogeneidade da vari√¢ncia. **Observa√ß√£o:** Caso as vari√¢ncias n√£o sejam homog√™neas, isso deve ser informado na linha de comando, pois o denominador da f√≥rmula acima ser√° corrigido.

> #### Avalia√ß√£o das premissas:
>
> Uma das maneiras de avaliarmos as premissas de normalidade e homogeneidade da vari√¢ncia relacionadas √†s an√°lises do teste T, ANOVA e regress√µes lineares simples e m√∫ltiplas √© o uso da inspe√ß√£o gr√°fica da distribui√ß√£o dos res√≠duos (Figura 1) [@zuur_protocol_2009]. A homegeneidade da vari√¢ncia utiliza um gr√°fico dos res√≠duos pelos valores preditos (Figura 1A). A distribui√ß√£o dos res√≠duos ser√° homog√™nea se n√£o observarmos nenhum padr√£o na distribui√ß√£o dos pontos (i.e. forma em V, U ou funil). A normalidade dos res√≠duos utiliza um gr√°fico de quantis-quantis (QQ-plots). A distribui√ß√£o dos res√≠duos ser√° normal se os pontos estiverem pr√≥ximos √† reta (Figure 1B).

![Inspe√ß√£o gr√°fica da homogeneidade da vari√¢ncia (A) e normalidade (B) dos res√≠duos. Os s√≠mbolos verdes indicam que os gr√°ficos em que os res√≠duos apresentam distribui√ß√£o homog√™nea e normal, enquanto os s√≠mbolos vermelhos indicam os gr√°ficos em que os res√≠duos violam as premissas do teste.](QQ-plot.jpg)

<p>

¬†

</p>

#### Exemplo pr√°tico 1 - Teste T para duas amostras com vari√¢ncias iguais

**Explica√ß√£o dos dados**

Neste exemplo avaliaremos o comprimento rostro-cloacal (CRC em mil√≠metros) de machos de *Physalaemus nattereri* (Anura:Leptodactylidae) amostrados em diferentes esta√ß√µes do ano com armadilhas de intercepta√ß√£o e queda na Regi√£o Noroeste do estado de S√£o Paulo [@daSilva2010].

**Pergunta:**

> O CRC dos machos de *P. nattereri* √© maior na esta√ß√£o chuvosa do que na esta√ß√£o seca?

**Predi√ß√µes**

> O CRC dos machos ser√° maior na esta√ß√£o chuvosa porque h√° uma vantangem seletiva para os indiv√≠duos maiores durante a atividade reprodutiva.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com os indiv√≠duos (unidade amostral) nas linhas e CRC (mm - vari√°vel resposta cont√≠nua) e esta√ß√£o (vari√°vel preditora categ√≥rica) como colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

**An√°lise**

Vamos olhar os dados usando a fun√ß√£o `head`

```{r}
head(CRC_PN_macho) 
```

Vamos verificar a normalidade dos res√≠duos usando o QQ-plot.

```{r}
## Teste de normalidade
residuos <- lm(CRC ~ Estacao, data = CRC_PN_macho)
qqPlot(residuos)
```

Os pontos est√£o pr√≥ximos a reta indicando que a distribui√ß√£o dos res√≠duos √© normal (Figura 1).

Outra possibilidade √© usar os testes de Shapiro-Wilk e Levene para verificar a normalidade e a homogeneidade da vari√¢ncia respectivamente.

::: {.alert .alert-info}
<strong> üìù Importante </strong>\
Hip√≥tese nula destes testes √© que a distribui√ß√£o √© normal ou homog√™nea:

-   Valor de p \< 0.05 significa que os dados n√£o apresentam distribui√ß√£o normal ou homog√™nea;

```{=html}
<!-- -->
```
-   valor de p \> 0.05 significa que os dados apresentam distribui√ß√£o normal ou homog√™nea.
:::

```{r}
# Teste de Shapiro
shapiro.test (CRC_PN_macho$CRC) 
```

Teste de Levene para homogeneidade de vari√¢ncia.

```{r}
## Teste de homogeneidade de vari√¢ncia
leveneTest(CRC ~ Estacao, data = CRC_PN_macho)
```

Percebam que a distribui√ß√£o dos res√≠duos foi normal e homog√™nea na inspe√ß√£o gr√°fica, assim como nos testes de Shapiro e Levene, respectivamente. Agora podemos realizar a an√°lise sabendo que os dados seguem as premissas requeridas pelo test T.

Vamos para os comandos da an√°lise do Teste T amostrans indenpendentes e vari√¢ncias iguais.

```{r}
## An√°lise Teste T 
t.test(CRC ~ Estacao, data = CRC_PN_macho, var.equal = TRUE)
```

Quatro valores devem ser apresentados ao leitores: i ) estat√≠stica do teste - representada por **t = 4,15**; ii) valor de significancia - representado por **p-value = 0,0001**; iii) graus de liberdade - representado por **df = 49**; e iv) diferen√ßa entre as m√©dias. Veja abaixo como descrever os resultados no seu trabalho.

Visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggplot(data = CRC_PN_macho, aes(x = Estacao, y = CRC, color = Estacao)) + 
  labs(x = "Esta√ß√µes", y = "CRC (mm) - P. nattereri") +
  geom_boxplot(fill = c("darkorange", "cyan4"), color = "black", 
               outlier.shape = NA) +
  geom_jitter(shape = 16, position = position_jitter(0.1), 
              cex = 5, alpha = 0.7) +
  scale_color_manual(values = c("black", "black")) +
  tema_livro() +
  theme(legend.position = "none")
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, rejeitamos a hip√≥tese nula de que as m√©dias do CRC dos machos entre as esta√ß√µes seca e chuvosa s√£o iguais. Os resultados mostram que os machos de *P. nattereri* coletados na esta√ß√£o chuvosa foram em m√©dia 0,43 mm maiores do que os coletados na esta√ß√£o seca (t~49~ = 4,15, P \< 0,001).

<p>

¬†

</p>

#### Exemplo pr√°tico 2 - Teste T para duas amostras independentes com vari√¢ncias diferentes

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos o comprimento rostro-cloacal (CRC - mil√≠metros) de f√™meas de *Leptodactylus podicipinus* amostradas em diferentes esta√ß√µes do ano com armadilhas de intercepta√ß√£o e queda na Regi√£o Noroeste do estado de S√£o Paulo [@daSilva2010]. **Observa√ß√£o:** Os dados foram alterados em rela√ß√£o a publica√ß√£o original para se enquadrarem no exemplo de amostras com vari√¢ncias diferentes.

**Pergunta:**

> O CRC das f√™meas de *L. podicipinus* √© maior na esta√ß√£o chuvosa do que na esta√ß√£o seca?

**Predi√ß√µes**

> O CRC das f√™meas ser√° maior na esta√ß√£o chuvosa porque h√° uma vantangem seletiva para os indiv√≠duos maiores durante a atividade reprodutiva.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com os indiv√≠duos (unidade amostral) nas linhas e CRC (mm - vari√°vel resposta cont√≠nua) e esta√ß√£o (vari√°vel preditora categ√≥rica) como colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

**An√°lise**

Olhar os dados usando a fun√ß√£o`head`

```{r}
head(CRC_LP_femea) 
```

Vamos avaliar as premissas do teste. Comen√ßando com o teste de normalidade.

```{r}
## Teste de normalidade usando QQ-plot
residuos_LP <- lm(CRC ~ Estacao, data = CRC_LP_femea)
qqPlot(residuos_LP)
```

Os res√≠duos apresentam distribui√ß√£o normal. Agora vamos avaliar a homogeneidade da vari√¢ncia.

```{r}
# Teste de homogeneidade da vari√¢ncia
leveneTest(CRC ~ Estacao, data = CRC_LP_femea)
```

Os res√≠duos n√£o apresentam distribui√ß√£o homog√™nea. Portanto, vamos realizazr o teste T com vari√¢ncias diferentes. Para isso, use o argumento `var.equal = FALSE`

```{r}
t.test(CRC ~ Estacao, data = CRC_LP_femea, var.equal = FALSE)
```

Neste exemplo, n√£o rejeitamos a hip√≥tese nula e consideramos que as m√©dias do CRC das f√™meas entre as esta√ß√µes seca e chuvosa s√£o iguais (t~6,49~ = 1,76, P = 0,12).

Visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggplot(data = CRC_LP_femea, aes(x = Estacao, y = CRC, color = Estacao)) + 
  labs(x = "Esta√ß√µes", y = "CRC (mm) - L. podicipinus", size = 15) +
  geom_boxplot(fill=c("darkorange", "cyan4"), color="black", outlier.shape = NA) +
  geom_jitter(shape = 16, position=position_jitter(0.2), cex = 5, alpha = 0.7) +
  scale_color_manual(values = c("darkorange", "cyan4")) +
  tema_livro() +
  theme(legend.position = "none")
```

**Interpreta√ß√£o dos resultados**

Os resultados mostram que as f√™meas de *L. podicipinus* coletadas na esta√ß√£o chuvosa n√£o s√£o maiores do que as f√™meas coletadas na esta√ß√£o seca, apesar de possuirem maior vari√¢ncia, o que pode ser biologicamente interessante.

<p>

¬†

</p>

## Teste T para amostras pareadas

O Teste T Pareado √© uma estat√≠stica que usa dados medidos duas vezes na mesma unidade amostral, resultando em pares de observa√ß√µes para cada amostra (amostras pareadas). Ele determina se a diferen√ßa da m√©dia entre duas observa√ß√µes √© zero.

> $$ t = \frac{\bar{d}}{S_{\bar{d}}}$$

Onde:

-   $\bar{d}$ = m√©dia da diferen√ßa das medidas pareadas. Observe que o teste n√£o usa as medidas originais, e sim, a diferen√ßa para cada par,

-   S<sub>$\bar{d}$</sub> = erro padr√£o da diferen√ßa das medidas pareadas.

> #### Premissas do Teste t para amostras pareadas:
>
> -   As unidades amostrais s√£o selecionadas aleatoriamente;
> -   As observa√ß√µes **n√£o** s√£o independentes;
> -   Distribui√ß√£o normal (gaussiana) dos valores da diferen√ßa para cada par.

<p>

¬†

</p>

#### Exemplo pr√°tico 1 - Teste T para amostras pareadas

**Explica√ß√£o dos dados**

Neste exemplo avaliaremos a diferen√ßa na riqueza de esp√©cies de artr√≥podes registradas em 27 localidades. Todas as localidades foram amostradas duas vezes. A primeira amostragem foi realizada na localidade antes da pertuba√ß√£o e a segunda amostragem foi realizada ap√≥s a localidade ter sofrido uma queimada. Portanto, existe uma depend√™ncia temporal uma vez que amostramos a mesma localidade antes e depois da queimada.

**Pergunta:**

> A riqueza de esp√©cies de artr√≥podes √© prejudicada pelas queimadas?

**Predi√ß√µes**

> A riqueza de esp√©cies de artr√≥podes ser√° maior antes da queimada devido a extin√ß√£o local das esp√©cies.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com as localidades nas linhas e riqueza de esp√©cies (vari√°vel resposta cont√≠nua) e estado (Pre-queimada ou P√≥s-queimada - vari√°vel preditora categ√≥rica) da localidade nas colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

**An√°lise**

Olhando os dados com a fun√ß√£o `head`

```{r}
head(Pareado) 
```

C√°lculo do Teste T com amostras pareadas.

```{r}
## An√°lise Teste T Pareado
# O uso do [] √© para selecionar dentro do vetor/coluna *Riqueza* os 27 
# primeiros n√∫meros [1:27] que representam as localidades antes da 
# queimada e os √∫ltimos 27 n√∫meros [28:54] que representam as mesmas 
# localidades p√≥s-queimada.
t.test(Pareado$Riqueza[1:27], Pareado$Riqueza[28:54], paired = TRUE)
```

Neste exemplo, rejeitamos a hip√≥tese nula de que a riqueza de esp√©cies de artr√≥podes √© igual antes e depois da queimada (t~26~ = 7,57, P \< 0,001).

Visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggpaired(Pareado, x = "Estado", y = "Riqueza",
         color = "Estado", line.color = "gray", line.size = 0.8, 
         palette = c("darkorange", "cyan4"), width = 0.8, 
         point.size = 4, xlab = "Estado das localidades", 
         ylab = "Riqueza de Esp√©cies") +
  expand_limits(y=c(0,150)) +
  tema_livro() 
```

**Interpreta√ß√£o dos resultados**

Os resultados mostram que as localidades ap√≥s as queimadas apresentam em m√©dia 44,5 esp√©cies de artr√≥podes a menos do que antes das queimadas.

<p>

¬†

</p>

## Correla√ß√£o de Pearson

√â um teste que mede a for√ßa relativa da rela√ß√£o linear entre duas vari√°veis cont√≠nuas (X e Y). Importante ressaltar que a an√°lise de correla√ß√£o n√£o assume que a vari√°vel X influencie a vari√°vel Y ou que exista uma rela√ß√£o de causa e efeito entre elas [@zar_biostatistical_2010]. A an√°lise √© definida em termos da vari√¢ncia de X, a vari√¢ncia de Y, e a covari√¢ncia de X e Y (i.e. como elas variam juntas).

> $$ r = \frac{\sum{XY} - \frac{\sum{X} \sum{Y}}{n}}{\sqrt{\left(\sum{X^2} - \frac{\sum{X}^2}{n}\right)\left(\sum{Y^2} - \frac{\sum{Y}^2}{n}\right)}} $$

Onde:

-   r = coeficiente de correla√ß√£o que indica a for√ßa da rela√ß√£o linear entre as duas vari√°veis. Seu limite de valores est√° entre -1 $\leq$ r $\le$ 1. A correla√ß√£o positiva indica que o aumento no valor de uma das vari√°veis √© acompanhado pelo aumento no valor da outra vari√°vel. A correla√ß√£o negativa indica que o aumento no valor de uma das vari√°veis √© acompanhado pela diminui√ß√£o no valor da outra vari√°vel. Se *r* √© igual a zero, n√£o existe correla√ß√£o entre as vari√°veis (Figura 2).

> #### Premissas da Correla√ß√£o de Person:
>
> -   As amostras devem ser independentes e pareadas (i.e. as duas vari√°veis devem ser medidas na mesma unidade amostral);
> -   As unidades amostrais s√£o selecionadas aleatoriamente;
> -   A rela√ß√£o entre as vari√°veis tem que ser linear.

![Exemplo de correla√ß√µes negativa (A), positiva (B) e nula (C) e vari√°veis que n√£o apresentam rela√ß√µes lineares entre si (D-E).](correlacao.jpg)

<p>

¬†

</p>

#### Exemplo pr√°tico 1 - Correla√ß√£o de Pearson

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos a correla√ß√£o entre a altura do tronco e o tamanho da raiz medidos em 35 indiv√≠duos de uma esp√©cie vegetal arbustiva.

**Pergunta:**

> Existe correla√ß√£o entre a altura do tronco e o tamanho da raiz dos arbustos?

**Predi√ß√µes**

> A altura do tronco √© positivamente correlacionada com o tamanho da raiz.

**Vari√°veis**

-   Vari√°veis

    -   Dataframe com os indiv√≠duos (unidade amostral) nas linhas e altura do tronco e tamanho da raiz (duas vari√°veis tem que ser cont√≠nuas) como colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

**An√°lise**

Vamos plhar os dados com a fun√ß√£o `head.`

```{r}
head(correlacao_arbustos) 
```

C√°lculo do Teste de Correla√ß√£o de Pearson. Para outros testes de correla√ß√£o como Kendall ou Spearman √© s√≥ alterar na

\# linha de comando a op√ß√£o \*method\* e inserir o teste desejado.

```{r}
## Corre√ß√£o de Person
cor.test(correlacao_arbustos$Tamanho_raiz, correlacao_arbustos$Tamanho_tronco,
         method = "pearson")
```

Neste exemplo, rejeitamos a hip√≥tese nula de que as vari√°veis n√£o s√£o correlacionadas (r = 0.89, P \< 0,001).

Visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggplot(data = correlacao_arbustos, aes(x = Tamanho_raiz, y = Tamanho_tronco)) + 
  labs(x = "Tamanho da raiz", y = "Altura do tronco") +
  geom_point(size = 4, shape = 21, fill = "darkorange", alpha = 0.7) +
  geom_text(x = 14, y = 14, label = "r = 0.89, P < 0.001", 
            color = "black", size = 5) +
  tema_livro() +
  theme(legend.position = "none") +
  geom_smooth(method = lm, se = FALSE, color = "black", linetype ="dashed") 
```

::: {.alert .alert-info}
<strong> üìù Importante: </strong> a linha de tend√™ncia tracejada no gr√°fico √© apenas para ilustrar a rela√ß√£o positiva entre as vari√°veis. Ela n√£o √© gerada pela an√°lise de correla√ß√£o.
:::

**Interpreta√ß√£o dos resultados**

Os resultados mostram que o aumento na altura dos arbutos √© acompanhado pelo aumento no tamanho da raiz.

<p>

¬†

</p>

## Regress√£o Linear Simples

A regress√£o linear simples √© usada para analisar a rela√ß√£o entre uma vari√°vel preditora (plotada no eixo-X) e uma vari√°vel resposta (plotada no eixo-Y). As duas vari√°veis devem ser cont√≠nuas. Diferente das correla√ß√µes, a regress√£o assume uma rela√ß√£o de causa e efeito entre as vari√°veis. O valor da vari√°vel preditora (X) causa, direta ou indiretamente, o valor da vari√°vel resposta (Y). Assim, Y √© uma fun√ß√£o linear de X:

> $$ Y = \beta_0 + \beta_{1}X_i + \epsilon_i $$

Onde:

-   $\beta_0$ = intercepto (*intercept*) que representa o valor da fun√ß√£o quando X = 0,

-   $\beta_{1}$ = inclina√ß√£o (*slope*) que mede a mudan√ßa na vari√°vel Y para cada mudan√ßa de unidade da vari√°vel X.

-   $\epsilon_{1}$ = erro aleat√≥rio referente √† vari√°vel Y que n√£o pode ser explicado pela vari√°vel X.

> #### Premissas da Regress√£o Linear Simples:
>
> -   As amostras devem ser independentes;
> -   As unidades amostrais s√£o selecionadas aleatoriamente;
> -   Distribui√ß√£o normal (gaussiana) dos res√≠duos;
> -   Homogeneidade da vari√¢ncia.

<p>

¬†

</p>

#### Exemplo pr√°tico 1 - Regress√£o linear simples

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos a rela√ß√£o entre o gradiente de temperatura m√©dia anual (¬∞C) e o tamanho m√©dio do comprimento rostro-cloacal (CRC em mm) de popula√ß√µes de *Dendropsophus minutus* (Anura:Hylidae) amostradas em 109 localidades no Brasil [@boaratti2015].

**Pergunta:**

> H√° rela√ß√£o de depend√™ncia entre o tamanho do CRC das popula√ß√µes e a temperatura das localidades onde os indiv√≠duos ocorrem?

**Predi√ß√µes**

> O CRC das popula√ß√µes ser√£o menores em localidades mais quentes do que em localidades mais frias de acordo com a Hip√≥tese do balan√ßo de calor [@olalla-t√°rraga2007].

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com as popula√ß√µes (unidade amostral) nas linhas e CRC (vari√°vel resposta) m√©dio (mm) e temperatura m√©dia anual (vari√°vel preditora) como colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

**An√°lise**

Olhando os dados com a fun√ß√£o `head`

```{r}
head(dados_regressao) 
```

Vamos calcular a regress√£o linear simples.

```{r}
## Regress√£o simples
modelo_regressao <- lm(CRC ~ Temperatura, data = dados_regressao)
```

Antes de vermos os resultados, vamos verificar a normalidade e homogeneidade das vari√¢ncias

```{r}
## Verificar as premissas do teste
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(modelo_regressao)
dev.off() # volta a configura√ß√£o dos gr√°ficos para o formato padr√£o 
```

Os gr√°ficos *Residuals vs Fitted*, *Scale-Location*, e *Residual vs Leverage* est√£o relacionados com a homogeneidade da vari√¢ncia. Nestes gr√°ficos, esperamos ver os pontos dispersos no espa√ßo sem padr√µes com formatos em *U* ou funil. Podemos observar que tanto a normalidade como a homogeneidade do res√≠duos est√£o dentro dos padr√µes esperados.

Vamos ver os resultados da regress√£o simples usando as fun√ß√µes `anova` e `summary`. A fun√ß√£o `anova` retorna uma tabela contendo o grau de liberdade (df), soma dos quadrados, valor de F e o valor de P.

```{r}
## Resultados usando a fun√ß√£o anova
anova(modelo_regressao)
```

A fun√ß√£o `summary` retorna uma tabela contendo o valor do intercepto, inclina√ß√£o da reta (*slope*) e o coeficiente de determina√ß√£o (R^2^) que indica a propor√ß√£o da varia√ß√£o na vari√°vel Y que pode ser atribu√≠da √† varia√ß√£o na vari√°vel X. Percebam que a parte final dos resultados apresentados no `summary`, s√£o os mesmo apresentados pela fun√ß√£o `anova`.

```{r}
# Resultados usando a fun√ß√£o summary
summary(modelo_regressao)
```

Vamos visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggplot(data = dados_regressao, aes(x = Temperatura, y = CRC)) + 
  labs(x = "Temperatura m√©dia anual (¬∞C)", 
       y = "Comprimento rostro-cloacal (mm)") +
  geom_point(size = 4, shape = 21, fill = "darkorange", alpha = 0.7) +
  tema_livro() +
  theme(legend.position = "none") +
  geom_smooth(method = lm, se = FALSE, color = "black") 
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, rejeitamos a hip√≥tese nula de que n√£o existe rela√ß√£o entre o tamanho do CRC das popula√ß√µes de *D. minutus* e a temperatura da localidade onde elas ocorrem (F~1,107~ = 38,92, P \< 0,001). Os resultados mostram que o tamanho do CRC das popula√ß√µes tem uma rela√ß√£o positiva com a temperatura das localidades. Assim, popula√ß√µes de *D. minutus* em localidades mais quentes apresentam maior CRC do que as popula√ß√µes em localidades mais frias.

<p>

¬†

</p>

## Regress√£o Linear M√∫ltipla

A regress√£o linear m√∫ltipla √© uma extens√£o da regress√£o linear simples. Ela √© usada quando queremos determinar o valor da vari√°vel resposta (Y) com base nos valores de duas ou mais vari√°veis preditoras (X~1~, X~2~, X~*n*~).

> $$ Y = \beta_0 + \beta_{1}X_1 + \beta_{n}X_n + \epsilon_i $$

Onde:

-   $\beta_0$ = intercepto (*intercept*) que representa o valor da fun√ß√£o quando X = 0;

-   $\beta_{n}$ = inclina√ß√£o (*slope*) que mede a mudan√ßa na vari√°vel Y para cada mudan√ßa de unidade das vari√°veis X~n~;

-   $\epsilon_{1}$ = erro aleat√≥rio referente a vari√°vel Y que n√£o pode ser explicado pelas vari√°veis preditoras.

> #### Premissas da Regress√£o Linear M√∫ltipla:
>
> -   As amostras devem ser independentes;
> -   As unidades amostrais s√£o selecionadas aleatoriamente;
> -   Distribui√ß√£o normal (gaussiana) dos res√≠duos;
> -   Homogeneidade da vari√¢ncia.

<p>

¬†

</p>

#### Exemplo pr√°tico 1 - Regress√£o linear m√∫ltipla

**Explica√ß√£o dos dados**

Utilizaremos o mesmo exemplo da regress√£o linear simples. Contudo, al√©m do gradiente de temperatura m√©dia anual (¬∞C), incluiremos o gradiente de precipita√ß√£o anual (mm) como outra vari√°vel preditora do tamanho m√©dio do comprimento rostro-cloacal (CRC em mm) de popula√ß√µes de *Dendropsophus minutus* (Anura:Hylidae) amostradas em 109 localidades no Brasil [@boaratti2015].

**Pergunta:**

> O tamanho do CRC das popula√ß√µes de *D. minutus* √© influ√™nciado pela temperatura e precipita√ß√£o das localidades onde os indiv√≠duos ocorrem?

**Predi√ß√µes**

> O CRC das popula√ß√µes ser√£o menores em localidades com clima quente e chuvoso do que em localidades com clima frio e seco.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com as popula√ß√µes (unidade amostral) nas linhas e CRC (vari√°vel resposta) m√©dio (mm) e temperatura e precipita√ß√£o (vari√°veis preditoras) como colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

**An√°lise**

Olhando os dados usando a fun√ß√£o `head`

```{r}
head(dados_regressao_mul) 
```

Comandos para o modelo de regress√£o m√∫ltipla.

```{r}
## Regress√£o m√∫ltipla
modelo_regressao_mul <- lm(CRC ~ Temperatura + Precipitacao,
                           data = dados_regressao_mul)
```

::: {.alert .alert-info}
<strong> üìù Importante </strong>\

Multicolinearidade ocorre quando as vari√°veis preditoras s√£o correlacionadas. Essa correla√ß√£o √© um problema porque as vari√°veis preditoras deveriam ser independentes. O Fator de Infla√ß√£o da Vari√¢ncia (VIF) √© um teste que identifica a correla√ß√£o entre as vari√°veis e mostra a for√ßa dessa correla√ß√£o. Alguns autores consideram valores de VIF acima de 10 como fortemente correlacionadas, outros mais conservadores consideram o valor de 3.
:::

Vamos analisar se as vari√°veis apresentam multicolinearidade.

```{r}
# Multicolinearidade
vif(modelo_regressao_mul)
```

Os valores s√£o menores que 3 indicando que n√£o h√° multicolinearidade.

Agora vamos verificar as premissas de normalidade e homogeneidade das vari√¢ncias.

```{r}
## Normalidade e homogeneidade 
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(modelo_regressao_mul)
dev.off()
```

Os res√≠duos apresentam distribui√ß√£o normal e vari√¢ncias homog√™neas.

Podemos ver os resultados da an√°lise.

```{r}
## Regress√£o m√∫ltipla
summary(modelo_regressao_mul)
```

Percebam que a temperatura tem uma rela√ß√£o significativa e positiva com o tamanho do CRC das popula√ß√µes (P \< 0.001), enquanto que a precipita√ß√£o n√£o apresenta rela√ß√£o com o CRC (P = 0.27). Neste caso, √© interessante saber se um modelo mais simples (e.g. contendo apenas temperatura) explicaria a distribui√ß√£o t√£o bem ou melhor do que este modelo mais complexo considerando duas vari√°veis (temperatura e precipita√ß√£o).

Para isso, podemos utilizar a *Likelihood Ratio Test* *(LRT)* para comparar modelos. A LRT compara dois modelos aninhados, testando se os par√¢metros do modelo mais complexo diferem significativamente do modelo mais simples. Em outras palavras, ele testa se h√° necessidade de se incluir uma vari√°vel extra no modelo para explicar os dados.

```{r}
## Criando os modelos aninhados
modelo_regressao_mul <- lm(CRC ~ Temperatura + Precipitacao, 
                           data = dados_regressao_mul)
modelo_regressao <- lm(CRC ~ Temperatura, data = dados_regressao_mul)

## Likelihood Ratio Test (LRT)
lrtest(modelo_regressao_mul, modelo_regressao)
```

::: {.alert .alert-info}
<strong> üìù Importante </strong>\

Hip√≥tese nula √© que o modelo mais simples √© o melhor

-   Valor de p \< 0.05 rejeita a hip√≥tese nula e o modelo mais complexo √© o melhor;

```{=html}
<!-- -->
```
-   valor de p \> 0.05 n√£o rejeita a hip√≥tese nula e o modelo mais simples √© o melhor.
:::

```{r}
## Comparando com o modelo somente com o intercepto
# Criando um modelo sem vari√°veis, s√≥ o intercepto.
modelo_intercepto <- lm(CRC ~ 1, data = dados_regressao_mul)
lrtest(modelo_regressao, modelo_intercepto)
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, a precipita√ß√£o n√£o est√° associada com a varia√ß√£o no tamanho do CRC das popula√ß√µes de *D. minutus*. Por outro lado, a temperatura explicou 26% da varia√ß√£o do tamanho do CRC das popula√ß√µes.

<p>

¬†

</p>

## An√°lises de Vari√¢ncia (ANOVA)

ANOVA refere-se a uma variedade de delineamentos experimentais nos quais a vari√°vel preditora √© categ√≥rica e a vari√°vel resposta √© cont√≠nua [@gotelli_primer_2012]. Exemplos desses delineamentos experimentais s√£o: ANOVA de um fator, ANOVA de dois fatores, ANOVA em blocos aleatorizados, ANOVA de medidas repetidas e ANOVA *split-splot*. De forma geral, a ANOVA √© um teste estat√≠stico usado para comparar a m√©dia entre grupos amostrados independentemente. Para isso, o teste leva em conta, al√©m das m√©dias dos grupos, a varia√ß√£o dos dados dentro e entre os grupos. Neste cap√≠tulo, iremos demonstrar as linhas de comandos para alguns dos principais delineamentos experimentais.

> #### Premissas da ANOVA:
>
> -   As amostras devem ser independentes. **Observa√ß√£o:** ANOVA de medidas repetidas e ANOVA *split-plot* s√£o designs experimentais que apresentam depend√™ncia entre as amostras, mas controlam esse deped√™ncia nas suas formula√ß√µes matem√°tcas;
> -   As unidades amostrais s√£o selecionadas aleatoriamente;
> -   Distribui√ß√£o normal (gaussiana) dos res√≠duos;
> -   Homogeneidade da vari√¢ncia.

<p>

¬†

</p>

## ANOVA de um fator

Este teste considera delineamentos experimentais com apenas um fator (ou tratamento) que pode ser composto por tr√™s ou mais grupos (ou n√≠veis).

#### Exemplo pr√°tico 1 - Anova de um fator

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos se o adubo X-2020 disponibilizado recentemente no mercado melhora o crescimento dos indiv√≠duos de *Coffea arabica* como divulgado pela empresa respons√°vel pela venda do produto. Para isso, foi realizado um experimento com indiv√≠duos de *C. arabica* cultivados em tr√™s grupos: i) grupo controle onde os indiv√≠duos n√£o receberam aduba√ß√£o, ii) grupo onde os indiv√≠duos receberam a adi√ß√£o do adubo tradicional mais utilizado pelos produtores de *C. arabica*, e iii) grupo onde os indiv√≠duos receberam a adi√ß√£o do adubo X-2020.

**Pergunta:**

> O crescimento dos indiv√≠duos de *C. arabica* √© melhorado pela adi√ß√£o do adubo X-2020?

**Predi√ß√µes**

> O crescimento dos indiv√≠duos de *C. arabica* ser√° maior no grupo que recebeu o adubo X-2020.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com as plantas (unidade amostral) nas linhas e o crescimento dos indiv√≠duos de *C. arabica* (vari√°vel resposta) e os tratamentos (vari√°vel preditora) nas colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°vel preditora e resposta nas colunas.

### An√°lise

Olhando os dados e criando o modelo para Anova de um fator.

```{r}
head(dados_anova_simples) 

## An√°lise ANOVA de um fator
Modelo_anova <- aov(Crescimento ~ Tratamento, data = dados_anova_simples) 
```

Vamos verificar a normalidade e homogeneidade da vari√¢ncia usando os testes de Shapiro-Wilk e bartett.test respectivamente.

```{r}
## Normalidade 
shapiro.test(dados_anova_simples$Crescimento[1:12])
shapiro.test(dados_anova_simples$Crescimento[13:24])
shapiro.test(dados_anova_simples$Crescimento[25:36])

## Normalidade 
bartlett.test(Crescimento ~ Tratamento, data = dados_anova_simples)
```

Os res√≠duos apresentam distribui√ß√£o normal e vari√¢ncia homog√™neas.

Vamos ver os resultados da an√°lise.

```{r}
## Resultados anova
anova(Modelo_anova)
```

Percebam que o resultado da ANOVA (Pr(\>F) \< 0.001) indica que devemos rejeitar a hip√≥tese nula que n√£o h√° diferen√ßa entre as m√©dias dos grupos. Contudo, os resultados n√£o mostram quais s√£o os grupos que apresentam diferen√ßas. Para isso, temos que realizar testes de compara√ß√µes m√∫ltiplas *post-hoc* para detectar os grupos que apresentam diferen√ßas significativas entre as m√©dias.

::: {.alert .alert-info}
<strong> üìù Importante </strong>\

Os testes *post-hoc* s√≥ devem ser utilizados quando rejeitamos a hip√≥tese nula (P \< 0.05) no teste da ANOVA.
:::

```{r}
## Diferen√ßas entre os tratamentos
# Teste de Tuckey's honest significant difference
TukeyHSD(Modelo_anova)
```

Visualizar os resultados em gr√°fico.

```{r}
# Reordenando a ordem que os grupos ir√£o aparecer no gr√°fico

dados_anova_simples$Tratamento <- factor(dados_anova_simples$Tratamento , 
                                      levels=c("Controle", "Adubo_Tradicional",
                                               "Adubo_X-2020"))

# Gr√°fico
ggplot(data = dados_anova_simples, aes(x = Tratamento, y = Crescimento, 
                                       color = Tratamento)) + 
  labs(x = "Aduba√ß√£o", y = "Crescimento Coffea arabica (cm)", size = 20) +
  geom_boxplot(fill = c("darkorange", "darkorchid", "cyan4"), color = "black",
               show.legend = FALSE, alpha = 0.4) +
  geom_jitter(shape = 16, position = position_jitter(0.1), cex = 4, alpha = 0.7) +
  scale_color_manual(values = c("darkorange", "darkorchid", "cyan4")) +
  scale_y_continuous(limits = c(0, 20), breaks = c(0, 5, 10, 15, 20)) +
  geom_text(x = 1, y = 12, label = "ab", color = "black", size = 5) +
  geom_text(x = 2, y = 17, label = "a", color = "black", size = 5) +
  geom_text(x = 3, y = 17, label = "b", color = "black", size = 5) +
  scale_x_discrete(labels = c("Sem adubo","Tradicional","X-2020")) +
  tema_livro() +
  theme(legend.position = "none") 
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, os indiv√≠duos de *C. arabica* que receberam aduba√ß√£o (tradicional e X-2020) apresentaram maior crescimento do que os indiv√≠duos que n√£o receberam aduba√ß√£o. Contudo, diferente do que foi divulgado pela empresa, o adubo X-2020 n√£o apresentou melhor desempenho que o adubo tradicional j√° utilizado pelos produtores.

<p>

¬†

</p>

## ANOVA com dois fatores ou ANOVA fatorial

Este teste considera delineamentos amostrais com dois fatores (ou tratamentos) que podem ser compostos por dois ou mais grupos (ou n√≠veis). Esta an√°lise tem uma vantagem, pois permite avaliar o efeito da intera√ß√£o entre os fatores na vari√°vel resposta. Quando a intera√ß√£o est√° presente, o impacto de um fator depende do n√≠vel (ou grupo) do outro fator.

#### Exemplo pr√°tico 1 - ANOVA com dois fatores

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos se o tempo que o corpo leva para eliminar uma droga utilizada em exames de resson√¢ncia magn√©tica est√° relacionado com o sistema XY de determina√ß√£o do sexo e/ou com a idade dos pacientes. Para isso, foi realizado um experimento com 40 pacientes distribu√≠dos da seguinte maneira: i) 10 indiv√≠duos XX - jovens, ii) 10 indiv√≠duos XX - idosas, iii) 10 indiv√≠duos XY - jovens, e iv) 10 indiv√≠duos XY - idosos.

**Pergunta:**

> O tempo de elimina√ß√£o da droga √© dependente do sistema XY de determina√ß√£o do sexo e idade dos pacientes?

**Predi√ß√µes**

> O tempo de elimina√ß√£o da droga vai ser mais r√°pido nas pacientes XX e jovens.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com os pacientes (unidade amostral) nas linhas e o tempo de elimina√ß√£o da droga (vari√°vel resposta) e os tratamentos sexo e idade dos pacientes (vari√°veis preditoras) nas colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e as vari√°veis preditoras e respostas nas colunas.

### An√°lise

Olhando os dados usando a fun√ß√£o `head`

```{r}
head(dados_dois_fatores) 
```

Comandos da ANOVA com dois fatores.

```{r}
## An√°lise Anova de dois fatores 
# A intera√ß√£o entre os fatores √© representada por *
Modelo1 <- aov(Tempo ~ Pessoas * Idade, data = dados_dois_fatores) 


# Olhando os resultados
anova(Modelo1)
```

Percebam que a intera√ß√£o n√£o apresenta um efeito significativo (P \> 0.05). Assim, iremos retirar a intera√ß√£o e verificar, usando Likelihood Ratio Test, se o modelo mais simples √© melhor.

```{r}
# Criando modelo sem intera√ß√£o.
Modelo2 <- aov(Tempo ~ Pessoas + Idade, data = dados_dois_fatores) 

## LRT
lrtest(Modelo1, Modelo2)
```

A intera√ß√£o n√£o √© importante. Ent√£o podemos seguir com o modelo mais simples. Vamos verficiar a normalidade e homogeneidade da vari√¢ncia.

```{r}
# Verificando as premissas do teste.
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(Modelo2)
dev.off()
```

Dois pontos est√£o fugindo da reta e chamam aten√ß√£o sobre a normalidade da distribui√ß√£o dos res√≠duos. A homogeneidade da vari√¢ncia est√° adequada. Por enquanto, vamos seguir a an√°lise, mas veja o \@ref(Cap8) para entender como lidar como modelos que os res√≠duos n√£o apresentam distribui√ß√£o normal.

```{r}
# Resultados do modelo
anova(Modelo2)
```

Percebam que o resultado da ANOVA (Pr(\>F) \< 0.001) indica que devemos rejeitar a hip√≥tese nula de que n√£o h√° diferen√ßa entre as m√©dias dos sistema XY e idade dos pacientes. Neste caso, n√£o precisamos realizar testes de compara√ß√µes m√∫ltiplas *post-hoc* porque os fatores apresentam apenas dois n√≠veis. Contudo, se no seu delineamento experimental um dos fatores apresentar tr√™s ou mais n√≠veis, voc√™ dever√° utilizar os testes de compara√ß√µes *post-hoc* para determinar as diferen√ßas entre os grupos.

Visualizar os resultados em gr√°fico.

**Interpreta√ß√£o dos resultados**

Neste exemplo, o sistema XY de determina√ß√£o do sexo e a idade dos pacientes t√™m um efeito no tempo de elimina√ß√£o da droga do organismo. Os pacientes XX e jovens apresentaram elimina√ß√£o mais r√°pida da droga do que pacientes XY e idosos.

<p>

¬†

</p>

#### Exemplo pr√°tico 2 - ANOVA com dois fatores com efeito da intera√ß√£o

**Explica√ß√£o dos dados**

Neste exemplo, usaremos os mesmos dados do exemplo anterior. Neste caso, alteramos os dados para que a intera√ß√£o seja significativa.

```{r}
head(dados_dois_fatores_interacao)

## An√°lise ANOVA com dois fatores 
Modelo_interacao1 <- aov(Tempo ~ Pessoas * Idade, 
                         data = dados_dois_fatores_interacao) 

## Olhando os resultados
anova(Modelo_interacao1)
```

Percebam que a intera√ß√£o √© significativa (P \< 0.05). Agora nossa interpreta√ß√£o precisa ser baseada na intera√ß√£o entre os fatores. Vamos visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggplot(data = dados_dois_fatores_interacao, aes(y = Tempo, x = Pessoas,
                                                color = Idade)) + 
  geom_boxplot() +
  stat_summary(fun = mean, geom ="point", aes(group = Idade, x = Pessoas),
               color = "black",
               position = position_dodge(0.7), size  = 4) +
  geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 40), color = "darkorange", 
            lwd  = 1.3, linetype = 2) + 
  geom_link(aes(x = 1.2, y = 28.5, xend = 2.2, yend = 26.5), 
            color = "cyan4", 
            lwd  = 1.3, linetype = 2) + 
  labs(x = "Sistema XY de determina√ß√£o do sexo", 
       y = "Tempo (horas) para eliminar a droga") +
  scale_color_manual(values = c("darkorange", "cyan4", "darkorange", 
                                "cyan4")) +
  scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) +
  tema_livro()  
```

**Interpreta√ß√£o dos resultados**

Percebam que para saber a resposta do fator idade (jovem ou idoso) na elimina√ß√£o da droga, voc√™ precisa saber com qual pessoa (XX ou XY) ele est√° associado. Isso porque a resposta de um fator, depende do outro fator. Jovens eliminam a droga do corpo mais r√°pido nas pessoas XY, enquanto os idosos eliminam a droga mais r√°pido nas pessoas XX.

<p>

¬†

</p>

#### Exemplo pr√°tico 3 - ANOVA com dois fatores com efeito da intera√ß√£o

**Explica√ß√£o dos dados**

Neste exemplo, usaremos os mesmos dados do exemplo anterior. Entretanto, alteramos os dados para que a intera√ß√£o seja significativa.

```{r}
# Olhando os dados
head(dados_dois_fatores_interacao2)

## An√°lise anova de dois fatores 
Modelo_interacao2 <- aov(Tempo ~ Pessoas * Idade, 
                         data = dados_dois_fatores_interacao2)

## Olhando os resultados
anova(Modelo_interacao2)
```

Percebam que a intera√ß√£o √© significativa (P \< 0.05), mas a idade n√£o √© significativa. Nossa interpreta√ß√£o precisa ser baseada na intera√ß√£o entre os fatores. Vamos visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggplot(data = dados_dois_fatores_interacao2, aes(y = Tempo, x = Pessoas, 
                                                 color = Idade)) + 
  geom_boxplot() +
  stat_summary(fun = mean, geom ="point", aes(group = Idade, x = Pessoas), 
               color = "black",
               position = position_dodge(0.7), size  = 4) +
  geom_link(aes(x = 0.8, y = 31, xend = 1.8, yend = 27), color = "darkorange", 
            lwd  = 1.3, linetype = 2) + 
  geom_link(aes(x = 1.2, y = 19, xend = 2.2, yend = 41), color = "cyan4", 
            lwd  = 1.3, linetype = 2) + 
  labs(x = "Sistema XY de determina√ß√£o do sexo", 
       y = "Tempo (horas) para eliminar a droga") +
  scale_color_manual(values = c("darkorange", "cyan4", "darkorange",
                                "cyan4")) +
  scale_y_continuous(limits = c(10, 50), breaks = c(10, 20, 30, 40, 50)) +
  tema_livro() 
```

**Interpreta√ß√£o dos resultados**

Percebam que as linhas se cruzam. Esse √© um exemplo cl√°ssico de intera√ß√£o. Novamente, para saber a resposta do fator idade (jovem ou idoso), voc√™ precisa saber com qual pessoa (XX ou XY) ele est√° associado. Jovens s√£o mais r√°pidos para eliminarem a droga em pessoas XX, enquanto os idosos s√£o mais r√°pidos para eliminarem a droga nas pessoas XY.

<p>

¬†

</p>

## ANOVA em blocos aleatorizados

No delineamento experimental com blocos aleatorizados, cada fator √© agrupado em blocos, com r√©plicas de cada n√≠vel do fator representado em cada bloco [@gotelli_primer_2012]. O bloco √© uma √°rea ou per√≠odo de tempo dentro do qual as condi√ß√µes ambientais s√£o relativamente homog√™neas. O objetivo do uso dos blocos √© controlar fontes de varia√ß√µes indesejadas na vari√°vel dependente que n√£o s√£o de interesse do pesquisador. Desta maneira, podemos retirar dos res√≠duos os efeitos das varia√ß√µes indesejadas que n√£o s√£o do nosso interesse, e testar com maior poder estat√≠stico os efeitos dos tratamentos de interesse. Importante, os blocos devem ser arranjados de forma que as condi√ß√µes ambientais sejam mais similares dentro dos blocos do que entre os blocos.

<p>

¬†

</p>

#### Exemplo pr√°tico 1 - ANOVA em blocos aleatorizados

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos a riqueza de esp√©cies de anuros amostradas em po√ßas artificiais instaladas a diferentes dist√¢ncias de seis fragmentos florestais no sudeste do Brasil [@daSilva2011]. Os fragmentos florestais apresentam diferen√ßas entre si que n√£o s√£o do interesse do pesquisador. Por isso, eles foram inclu√≠dos como blocos nas an√°lises. As po√ßas artificiais foram instaladas em todos os fragmentos florestais com base no seguinte delineamento experimental [@daSilva2011]: i) quatro po√ßas no interior do fragmento a 100 m de dist√¢ncia da borda do fragmento; ii) quatro po√ßas no interior no fragmento a 50 m de dist√¢ncia da borda do fragmento; iii) quatro po√ßas na borda do fragmento; iv) quatro po√ßas na matriz de pastagem a 50 m de dist√¢ncia da borda do fragmento; e v) quatro po√ßas na matriz de pastagem a 100 m de dist√¢ncia da borda do fragmento. Percebam que todos os tratamentos foram instalados em todos os blocos.

**Pergunta:**

> A dist√¢ncia da po√ßa artifical ao fragmento florestal influencia a riqueza de esp√©cies anuros?

**Predi√ß√µes**

> Po√ßas na borda do fragmento florestal apresentar√£o maior riqueza de esp√©cies do que po√ßas distantes da borda.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com as po√ßas (unidade amostral) nas linhas e a riqueza de esp√©cies (vari√°vel reposta), dist√¢ncia dos fragmentos florestais (vari√°vel preditora categ√≥rica) e fragmentos florestais (blocos) nas colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

**An√°lise**

Olhando os dados usando a fun√ß√£o `head.`

```{r}
head(dados_bloco) 
```

H√° duas formas de incluir os efeitos dos blocos nos modelos.

```{r}
## An√°lise Anova em blocos aleatorizados
model_bloco1 <- aov(Riqueza ~ Pocas + Blocos, data = dados_bloco)
summary(model_bloco1)

model_bloco2 <- aov(Riqueza ~ Pocas + Error(Blocos), data = dados_bloco)
summary(model_bloco2)
```

Percebam que as duas formas apresentam os mesmos resultados para o efeito \#' da dist√¢ncia das po√ßas que √© o fator de interesse no estudo. Lembre-se que nos delineamentos experimentais em bloco, o pesquisador n√£o est√° interessado no efeito do bloco, mas sim em controlar a varia√ß√£o associada a ele.

O que n√£o pode acontecer √© ignorar o efeito do bloco que √© incorporado pelos res√≠duos quando n√£o informado no modelo. Veja abaixo a forma errada de analisar delineamento experimental com blocos.

```{r}
## Forma errada de an√°lisar Anova em blocos
modelo_errado <- aov(Riqueza ~ Pocas, data = dados_bloco)
anova(modelo_errado)
```

O resultado da ANOVA (Pr(\>F) \< 0.001) indica que devemos rejeitar a hip√≥tese nula que n√£o h√° diferen√ßa entre as m√©dias dos grupos. Contudo, os resultados n√£o mostram quais s√£o os grupos que apresentam diferen√ßas. Para isso, temos que realizar testes de compara√ß√µes m√∫ltiplas *post-hoc* para detectar os grupos que apresentam diferen√ßas significativas entre as m√©dias.

```{r}
## Teste de Tuckey's honest significant difference
pairs(lsmeans(model_bloco1, "Pocas"), adjust = "tukey")
```

Visualizar os resultados em gr√°fico.

```{r}
# Reordenando a ordem que os grupos ir√£o aparecer no gr√°fico.
dados_bloco$Pocas <- factor(dados_bloco$Pocas, 
                              levels = c("Int-100m", "Int-50m", "Borda",
                                       "Mat-50m", "Mat-100m"))

## Gr√°fico
ggplot(data = dados_bloco, aes(x = Pocas, y = Riqueza)) + 
  labs(x = "Po√ßas artificiais", y = "Riqueza de esp√©cies de anuros") +
  geom_boxplot(color = "black", show.legend = FALSE,
               alpha = 0.4) +
  geom_jitter(shape = 16, position = position_jitter(0.1), cex = 4, alpha = 0.7) +
  scale_x_discrete(labels = c("-100m","-50m","Borda", "50m", "100m")) +
  tema_livro() +
  theme(legend.position = "none") 
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, rejeitamos a hip√≥tese nula de que a dist√¢ncia das po√ßas artificiais at√© as bordas dos fragmentos florestais n√£o influ√™ncia a riqueza de esp√©cies de anuros. As po√ßas artificiais instaladas nas bordas dos fragmentos florestais apresentaram maior riqueza de esp√©cies do que as po√ßas distantes.

<p>

¬†

</p>

## An√°lise de covari√¢ncia (ANCOVA)

A ANCOVA pode ser compreendida como uma extens√£o da ANOVA com a adi√ß√£o de vari√°vel cont√≠nua (covari√°vel) medida em todas as unidades amostrais [@gotelli_primer_2012]. A ideia √© que a covari√°vel tamb√©m afete os valores da vari√°vel resposta. N√£o incluir a covari√°vel ir√° fazer com que a varia√ß√£o n√£o explicada pelo modelo concentre-se nos res√≠duos. Incluindo a covari√°vel, o tamanho do res√≠duo √© menor, e o teste para avaliar as diferen√ßas nos tratamentos, que √© o interesse do pesquisador, ter√° mais poder estat√≠stico.

<p>

¬†

</p>

#### Exemplo pr√°tico 1 - ANCOVA

**Explica√ß√£o dos dados**

Neste exemplo, avaliaremos o efeito da herbivoria na biomassa dos frutos de uma esp√©cie de √°rvore na Mata Atl√¢ntica. O delineamento experimental permitiu que alguns indiv√≠duos sofressem herbivoria e outros n√£o. Os pesquisadores tamb√©m mediram o tamanho da raiz dos ind√≠viduos para inseri-la como uma covari√°vel no modelo.

**Pergunta:**

> A herbivoria diminiu a biomassa dos frutos?

**Predi√ß√µes**

> Os indiv√≠duos que sofreram herbivoria ir√£o produzir frutos com menor biomassa do que os indiv√≠duos sem herbivoria.

**Vari√°veis**

-   Vari√°veis resposta e preditoras

    -   Dataframe com as indiv√≠duos da esp√©cie de planta (unidade amostral) nas linhas e a biomassa dos frutos (vari√°vel resposta), herbivoria (vari√°vel preditora categ√≥rica) e tamanho da raiz (covari√°vel cont√≠nua) nas colunas.

**Checklist**

-   Verificar se o seu dataframe est√° com as unidades amostrais nas linhas e vari√°veis preditoras e respostas nas colunas.

### An√°lise

Olhando os dados usando a fun√ß√£o `head`

```{r}
head(dados_ancova) 
```

C√°lculo da ANCOVA.

```{r}
## Ancova
modelo_ancova <- lm(Biomassa ~ Herbivoria * Raiz, data = dados_ancova)

# Verificando as premissas da Anova.
plot_grid(plot_model(modelo_ancova, type = "diag"))
```

As premissas da anova est√£o adequadas. Vamos olhar os resultados do modelo.

```{r}
## Resultados do modelo
anova(modelo_ancova)
```

Percebam que o resultado da ANCOVA (Pr(\>F) \< 0.001) indica que tanto a herbivoria como o tamanho da raiz (covari√°vel) t√™m efeitos significativos na biomassa dos frutos. Contudo, a intera√ß√£o entre as vari√°veis n√£o foi signigicativa. Vamos usar o Likelihood ratio test (LRT) para ver se podemos seguir com um modelo mais simples (sem intera√ß√£o).

```{r}
## Criando modelo sem intera√ß√£o
modelo_ancova2 <- lm(Biomassa ~ Herbivoria + Raiz, data = dados_ancova)


## Likelihood Rate Test
lrtest(modelo_ancova, modelo_ancova2)
```

A intera√ß√£o n√£o √© importante. Seguiremos com o modelo mais simples.

Visualizar os resultados em gr√°fico.

```{r}
## Gr√°fico
ggplot(data = dados_ancova, aes(x = Raiz, y = Biomassa, fill = Herbivoria)) + 
  labs(x = "Tamanho da raiz (cm)", y = "Biomassa dos frutos (g)") +
  geom_point(size = 4, shape = 21, alpha = 0.7) +
  tema_livro() +
  scale_colour_manual(values = c("darkorange", "cyan4")) +
  scale_fill_manual(values = c("darkorange", "cyan4"),
                     labels = c("Com herbivoria", "Sem herbivoria")) +
  geom_smooth(aes(color = Herbivoria), method = "lm", show.legend = FALSE)
```

**Interpreta√ß√£o dos resultados**

Neste exemplo, o tamanho da raiz (covari√°vel) tem uma rela√ß√£o positiva com a biomassa dos frutos. Quanto maior o tamanho da raiz, maior a biomassa dos frutos. Usando a ANCOVA e controlando o efeito da covari√°vel, percebemos que a herbivoria tamb√©m afeta a biomassa dos frutos. Os indiv√≠duos com mesmo tamanho de raiz que n√£o sofreram herbivoria produziram frutos com maior biomassa do que os indiv√≠duos com herbivoria.

<p>

¬†

</p>

### Para se aprofundar

-   Recomendamos aos interessados os livros: i) Zar [-@zar_biostatistical_2010] Biostatiscal analysis; ii) Gotelli & Ellison [-@gotelli_primer_2012] A primer of ecological statistics; e iii) Quinn & Keough [-@quinn_experimental_2002] Experimental design and data analysis for biologists.

